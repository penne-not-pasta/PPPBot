import discord, helpers

sdm = [
	["vfmsub132pd:vfmsub213pd:vfmsub231pd", "    VFMSUB132PD/VFMSUB213PD/VFMSUB231PD \u2014 Fused Multiply-Subtract of Packed\n                     DoublePrecision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 9A /r                          precision floating-point \n   VFMSUB132PD xmm1, xmm2,  A     V/V       FMA      values from xmm1 and     \n   xmm3/m128                                         xmm3/mem, subtract xmm2  \n                                                     and put result in xmm1.  \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 AA /r                          precision floating-point \n   VFMSUB213PD xmm1, xmm2,  A     V/V       FMA      values from xmm1 and     \n   xmm3/m128                                         xmm2, subtract xmm3/mem  \n                                                     and put result in xmm1.  \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 BA /r                          precision floating-point \n   VFMSUB231PD xmm1, xmm2,  A     V/V       FMA      values from xmm2 and     \n   xmm3/m128                                         xmm3/mem, subtract xmm1  \n                                                     and put result in xmm1.  \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 9A /r                          precision floating-point \n   VFMSUB132PD ymm1, ymm2,  A     V/V       FMA      values from ymm1 and     \n   ymm3/m256                                         ymm3/mem, subtract ymm2  \n                                                     and put result in ymm1.  \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 AA /r                          precision floating-point \n   VFMSUB213PD ymm1, ymm2,  A     V/V       FMA      values from ymm1 and     \n   ymm3/m256                                         ymm2, subtract ymm3/mem  \n                                                     and put result in ymm1.  \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 BA /r                          precision floating-point \n   VFMSUB231PD ymm1, ymm2,  A     V/V       FMA      values from ymm2 and     \n   ymm3/m256                                         ymm3/mem, subtract ymm1  \n                                                     and put result in ymm1.S \n                                                     Multiply packed double   \n   EVEX.128.66.0F38.W1 9A                            precision floating-point \n   /r VFMSUB132PD xmm1                      AVX512VL values from xmm1 and     \n   {k1}{z}, xmm2,           B     V/V       AVX512F  xmm3/m128/m64bcst,       \n   xmm3/m128/m64bcst                                 subtract xmm2 and put    \n                                                     result in xmm1 subject   \n                                                     to writemask k1.         \n                                                     Multiply packed double   \n   EVEX.128.66.0F38.W1 AA                            precision floating-point \n   /r VFMSUB213PD xmm1                      AVX512VL values from xmm1 and     \n   {k1}{z}, xmm2,           B     V/V       AVX512F  xmm2, subtract           \n   xmm3/m128/m64bcst                                 xmm3/m128/m64bcst and    \n                                                     put result in xmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n   EVEX.128.66.0F38.W1 BA                            precision floating-point \n   /r VFMSUB231PD xmm1                      AVX512VL values from xmm2 and     \n   {k1}{z}, xmm2,           B     V/V       AVX512F  xmm3/m128/m64bcst,       \n   xmm3/m128/m64bcst                                 subtract xmm1 and put    \n                                                     result in xmm1 subject   \n                                                     to writemask k1.         \n                                                     Multiply packed double   \n   EVEX.256.66.0F38.W1 9A                            precision floating-point \n   /r VFMSUB132PD ymm1                      AVX512VL values from ymm1 and     \n   {k1}{z}, ymm2,           B     V/V       AVX512F  ymm3/m256/m64bcst,       \n   ymm3/m256/m64bcst                                 subtract ymm2 and put    \n                                                     result in ymm1 subject   \n                                                     to writemask k1.         \n                                                     Multiply packed double   \n   EVEX.256.66.0F38.W1 AA                            precision floating-point \n   /r VFMSUB213PD ymm1                      AVX512VL values from ymm1 and     \n   {k1}{z}, ymm2,           B     V/V       AVX512F  ymm2, subtract           \n   ymm3/m256/m64bcst                                 ymm3/m256/m64bcst and    \n                                                     put result in ymm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n   EVEX.256.66.0F38.W1 BA                            precision floating-point \n   /r VFMSUB231PD ymm1                      AVX512VL values from ymm2 and     \n   {k1}{z}, ymm2,           B     V/V       AVX512F  ymm3/m256/m64bcst,       \n   ymm3/m256/m64bcst                                 subtract ymm1 and put    \n                                                     result in ymm1 subject   \n                                                     to writemask k1.         \n                                                     Multiply packed double   \n   EVEX.512.66.0F38.W1 9A                            precision floating-point \n   /r VFMSUB132PD zmm1                               values from zmm1 and     \n   {k1}{z}, zmm2,           B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   zmm3/m512/m64bcst{er}                             subtract zmm2 and put    \n                                                     result in zmm1 subject   \n                                                     to writemask k1.         \n                                                     Multiply packed double   \n   EVEX.512.66.0F38.W1 AA                            precision floating-point \n   /r VFMSUB213PD zmm1                               values from zmm1 and     \n   {k1}{z}, zmm2,           B     V/V       AVX512F  zmm2, subtract           \n   zmm3/m512/m64bcst{er}                             zmm3/m512/m64bcst and    \n                                                     put result in zmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n   EVEX.512.66.0F38.W1 BA                            precision floating-point \n   /r VFMSUB231PD zmm1                               values from zmm2 and     \n   {k1}{z}, zmm2,           B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   zmm3/m512/m64bcst{er}                             subtract zmm1 and put    \n                                                     result in zmm1 subject   \n                                                     to writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a set of SIMD multiply-subtract computation on packed double\n   precision floating-point values using three source operands and writes the\n   multiply-subtract results in the destination operand. The destination\n   operand is also the first source operand. The second operand must be a\n   SIMD register. The third source operand can be a SIMD register or a memory\n   location.\n\n   VFMSUB132PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the first source operand to the two, four or\n   eight packed double precision floating-point values in the third source\n   operand. From the infinite precision intermediate result, subtracts the\n   two, four or eight packed double precision floating-point values in the\n   second source operand, performs rounding and stores the resulting two,\n   four or eight packed double precision floating-point values to the\n   destination operand (first source operand).\n\n   VFMSUB213PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source operand to the two, four or\n   eight packed double precision floating-point values in the first source\n   operand. From the infinite precision intermediate result, subtracts the\n   two, four or eight packed double precision floating-point values in the\n   third source operand, performs rounding and stores the resulting two, four\n   or eight packed double precision floating-point values to the destination\n   operand (first source operand).\n\n   VFMSUB231PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source to the two, four or eight\n   packed double precision floating-point values in the third source operand.\n   From the infinite precision intermediate result, subtracts the two, four\n   or eight packed double precision floating-point values in the first source\n   operand, performs rounding and stores the resulting two, four or eight\n   packed double precision floating-point values to the destination operand\n   (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["movddup", "           MOVDDUP \u2014 Replicate Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Move double precision      \n   F2 0F 12 /r MOVDDUP     A    V/V       SSE3     floating-point value from  \n   xmm1, xmm2/m64                                  xmm2/m64 and duplicate     \n                                                   into xmm1.                 \n                                                   Move double precision      \n   VEX.128.F2.0F.WIG 12 /r A    V/V       AVX      floating-point value from  \n   VMOVDDUP xmm1, xmm2/m64                         xmm2/m64 and duplicate     \n                                                   into xmm1.                 \n                                                   Move even index double     \n   VEX.256.F2.0F.WIG 12 /r                         precision floating-point   \n   VMOVDDUP ymm1,          A    V/V       AVX      values from ymm2/mem and   \n   ymm2/m256                                       duplicate each element     \n                                                   into ymm1.                 \n                                                   Move double precision      \n   EVEX.128.F2.0F.W1 12 /r                AVX512VL floating-point value from  \n   VMOVDDUP xmm1 {k1}{z},  B    V/V       AVX512F  xmm2/m64 and duplicate     \n   xmm2/m64                                        each element into xmm1     \n                                                   subject to writemask k1.   \n                                                   Move even index double     \n   EVEX.256.F2.0F.W1 12 /r                         precision floating-point   \n   VMOVDDUP ymm1 {k1}{z},  B    V/V       AVX512VL values from ymm2/m256 and  \n   ymm2/m256                              AVX512F  duplicate each element     \n                                                   into ymm1 subject to       \n                                                   writemask k1.              \n                                                   Move even index double     \n   EVEX.512.F2.0F.W1 12 /r                         precision floating-point   \n   VMOVDDUP zmm1 {k1}{z},  B    V/V       AVX512F  values from zmm2/m512 and  \n   zmm2/m512                                       duplicate each element     \n                                                   into zmm1 subject to       \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     MOVDDUP    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   For 256-bit or higher versions: Duplicates even-indexed double precision\n   floating-point values from the source operand (the second operand) and\n   into adjacent pair and store to the destination operand (the first\n   operand).\n\n   For 128-bit versions: Duplicates the low double precision floating-point\n   value from the source operand (the second operand) and store to the\n   destination operand (the first operand).\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register are unchanged. The source operand is XMM register or\n   a 64-bit memory location.\n\n   VEX.128 and EVEX.128 encoded version: Bits (MAXVL-1:128) of the\n   destination register are zeroed. The source operand is XMM register or a\n   64-bit memory location. The destination is updated conditionally under the\n   writemask for EVEX version.\n\n   VEX.256 and EVEX.256 encoded version: Bits (MAXVL-1:256) of the\n   destination register are zeroed. The source operand is YMM register or a\n   256-bit memory location. The destination is updated conditionally under\n   the write-mask for EVEX version.\n\n   EVEX.512 encoded version: The destination is updated according to the\n   writemask. The source operand is ZMM register or a 512-bit memory\n   location.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   X3 X2 X1 X0 SRC DEST X2 X2 X0 X0 Figure 4-2. VMOVDDUP Operation\n"],
	["and", "                               AND \u2014 Logical AND\n\n   Opcode   Instruction    Op/En 64-bit Compat/Leg Description                \n                                 Mode   Mode       \n   24 ib    AND AL, imm8   I     Valid  Valid      AL AND imm8.               \n   25 iw    AND AX, imm16  I     Valid  Valid      AX AND imm16.              \n   25 id    AND EAX, imm32 I     Valid  Valid      EAX AND imm32.             \n   REX.W +  AND RAX, imm32 I     Valid  N.E.       RAX AND imm32              \n   25 id                                           sign-extended to 64-bits.  \n   80 /4 ib AND r/m8, imm8 MI    Valid  Valid      r/m8 AND imm8.             \n   REX + 80 AND r/m8^*,    MI    Valid  N.E.       r/m8 AND imm8.             \n   /4 ib    imm8           \n   81 /4 iw AND r/m16,     MI    Valid  Valid      r/m16 AND imm16.           \n            imm16          \n   81 /4 id AND r/m32,     MI    Valid  Valid      r/m32 AND imm32.           \n            imm32          \n   REX.W +  AND r/m64,     MI    Valid  N.E.       r/m64 AND imm32 sign       \n   81 /4 id imm32                                  extended to 64-bits.       \n   83 /4 ib AND r/m16,     MI    Valid  Valid      r/m16 AND imm8             \n            imm8                                   (sign-extended).           \n   83 /4 ib AND r/m32,     MI    Valid  Valid      r/m32 AND imm8             \n            imm8                                   (sign-extended).           \n   REX.W +  AND r/m64,     MI    Valid  N.E.       r/m64 AND imm8             \n   83 /4 ib imm8                                   (sign-extended).           \n   20 /r    AND r/m8, r8   MR    Valid  Valid      r/m8 AND r8.               \n   REX + 20 AND r/m8^*,    MR    Valid  N.E.       r/m64 AND r8               \n   /r       r8^*                                   (sign-extended).           \n   21 /r    AND r/m16, r16 MR    Valid  Valid      r/m16 AND r16.             \n   21 /r    AND r/m32, r32 MR    Valid  Valid      r/m32 AND r32.             \n   REX.W +  AND r/m64, r64 MR    Valid  N.E.       r/m64 AND r32.             \n   21 /r    \n   22 /r    AND r8, r/m8   RM    Valid  Valid      r8 AND r/m8.               \n   REX + 22 AND r8^*,      RM    Valid  N.E.       r/m64 AND r8               \n   /r       r/m8^*                                 (sign-extended).           \n   23 /r    AND r16, r/m16 RM    Valid  Valid      r16 AND r/m16.             \n   23 /r    AND r32, r/m32 RM    Valid  Valid      r32 AND r/m32.             \n   REX.W +  AND r64, r/m64 RM    Valid  N.E.       r64 AND r/m64.             \n   23 /r    \n\n     *In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8/16/32    N/A       N/A       \n   I     AL/AX/EAX/RAX    imm8/16/32    N/A       N/A       \n\nDescription \u00b6\n\n   Performs a bitwise AND operation on the destination (first) and source\n   (second) operands and stores the result in the destination operand\n   location. The source operand can be an immediate, a register, or a memory\n   location; the destination operand can be a register or a memory location.\n   (However, two memory operands cannot be used in one instruction.) Each bit\n   of the result is set to 1 if both corresponding bits of the first and\n   second operands are 1; otherwise, it is set to 0.\n\n   This instruction can be used with a LOCK prefix to allow the it to be\n   executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The OF and CF flags are cleared; the SF, ZF, and PF flags are set\n   according to the result. The state of the AF flag is undefined.\n"],
	["fstenv:fnstenv", "                   FSTENV/FNSTENV \u2014 Store x87 FPU Environment\n\n   Opcode   Instruction 64-Bit Compat/Leg Description                         \n                        Mode   Mode       \n                                          Store FPU environment to m14byte or \n            FSTENV                        m28byte after checking for pending  \n   9B D9 /6 m14/28byte  Valid  Valid      unmasked floating-point exceptions. \n                                          Then mask all floating-point        \n                                          exceptions.                         \n                                          Store FPU environment to m14byte or \n            FNSTENV^1                     m28byte without checking for        \n   D9 /6    m14/28byte  Valid  Valid      pending unmasked floating-point     \n                                          exceptions. Then mask all           \n                                          floating-point exceptions.          \n\n     1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Saves the current FPU operating environment at the memory location\n   specified with the destination operand, and then masks all floating-point\n   exceptions. The FPU operating environment consists of the FPU control\n   word, status word, tag word, instruction pointer, data pointer, and last\n   opcode. Figures 8-9 through 8-12 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, show the layout in memory of the\n   stored environment, depending on the operating mode of the processor\n   (protected or real) and the current operand-size attribute (16-bit or\n   32-bit). In virtual-8086 mode, the real mode layouts are used.\n\n   The FSTENV instruction checks for and handles any pending unmasked\n   floating-point exceptions before storing the FPU environment; the FNSTENV\n   instruction does not. The saved image reflects the state of the FPU after\n   all floating-point instructions preceding the FSTENV/FNSTENV instruction\n   in the instruction stream have been executed.\n\n   These instructions are often used by exception handlers because they\n   provide access to the FPU instruction and data pointers. The environment\n   is typically saved in the stack. Masking all exceptions after saving the\n   environment prevents floating-point exceptions from interrupting the\n   exception handler.\n\n   The assembler issues two instructions for the FSTENV instruction (an FWAIT\n   instruction followed by an FNSTENV instruction), and the processor\n   executes each of these instructions separately. If an exception is\n   generated for either of these instructions, the save EIP points to the\n   instruction that caused the exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   When operating a Pentium or Intel486 processor in MS-DOS compatibility\n   mode, it is possible (under unusual circumstances) for an FNSTENV\n   instruction to be interrupted prior to being executed to handle a pending\n   FPU exception. See the section titled \u201cNo-Wait FPU Instructions Can Get\n   FPU Interrupt in Window\u201d in Appendix D of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a description of\n   these circumstances. An FNSTENV instruction cannot be interrupted in this\n   way on later Intel processors, except for the Intel Quark^TM X1000\n   processor.\n\nFPU Flags Affected \u00b6\n\n   The C0, C1, C2, and C3 are undefined.\n"],
	["vmlaunch:vmresume", "               VMLAUNCH/VMRESUME \u2014 Launch/Resume Virtual Machine\n\n   Opcode/Instruction Op/En Description                                     \n   0F 01 C2 VMLAUNCH  ZO    Launch virtual machine managed by current VMCS. \n   0F 01 C3 VMRESUME  ZO    Resume virtual machine managed by current VMCS. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    NA        NA        NA        NA        \n\nDescription \u00b6\n\n   Effects a VM entry managed by the current VMCS.\n\n     * VMLAUNCH fails if the launch state of current VMCS is not \u201cclear\u201d. If\n       the instruction is successful, it sets the launch state to \u201claunched.\u201d\n     * VMRESUME fails if the launch state of the current VMCS is not\n       \u201claunched.\u201d\n\n   If VM entry is attempted, the logical processor performs a series of\n   consistency checks as detailed in Chapter 27, \u201cVM Entries.\u201d Failure to\n   pass checks on the VMX controls or on the host-state area passes control\n   to the instruction following the VMLAUNCH or VMRESUME instruction. If\n   these pass but checks on the guest-state area fail, the logical processor\n   loads state from the host-state area of the VMCS, passing control to the\n   instruction referenced by the RIP field in the host-state area.\n\n   VM entry is not allowed when events are blocked by MOV SS or POP SS.\n   Neither VMLAUNCH nor VMRESUME should be used immediately after either MOV\n   to SS or POP to SS.\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["vcvttpd2uqq", "  VCVTTPD2UQQ \u2014 Convert With Truncation Packed Double Precision Floating-Point\n                   Values toPacked Unsigned Quadword Integers\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Convert two packed      \n                                                      double precision        \n   EVEX.128.66.0F.W1 78 /r                            floating-point values   \n   VCVTTPD2UQQ xmm1 {k1}{z}, A     V/V       AVX512VL from xmm2/m128/m64bcst  \n   xmm2/m128/m64bcst                         AVX512DQ to two packed unsigned  \n                                                      quadword integers in    \n                                                      xmm1 using truncation   \n                                                      with writemask k1.      \n                                                      Convert four packed     \n                                                      double precision        \n   EVEX.256.66.0F.W1 78 /r                            floating-point values   \n   VCVTTPD2UQQ ymm1 {k1}{z}, A     V/V       AVX512VL from ymm2/m256/m64bcst  \n   ymm2/m256/m64bcst                         AVX512DQ to four packed unsigned \n                                                      quadword integers in    \n                                                      ymm1 using truncation   \n                                                      with writemask k1.      \n                                                      Convert eight packed    \n                                                      double precision        \n   EVEX.512.66.0F.W1 78 /r                            floating-point values   \n   VCVTTPD2UQQ zmm1 {k1}{z}, A     V/V       AVX512DQ from zmm2/mem to eight  \n   zmm2/m512/m64bcst{sae}                             packed unsigned         \n                                                      quadword integers in    \n                                                      zmm1 using truncation   \n                                                      with writemask k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation packed double precision floating-point values in\n   the source operand (second operand) to packed unsigned quadword integers\n   in the destination operand (first operand).\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register or a\n   512/256/128-bit memory location. The destination operation is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["vmulph", "                      VMULPH \u2014 Multiply Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   bit Mode Flag 64/32 CPUID       \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Multiply packed FP16 \n                                                         values from          \n   EVEX.128.NP.MAP5.W0 59 /r                 AVX512-FP16 xmm3/m128/m16bcst to \n   VMULPH xmm1{k1}{z}, xmm2,       A V/V     AVX512VL    xmm2 and store the   \n   xmm3/m128/m16bcst                                     result in xmm1       \n                                                         subject to writemask \n                                                         k1.                  \n                                                         Multiply packed FP16 \n                                                         values from          \n   EVEX.256.NP.MAP5.W0 59 /r                 AVX512-FP16 ymm3/m256/m16bcst to \n   VMULPH ymm1{k1}{z}, ymm2,       A V/V     AVX512VL    ymm2 and store the   \n   ymm3/m256/m16bcst                                     result in ymm1       \n                                                         subject to writemask \n                                                         k1.                  \n                                                         Multiply packed FP16 \n                                                         values in            \n   EVEX.512.NP.MAP5.W0 59 /r                             zmm3/m512/m16bcst    \n   VMULPH zmm1{k1}{z}, zmm2,       A V/V     AVX512-FP16 with zmm2 and store  \n   zmm3/m512/m16bcst {er}                                the result in zmm1   \n                                                         subject to writemask \n                                                         k1.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction multiplies packed FP16 values from source operands and\n   stores the packed FP16 result in the destination operand. The destination\n   elements are updated according to the writemask.\n"],
	["vptestmb:vptestmw:vptestmd:vptestmq", "         VPTESTMB/VPTESTMW/VPTESTMD/VPTESTMQ \u2014 Logical AND and Set Mask\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Bitwise AND of packed     \n                                                    byte integers in xmm2 and \n   EVEX.128.66.0F38.W0 26                           xmm3/m128 and set mask k2 \n   /r VPTESTMB k2 {k1},    A     V/V       AVX512VL to reflect the            \n   xmm2, xmm3/m128                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    byte integers in ymm2 and \n   EVEX.256.66.0F38.W0 26                           ymm3/m256 and set mask k2 \n   /r VPTESTMB k2 {k1},    A     V/V       AVX512VL to reflect the            \n   ymm2, ymm3/m256                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    byte integers in zmm2 and \n   EVEX.512.66.0F38.W0 26                           zmm3/m512 and set mask k2 \n   /r VPTESTMB k2 {k1},    A     V/V       AVX512BW to reflect the            \n   zmm2, zmm3/m512                                  zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    word integers in xmm2 and \n   EVEX.128.66.0F38.W1 26                           xmm3/m128 and set mask k2 \n   /r VPTESTMW k2 {k1},    A     V/V       AVX512VL to reflect the            \n   xmm2, xmm3/m128                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    word integers in ymm2 and \n   EVEX.256.66.0F38.W1 26                           ymm3/m256 and set mask k2 \n   /r VPTESTMW k2 {k1},    A     V/V       AVX512VL to reflect the            \n   ymm2, ymm3/m256                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    word integers in zmm2 and \n   EVEX.512.66.0F38.W1 26                           zmm3/m512 and set mask k2 \n   /r VPTESTMW k2 {k1},    A     V/V       AVX512BW to reflect the            \n   zmm2, zmm3/m512                                  zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    doubleword integers in    \n                                                    xmm2 and                  \n   EVEX.128.66.0F38.W0 27                  AVX512VL xmm3/m128/m32bcst and set \n   /r VPTESTMD k2 {k1},    B     V/V       AVX512F  mask k2 to reflect the    \n   xmm2, xmm3/m128/m32bcst                          zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    doubleword integers in    \n                                                    ymm2 and                  \n   EVEX.256.66.0F38.W0 27                  AVX512VL ymm3/m256/m32bcst and set \n   /r VPTESTMD k2 {k1},    B     V/V       AVX512F  mask k2 to reflect the    \n   ymm2, ymm3/m256/m32bcst                          zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    doubleword integers in    \n                                                    zmm2 and                  \n   EVEX.512.66.0F38.W0 27                           zmm3/m512/m32bcst and set \n   /r VPTESTMD k2 {k1},    B     V/V       AVX512F  mask k2 to reflect the    \n   zmm2, zmm3/m512/m32bcst                          zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    quadword integers in xmm2 \n   EVEX.128.66.0F38.W1 27                           and xmm3/m128/m64bcst and \n   /r VPTESTMQ k2 {k1},    B     V/V       AVX512VL set mask k2 to reflect    \n   xmm2, xmm3/m128/m64bcst                 AVX512F  the zero/non-zero status  \n                                                    of each element of the    \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    quadword integers in ymm2 \n   EVEX.256.66.0F38.W1 27                           and ymm3/m256/m64bcst and \n   /r VPTESTMQ k2 {k1},    B     V/V       AVX512VL set mask k2 to reflect    \n   ymm2, ymm3/m256/m64bcst                 AVX512F  the zero/non-zero status  \n                                                    of each element of the    \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise AND of packed     \n                                                    quadword integers in zmm2 \n   EVEX.512.66.0F38.W1 27                           and zmm3/m512/m64bcst and \n   /r VPTESTMQ k2 {k1},    B     V/V       AVX512F  set mask k2 to reflect    \n   zmm2, zmm3/m512/m64bcst                          the zero/non-zero status  \n                                                    of each element of the    \n                                                    result, under writemask   \n                                                    k1.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a bitwise logical AND operation on the first source operand (the\n   second operand) and second source operand (the third operand) and stores\n   the result in the destination operand (the first operand) under the\n   write-mask. Each bit of the result is set to 1 if the bitwise AND of the\n   corresponding elements of the first and second src operands is non-zero;\n   otherwise it is set to 0.\n\n   VPTESTMD/VPTESTMQ: The first source operand is a ZMM/YMM/XMM register. The\n   second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is a mask register updated under\n   the writemask.\n\n   VPTESTMB/VPTESTMW: The first source operand is a ZMM/YMM/XMM register. The\n   second source operand can be a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location. The destination operand is a mask register updated under\n   the writemask.\n"],
	["vcvttsh2usi", "  VCVTTSH2USI \u2014 Convert with Truncation Low FP16 Value to an Unsigned Integer\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode    \n   Flag Support 64/32 CPUID Feature   \n   Instruction En Bit Mode Flag CPUID \n   Feature Instruction En Bit Mode    \n   Flag Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag 64/32 \n   CPUID Feature Instruction En Bit   \n   Mode Flag CPUID Feature            \n   Instruction En Bit Mode Flag Op/   \n   64/32 CPUID Feature                \n                                                            Convert FP16      \n                                                            value in the low  \n                                                            element of        \n   EVEX.LLIG.F3.MAP5.W0 78 /r         A V/V^1   AVX512-FP16 xmm1/m16 to an    \n   VCVTTSH2USI r32, xmm1/m16 {sae}                          unsigned integer  \n                                                            and store the     \n                                                            result in r32     \n                                                            using truncation. \n                                                            Convert FP16      \n                                                            value in the low  \n                                                            element of        \n   EVEX.LLIG.F3.MAP5.W1 78 /r         A V/N.E.  AVX512-FP16 xmm1/m16 to an    \n   VCVTTSH2USI r64, xmm1/m16 {sae}                          unsigned integer  \n                                                            and store the     \n                                                            result in r64     \n                                                            using truncation. \n\n     1. Outside of 64b mode, the EVEX.W field is ignored. The instruction\n     behaves as if W=0 was used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP16 element in the source operand to an\n   unsigned integer in the destination general purpose register.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer indefinite value is returned.\n"],
	["vsqrtsh", "               VSQRTSH \u2014 Compute Square Root of Scalar FP16 Value\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En bit Mode Flag     \n   CPUID Feature Instruction En bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En bit Mode Flag     \n   CPUID Feature Instruction En bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Compute square root \n                                                          of the low FP16     \n                                                          value in xmm3/m16   \n   EVEX.LLIG.F3.MAP5.W0 51 /r                             and store the       \n   VSQRTSH xmm1{k1}{z}, xmm2,       A V/V     AVX512-FP16 result in xmm1      \n   xmm3/m16 {er}                                          subject to          \n                                                          writemask k1. Bits  \n                                                          127:16 from xmm2    \n                                                          are copied to       \n                                                          xmm1[127:16].       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a scalar FP16 square-root computation on the\n   source operand and stores the FP16 result in the destination operand. Bits\n   127:16 of the destination operand are copied from the corresponding bits\n   of the first source operand. Bits MAXVL-1:128 of the destination operand\n   are zeroed. The low FP16 element of the destination is updated according\n   to the writemask.\n"],
	["fyl2x", "                           FYL2X \u2014 Compute y \u2217 log2x\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Replace ST(1) with (ST(1) \u2217 \n   D9 F1  FYL2X       Valid       Valid           log_2ST(0)) and pop the     \n                                                  register stack.             \n\nDescription \u00b6\n\n   Computes (ST(1) \u2217 log_2 (ST(0))), stores the result in register ST(1), and\n   pops the FPU register stack. The source operand in ST(0) must be a\n   non-zero positive number.\n\n   The following table shows the results obtained when taking the log of\n   various classes of numbers, assuming that neither overflow nor underflow\n   occurs.\n\n   ST(0) \n             \u2212\u221e  \u2212F  \u00b10  +0<+F<+1 +1  +F>+1 +\u221e  NaN \n         \u2212\u221e  *   *   +\u221e  +\u221e       *   \u2212\u221e    \u2212\u221e  NaN \n         \u2212F  *   *   **  +F       \u22120  \u2212F    \u2212\u221e  NaN \n   ST(1) \u22120  *   *   *   +0       \u22120  \u22120    *   NaN \n         +0  *   *   *   \u22120       +0  +0    *   NaN \n         +F  *   *   **  \u2212F       +0  +F    +\u221e  NaN \n         +\u221e  *   *   \u2212\u221e  \u2212\u221e       *   +\u221e    +\u221e  NaN \n         NaN NaN NaN NaN NaN      NaN NaN   NaN NaN \n\n   Table 3-48. FYL2X Results\n\n     F Means finite floating-point value.\n\n     * Indicatesfloating-pointinvalid-operation(#IA)exception.\n\n     ** Indicates floating-point zero-divide (#Z) exception.\n\n   If the divide-by-zero exception is masked and register ST(0) contains \u00b10,\n   the instruction returns \u221e with a sign that is the opposite of the sign of\n   the source operand in register ST(1).\n\n   The FYL2X instruction is designed with a built-in multiplication to\n   optimize the calculation of logarithms with an arbitrary positive base\n   (b):\n\n   log_bx := (log_2b)^\u20131 \u2217 log_2x\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["fxam", "                         FXAM \u2014 Examine Floating-Point\n\n   Opcode  Mode Leg Mode Description                        \n   D9 E5                 Classify value or number in ST(0). \n\nDescription \u00b6\n\n   Examines the contents of the ST(0) register and sets the condition code\n   flags C0, C2, and C3 in the FPU status word to indicate the class of value\n   or number in the register (see the table below).\n\n   Class                C3 C2 C0 \n   Unsupported          0  0  0  \n   NaN                  0  0  1  \n   Normal finite number 0  1  0  \n   Infinity             0  1  1  \n   Zero                 1  0  0  \n   Empty                1  0  1  \n   Denormal number      1  1  0  \n\n   Table 3-42. FXAM Results .\n\n   The C1 flag is set to the sign of the value in ST(0), regardless of\n   whether the register is empty or full.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Sign of value in ST(0). \n   C0, C2, C3 See Table 3-42.         \n"],
	["unpcklpd", "  UNPCKLPD \u2014 Unpack and Interleave Low Packed Double Precision Floating-Point\n                                     Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Unpacks and Interleaves    \n   66 0F 14 /r UNPCKLPD                            double precision           \n   xmm1, xmm2/m128         A    V/V       SSE2     floating-point values from \n                                                   low quadwords of xmm1 and  \n                                                   xmm2/m128.                 \n                                                   Unpacks and Interleaves    \n   VEX.128.66.0F.WIG 14 /r                         double precision           \n   VUNPCKLPD xmm1,xmm2,    B    V/V       AVX      floating-point values from \n   xmm3/m128                                       low quadwords of xmm2 and  \n                                                   xmm3/m128.                 \n                                                   Unpacks and Interleaves    \n   VEX.256.66.0F.WIG 14 /r                         double precision           \n   VUNPCKLPD ymm1,ymm2,    B    V/V       AVX      floating-point values from \n   ymm3/m256                                       low quadwords of ymm2 and  \n                                                   ymm3/m256.                 \n                                                   Unpacks and Interleaves    \n   EVEX.128.66.0F.W1 14 /r                         double precision           \n   VUNPCKLPD xmm1 {k1}{z}, C    V/V       AVX512VL floating-point values from \n   xmm2, xmm3/m128/m64bcst                AVX512F  low quadwords of xmm2 and  \n                                                   xmm3/m128/m64bcst subject  \n                                                   to write mask k1.          \n                                                   Unpacks and Interleaves    \n   EVEX.256.66.0F.W1 14 /r                         double precision           \n   VUNPCKLPD ymm1 {k1}{z}, C    V/V       AVX512VL floating-point values from \n   ymm2, ymm3/m256/m64bcst                AVX512F  low quadwords of ymm2 and  \n                                                   ymm3/m256/m64bcst subject  \n                                                   to write mask k1.          \n                                                   Unpacks and Interleaves    \n   EVEX.512.66.0F.W1 14 /r                         double precision           \n   VUNPCKLPD zmm1 {k1}{z}, C    V/V       AVX512F  floating-point values from \n   zmm2, zmm3/m512/m64bcst                         low quadwords of zmm2 and  \n                                                   zmm3/m512/m64bcst subject  \n                                                   to write mask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs an interleaved unpack of the low double precision floating-point\n   values from the first source operand and the second source operand.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified. When unpacking from a memory\n   operand, an implementation may fetch only the appropriate 64 bits;\n   however, alignment to 16-byte boundary and normal segment checking will\n   still be enforced.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand is a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register, a 256-bit memory location, or a\n   256-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a YMM register, conditionally updated using writemask k1.\n\n   EVEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is a XMM register, a 128-bit memory location, or a\n   128-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a XMM register, conditionally updated using writemask k1.\n"],
	["vdivsh", "                       VDIVSH \u2014 Divide Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En Bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Divide low FP16     \n                                                          value in xmm2 by    \n                                                          low FP16 value in   \n   EVEX.LLIG.F3.MAP5.W0 5E /r                             xmm3/m16, and store \n   VDIVSH xmm1{k1}{z}, xmm2,        A V/V     AVX512-FP16 the result in xmm1  \n   xmm3/m16 {er}                                          subject to          \n                                                          writemask k1. Bits  \n                                                          127:16 of xmm2 are  \n                                                          copied to           \n                                                          xmm1[127:16].       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction divides the low FP16 value from the first source operand\n   by the corresponding value in the second source operand, storing the FP16\n   result in the destination operand. Bits 127:16 of the destination operand\n   are copied from the corresponding bits of the first source operand. Bits\n   MAXVL-1:128 of the destination operand are zeroed. The low FP16 element of\n   the destination is updated according to the writemask.\n"],
	["clrssbsy", "         CLRSSBSY \u2014 Clear Busy Flag in a Supervisor Shadow Stack Token\n\n                        Op / 64/32 bit    CPUID                               \n   Opcode/Instruction   En   Mode Support Feature Description\n                                          Flag    \n   F3 0F AE /6 CLRSSBSY                           Clear busy flag in          \n   m64                  M    V/V          CET_SS  supervisor shadow stack     \n                                                  token reference by m64.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2 Operand 3 Operand 4 \n   M     N/A        ModRM:r/m (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Clear busy flag in supervisor shadow stack token reference by m64.\n   Subsequent to marking the shadow stack as not busy the SSP is loaded with\n   value 0.\n\nFlags Affected \u00b6\n\n   CF is set if an invalid token was detected, else it is cleared. ZF, PF,\n   AF, OF, and SF are cleared.\n"],
	["clc", "                             CLC \u2014 Clear Carry Flag\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description    \n   F8     CLC         ZO    Valid       Valid           Clear CF flag. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Clears the CF flag in the EFLAGS register. Operation is the same in all\n   modes.\n\nFlags Affected \u00b6\n\n   The CF flag is set to 0. The OF, ZF, SF, AF, and PF flags are unaffected.\n"],
	["sysexit", "                  SYSEXIT \u2014 Fast Return from Fast System Call\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   0F 35      SYSEXIT     ZO    Valid  Valid      Fast return to privilege    \n                                                  level 3 user code.          \n   REX.W + 0F                                     Fast return to 64-bit mode  \n   35         SYSEXIT     ZO    Valid  Valid      privilege level 3 user      \n                                                  code.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Executes a fast return to privilege level 3 user code. SYSEXIT is a\n   companion instruction to the SYSENTER instruction. The instruction is\n   optimized to provide the maximum performance for returns from system\n   procedures executing at protections levels 0 to user procedures executing\n   at protection level 3. It must be executed from code executing at\n   privilege level 0.\n\n   With a 64-bit operand size, SYSEXIT remains in 64-bit mode; otherwise, it\n   either enters compatibility mode (if the logical processor is in IA-32e\n   mode) or remains in protected mode (if it is not).\n\n   Prior to executing SYSEXIT, software must specify the privilege level 3\n   code segment and code entry point, and the privilege level 3 stack segment\n   and stack pointer by writing values into the following MSR and\n   general-purpose registers:\n\n     * IA32_SYSENTER_CS (MSR address 174H) \u2014 Contains a 32-bit value that is\n       used to determine the segment selectors for the privilege level 3 code\n       and stack segments (see the Operation section)\n     * RDX \u2014 The canonical address in this register is loaded into RIP (thus,\n       this value references the first instruction to be executed in the user\n       code). If the return is not to 64-bit mode, only bits 31:0 are loaded.\n     * ECX \u2014 The canonical address in this register is loaded into RSP (thus,\n       this value contains the stack pointer for the privilege level 3\n       stack). If the return is not to 64-bit mode, only bits 31:0 are\n       loaded.\n\n   The IA32_SYSENTER_CS MSR can be read from and written to using RDMSR and\n   WRMSR.\n\n   While SYSEXIT loads the CS and SS selectors with values derived from the\n   IA32_SYSENTER_CS MSR, the CS and SS descriptor caches are not loaded from\n   the descriptors (in GDT or LDT) referenced by those selectors. Instead,\n   the descriptor caches are loaded with fixed values. See the Operation\n   section for details. It is the responsibility of OS software to ensure\n   that the descriptors (in GDT or LDT) referenced by those selector values\n   correspond to the fixed values loaded into the descriptor caches; the\n   SYSEXIT instruction does not ensure this correspondence.\n\n   The SYSEXIT instruction can be invoked from all operating modes except\n   real-address mode and virtual-8086 mode.\n\n   The SYSENTER and SYSEXIT instructions were introduced into the IA-32\n   architecture in the Pentium II processor. The availability of these\n   instructions on a processor is indicated with the SYSENTER/SYSEXIT present\n   (SEP) feature flag returned to the EDX register by the CPUID instruction.\n   An operating system that qualifies the SEP flag must also qualify the\n   processor family and model to ensure that the SYSENTER/SYSEXIT\n   instructions are actually present. For example:\n\n   IF CPUID SEP bit is set\n\n   THEN IF (Family = 6) and (Model < 3) and (Stepping < 3)\n\n   THEN\n\n   SYSENTER/SYSEXIT_Not_Supported; FI;\n\n   ELSE\n\n   SYSENTER/SYSEXIT_Supported; FI;\n\n   FI;\n\n   When the CPUID instruction is executed on the Pentium Pro processor (model\n   1), the processor returns a the SEP flag as set, but does not support the\n   SYSENTER/SYSEXIT instructions.\n\n   When shadow stacks are enabled at privilege level 3 the instruction loads\n   SSP with value from IA32_PL3_SSP MSR. Refer to Chapter 6, \u201cInterrupt and\n   Exception Handling\u201a\u201d and Chapter 17, \u201cControl-flow Enforcement Technology\n   (CET)\u201a\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1, for additional CET details.\n\n   Instruction ordering. Instructions following a SYSEXIT may be fetched from\n   memory before earlier instructions complete execution, but they will not\n   execute (even speculatively) until all instructions prior to the SYSEXIT\n   have completed execution (the later instructions may execute before data\n   stored by the earlier instructions have become globally visible).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["enclu", "       ENCLU \u2014 Execute an Enclave User Function of Specified Leaf Number\n\n   Opcode/Instruction Op/En 64/32 bit    CPUID        Description             \n                            Mode Support Feature Flag \n                                                      This instruction is     \n   NP 0F 01 D7 ENCLU  ZO    V/V          NA           used to execute         \n                                                      non-privileged Intel    \n                                                      SGX leaf functions.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Implicit Register Operands \n   ZO    NA        NA        NA        See Section 38.4           \n\n  Description \u00b6\n\n   The ENCLU instruction invokes the specified non-privileged Intel SGX leaf\n   functions. Software specifies the leaf function by setting the appropriate\n   value in the register EAX as input. The registers RBX, RCX, and RDX have\n   leaf-specific purpose, and may act as input, as output, or may be unused.\n   In 64-bit mode, the instruction ignores upper 32 bits of the RAX register.\n\n   The ENCLU instruction produces an invalid-opcode exception (#UD) if CR0.PE\n   = 0 or RFLAGS.VM = 1, or if it is executed in system-management mode\n   (SMM). Additionally, any attempt to execute this instruction when CPL < 3\n   results in #UD. The instruction produces a general-protection exception\n   (#GP) if either CR0.PG or CR0.NE is 0, or if an attempt is made to invoke\n   an undefined leaf function. The ENCLU instruction produces a device not\n   available exception (#NM) if CR0.TS = 1.\n\n   Addresses and operands are 32 bits outside 64-bit mode (IA32_EFER.LMA = 0\n   or CS.L = 0) and are 64 bits in 64-bit mode (IA32_EFER.LMA = 1 and CS.L =\n   1). CS.D value has no impact on address calculation. The DS segment is\n   used to create linear addresses.\n\n   Segment override prefixes and address-size override prefixes are ignored,\n   as is the REX prefix in 64-bit mode.\n\n  Flags Affected \u00b6\n\n   See individual leaf functions\n"],
	["tdpbf16ps", " TDPBF16PS \u2014 Dot Product of BF16 Tiles Accumulated into Packed Single Precision\n                                      Tile\n\n                               64/32 bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature  Description\n                               Support   Flag     \n                                                  Matrix multiply BF16        \n   VEX.128.F3.0F38.W0 5C                          elements from tmm2 and      \n   11:rrr:bbb TDPBF16PS  A     V/N.E.    AMX-BF16 tmm3, and accumulate the    \n   tmm1, tmm2, tmm3                               packed single precision     \n                                                  elements in tmm1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3    Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) VEX.vvvv (r) N/A       \n\nDescription \u00b6\n\n   This instruction performs a set of SIMD dot-products of two BF16 elements\n   and accumulates the results into a packed single precision tile. Each\n   dword element in input tiles tmm2 and tmm3 is interpreted as a BF16 pair.\n   For each possible combination of (row of tmm2, column of tmm3), the\n   instruction performs a set of SIMD dot-products on all corresponding BF16\n   pairs (one pair from tmm2 and one pair from tmm3), adds the results of\n   those dot-products, and then accumulates the result into the corresponding\n   row and column of tmm1.\n\n   \u201cRound to nearest even\u201d rounding mode is used when doing each accumulation\n   of the FMA. Output denormals are always flushed to zero and input\n   denormals are always treated as zero. MXCSR is not consulted nor updated.\n\n   Any attempt to execute the TDPBF16PS instruction inside a TSX transaction\n   will result in a transaction abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["stac", "                     STAC \u2014 Set AC Flag in EFLAGS Register\n\n   Opcode/Instruction Op / 64/32 bit Mode CPUID        Description            \n                      En   Support        Feature Flag \n   NP 0F 01 CB STAC   ZO   V/V            SMAP         Set the AC flag in the \n                                                       EFLAGS register.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Sets the AC flag bit in EFLAGS register. This may enable alignment\n   checking of user-mode data accesses. This allows explicit supervisor-mode\n   data accesses to user-mode pages even if the SMAP bit is set in the CR4\n   register.\n\n   This instruction's operation is the same in non-64-bit modes and 64-bit\n   mode. Attempts to execute STAC when CPL > 0 cause #UD.\n\nFlags Affected \u00b6\n\n   AC set. Other flags are unaffected.\n"],
	["vsubph", "                      VSUBPH \u2014 Subtract Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   bit Mode Flag 64/32 CPUID       \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Subtract packed FP16 \n                                                         values from          \n   EVEX.128.NP.MAP5.W0 5C /r                 AVX512-FP16 xmm3/m128/m16bcst to \n   VSUBPH xmm1{k1}{z}, xmm2,       A V/V     AVX512VL    xmm2, and store the  \n   xmm3/m128/m16bcst                                     result in xmm1       \n                                                         subject to writemask \n                                                         k1.                  \n                                                         Subtract packed FP16 \n                                                         values from          \n   EVEX.256.NP.MAP5.W0 5C /r                 AVX512-FP16 ymm3/m256/m16bcst to \n   VSUBPH ymm1{k1}{z}, ymm2,       A V/V     AVX512VL    ymm2, and store the  \n   ymm3/m256/m16bcst                                     result in ymm1       \n                                                         subject to writemask \n                                                         k1.                  \n                                                         Subtract packed FP16 \n                                                         values from          \n   EVEX.512.NP.MAP5.W0 5C /r                             zmm3/m512/m16bcst to \n   VSUBPH zmm1{k1}{z}, zmm2,       A V/V     AVX512-FP16 zmm2, and store the  \n   zmm3/m512/m16bcst {er}                                result in zmm1       \n                                                         subject to writemask \n                                                         k1.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction subtracts packed FP16 values from second source operand\n   from the corresponding elements in the first source operand, storing the\n   packed FP16 result in the destination operand. The destination elements\n   are updated according to the writemask.\n"],
	["sti", "                            STI \u2014 Set Interrupt Flag\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Description                \n                                        Mode       \n                                                   Set interrupt flag;        \n                                                   external, maskable         \n   FB     STI         ZO    Valid       Valid      interrupts enabled at the  \n                                                   end of the next            \n                                                   instruction.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   In most cases, STI sets the interrupt flag (IF) in the EFLAGS register.\n   This allows the processor to respond to maskable hardware interrupts.\n\n   If IF = 0, maskable hardware interrupts remain inhibited on the\n   instruction boundary following an execution of STI. (The delayed effect of\n   this instruction is provided to allow interrupts to be enabled just before\n   returning from a procedure or subroutine. For instance, if an STI\n   instruction is followed by an RET instruction, the RET instruction is\n   allowed to execute before external interrupts are recognized. No\n   interrupts can be recognized if an execution of CLI immediately follow\n   such an execution of STI.) The inhibition ends after delivery of another\n   event (e.g., exception) or the execution of the next instruction.\n\n   The IF flag and the STI and CLI instructions do not prohibit the\n   generation of exceptions and nonmaskable interrupts (NMIs). However, NMIs\n   (and system-management interrupts) may be inhibited on the instruction\n   boundary following an execution of STI that begins with IF = 0.\n\n   Operation is different in two modes defined as follows:\n\n     * PVI mode (protected-mode virtual interrupts): CR0.PE = 1, EFLAGS.VM =\n       0, CPL = 3, and CR4.PVI = 1;\n     * VME mode (virtual-8086 mode extensions): CR0.PE = 1, EFLAGS.VM = 1,\n       and CR4.VME = 1.\n\n   If IOPL < 3, EFLAGS.VIP = 1, and either VME mode or PVI mode is active,\n   STI sets the VIF flag in the EFLAGS register, leaving IF unaffected.\n\n   Table 4-19 indicates the action of the STI instruction depending on the\n   processor operating mode, IOPL, CPL, and EFLAGS.VIP.\n\n   Mode                    IOPL  EFLAGS.VIP STI Result \n   Real-address            _X^1  X          IF = 1     \n   Protected, not PVI^2    \u2265 CPL X          IF = 1     \n                           < CPL X          #GP fault  \n                           3     X          IF = 1     \n   Protected, PVI^3        0\u20132   0          VIF = 1    \n                                 1          #GP fault  \n   Virtual-8086, not VME^3 3     X          IF = 1     \n                           0\u20132   X          #GP fault  \n                           3     X          IF = 1     \n   Virtual-8086, VME^3     0\u20132   0          VIF = 1    \n                                 1          #GP fault  \n\n   Table 4-19. Decision Table for STI Results\n\n     1. X = This setting has no effect on instruction operation.\n\n   2. For this table, \u201cprotected mode\u201d applies whenever CR0.PE = 1 and\n   EFLAGS.VM = 0; it includes compatibility mode and 64-bit mode.\n\n   3. PVI mode and virtual-8086 mode each imply CPL = 3.\n\nFlags Affected \u00b6\n\n   Either the IF flag or the VIF flag is set to 1. Other flags are\n   unaffected.\n"],
	["vgetexpps", " VGETEXPPS \u2014 Convert Exponents of Packed Single Precision Floating-Point Values\n                    to SinglePrecision Floating-Point Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Convert the exponent of \n                                                      packed single-precision \n                                                      floating-point values   \n                                                      in the source operand   \n   EVEX.128.66.0F38.W0 42 /r                 AVX512VL to single-precision     \n   VGETEXPPS xmm1 {k1}{z},   A     V/V       AVX512F  floating-point results  \n   xmm2/m128/m32bcst                                  representing unbiased   \n                                                      integer exponents and   \n                                                      stores the results in   \n                                                      the destination         \n                                                      register.               \n                                                      Convert the exponent of \n                                                      packed single-precision \n                                                      floating-point values   \n                                                      in the source operand   \n   EVEX.256.66.0F38.W0 42 /r                 AVX512VL to single-precision     \n   VGETEXPPS ymm1 {k1}{z},   A     V/V       AVX512F  floating-point results  \n   ymm2/m256/m32bcst                                  representing unbiased   \n                                                      integer exponents and   \n                                                      stores the results in   \n                                                      the destination         \n                                                      register.               \n                                                      Convert the exponent of \n                                                      packed single-precision \n                                                      floating-point values   \n                                                      in the source operand   \n   EVEX.512.66.0F38.W0 42 /r                          to single-precision     \n   VGETEXPPS zmm1 {k1}{z},   A     V/V       AVX512F  floating-point results  \n   zmm2/m512/m32bcst{sae}                             representing unbiased   \n                                                      integer exponents and   \n                                                      stores the results in   \n                                                      the destination         \n                                                      register.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Extracts the biased exponents from the normalized single-precision\n   floating-point representation of each dword element of the source operand\n   (the second operand) as unbiased signed integer value, or convert the\n   denormal representation of input data to unbiased negative integer values.\n   Each integer value of the unbiased exponent is converted to\n   single-precision floating-point value and written to the corresponding\n   dword elements of the destination operand (the first operand) as\n   single-precision floating-point numbers.\n\n   The destination operand is a ZMM/YMM/XMM register and updated under the\n   writemask. The source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 32-bit memory location.\n\n   EVEX.vvvv is reserved and must be 1111b, otherwise instructions will #UD.\n\n   Each GETEXP operation converts the exponent value into a floating-point\n   number (permitting input value in denormal representation). Special cases\n   of input values are listed in Table 5-17.\n\n   The formula is:\n\n   GETEXP(x) = floor(log_2(|x|))\n\n   Notation floor(x) stands for maximal integer not exceeding real number x.\n\n   Software usage of VGETEXPxx and VGETMANTxx instructions generally involve\n   a combination of GETEXP operation and GETMANT operation (see VGETMANTPD).\n   Thus VGETEXPxx instruction do not require software to handle SIMD\n   floating-point exceptions.\n\n   Input Operand    Result               Comments                             \n   src1 = NaN       QNaN(src1)                                                \n   0 < |src1| < INF floor(log_2(|src1|)) If (SRC = SNaN) then #IE If (SRC =   \n   | src1| = +INF   +INF                 denormal) then #DE\n   | src1| = 0      -INF                 \n\n   Table 5-17. VGETEXPPS/SS Special Cases\n\n   Figure 5-14 illustrates the VGETEXPPS functionality on input values with\n   normalized representation.\n\n   31 30 29 28 27 26 25 24 23 22212019181716151413121110 9 8 7 6 5 4 3 2 1 0\n   exp Fraction s Src = 2^1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n   0 0 0 0 0 0 0 SAR Src, 23 = 080h 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n   0 0 0 1 0 0 0 0 0 0 0 -Bias 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n   1 1 0 0 0 0 0 0 1 Tmp - Bias = 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n   0 0 0 0 0 0 0 0 0 0 1 Cvt_PI2PS(01h) = 2^0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n   0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Figure 5-14. VGETEXPPS Functionality On\n   Normal Input values\n"],
	["aesenc128kl", " AESENC128KL \u2014 Perform Ten Rounds of AES Encryption Flow With Key Locker Using\n                                  128-Bit Key\n\n                               64/32-bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                                         Flag    \n   F3 0F 38 DC                                   Encrypt xmm using 128-bit    \n   !(11):rrr:bbb         A     V/V       AESKLE  AES key indicated by handle  \n   AESENC128KL xmm, m384                         at m384 and store result in  \n                                                 xmm.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   The AESENC128KL^1 instruction performs ten rounds of AES to encrypt the\n   first operand using the 128-bit key indicated by the handle from the\n   second operand. It stores the result in the first operand if the operation\n   succeeds (e.g., does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n"],
	["add", "                                   ADD \u2014 Add\n\n   Opcode     Instruction     Op/En 64-bit Compat/Leg Description             \n                                    Mode   Mode       \n   04 ib      ADD AL, imm8    I     Valid  Valid      Add imm8 to AL.         \n   05 iw      ADD AX, imm16   I     Valid  Valid      Add imm16 to AX.        \n   05 id      ADD EAX, imm32  I     Valid  Valid      Add imm32 to EAX.       \n   REX.W + 05 ADD RAX, imm32  I     Valid  N.E.       Add imm32 sign-extended \n   id                                                 to 64-bits to RAX.      \n   80 /0 ib   ADD r/m8, imm8  MI    Valid  Valid      Add imm8 to r/m8.       \n   REX + 80   ADD r/m8^*,     MI    Valid  N.E.       Add sign-extended imm8  \n   /0 ib      imm8                                    to r/m8.                \n   81 /0 iw   ADD r/m16,      MI    Valid  Valid      Add imm16 to r/m16.     \n              imm16           \n   81 /0 id   ADD r/m32,      MI    Valid  Valid      Add imm32 to r/m32.     \n              imm32           \n   REX.W + 81 ADD r/m64,      MI    Valid  N.E.       Add imm32 sign-extended \n   /0 id      imm32                                   to 64-bits to r/m64.    \n   83 /0 ib   ADD r/m16, imm8 MI    Valid  Valid      Add sign-extended imm8  \n                                                      to r/m16.               \n   83 /0 ib   ADD r/m32, imm8 MI    Valid  Valid      Add sign-extended imm8  \n                                                      to r/m32.               \n   REX.W + 83 ADD r/m64, imm8 MI    Valid  N.E.       Add sign-extended imm8  \n   /0 ib                                              to r/m64.               \n   00 /r      ADD r/m8, r8    MR    Valid  Valid      Add r8 to r/m8.         \n   REX + 00   ADD r/m8^*,     MR    Valid  N.E.       Add r8 to r/m8.         \n   /r         r8^*            \n   01 /r      ADD r/m16, r16  MR    Valid  Valid      Add r16 to r/m16.       \n   01 /r      ADD r/m32, r32  MR    Valid  Valid      Add r32 to r/m32.       \n   REX.W + 01 ADD r/m64, r64  MR    Valid  N.E.       Add r64 to r/m64.       \n   /r         \n   02 /r      ADD r8, r/m8    RM    Valid  Valid      Add r/m8 to r8.         \n   REX + 02   ADD r8^*,       RM    Valid  N.E.       Add r/m8 to r8.         \n   /r         r/m8^*          \n   03 /r      ADD r16, r/m16  RM    Valid  Valid      Add r/m16 to r16.       \n   03 /r      ADD r32, r/m32  RM    Valid  Valid      Add r/m32 to r32.       \n   REX.W + 03 ADD r64, r/m64  RM    Valid  N.E.       Add r/m64 to r64.       \n   /r         \n\n     *In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8/16/32    N/A       N/A       \n   I     AL/AX/EAX/RAX    imm8/16/32    N/A       N/A       \n\nDescription \u00b6\n\n   Adds the destination operand (first operand) and the source operand\n   (second operand) and then stores the result in the destination operand.\n   The destination operand can be a register or a memory location; the source\n   operand can be an immediate, a register, or a memory location. (However,\n   two memory operands cannot be used in one instruction.) When an immediate\n   value is used as an operand, it is sign-extended to the length of the\n   destination operand format.\n\n   The ADD instruction performs integer addition. It evaluates the result for\n   both signed and unsigned integer operands and sets the OF and CF flags to\n   indicate a carry (overflow) in the signed or unsigned result,\n   respectively. The SF flag indicates the sign of the signed result.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The OF, SF, ZF, AF, CF, and PF flags are set according to the result.\n"],
	["vextractf128:vextractf32x4:vextractf64x2:vextractf32x8:vextractf64x4", " VEXTRACTF128/VEXTRACTF32x4/VEXTRACTF64x2/VEXTRACTF32x8/VEXTRACTF64x4 \u2014 Extract\n                          Packed Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Extract 128 bits of      \n   VEX.256.66.0F3A.W0 19 /r                          packed floating-point    \n   ib VEXTRACTF128          A     V/V       AVX      values from ymm2 and     \n   xmm1/m128, ymm2, imm8                             store results in         \n                                                     xmm1/m128.               \n                                                     Extract 128 bits of      \n   EVEX.256.66.0F3A.W0 19                            packed single precision  \n   /r ib VEXTRACTF32X4      C     V/V       AVX512VL floating-point values    \n   xmm1/m128 {k1}{z}, ymm2,                 AVX512F  from ymm2 and store      \n   imm8                                              results in xmm1/m128     \n                                                     subject to writemask k1. \n                                                     Extract 128 bits of      \n   EVEX.512.66.0F3A.W0 19                            packed single precision  \n   /r ib VEXTRACTF32x4      C     V/V       AVX512F  floating-point values    \n   xmm1/m128 {k1}{z}, zmm2,                          from zmm2 and store      \n   imm8                                              results in xmm1/m128     \n                                                     subject to writemask k1. \n                                                     Extract 128 bits of      \n   EVEX.256.66.0F3A.W1 19                            packed double precision  \n   /r ib VEXTRACTF64X2      B     V/V       AVX512VL floating-point values    \n   xmm1/m128 {k1}{z}, ymm2,                 AVX512DQ from ymm2 and store      \n   imm8                                              results in xmm1/m128     \n                                                     subject to writemask k1. \n                                                     Extract 128 bits of      \n   EVEX.512.66.0F3A.W1 19                            packed double precision  \n   /r ib VEXTRACTF64X2      B     V/V       AVX512DQ floating-point values    \n   xmm1/m128 {k1}{z}, zmm2,                          from zmm2 and store      \n   imm8                                              results in xmm1/m128     \n                                                     subject to writemask k1. \n                                                     Extract 256 bits of      \n   EVEX.512.66.0F3A.W0 1B                            packed single precision  \n   /r ib VEXTRACTF32X8      D     V/V       AVX512DQ floating-point values    \n   ymm1/m256 {k1}{z}, zmm2,                          from zmm2 and store      \n   imm8                                              results in ymm1/m256     \n                                                     subject to writemask k1. \n                                                     Extract 256 bits of      \n   EVEX.512.66.0F3A.W1 1B                            packed double precision  \n   /r ib VEXTRACTF64x4      C     V/V       AVX512F  floating-point values    \n   ymm1/m256 {k1}{z}, zmm2,                          from zmm2 and store      \n   imm8                                              results in ymm1/m256     \n                                                     subject to writemask k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   B     Tuple2     ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   C     Tuple4     ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   D     Tuple8     ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n\n  Description \u00b6\n\n   VEXTRACTF128/VEXTRACTF32x4 and VEXTRACTF64x2 extract 128-bits of single\n   precision floating-point values from the source operand (the second\n   operand) and store to the low 128-bit of the destination operand (the\n   first operand). The 128-bit data extraction occurs at an 128-bit granular\n   offset specified by imm8[0] (256-bit) or imm8[1:0] as the multiply factor.\n   The destination may be either a vector register or an 128-bit memory\n   location.\n\n   VEXTRACTF32x4: The low 128-bit of the destination operand is updated at\n   32-bit granularity according to the writemask.\n\n   VEXTRACTF32x8 and VEXTRACTF64x4 extract 256-bits of double precision\n   floating-point values from the source operand (second operand) and store\n   to the low 256-bit of the destination operand (the first operand). The\n   256-bit data extraction occurs at an 256-bit granular offset specified by\n   imm8[0] (256-bit) or imm8[0] as the multiply factor The destination may be\n   either a vector register or a 256-bit memory location.\n\n   VEXTRACTF64x4: The low 256-bit of the destination operand is updated at\n   64-bit granularity according to the writemask.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   The high 6 bits of the immediate are ignored.\n\n   If VEXTRACTF128 is encoded with VEX.L= 0, an attempt to execute the\n   instruction encoded with VEX.L= 0 will cause an #UD exception.\n"],
	["haddps", "         HADDPS \u2014 Packed Single Precision Floating-Point Horizontal Add\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Horizontal add packed      \n   F2 0F 7C /r HADDPS      RM    V/V       SSE3    single precision           \n   xmm1, xmm2/m128                                 floating-point values from \n                                                   xmm2/m128 to xmm1.         \n   VEX.128.F2.0F.WIG 7C /r                         Horizontal add packed      \n   VHADDPS xmm1, xmm2,     RVM   V/V       AVX     single precision           \n   xmm3/m128                                       floating-point values from \n                                                   xmm2 and xmm3/mem.         \n   VEX.256.F2.0F.WIG 7C /r                         Horizontal add packed      \n   VHADDPS ymm1, ymm2,     RVM   V/V       AVX     single precision           \n   ymm3/m256                                       floating-point values from \n                                                   ymm2 and ymm3/mem.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds the single precision floating-point values in the first and second\n   dwords of the destination operand and stores the result in the first dword\n   of the destination operand.\n\n   Adds single precision floating-point values in the third and fourth dword\n   of the destination operand and stores the result in the second dword of\n   the destination operand.\n\n   Adds single precision floating-point values in the first and second dword\n   of the source operand and stores the result in the third dword of the\n   destination operand.\n\n   Adds single precision floating-point values in the third and fourth dword\n   of the source operand and stores the result in the fourth dword of the\n   destination operand.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n\n   See Figure 3-19 for HADDPS; see Figure 3-20 for VHADDPS.\n\n   HADDPS xmm1, xmm2/m128 xmm2/ [127:96] [95:64] [63:32] [31:0] m128 xmm1\n   [127:96] [95:64] [63:32] [31:0] xmm2/m128 xmm2/m128 RESULT: xmm1[95:64] +\n   xmm1[31:0] + [95:64] + xmm2/ [31:0] + xmm2/ xmm1 xmm1[127:96] xmm1[63:32]\n   m128[127:96] m128[63:32] [127:96] [95:64] [63:32] [31:0] Figure 3-19.\n   HADDPS\u2014Packed Single Precision Floating-Point Horizontal Add X7 X6 X5 X4\n   X3 X2 X1 X0 SRC1 Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 SRC2 Y6+Y7 Y4+Y5 X6+X7 X4+X5\n   Y2+Y3 Y0+Y1 DEST X2+X3 X0+X1 Figure 3-20. VHADDPS Operation\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n"],
	["vfpclassss", "               VFPCLASSSS \u2014 Tests Type of a Scalar Float32 Value\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Tests the input for the   \n                                                    following categories:     \n                                                    NaN, +0, -0, +Infinity,   \n                                                    -Infinity, denormal,      \n   EVEX.LLIG.66.0F3A.W0 67                          finite negative. The      \n   /r VFPCLASSSS k2 {k1},  A     V/V       AVX512DQ immediate field provides  \n   xmm2/m32, imm8                                   a mask bit for each of    \n                                                    these category tests. The \n                                                    masked test results are   \n                                                    OR-ed together to form a  \n                                                    mask result.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   The FPCLASSSS instruction checks the low single-precision floating-point\n   value in the source operand for special categories, specified by the set\n   bits in the imm8 byte. Each set bit in imm8 specifies a category of\n   floating-point values that the input data element is classified against.\n   The classified results of all specified categories of an input value are\n   ORed together to form the final boolean result for the input element. The\n   result is written to the low bit in a mask register k2 according to the\n   writemask k1. Bits MAX_KL-1: 1 of the destination are cleared.\n\n   The classification categories specified by imm8 are shown in Figure 5-13.\n   The classification test for each category is listed in Table 5-14.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["encls", "      ENCLS \u2014 Execute an Enclave System Function of Specified Leaf Number\n\n   Opcode/Instruction Op/En 64/32 bit    CPUID        Description             \n                            Mode Support Feature Flag \n                                                      This instruction is     \n                                                      used to execute         \n   NP 0F 01 CF ENCLS  ZO    V/V          NA           privileged Intel SGX    \n                                                      leaf functions that are \n                                                      used for managing and   \n                                                      debugging the enclaves. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Implicit Register Operands \n   ZO    NA        NA        NA        See Section 38.3           \n\n  Description \u00b6\n\n   The ENCLS instruction invokes the specified privileged Intel SGX leaf\n   function for managing and debugging enclaves. Software specifies the leaf\n   function by setting the appropriate value in the register EAX as input.\n   The registers RBX, RCX, and RDX have leaf-specific purpose, and may act as\n   input, as output, or may be unused. In 64-bit mode, the instruction\n   ignores upper 32 bits of the RAX register.\n\n   The ENCLS instruction produces an invalid-opcode exception (#UD) if CR0.PE\n   = 0 or RFLAGS.VM = 1, or if it is executed in system-management mode\n   (SMM). Additionally, any attempt to execute the instruction when CPL > 0\n   results in #UD. The instruction produces a general-protection exception\n   (#GP) if CR0.PG = 0 or if an attempt is made to invoke an undefined leaf\n   function.\n\n   In VMX non-root operation, execution of ENCLS may cause a VM exit if the\n   \u201cenable ENCLS exiting\u201d VM-execution control is 1. In this case, execution\n   of individual leaf functions of ENCLS is governed by the ENCLS-exiting\n   bitmap field in the VMCS. Each bit in that field corresponds to the index\n   of an ENCLS leaf function (as provided in EAX).\n\n   Software in VMX root operation can thus intercept the invocation of\n   various ENCLS leaf functions in VMX non-root operation by setting the\n   \u201cenable ENCLS exiting\u201d VM-execution control and setting the corresponding\n   bits in the ENCLS-exiting bitmap.\n\n   Addresses and operands are 32 bits outside 64-bit mode (IA32_EFER.LMA = 0\n   || CS.L = 0) and are 64 bits in 64-bit mode (IA32_EFER.LMA = 1 || CS.L =\n   1). CS.D value has no impact on address calculation. The DS segment is\n   used to create linear addresses.\n\n   Segment override prefixes and address-size override prefixes are ignored,\n   and is the REX prefix in 64-bit mode.\n\n  Flags Affected \u00b6\n\n   See individual leaf functions\n"],
	["etrack", "                        ETRACK \u2014 Activates EBLOCK Checks\n\n                                 64/32 bit    CPUID                           \n   Opcode/Instruction      Op/En Mode Support Feature Description\n                                              Flag    \n                                                      This leaf function      \n   EAX = 0CH ENCLS[ETRACK] IR    V/V          SGX1    activates EBLOCK        \n                                                      checks.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                                 RCX                              \n   IR    ETRACK (In) Return error code (Out) Pointer to the SECS of the EPC   \n                                             page (In)                        \n\n  Description \u00b6\n\n   This leaf function provides the mechanism for hardware to track that\n   software has completed the required TLB address clears successfully. The\n   instruction can only be executed when the current privilege level is 0.\n\n   The content of RCX is an effective address of an EPC page.\n\n   The table below provides additional information on the memory parameter of\n   ETRACK leaf function.\n\nETRACK Memory Parameter Semantics \u00b6\n\n   EPCPAGE                                \n   Read/Write access permitted by Enclave \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    ETRACK successful.                             \n   SGX_PREV_TRK_INCMPL         All processors did not complete the previous   \n                               shoot-down sequence.                           \n\n   Table 38-45. ETRACK Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                           Parameter     Base Concurrency Restrictions\n                                                       On Conflict      \n   ETRACK ETRACK SECS [DS:RCX]    SECS [DS:RCX] \n   Shared ETRACK SECS [DS:RCX]    \n\n   Table 38-46. Base Concurrency Restrictions of ETRACK\n\n                  Additional Concurrency Restrictions\n                  vs. EACCEPT,                                      \n                  EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\n Leaf   Parameter EMODPE, EMODPR,     EINIT\n                  EMODT      \n                  Access     On       Access     On       Access    On Conflict  \n                             Conflict            Conflict \n ETRACK SECS      Concurrent          Concurrent          Exclusive SGX_EPC_PAGE \n        [DS:RCX]                                                    _CONFLICT    \n\n   Table 38-47. Additional Concurrency Restrictions of ETRACK\n\n  Flags Affected \u00b6\n\n   Sets ZF if SECS is in use or invalid, otherwise cleared. Clears CF, PF,\n   AF, OF, SF.\n"],
	["vcvtpd2ph", "  VCVTPD2PH \u2014 Convert Packed Double Precision FP Values to Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert two packed    \n                                                        double precision      \n                                                        floating-point values \n   EVEX.128.66.MAP5.W1 5A /r                AVX512-FP16 in xmm2/m128/m64bcst  \n   VCVTPD2PH xmm1{k1}{z},         A V/V     AVX512VL    to two packed FP16    \n   xmm2/m128/m64bcst                                    values, and store the \n                                                        result in xmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert four packed   \n                                                        double precision      \n                                                        floating-point values \n   EVEX.256.66.MAP5.W1 5A /r                AVX512-FP16 in ymm2/m256/m64bcst  \n   VCVTPD2PH xmm1{k1}{z},         A V/V     AVX512VL    to four packed FP16   \n   ymm2/m256/m64bcst                                    values, and store the \n                                                        result in xmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert eight packed  \n                                                        double precision      \n                                                        floating-point values \n   EVEX.512.66.MAP5.W1 5A /r                            in zmm2/m512/m64bcst  \n   VCVTPD2PH xmm1{k1}{z},         A V/V     AVX512-FP16 to eight packed FP16  \n   zmm2/m512/m64bcst {er}                               values, and store the \n                                                        result in ymm1        \n                                                        subject to writemask  \n                                                        k1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts two, four, or eight packed double precision\n   floating-point values in the source operand (second operand) to two, four,\n   or eight packed FP16 values in the destination operand (first operand).\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasts\n   from a 64-bit memory location. The destination operand is a XMM register\n   conditionally updated with writemask k1. The upper bits\n   (MAXVL-1:128/64/32) of the corresponding destination are zeroed.\n\n   EVEX.vvvv are reserved and must be 1111b otherwise instructions will #UD.\n\n   This instruction uses MXCSR.DAZ for handling FP64 inputs. FP16 outputs can\n   be normal or denormal, and are not conditionally flushed to zero.\n"],
	["maxpd", "        MAXPD \u2014 Maximum of Packed Double Precision Floating-Point Values\n\n                              Op 64/32 bit CPUID                              \n   Opcode/Instruction         /  Mode      Feature  Description\n                              En Support   Flag     \n                                                    Return the maximum double \n   66 0F 5F /r MAXPD xmm1,    A  V/V       SSE2     precision floating-point  \n   xmm2/m128                                        values between xmm1 and   \n                                                    xmm2/m128.                \n   VEX.128.66.0F.WIG 5F /r                          Return the maximum double \n   VMAXPD xmm1, xmm2,         B  V/V       AVX      precision floating-point  \n   xmm3/m128                                        values between xmm2 and   \n                                                    xmm3/m128.                \n                                                    Return the maximum packed \n   VEX.256.66.0F.WIG 5F /r                          double precision          \n   VMAXPD ymm1, ymm2,         B  V/V       AVX      floating-point values     \n   ymm3/m256                                        between ymm2 and          \n                                                    ymm3/m256.                \n                                                    Return the maximum packed \n                                                    double precision          \n   EVEX.128.66.0F.W1 5F /r                 AVX512VL floating-point values     \n   VMAXPD xmm1 {k1}{z}, xmm2, C  V/V       AVX512F  between xmm2 and          \n   xmm3/m128/m64bcst                                xmm3/m128/m64bcst and     \n                                                    store result in xmm1      \n                                                    subject to writemask k1.  \n                                                    Return the maximum packed \n                                                    double precision          \n   EVEX.256.66.0F.W1 5F /r                 AVX512VL floating-point values     \n   VMAXPD ymm1 {k1}{z}, ymm2, C  V/V       AVX512F  between ymm2 and          \n   ymm3/m256/m64bcst                                ymm3/m256/m64bcst and     \n                                                    store result in ymm1      \n                                                    subject to writemask k1.  \n                                                    Return the maximum packed \n                                                    double precision          \n   EVEX.512.66.0F.W1 5F /r                          floating-point values     \n   VMAXPD zmm1 {k1}{z}, zmm2, C  V/V       AVX512F  between zmm2 and          \n   zmm3/m512/m64bcst{sae}                           zmm3/m512/m64bcst and     \n                                                    store result in zmm1      \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed double precision floating-point\n   values in the first source operand and the second source operand and\n   returns the maximum value for each pair of values to the destination\n   operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of MAXPD can be emulated using a sequence of\n   instructions, such as a comparison followed by AND, ANDN, and OR.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. The upper bits (MAXVL-1:256) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["bts", "                             BTS \u2014 Bit Test and Set\n\n   Opcode      Instruction     Op/En 64-bit Compat/Leg Description            \n                                     Mode   Mode       \n   0F AB /r    BTS r/m16, r16  MR    Valid  Valid      Store selected bit in  \n                                                       CF flag and set.       \n   0F AB /r    BTS r/m32, r32  MR    Valid  Valid      Store selected bit in  \n                                                       CF flag and set.       \n   REX.W + 0F  BTS r/m64, r64  MR    Valid  N.E.       Store selected bit in  \n   AB /r                                               CF flag and set.       \n   0F BA /5 ib BTS r/m16, imm8 MI    Valid  Valid      Store selected bit in  \n                                                       CF flag and set.       \n   0F BA /5 ib BTS r/m32, imm8 MI    Valid  Valid      Store selected bit in  \n                                                       CF flag and set.       \n   REX.W + 0F  BTS r/m64, imm8 MI    Valid  N.E.       Store selected bit in  \n   BA /5 ib                                            CF flag and set.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8          N/A       N/A       \n\nDescription \u00b6\n\n   Selects the bit in a bit string (specified with the first operand, called\n   the bit base) at the bit-position designated by the bit offset operand\n   (second operand), stores the value of the bit in the CF flag, and sets the\n   selected bit in the bit string to 1. The bit base operand can be a\n   register or a memory location; the bit offset operand can be a register or\n   an immediate value:\n\n     * If the bit base operand specifies a register, the instruction takes\n       the modulo 16, 32, or 64 of the bit offset operand (modulo size\n       depends on the mode and register size; 64-bit operands are available\n       only in 64-bit mode). This allows any bit position to be selected.\n     * If the bit base operand specifies a memory location, the operand\n       represents the address of the byte in memory that contains the bit\n       base (bit 0 of the specified byte) of the bit string. The range of the\n       bit position that can be referenced by the offset operand depends on\n       the operand size.\n\n   See also: Bit(BitBase, BitOffset) on page 3-11.\n\n   Some assemblers support immediate bit offsets larger than 31 by using the\n   immediate bit offset field in combination with the displacement field of\n   the memory operand. See \u201cBT\u2014Bit Test\u201d in this chapter for more information\n   on this addressing mechanism.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The CF flag contains the value of the selected bit before it is set. The\n   ZF flag is unaffected. The OF, SF, AF, and PF flags are undefined.\n"],
	["neg", "                        NEG \u2014 Two's Complement Negation\n\n   Opcode      Instruction Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   F6 /3       NEG r/m8    M     Valid  Valid      Two's complement negate    \n                                                   r/m8.                      \n   REX + F6 /3 NEG r/m8^1  M     Valid  N.E.       Two's complement negate    \n                                                   r/m8.                      \n   F7 /3       NEG r/m16   M     Valid  Valid      Two's complement negate    \n                                                   r/m16.                     \n   F7 /3       NEG r/m32   M     Valid  Valid      Two's complement negate    \n                                                   r/m32.                     \n   REX.W + F7  NEG r/m64   M     Valid  N.E.       Two's complement negate    \n   /3                                              r/m64.                     \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Replaces the value of operand (the destination operand) with its two's\n   complement. (This operation is equivalent to subtracting the operand from\n   0.) The destination operand is located in a general-purpose register or a\n   memory location.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The CF flag set to 0 if the source operand is 0; otherwise it is set to 1.\n   The OF, SF, ZF, AF, and PF flags are set according to the result.\n"],
	["vfmadd132sd:vfmadd213sd:vfmadd231sd", "       VFMADD132SD/VFMADD213SD/VFMADD231SD \u2014 Fused Multiply-Add of Scalar\n                     DoublePrecision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Multiply scalar double    \n   VEX.LIG.66.0F38.W1 99 /r                         precision floating-point  \n   VFMADD132SD xmm1, xmm2,  A     V/V       FMA     value from xmm1 and       \n   xmm3/m64                                         xmm3/m64, add to xmm2 and \n                                                    put result in xmm1.       \n                                                    Multiply scalar double    \n   VEX.LIG.66.0F38.W1 A9 /r                         precision floating-point  \n   VFMADD213SD xmm1, xmm2,  A     V/V       FMA     value from xmm1 and xmm2, \n   xmm3/m64                                         add to xmm3/m64 and put   \n                                                    result in xmm1.           \n                                                    Multiply scalar double    \n   VEX.LIG.66.0F38.W1 B9 /r                         precision floating-point  \n   VFMADD231SD xmm1, xmm2,  A     V/V       FMA     value from xmm2 and       \n   xmm3/m64                                         xmm3/m64, add to xmm1 and \n                                                    put result in xmm1.       \n   EVEX.LLIG.66.0F38.W1 99                          Multiply scalar double    \n   /r VFMADD132SD xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm1 and       \n   xmm3/m64{er}                                     xmm3/m64, add to xmm2 and \n                                                    put result in xmm1.       \n   EVEX.LLIG.66.0F38.W1 A9                          Multiply scalar double    \n   /r VFMADD213SD xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm1 and xmm2, \n   xmm3/m64{er}                                     add to xmm3/m64 and put   \n                                                    result in xmm1.           \n   EVEX.LLIG.66.0F38.W1 B9                          Multiply scalar double    \n   /r VFMADD231SD xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm2 and       \n   xmm3/m64{er}                                     xmm3/m64, add to xmm1 and \n                                                    put result in xmm1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a SIMD multiply-add computation on the low double precision\n   floating-point values using three source operands and writes the\n   multiply-add result in the destination operand. The destination operand is\n   also the first source operand. The first and second operand are XMM\n   registers. The third source operand can be an XMM register or a 64-bit\n   memory location.\n\n   VFMADD132SD: Multiplies the low double precision floating-point value from\n   the first source operand to the low double precision floating-point value\n   in the third source operand, adds the infinite precision intermediate\n   result to the low double precision floating-point values in the second\n   source operand, performs rounding and stores the resulting double\n   precision floating-point value to the destination operand (first source\n   operand).\n\n   VFMADD213SD: Multiplies the low double precision floating-point value from\n   the second source operand to the low double precision floating-point value\n   in the first source operand, adds the infinite precision intermediate\n   result to the low double precision floating-point value in the third\n   source operand, performs rounding and stores the resulting double\n   precision floating-point value to the destination operand (first source\n   operand).\n\n   VFMADD231SD: Multiplies the low double precision floating-point value from\n   the second source to the low double precision floating-point value in the\n   third source operand, adds the infinite precision intermediate result to\n   the low double precision floating-point value in the first source operand,\n   performs rounding and stores the resulting double precision floating-point\n   value to the destination operand (first source operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:64 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination is\n   updated according to the writemask.\n"],
	["aesdecwide128kl", "AESDECWIDE128KL \u2014 Perform Ten Rounds of AES Decryption Flow With Key Locker on 8\n                            BlocksUsing 128-Bit Key\n\n   Opcode/Instruction    Op/En 64/32-bit CPUID Feature Description            \n                               Mode      Flag          \n                                                       Decrypt XMM0-7 using   \n   F3 0F 38 D8                                         128-bit AES key        \n   !(11):001:bbb                                       indicated by handle at \n   AESDECWIDE128KL m384, A     V/V       AESKLEWIDE_KL m384 and store each    \n   <XMM0-7>                                            resultant block back   \n                                                       to its corresponding   \n                                                       register.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operands 2\u20149           \n   A     N/A   ModRM:r/m (r) Implicit XMM0-7 (r, w) \n\nDescription \u00b6\n\n   The AESDECWIDE128KL^1 instruction performs ten rounds of AES to decrypt\n   each of the eight blocks in XMM0-7 using the 128-bit key indicated by the\n   handle from the second operand. It replaces each input block in XMM0-7\n   with its corresponding decrypted block if the operation succeeds (e.g.,\n   does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n\n   1. Further details on Key Locker and usage of this instruction can be\n   found here:\n\n  https://software.intel.com/content/www/us/en/develop/download/intel-key-locker-specification.html.\n  \u00b6\n"],
	["lzcnt", "                 LZCNT \u2014 Count the Number of Leading Zero Bits\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Count the number of        \n   F3 0F BD /r LZCNT r16,  RM    V/V       LZCNT   leading zero bits in       \n   r/m16                                           r/m16, return result in    \n                                                   r16.                       \n                                                   Count the number of        \n   F3 0F BD /r LZCNT r32,  RM    V/V       LZCNT   leading zero bits in       \n   r/m32                                           r/m32, return result in    \n                                                   r32.                       \n                                                   Count the number of        \n   F3 REX.W 0F BD /r LZCNT RM    V/N.E.    LZCNT   leading zero bits in       \n   r64, r/m64                                      r/m64, return result in    \n                                                   r64.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Counts the number of leading most significant zero bits in a source\n   operand (second operand) returning the result into a destination (first\n   operand).\n\n   LZCNT differs from BSR. For example, LZCNT will produce the operand size\n   when the input operand is zero. It should be noted that on processors that\n   do not support LZCNT, the instruction byte encoding is executed as BSR.\n\n   In 64-bit mode 64-bit operand size requires REX.W=1.\n\nFlags Affected \u00b6\n\n   ZF flag is set to 1 in case of zero output (most significant bit of the\n   source is set), and to 0 otherwise, CF flag is set to 1 if input was zero\n   and cleared otherwise. OF, SF, PF, and AF flags are undefined.\n"],
	["pmullw", "         PMULLW \u2014 Multiply Packed Signed Integers and Store Low Result\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply the packed      \n                                                     signed word integers in  \n   NP 0F D5 /r^1 PMULLW mm, A     V/V       MMX      mm1 register and         \n   mm/m64                                            mm2/m64, and store the   \n                                                     low 16 bits of the       \n                                                     results in mm1.          \n                                                     Multiply the packed      \n   66 0F D5 /r PMULLW xmm1,                          signed word integers in  \n   xmm2/m128                A     V/V       SSE2     xmm1 and xmm2/m128, and  \n                                                     store the low 16 bits of \n                                                     the results in xmm1.     \n                                                     Multiply the packed      \n   VEX.128.66.0F.WIG D5 /r                           dword signed integers in \n   VPMULLW xmm1, xmm2,      B     V/V       AVX      xmm2 and xmm3/m128 and   \n   xmm3/m128                                         store the low 32 bits of \n                                                     each product in xmm1.    \n                                                     Multiply the packed      \n   VEX.256.66.0F.WIG D5 /r                           signed word integers in  \n   VPMULLW ymm1, ymm2,      B     V/V       AVX2     ymm2 and ymm3/m256, and  \n   ymm3/m256                                         store the low 16 bits of \n                                                     the results in ymm1.     \n                                                     Multiply the packed      \n   EVEX.128.66.0F.WIG D5 /r                          signed word integers in  \n   VPMULLW xmm1 {k1}{z},    C     V/V       AVX512VL xmm2 and xmm3/m128, and  \n   xmm2, xmm3/m128                          AVX512BW store the low 16 bits of \n                                                     the results in xmm1      \n                                                     under writemask k1.      \n                                                     Multiply the packed      \n   EVEX.256.66.0F.WIG D5 /r                          signed word integers in  \n   VPMULLW ymm1 {k1}{z},    C     V/V       AVX512VL ymm2 and ymm3/m256, and  \n   ymm2, ymm3/m256                          AVX512BW store the low 16 bits of \n                                                     the results in ymm1      \n                                                     under writemask k1.      \n                                                     Multiply the packed      \n   EVEX.512.66.0F.WIG D5 /r                          signed word integers in  \n   VPMULLW zmm1 {k1}{z},    C     V/V       AVX512BW zmm2 and zmm3/m512, and  \n   zmm2, zmm3/m512                                   store the low 16 bits of \n                                                     the results in zmm1      \n                                                     under writemask k1.      \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD signed multiply of the packed signed word integers in the\n   destination operand (first operand) and the source operand (second\n   operand), and stores the low 16 bits of each intermediate 32-bit result in\n   the destination operand. (Figure 4-12 shows this operation when using\n   64-bit operands.)\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The source operand can be an MMX\n   technology register or a 64-bit memory location. The destination operand\n   is an MMX technology register.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed. VEX.L must be 0, otherwise the instruction will #UD.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n\n   SRC X3 X2 X1 X0 DEST DEST DEST DEST DEST DEST DEST DEST DEST Y2 Y1 Y0 Z3 =\n   X3 \u2217 Y3 Z2 = X2 \u2217 Y2 Z1 = X1 \u2217 Y1 Z0 = X0 \u2217 Y0 TEMP DEST Z3[15:0] Z2[15:0]\n   Z1[15:0] Z0[15:0] Figure 4-13. PMULLU Instruction Operation Using 64-bit\n   Operands\n\nFlags Affected \u00b6\n\n   None.\n"],
	["not", "                        NOT \u2014 One's Complement Negation\n\n   Opcode      Instruction Op/En 64-Bit Mode Compat/Leg Description           \n                                             Mode       \n   F6 /2       NOT r/m8    M     Valid       Valid      Reverse each bit of   \n                                                        r/m8.                 \n   REX + F6 /2 NOT r/m8^1  M     Valid       N.E.       Reverse each bit of   \n                                                        r/m8.                 \n   F7 /2       NOT r/m16   M     Valid       Valid      Reverse each bit of   \n                                                        r/m16.                \n   F7 /2       NOT r/m32   M     Valid       Valid      Reverse each bit of   \n                                                        r/m32.                \n   REX.W + F7  NOT r/m64   M     Valid       N.E.       Reverse each bit of   \n   /2                                                   r/m64.                \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a bitwise NOT operation (each 1 is set to 0, and each 0 is set to\n   1) on the destination operand and stores the result in the destination\n   operand location. The destination operand can be a register or a memory\n   location.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["in", "                              IN \u2014 Input From Port\n\n   Opcode Instruction  Op/En 64-Bit Compat/Leg Mode Description               \n                             Mode   \n   E4 ib  IN AL, imm8  I     Valid  Valid           Input byte from imm8 I/O  \n                                                    port address into AL.     \n   E5 ib  IN AX, imm8  I     Valid  Valid           Input word from imm8 I/O  \n                                                    port address into AX.     \n   E5 ib  IN EAX, imm8 I     Valid  Valid           Input dword from imm8 I/O \n                                                    port address into EAX.    \n   EC     IN AL,DX     ZO    Valid  Valid           Input byte from I/O port  \n                                                    in DX into AL.            \n   ED     IN AX,DX     ZO    Valid  Valid           Input word from I/O port  \n                                                    in DX into AX.            \n   ED     IN EAX,DX    ZO    Valid  Valid           Input doubleword from I/O \n                                                    port in DX into EAX.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   I     imm8      N/A       N/A       N/A       \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Copies the value from the I/O port specified with the second operand\n   (source operand) to the destination operand (first operand). The source\n   operand can be a byte-immediate or the DX register; the destination\n   operand can be register AL, AX, or EAX, depending on the size of the port\n   being accessed (8, 16, or 32 bits, respectively). Using the DX register as\n   a source operand allows I/O port addresses from 0 to 65,535 to be\n   accessed; using a byte immediate allows I/O port addresses 0 to 255 to be\n   accessed.\n\n   When accessing an 8-bit I/O port, the opcode determines the port size;\n   when accessing a 16- and 32-bit I/O port, the operand-size attribute\n   determines the port size. At the machine code level, I/O instructions are\n   shorter when accessing 8-bit I/O ports. Here, the upper eight bits of the\n   port address will be 0.\n\n   This instruction is only useful for accessing I/O ports located in the\n   processor\u2019s I/O address space. See Chapter 19, \u201cInput/Output,\u201d in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1,\n   for more information on accessing I/O ports in the I/O address space.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["rcl:rcr:rol:ror", "                            RCL/RCR/ROL/ROR \u2014 Rotate\n\n   Opcode^1\n\n            Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   D0 /2    RCL r/m8, 1     M1    Valid  Valid      Rotate 9 bits (CF, r/m8)  \n                                                    left once.                \n   REX + D0 RCL r/m8^2, 1   M1    Valid  N.E.       Rotate 9 bits (CF, r/m8)  \n   /2                                               left once.                \n   D2 /2    RCL r/m8, CL    MC    Valid  Valid      Rotate 9 bits (CF, r/m8)  \n                                                    left CL times.            \n   REX + D2 RCL r/m8^2, CL  MC    Valid  N.E.       Rotate 9 bits (CF, r/m8)  \n   /2                                               left CL times.            \n   C0 /2 ib RCL r/m8, imm8  MI    Valid  Valid      Rotate 9 bits (CF, r/m8)  \n                                                    left imm8 times.          \n   REX + C0 RCL r/m8^2,     MI    Valid  N.E.       Rotate 9 bits (CF, r/m8)  \n   /2 ib    imm8                                    left imm8 times.          \n   D1 /2    RCL r/m16, 1    M1    Valid  Valid      Rotate 17 bits (CF,       \n                                                    r/m16) left once.         \n   D3 /2    RCL r/m16, CL   MC    Valid  Valid      Rotate 17 bits (CF,       \n                                                    r/m16) left CL times.     \n   C1 /2 ib RCL r/m16, imm8 MI    Valid  Valid      Rotate 17 bits (CF,       \n                                                    r/m16) left imm8 times.   \n   D1 /2    RCL r/m32, 1    M1    Valid  Valid      Rotate 33 bits (CF,       \n                                                    r/m32) left once.         \n   REX.W +                                          Rotate 65 bits (CF,       \n   D1 /2    RCL r/m64, 1    M1    Valid  N.E.       r/m64) left once. Uses a  \n                                                    6 bit count.              \n   D3 /2    RCL r/m32, CL   MC    Valid  Valid      Rotate 33 bits (CF,       \n                                                    r/m32) left CL times.     \n   REX.W +                                          Rotate 65 bits (CF,       \n   D3 /2    RCL r/m64, CL   MC    Valid  N.E.       r/m64) left CL times.     \n                                                    Uses a 6 bit count.       \n   C1 /2 ib RCL r/m32, imm8 MI    Valid  Valid      Rotate 33 bits (CF,       \n                                                    r/m32) left imm8 times.   \n   REX.W +                                          Rotate 65 bits (CF,       \n   C1 /2 ib RCL r/m64, imm8 MI    Valid  N.E.       r/m64) left imm8 times.   \n                                                    Uses a 6 bit count.       \n   D0 /3    RCR r/m8, 1     M1    Valid  Valid      Rotate 9 bits (CF, r/m8)  \n                                                    right once.               \n   REX + D0 RCR r/m8^2, 1   M1    Valid  N.E.       Rotate 9 bits (CF, r/m8)  \n   /3                                               right once.               \n   D2 /3    RCR r/m8, CL    MC    Valid  Valid      Rotate 9 bits (CF, r/m8)  \n                                                    right CL times.           \n   REX + D2 RCR r/m8^2, CL  MC    Valid  N.E.       Rotate 9 bits (CF, r/m8)  \n   /3                                               right CL times.           \n   C0 /3 ib RCR r/m8, imm8  MI    Valid  Valid      Rotate 9 bits (CF, r/m8)  \n                                                    right imm8 times.         \n   REX + C0 RCR r/m8^2,     MI    Valid  N.E.       Rotate 9 bits (CF, r/m8)  \n   /3 ib    imm8                                    right imm8 times.         \n   D1 /3    RCR r/m16, 1    M1    Valid  Valid      Rotate 17 bits (CF,       \n                                                    r/m16) right once.        \n   D3 /3    RCR r/m16, CL   MC    Valid  Valid      Rotate 17 bits (CF,       \n                                                    r/m16) right CL times.    \n   C1 /3 ib RCR r/m16, imm8 MI    Valid  Valid      Rotate 17 bits (CF,       \n                                                    r/m16) right imm8 times.  \n                                                    Rotate 33 bits (CF,       \n   D1 /3    RCR r/m32, 1    M1    Valid  Valid      r/m32) right once. Uses a \n                                                    6 bit count.              \n   REX.W +                                          Rotate 65 bits (CF,       \n   D1 /3    RCR r/m64, 1    M1    Valid  N.E.       r/m64) right once. Uses a \n                                                    6 bit count.              \n   D3 /3    RCR r/m32, CL   MC    Valid  Valid      Rotate 33 bits (CF,       \n                                                    r/m32) right CL times.    \n   REX.W +                                          Rotate 65 bits (CF,       \n   D3 /3    RCR r/m64, CL   MC    Valid  N.E.       r/m64) right CL times.    \n                                                    Uses a 6 bit count.       \n   C1 /3 ib RCR r/m32, imm8 MI    Valid  Valid      Rotate 33 bits (CF,       \n                                                    r/m32) right imm8 times.  \n   REX.W +                                          Rotate 65 bits (CF,       \n   C1 /3 ib RCR r/m64, imm8 MI    Valid  N.E.       r/m64) right imm8 times.  \n                                                    Uses a 6 bit count.       \n   D0 /0    ROL r/m8, 1     M1    Valid  Valid      Rotate 8 bits r/m8 left   \n                                                    once.                     \n   REX + D0 ROL r/m8^2, 1   M1    Valid  N.E.       Rotate 8 bits r/m8 left   \n   /0                                               once                      \n   D2 /0    ROL r/m8, CL    MC    Valid  Valid      Rotate 8 bits r/m8 left   \n                                                    CL times.                 \n   REX + D2 ROL r/m8^2, CL  MC    Valid  N.E.       Rotate 8 bits r/m8 left   \n   /0                                               CL times.                 \n   C0 /0 ib ROL r/m8, imm8  MI    Valid  Valid      Rotate 8 bits r/m8 left   \n                                                    imm8 times.               \n\n   Opcode^1\n\n            Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   REX + C0 ROL r/m8^2,     MI    Valid  N.E.       Rotate 8 bits r/m8 left   \n   /0 ib    imm8                                    imm8 times.               \n   D1 /0    ROL r/m16, 1    M1    Valid  Valid      Rotate 16 bits r/m16 left \n                                                    once.                     \n   D3 /0    ROL r/m16, CL   MC    Valid  Valid      Rotate 16 bits r/m16 left \n                                                    CL times.                 \n   C1 /0 ib ROL r/m16, imm8 MI    Valid  Valid      Rotate 16 bits r/m16 left \n                                                    imm8 times.               \n   D1 /0    ROL r/m32, 1    M1    Valid  Valid      Rotate 32 bits r/m32 left \n                                                    once.                     \n   REX.W +  ROL r/m64, 1    M1    Valid  N.E.       Rotate 64 bits r/m64 left \n   D1 /0                                            once. Uses a 6 bit count. \n   D3 /0    ROL r/m32, CL   MC    Valid  Valid      Rotate 32 bits r/m32 left \n                                                    CL times.                 \n   REX.W +                                          Rotate 64 bits r/m64 left \n   D3 /0    ROL r/m64, CL   MC    Valid  N.E.       CL times. Uses a 6 bit    \n                                                    count.                    \n   C1 /0 ib ROL r/m32, imm8 MI    Valid  Valid      Rotate 32 bits r/m32 left \n                                                    imm8 times.               \n   REX.W +                                          Rotate 64 bits r/m64 left \n   C1 /0 ib ROL r/m64, imm8 MI    Valid  N.E.       imm8 times. Uses a 6 bit  \n                                                    count.                    \n   D0 /1    ROR r/m8, 1     M1    Valid  Valid      Rotate 8 bits r/m8 right  \n                                                    once.                     \n   REX + D0 ROR r/m8^2, 1   M1    Valid  N.E.       Rotate 8 bits r/m8 right  \n   /1                                               once.                     \n   D2 /1    ROR r/m8, CL    MC    Valid  Valid      Rotate 8 bits r/m8 right  \n                                                    CL times.                 \n   REX + D2 ROR r/m8^2, CL  MC    Valid  N.E.       Rotate 8 bits r/m8 right  \n   /1                                               CL times.                 \n   C0 /1 ib ROR r/m8, imm8  MI    Valid  Valid      Rotate 8 bits r/m16 right \n                                                    imm8 times.               \n   REX + C0 ROR r/m8^2,     MI    Valid  N.E.       Rotate 8 bits r/m16 right \n   /1 ib    imm8                                    imm8 times.               \n   D1 /1    ROR r/m16, 1    M1    Valid  Valid      Rotate 16 bits r/m16      \n                                                    right once.               \n   D3 /1    ROR r/m16, CL   MC    Valid  Valid      Rotate 16 bits r/m16      \n                                                    right CL times.           \n   C1 /1 ib ROR r/m16, imm8 MI    Valid  Valid      Rotate 16 bits r/m16      \n                                                    right imm8 times.         \n   D1 /1    ROR r/m32, 1    M1    Valid  Valid      Rotate 32 bits r/m32      \n                                                    right once.               \n   REX.W +                                          Rotate 64 bits r/m64      \n   D1 /1    ROR r/m64, 1    M1    Valid  N.E.       right once. Uses a 6 bit  \n                                                    count.                    \n   D3 /1    ROR r/m32, CL   MC    Valid  Valid      Rotate 32 bits r/m32      \n                                                    right CL times.           \n   REX.W +                                          Rotate 64 bits r/m64      \n   D3 /1    ROR r/m64, CL   MC    Valid  N.E.       right CL times. Uses a 6  \n                                                    bit count.                \n   C1 /1 ib ROR r/m32, imm8 MI    Valid  Valid      Rotate 32 bits r/m32      \n                                                    right imm8 times.         \n   REX.W +                                          Rotate 64 bits r/m64      \n   C1 /1 ib ROR r/m64, imm8 MI    Valid  N.E.       right imm8 times. Uses a  \n                                                    6 bit count.              \n\n     1. See the IA-32 Architecture Compatibility section below.\n\n     2. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M1    ModRM:r/m (w) 1         N/A       N/A       \n   MC    ModRM:r/m (w) CL        N/A       N/A       \n   MI    ModRM:r/m (w) imm8      N/A       N/A       \n\nDescription \u00b6\n\n   Shifts (rotates) the bits of the first operand (destination operand) the\n   number of bit positions specified in the second operand (count operand)\n   and stores the result in the destination operand. The destination operand\n   can be a register or a memory location; the count operand is an unsigned\n   integer that can be an immediate or a value in the CL register. The count\n   is masked to 5 bits (or 6 bits if in 64-bit mode and REX.W = 1).\n\n   The rotate left (ROL) and rotate through carry left (RCL) instructions\n   shift all the bits toward more-significant bit positions, except for the\n   most-significant bit, which is rotated to the least-significant bit\n   location. The rotate right (ROR) and rotate through carry right (RCR)\n   instructions shift all the bits toward less significant bit positions,\n   except for the least-significant bit, which is rotated to the\n   most-significant bit location.\n\n   The RCL and RCR instructions include the CF flag in the rotation. The RCL\n   instruction shifts the CF flag into the least-significant bit and shifts\n   the most-significant bit into the CF flag. The RCR instruction shifts the\n   CF flag into the most-significant bit and shifts the least-significant bit\n   into the CF flag. For the ROL and ROR instructions, the original value of\n   the CF flag is not a part of the result, but the CF flag receives a copy\n   of the bit that was shifted from one end to the other.\n\n   The OF flag is defined only for the 1-bit rotates; it is undefined in all\n   other cases (except RCL and RCR instructions only: a zero-bit rotate does\n   nothing, that is affects no flags). For left rotates, the OF flag is set\n   to the exclusive OR of the CF bit (after the rotate) and the\n   most-significant bit of the result. For right rotates, the OF flag is set\n   to the exclusive OR of the two most-significant bits of the result.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits access to\n   additional registers (R8-R15). Use of REX.W promotes the first operand to\n   64 bits and causes the count operand to become a 6-bit counter.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The 8086 does not mask the rotation count. However, all other IA-32\n   processors (starting with the Intel 286 processor) do mask the rotation\n   count to 5 bits, resulting in a maximum count of 31. This masking is done\n   in all operating modes (including the virtual-8086 mode) to reduce the\n   maximum execution time of the instructions.\n\nFlags Affected \u00b6\n\n   For RCL and RCR instructions, a zero-bit rotate does nothing, i.e.,\n   affects no flags. For ROL and ROR instructions, if the masked count is 0,\n   the flags are not affected. If the masked count is 1, then the OF flag is\n   affected, otherwise (masked count is greater than 1) the OF flag is\n   undefined.\n\n   For all instructions, the CF flag is affected when the masked count is\n   non-zero. The SF, ZF, AF, and PF flags are always unaffected.\n"],
	["vrangeps", "  VRANGEPS \u2014 Range Restriction Calculation for Packed Pairs of Float32 Values\n\n                                   64/32    CPUID                             \n   Opcode/Instruction        Op/En bit Mode Feature  Description\n                                   Support  Flag     \n                                                     Calculate four RANGE     \n                                                     operation output value   \n                                                     from 4 pairs of          \n                                                     single-precision         \n   EVEX.128.66.0F3A.W0 50 /r                         floating-point values in \n   ib VRANGEPS xmm1 {k1}{z}, A     V/V      AVX512VL xmm2 and                 \n   xmm2, xmm3/m128/m32bcst,                 AVX512DQ xmm3/m128/m32bcst, store \n   imm8                                              the results to xmm1      \n                                                     under the writemask k1.  \n                                                     Imm8 specifies the       \n                                                     comparison and sign of   \n                                                     the range operation.     \n                                                     Calculate eight RANGE    \n                                                     operation output value   \n                                                     from 8 pairs of          \n                                                     single-precision         \n   EVEX.256.66.0F3A.W0 50 /r                         floating-point values in \n   ib VRANGEPS ymm1 {k1}{z}, A     V/V      AVX512VL ymm2 and                 \n   ymm2, ymm3/m256/m32bcst,                 AVX512DQ ymm3/m256/m32bcst, store \n   imm8                                              the results to ymm1      \n                                                     under the writemask k1.  \n                                                     Imm8 specifies the       \n                                                     comparison and sign of   \n                                                     the range operation.     \n                                                     Calculate 16 RANGE       \n                                                     operation output value   \n                                                     from 16 pairs of         \n   EVEX.512.66.0F3A.W0 50 /r                         single-precision         \n   ib VRANGEPS zmm1 {k1}{z},                         floating-point values in \n   zmm2,                     A     V/V      AVX512DQ zmm2 and                 \n   zmm3/m512/m32bcst{sae},                           zmm3/m512/m32bcst, store \n   imm8                                              the results to zmm1      \n                                                     under the writemask k1.  \n                                                     Imm8 specifies the       \n                                                     comparison and sign of   \n                                                     the range operation.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   This instruction calculates 4/8/16 range operation outputs from two sets\n   of packed input single-precision floating-point values in the first source\n   operand (the second operand) and the second source operand (the third\n   operand). The range outputs are written to the destination operand (the\n   first operand) under the writemask k1.\n\n   Bits7:4 of imm8 byte must be zero. The range operation output is performed\n   in two parts, each configured by a two-bit control field within imm8[3:0]:\n\n     * Imm8[1:0] specifies the initial comparison operation to be one of max,\n       min, max absolute value or min absolute value of the input value pair.\n       Each comparison of two input values produces an intermediate result\n       that combines with the sign selection control (imm8[3:2]) to determine\n       the final range operation output.\n     * Imm8[3:2] specifies the sign of the range operation output to be one\n       of the following: from the first input value, from the comparison\n       result, set or clear.\n\n   The encodings of imm8[1:0] and imm8[3:2] are shown in Figure 5-27.\n\n   When one or more of the input value is a NAN, the comparison operation may\n   signal invalid exception (IE). Details with one of more input value is NAN\n   is listed in Table 5-23. If the comparison raises an IE, the sign select\n   control (imm8[3:2]) has no effect to the range operation output; this is\n   indicated also in Table 5-23.\n\n   When both input values are zeros of opposite signs, the comparison\n   operation of MIN/MAX in the range compare operation is slightly different\n   from the conceptually similar floating-point MIN/MAX operation that are\n   found in the instructions VMAXPD/VMINPD. The details of\n   MIN/MAX/MIN_ABS/MAX_ABS operation for VRANGEPD/PS/SD/SS for magnitude-0,\n   opposite-signed input cases are listed in Table 5-24.\n\n   Additionally, non-zero, equal-magnitude with opposite-sign input values\n   perform MIN_ABS or MAX_ABS comparison operation with result listed in\n   Table 5-25.\n"],
	["parameters", "                 GETSEC[PARAMETERS] \u2014 Report the SMX Parameters\n\n   Opcode           Instruction        Description                            \n                                       Report the SMX parameters. The         \n   NP 0F 37 (EAX=6) GETSEC[PARAMETERS] parameters index is input in EBX with  \n                                       the result returned in EAX, EBX, and   \n                                       ECX.                                   \n\nDescription \u00b6\n\n   The GETSEC[PARAMETERS] instruction returns specific parameter information\n   for SMX features supported by the processor. Parameter information is\n   returned in EAX, EBX, and ECX, with the input parameter selected using\n   EBX.\n\n   Software retrieves parameter information by searching with an input index\n   for EBX starting at 0, and then reading the returned results in EAX, EBX,\n   and ECX. EAX[4:0] is designated to return a parameter type field\n   indicating if a parameter is available and what type it is. If EAX[4:0] is\n   returned with 0, this designates a null parameter and indicates no more\n   parameters are available.\n\n   Table 7-7 defines the parameter types supported in current and future\n   implementations.\n\n   Parameter Parameter                                                        \n   Type      Description      EAX[31:5]             EBX[31:0]    ECX[31:0]\n   EAX[4:0]  \n   0         NULL             Reserved (0 returned) Reserved     Reserved     \n                                                    (unmodified) (unmodified) \n             Supported AC                           Version      Version      \n   1         module versions  Reserved (0 returned) comparison   numbers      \n                                                    mask         supported    \n             Max size of                                                      \n   2         authenticated    Multiply by 32 for    Reserved     Reserved     \n             code execution   size in bytes         (unmodified) (unmodified)\n             area             \n             External memory                        Reserved     Reserved     \n   3         types supported  Memory type bit mask  (unmodified) (unmodified) \n             during AC mode   \n             Selective SENTER EAX[14:8] correspond                            \n   4         functionality    to available SENTER   Reserved     Reserved     \n             control          function disable      (unmodified) (unmodified)\n                              controls              \n             TXT extensions   TXT Feature                                     \n   5         support          Extensions Flags (see Reserved     Reserved\n                              Table )               \n   6-31      Undefined        Reserved (unmodified) Reserved     Reserved     \n                                                    (unmodified) (unmodified) \n\n   Table 7-7. SMX Reporting Parameters Format\n\n   Bit  Definition      Description                                           \n                        Returns 1 if this processor implements a              \n        Processor based processor-rooted S-CRTM capability and 0 if not       \n   5    S-CRTM support  (S-CRTM is rooted in BIOS). This flag cannot be used  \n                        to infer whether the chipset supports TXT or whether  \n                        the processor support SMX.                            \n                        Returns 1 if it machine check status registers can be \n                        preserved through ENTERACCS and SENTER. If this bit   \n                        is 1, the caller of ENTERACCS and SENTER is not       \n   6    Machine Check   required to clear machine check error status bits     \n        Handling        before invoking these GETSEC leaves. If this bit      \n                        returns 0, the caller of ENTERACCS and SENTER must    \n                        clear all machine check error status bits before      \n                        invoking these GETSEC leaves.                         \n   31:7 Reserved        Reserved for future use. Will return 0.               \n\n   Table 7-8. TXT Feature Extensions Flags\n\n   Supported AC module versions (as defined by the AC module HeaderVersion\n   field) can be determined for a particular SMX capable processor by the\n   type 1 parameter. Using EBX to index through the available parameters\n   reported by GETSEC[PARAMETERS] for each unique parameter set returned for\n   type 1, software can determine the complete list of AC module version(s)\n   supported.\n\n   For each parameter set, EBX returns the comparison mask and ECX returns\n   the available HeaderVersion field values supported, after AND'ing the\n   target HeaderVersion with the comparison mask. Software can then determine\n   if a particular AC module version is supported by following the\n   pseudo-code search routine given below:\n\n   parameter_search_index= 0 do { EBX= parameter_search_index++ EAX= 6 GETSEC\n   if (EAX[4:0] = 1) { if ((version_query & EBX) = ECX) {\n   version_is_supported= 1 break } }\n\n   } while (EAX[4:0] =\u0338 0)\n\n   If only AC modules with a HeaderVersion of 0 are supported by the\n   processor, then only one parameter set of type 1 will be returned, as\n   follows: EAX = 00000001H,\n\n   EBX = FFFFFFFFH and ECX = 00000000H.\n\n   The maximum capacity for an authenticated code execution area supported by\n   the processor is reported with the parameter type of 2. The maximum\n   supported size in bytes is determined by multiplying the returned size in\n   EAX[31:5] by 32. Thus, for a maximum supported authenticated RAM size of\n   32KBytes, EAX returns with 00008002H.\n\n   Supportable memory types for memory mapped outside of the authenticated\n   code execution area are reported with the parameter type of 3. While is\n   active, as initiated by the GETSEC functions SENTER and ENTERACCS and\n   terminated by EXITAC, there are restrictions on what memory types are\n   allowed for the rest of system memory. It is the responsibility of the\n   system software to initialize the memory type range register (MTRR) MSRs\n   and/or the page attribute table (PAT) to only map memory types consistent\n   with the reporting of this parameter. The reporting of supportable memory\n   types of external memory is indicated using a bit map returned in\n   EAX[31:8]. These bit positions correspond to the memory type encodings\n   defined for the MTRR MSR and PAT programming. See Table 7-9.\n\n   The parameter type of 4 is used for enumerating the availability of\n   selective GETSEC[SENTER] function disable controls. If a 1 is reported in\n   bits 14:8 of the returned parameter EAX, then this indicates a disable\n   control capability exists with SENTER for a particular function. The\n   enumerated field in bits 14:8 corresponds to use of the EDX input\n   parameter bits 6:0 for SENTER. If an enumerated field bit is set to 1,\n   then the corresponding EDX input parameter bit of EDX may be set to 1 to\n   disable that designated function. If the enumerated field bit is 0 or this\n   parameter is not reported, then no disable capability exists with the\n   corresponding EDX input parameter for SENTER, and EDX bit(s) must be\n   cleared to 0 to enable execution of SENTER. If no selective disable\n   capability for SENTER exists as enumerated, then the corresponding bits in\n   the IA32_FEATURE_CONTROL MSR bits 14:8 must also be programmed to 1 if the\n   SENTER global enable bit 15 of the MSR is set. This is required to enable\n   future extensibility of SENTER selective disable capability with respect\n   to potentially separate software initialization of the MSR.\n\n   EAX Bit Position Parameter Description \n   8                Uncacheable (UC)      \n   9                Write Combining (WC)  \n   11:10            Reserved              \n   12               Write-through (WT)    \n   13               Write-protected (WP)  \n   14               Write-back (WB)       \n   31:15            Reserved              \n\n   Table 7-9. External Memory Types Using Parameter 3\n\n   If the GETSEC[PARAMETERS] leaf or specific parameter is not present for a\n   given SMX capable processor, then default parameter values should be\n   assumed. These are defined in Table 7-10.\n\n   Parameter Type EAX[4:0] Default Setting Parameter Description              \n   1                       0.0 only        Supported AC module versions.      \n   2                       32 KBytes       Authenticated code execution area  \n                                           size.                              \n   3                       UC only         External memory types supported    \n                                           during AC execution mode.          \n   4                       None            Available SENTER selective disable \n                                           controls.                          \n\n   Table 7-10. Default Parameter Values\n\nFlags Affected \u00b6\n\n   None.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX Ignored.\n\nVM-Exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["adcx", "        ADCX \u2014 Unsigned Integer Addition of Two Operands With Carry Flag\n\n                                  64/32bit     CPUID                          \n   Opcode/Instruction       Op/En Mode Support Feature Description\n                                               Flag    \n   66 0F 38 F6 /r ADCX r32,                            Unsigned addition of   \n   r/m32                    RM    V/V          ADX     r32 with CF, r/m32 to  \n                                                       r32, writes CF.        \n   66 REX.w 0F 38 F6 /r                                Unsigned addition of   \n   ADCX r64, r/m64          RM    V/N.E.       ADX     r64 with CF, r/m64 to  \n                                                       r64, writes CF.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs an unsigned addition of the destination operand (first operand),\n   the source operand (second operand) and the carry-flag (CF) and stores the\n   result in the destination operand. The destination operand is a\n   general-purpose register, whereas the source operand can be a\n   general-purpose register or memory location. The state of CF can represent\n   a carry from a previous addition. The instruction sets the CF flag with\n   the carry generated by the unsigned addition of the operands.\n\n   The ADCX instruction is executed in the context of multi-precision\n   addition, where we add a series of operands with a carry-chain. At the\n   beginning of a chain of additions, we need to make sure the CF is in a\n   desired initial state. Often, this initial state needs to be 0, which can\n   be achieved with an instruction to zero the CF (e.g. XOR).\n\n   This instruction is supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode.\n\n   In 64-bit mode, the default operation size is 32 bits. Using a REX Prefix\n   in the form of REX.R permits access to additional registers (R8-15). Using\n   REX Prefix in the form of REX.W promotes operation to 64 bits.\n\n   ADCX executes normally either inside or outside a transaction region.\n\n   Note: ADCX defines the OF flag differently than the ADD/ADC instructions\n   as defined in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 2A.\n\nFlags Affected \u00b6\n\n   CF is updated based on result. OF, SF, ZF, AF, and PF flags are\n   unmodified.\n"],
	["vrndscalesh", "VRNDSCALESH \u2014 Round Scalar FP16 Value to Include a Given Number of Fraction Bits\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   bit Mode Flag 64/32 CPUID       \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Round the low FP16   \n                                                         value in xmm3/m16 to \n                                                         a number of fraction \n                                                         bits specified by    \n   EVEX.LLIG.NP.0F3A.W0 0A /r /ib                        the imm8 field.      \n   VRNDSCALESH xmm1{k1}{z}, xmm2,  A V/V     AVX512-FP16 Store the result in  \n   xmm3/m16 {sae}, imm8                                  xmm1 subject to      \n                                                         writemask k1. Bits   \n                                                         127:16 from xmm2 are \n                                                         copied to            \n                                                         xmm1[127:16].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   This instruction rounds the low FP16 value in the second source operand by\n   the rounding mode specified in the immediate operand (see Table 5-32) and\n   places the result in the destination operand.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   The rounding process rounds the input to an integral value, plus number\n   bits of fraction that are specified by imm8[7:4] (to be included in the\n   result), and returns the result as a FP16 value.\n\n   Note that no overflow is induced while executing this instruction\n   (although the source is scaled by the imm8[7:4] value).\n\n   The immediate operand also specifies control fields for the rounding\n   operation. Three bit fields are defined and shown in Table 5-32, \u201cImm8\n   Controls for VRNDSCALEPH/VRNDSCALESH.\u201d Bit 3 of the immediate byte\n   controls the processor behavior for a precision exception, bit 2 selects\n   the source of rounding mode control, and bits 1:0 specify a non-sticky\n   rounding-mode value.\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN.\n\n   The sign of the result of this instruction is preserved, including the\n   sign of zero. Special cases are described in Table 5-33.\n\n   If this instruction encoding\u2019s SPE bit (bit 3) in the immediate operand is\n   1, VRNDSCALESH can set MXCSR.UE without MXCSR.PE.\n\n   The formula of the operation on each data element for VRNDSCALESH is:\n\n   ROUND(x) = 2^\u2212M *Round_to_INT(x * 2^M, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   M=imm[7:4];\n\n   The operation of x * 2^M is computed as if the exponent range is unlimited\n   (i.e., no overflow ever occurs).\n"],
	["stos:stosb:stosw:stosd:stosq", "                  STOS/STOSB/STOSW/STOSD/STOSQ \u2014 Store String\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n                                                  For legacy mode, store AL   \n   AA         STOS m8     ZO    Valid  Valid      at address ES:(E)DI; For    \n                                                  64-bit mode store AL at     \n                                                  address RDI or EDI.         \n                                                  For legacy mode, store AX   \n   AB         STOS m16    ZO    Valid  Valid      at address ES:(E)DI; For    \n                                                  64-bit mode store AX at     \n                                                  address RDI or EDI.         \n                                                  For legacy mode, store EAX  \n   AB         STOS m32    ZO    Valid  Valid      at address ES:(E)DI; For    \n                                                  64-bit mode store EAX at    \n                                                  address RDI or EDI.         \n   REX.W + AB STOS m64    ZO    Valid  N.E.       Store RAX at address RDI or \n                                                  EDI.                        \n                                                  For legacy mode, store AL   \n   AA         STOSB       ZO    Valid  Valid      at address ES:(E)DI; For    \n                                                  64-bit mode store AL at     \n                                                  address RDI or EDI.         \n                                                  For legacy mode, store AX   \n   AB         STOSW       ZO    Valid  Valid      at address ES:(E)DI; For    \n                                                  64-bit mode store AX at     \n                                                  address RDI or EDI.         \n                                                  For legacy mode, store EAX  \n   AB         STOSD       ZO    Valid  Valid      at address ES:(E)DI; For    \n                                                  64-bit mode store EAX at    \n                                                  address RDI or EDI.         \n   REX.W + AB STOSQ       ZO    Valid  N.E.       Store RAX at address RDI or \n                                                  EDI.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   In non-64-bit and default 64-bit mode; stores a byte, word, or doubleword\n   from the AL, AX, or EAX register (respectively) into the destination\n   operand. The destination operand is a memory location, the address of\n   which is read from either the ES:EDI or ES:DI register (depending on the\n   address-size attribute of the instruction and the mode of operation). The\n   ES segment cannot be overridden with a segment override prefix.\n\n   At the assembly-code level, two forms of the instruction are allowed: the\n   \u201cexplicit-operands\u201d form and the \u201cno-operands\u201d form. The explicit-operands\n   form (specified with the STOS mnemonic) allows the destination operand to\n   be specified explicitly. Here, the destination operand should be a symbol\n   that indicates the size and location of the destination value. The source\n   operand is then automatically selected to match the size of the\n   destination operand (the AL register for byte operands, AX for word\n   operands, EAX for doubleword operands). The explicit-operands form is\n   provided to allow documentation; however, note that the documentation\n   provided by this form can be misleading. That is, the destination operand\n   symbol must specify the correct type (size) of the operand (byte, word, or\n   doubleword), but it does not have to specify the correct location. The\n   location is always specified by the ES:(E)DI register. These must be\n   loaded correctly before the store string instruction is executed.\n\n   The no-operands form provides \u201cshort forms\u201d of the byte, word, doubleword,\n   and quadword versions of the STOS instructions. Here also ES:(E)DI is\n   assumed to be the destination operand and AL, AX, or EAX is assumed to be\n   the source operand. The size of the destination and source operands is\n   selected by the mnemonic: STOSB (byte read from register AL), STOSW (word\n   from AX), STOSD (doubleword from EAX).\n\n   After the byte, word, or doubleword is transferred from the register to\n   the memory location, the (E)DI register is incremented or decremented\n   according to the setting of the DF flag in the EFLAGS register. If the DF\n   flag is 0, the register is incremented; if the DF flag is 1, the register\n   is decremented (the register is incremented or decremented by 1 for byte\n   operations, by 2 for word operations, by 4 for doubleword operations).\n\n     To improve performance, more recent processors support modifications to\n     the processor\u2019s operation during the string store operations initiated\n     with STOS and STOSB. See Section 7.3.9.3 in the Intel^\u00ae 64 and IA-32\n     Architectures Software Developer\u2019s Manual, Volume 1, for additional\n     information on fast-string operation.\n\n   In 64-bit mode, the default address size is 64 bits, 32-bit address size\n   is supported using the prefix 67H. Using a REX prefix in the form of REX.W\n   promotes operation on doubleword operand to 64 bits. The promoted\n   no-operand mnemonic is STOSQ. STOSQ (and its explicit operands variant)\n   store a quadword from the RAX register into the destination addressed by\n   RDI or EDI. See the summary chart at the beginning of this section for\n   encoding data and limits.\n\n   The STOS, STOSB, STOSW, STOSD, STOSQ instructions can be preceded by the\n   REP prefix for block stores of ECX bytes, words, or doublewords. More\n   often, however, these instructions are used within a LOOP construct\n   because data needs to be moved into the AL, AX, or EAX register before it\n   can be stored. See \u201cREP/REPE/REPZ /REPNE/REPNZ\u2014Repeat String Operation\n   Prefix\u201d in this chapter for a description of the REP prefix.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["valignd:valignq", "              VALIGND/VALIGNQ \u2014 Align Doubleword/Quadword Vectors\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Shift right and merge     \n                                                    vectors xmm2 and          \n   EVEX.128.66.0F3A.W0 03                           xmm3/m128/m32bcst with    \n   /r ib VALIGND xmm1      A     V/V       AVX512VL double-word granularity   \n   {k1}{z}, xmm2,                          AVX512F  using imm8 as number of   \n   xmm3/m128/m32bcst, imm8                          elements to shift, and    \n                                                    store the final result in \n                                                    xmm1, under writemask.    \n                                                    Shift right and merge     \n                                                    vectors xmm2 and          \n   EVEX.128.66.0F3A.W1 03                           xmm3/m128/m64bcst with    \n   /r ib VALIGNQ xmm1      A     V/V       AVX512VL quad-word granularity     \n   {k1}{z}, xmm2,                          AVX512F  using imm8 as number of   \n   xmm3/m128/m64bcst, imm8                          elements to shift, and    \n                                                    store the final result in \n                                                    xmm1, under writemask.    \n                                                    Shift right and merge     \n                                                    vectors ymm2 and          \n   EVEX.256.66.0F3A.W0 03                           ymm3/m256/m32bcst with    \n   /r ib VALIGND ymm1      A     V/V       AVX512VL double-word granularity   \n   {k1}{z}, ymm2,                          AVX512F  using imm8 as number of   \n   ymm3/m256/m32bcst, imm8                          elements to shift, and    \n                                                    store the final result in \n                                                    ymm1, under writemask.    \n                                                    Shift right and merge     \n                                                    vectors ymm2 and          \n   EVEX.256.66.0F3A.W1 03                           ymm3/m256/m64bcst with    \n   /r ib VALIGNQ ymm1      A     V/V       AVX512VL quad-word granularity     \n   {k1}{z}, ymm2,                          AVX512F  using imm8 as number of   \n   ymm3/m256/m64bcst, imm8                          elements to shift, and    \n                                                    store the final result in \n                                                    ymm1, under writemask.    \n                                                    Shift right and merge     \n                                                    vectors zmm2 and          \n   EVEX.512.66.0F3A.W0 03                           zmm3/m512/m32bcst with    \n   /r ib VALIGND zmm1      A     V/V       AVX512F  double-word granularity   \n   {k1}{z}, zmm2,                                   using imm8 as number of   \n   zmm3/m512/m32bcst, imm8                          elements to shift, and    \n                                                    store the final result in \n                                                    zmm1, under writemask.    \n                                                    Shift right and merge     \n                                                    vectors zmm2 and          \n   EVEX.512.66.0F3A.W1 03                           zmm3/m512/m64bcst with    \n   /r ib VALIGNQ zmm1      A     V/V       AVX512F  quad-word granularity     \n   {k1}{z}, zmm2,                                   using imm8 as number of   \n   zmm3/m512/m64bcst, imm8                          elements to shift, and    \n                                                    store the final result in \n                                                    zmm1, under writemask.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Concatenates and shifts right doubleword/quadword elements of the first\n   source operand (the second operand) and the second source operand (the\n   third operand) into a 1024/512/256-bit intermediate vector. The low\n   512/256/128-bit of the intermediate vector is written to the destination\n   operand (the first operand) using the writemask k1. The destination and\n   first source operands are ZMM/YMM/XMM registers. The second source operand\n   can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 32/64-bit memory location.\n\n   This instruction is writemasked, so only those elements with the\n   corresponding bit set in vector mask register k1 are computed and stored\n   into zmm1. Elements in zmm1 with the corresponding bit clear in k1 retain\n   their previous values (merging-masking) or are set to 0 (zeroing-masking).\n"],
	["cli", "                           CLI \u2014 Clear Interrupt Flag\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description           \n                                                        Clear interrupt flag; \n   FA     CLI         ZO    Valid       Valid           interrupts disabled   \n                                                        when interrupt flag   \n                                                        cleared.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   In most cases, CLI clears the IF flag in the EFLAGS register and no other\n   flags are affected. Clearing the IF flag causes the processor to ignore\n   maskable external interrupts. The IF flag and the CLI and STI instruction\n   have no effect on the generation of exceptions and NMI interrupts.\n\n   Operation is different in two modes defined as follows:\n\n     * PVI mode (protected-mode virtual interrupts): CR0.PE = 1, EFLAGS.VM =\n       0, CPL = 3, and CR4.PVI = 1;\n     * VME mode (virtual-8086 mode extensions): CR0.PE = 1, EFLAGS.VM = 1,\n       and CR4.VME = 1.\n\n   If IOPL < 3 and either VME mode or PVI mode is active, CLI clears the VIF\n   flag in the EFLAGS register, leaving IF unaffected.\n\n   Table 3-7 indicates the action of the CLI instruction depending on the\n   processor operating mode, IOPL, and CPL.\n\n   Mode                    IOPL  CLI Result \n   Real-address            _X^1  IF = 0     \n   Protected, not PVI^2    \u2265 CPL IF = 0     \n                           < CPL #GP fault  \n   Protected, PVI^3        3     IF = 0     \n                           0\u20132   VIF = 0    \n   Virtual-8086, not VME^3 3     IF = 0     \n                           0\u20132   #GP fault  \n   Virtual-8086, VME^3     3     IF = 0     \n                           0\u20132   VIF = 0    \n\n   Table 3-7. Decision Table for CLI Results\n\n     1. X = This setting has no effect on instruction operation.\n\n     2. For this table, \u201cprotected mode\u201d applies whenever CR0.PE = 1 and\n     EFLAGS.VM = 0; it includes compatibility mode and 64-bit mode.\n\n     3. PVI mode and virtual-8086 mode each imply CPL = 3.\n\nFlags Affected \u00b6\n\n   Either the IF flag or the VIF flag is cleared to 0. Other flags are\n   unaffected.\n"],
	["maskmovq", "                  MASKMOVQ \u2014 Store Selected Bytes of Quadword\n\n   Opcode/Instruction   Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                Selectively write bytes from  \n   NP 0F F7 /r MASKMOVQ                         mm1 to memory location using  \n   mm1, mm2             RM    Valid  Valid      the byte mask in mm2. The     \n                                                default memory location is    \n                                                specified by DS:DI/EDI/RDI.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Stores selected bytes from the source operand (first operand) into a\n   64-bit memory location. The mask operand (second operand) selects which\n   bytes from the source operand are written to memory. The source and mask\n   operands are MMX technology registers. The memory location specified by\n   the effective address in the DI/EDI/RDI register (the default segment\n   register is DS, but this may be overridden with a segment-override\n   prefix). The memory location does not need to be aligned on a natural\n   boundary. (The size of the store address depends on the address-size\n   attribute.)\n\n   The most significant bit in each byte of the mask operand determines\n   whether the corresponding byte in the source operand is written to the\n   corresponding byte location in memory: 0 indicates no write and 1\n   indicates write.\n\n   The MASKMOVQ instruction generates a non-temporal hint to the processor to\n   minimize cache pollution. The non-temporal hint is implemented by using a\n   write combining (WC) memory type protocol (see \u201cCaching of Temporal vs.\n   Non-Temporal Data\u201d in Chapter 10, of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1). Because the WC\n   protocol uses a weakly-ordered memory consistency model, a fencing\n   operation implemented with the SFENCE or MFENCE instruction should be used\n   in conjunction with MASKMOVQ instructions if multiple processors might use\n   different memory types to read/write the destination memory locations.\n\n   This instruction causes a transition from x87 FPU to MMX technology state\n   (that is, the x87 FPU top-of-stack pointer is set to 0 and the x87 FPU tag\n   word is set to all 0s [valid]).\n\n   The behavior of the MASKMOVQ instruction with a mask of all 0s is as\n   follows:\n\n     * No data will be written to memory.\n     * Transition from x87 FPU to MMX technology state will occur.\n     * Exceptions associated with addressing memory and page faults may still\n       be signaled (implementation dependent).\n     * Signaling of breakpoints (code or data) is not guaranteed\n       (implementation dependent).\n     * If the destination memory region is mapped as UC or WP, enforcement of\n       associated semantics for these memory types is not guaranteed (that\n       is, is reserved) and is implementation-specific.\n\n   The MASKMOVQ instruction can be used to improve performance for algorithms\n   that need to merge data on a byteby-byte basis. It should not cause a read\n   for ownership; doing so generates unnecessary bandwidth since data is to\n   be written directly using the byte-mask without allocating old data prior\n   to the store.\n\n   In 64-bit mode, the memory address is specified by DS:RDI.\n"],
	["rsqrtps", "    RSQRTPS \u2014 Compute Reciprocals of Square Roots of Packed Single Precision\n                              Floating-PointValues\n\n                              64/32 bit CPUID                                 \n   Opcode*/Instruction  Op/En Mode      Feature Description\n                              Support   Flag    \n                                                Computes the approximate      \n                                                reciprocals of the square     \n   NP 0F 52 /r RSQRTPS  RM    V/V       SSE     roots of the packed single    \n   xmm1, xmm2/m128                              precision floating-point      \n                                                values in xmm2/m128 and       \n                                                stores the results in xmm1.   \n                                                Computes the approximate      \n   VEX.128.0F.WIG 52 /r                         reciprocals of the square     \n   VRSQRTPS xmm1,       RM    V/V       AVX     roots of packed single        \n   xmm2/m128                                    precision values in xmm2/mem  \n                                                and stores the results in     \n                                                xmm1.                         \n                                                Computes the approximate      \n   VEX.256.0F.WIG 52 /r                         reciprocals of the square     \n   VRSQRTPS ymm1,       RM    V/V       AVX     roots of packed single        \n   ymm2/m256                                    precision values in ymm2/mem  \n                                                and stores the results in     \n                                                ymm1.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs a SIMD computation of the approximate reciprocals of the square\n   roots of the four packed single precision floating-point values in the\n   source operand (second operand) and stores the packed single precision\n   floating-point results in the destination operand. The source operand can\n   be an XMM register or a 128-bit memory location. The destination operand\n   is an XMM register. See Figure 10-5 in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for an illustration\n   of a SIMD single precision floating-point operation.\n\n   The relative error for this approximation is:\n\n   |Relative Error| \u2264 1.5 \u2217 2^\u221212\n\n   The RSQRTPS instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e of the sign of the\n   source value is returned. A denormal source value is treated as a 0.0 (of\n   the same sign). When a source value is a negative value (other than \u22120.0),\n   a floating-point indefinite is returned. When a source value is an SNaN or\n   QNaN, the SNaN is converted to a QNaN or the source QNaN is returned.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["clts", "                     CLTS \u2014 Clear Task-Switched Flag in CR0\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description           \n   0F 06  CLTS        ZO    Valid       Valid           Clears TS flag in     \n                                                        CR0.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Clears the task-switched (TS) flag in the CR0 register. This instruction\n   is intended for use in operating-system procedures. It is a privileged\n   instruction that can only be executed at a CPL of 0. It is allowed to be\n   executed in real-address mode to allow initialization for protected mode.\n\n   The processor sets the TS flag every time a task switch occurs. The flag\n   is used to synchronize the saving of FPU context in multitasking\n   applications. See the description of the TS flag in the section titled\n   \u201cControl Registers\u201d in Chapter 2 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3A, for more information about this\n   flag.\n\n   CLTS operation is the same in non-64-bit modes and 64-bit mode.\n\n   See Chapter 26, \u201cVMX Non-Root Operation,\u201d of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3C, for more information\n   about the behavior of this instruction in VMX non-root operation.\n\nFlags Affected \u00b6\n\n   The TS flag in CR0 register is cleared.\n"],
	["hsubps", "      HSUBPS \u2014 Packed Single Precision Floating-Point Horizontal Subtract\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Horizontal subtract packed \n   F2 0F 7D /r HSUBPS      RM    V/V       SSE3    single precision           \n   xmm1, xmm2/m128                                 floating-point values from \n                                                   xmm2/m128 to xmm1.         \n   VEX.128.F2.0F.WIG 7D /r                         Horizontal subtract packed \n   VHSUBPS xmm1, xmm2,     RVM   V/V       AVX     single precision           \n   xmm3/m128                                       floating-point values from \n                                                   xmm2 and xmm3/mem.         \n   VEX.256.F2.0F.WIG 7D /r                         Horizontal subtract packed \n   VHSUBPS ymm1, ymm2,     RVM   V/V       AVX     single precision           \n   ymm3/m256                                       floating-point values from \n                                                   ymm2 and ymm3/mem.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Subtracts the single precision floating-point value in the second dword of\n   the destination operand from the first dword of the destination operand\n   and stores the result in the first dword of the destination operand.\n\n   Subtracts the single precision floating-point value in the fourth dword of\n   the destination operand from the third dword of the destination operand\n   and stores the result in the second dword of the destination operand.\n\n   Subtracts the single precision floating-point value in the second dword of\n   the source operand from the first dword of the source operand and stores\n   the result in the third dword of the destination operand.\n\n   Subtracts the single precision floating-point value in the fourth dword of\n   the source operand from the third dword of the source operand and stores\n   the result in the fourth dword of the destination operand.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n\n   See Figure 3-23 for HSUBPS; see Figure 3-24 for VHSUBPS.\n\n   HSUBPS xmm1, xmm2/m128 xmm2/ [127:96] [95:64] [63:32] [31:0] m128 xmm1\n   [127:96] [95:64] [63:32] [31:0] xmm2/m128 xmm2/m128 RESULT: xmm1[95:64] -\n   xmm1[31:0] - [95:64] - xmm2/ [31:0] - xmm2/ xmm1 xmm1[127:96] xmm1[63:32]\n   m128[127:96] m128[63:32] [127:96] [95:64] [63:32] [31:0] Figure 3-23.\n   HSUBPS\u2014Packed Single Precision Floating-Point Horizontal Subtract X7 X6 X5\n   X4 X3 X2 X1 X0 SRC1 Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 SRC2 Y6-Y7 Y4-Y5 X6-X7 X4-X5\n   Y2-Y3 Y0-Y1 DEST X2-X3 X0-X1 Figure 3-24. VHSUBPS Operation\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n"],
	["vp4dpwssd", " VP4DPWSSD \u2014 Dot Product of Signed Words With Dword Accumulation (4-Iterations)\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply signed words \n                                                        from source register  \n   EVEX.512.F2.0F38.W0 52                               block indicated by    \n   /r VP4DPWSSD           A     V/V       AVX512_4VNNIW zmm2 by signed words  \n   zmm1{k1}{z}, zmm2+3,                                 from m128 and         \n   m128                                                 accumulate resulting  \n                                                        signed dwords in      \n                                                        zmm1.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple     Operand 1        Operand 2 Operand 3 Operand 4   \n   A     Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   This instruction computes 4 sequential register source-block dot-products\n   of two signed word operands with doubleword accumulation; see Figure 8-1\n   below. The memory operand is sequentially selected in each of the four\n   steps.\n\n   In the above box, the notation of \u201c+3\u201d' is used to denote that the\n   instruction accesses 4 source registers based on that operand; sources are\n   consecutive, start in a multiple of 4 boundary, and contain the encoded\n   register operand.\n\n   This instruction supports memory fault suppression. The entire memory\n   operand is loaded if any bit of the lowest 16-bits of the mask is set to 1\n   or if a \u201cno masking\u201d encoding is used.\n\n   The tuple type Tuple1_4X implies that four 32-bit elements (16 bytes) are\n   referenced by the memory operation portion of this instruction.\n\n   16 16 16 16b a a a a0 b b b b0 32 32b c c0 c1=c1+a2*b0+a3*b1\n   c0=c0+a0*b0+a1*b1 32 32b Figure 8-1. Register Source-Block Dot Product of\n   Two Signed Word Operands With Doubleword Accumulation^1\n\n     1. For illustration purposes, one source-block dot product instance is\n     shown out of the four.\n"],
	["sqrtss", "         SQRTSS \u2014 Compute Square Root of Scalar Single Precision Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Computes square root of the \n   F3 0F 51 /r SQRTSS                             low single precision        \n   xmm1, xmm2/m32          A    V/V       SSE     floating-point value in     \n                                                  xmm2/m32 and stores the     \n                                                  results in xmm1.            \n                                                  Computes square root of the \n                                                  low single precision        \n                                                  floating-point value in     \n   VEX.LIG.F3.0F.WIG 51 /r                        xmm3/m32 and stores the     \n   VSQRTSS xmm1, xmm2,     B    V/V       AVX     results in xmm1. Also,      \n   xmm3/m32                                       upper single precision      \n                                                  floating-point values       \n                                                  (bits[127:32]) from xmm2    \n                                                  are copied to xmm1[127:32]. \n                                                  Computes square root of the \n                                                  low single precision        \n                                                  floating-point value in     \n   EVEX.LLIG.F3.0F.W0 51                          xmm3/m32 and stores the     \n   /r VSQRTSS xmm1         C    V/V       AVX512F results in xmm1 under       \n   {k1}{z}, xmm2,                                 writemask k1. Also, upper   \n   xmm3/m32{er}                                   single precision            \n                                                  floating-point values       \n                                                  (bits[127:32]) from xmm2    \n                                                  are copied to xmm1[127:32]. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Computes the square root of the low single precision floating-point value\n   in the second source operand and stores the single precision\n   floating-point result in the destination operand. The second source\n   operand can be an XMM register or a 32-bit memory location. The first\n   source and destination operands is an XMM register.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:32) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 and EVEX encoded versions: Bits 127:32 of the destination operand\n   are copied from the corresponding bits of the first source operand. Bits\n   (MAXVL-1:128) of the destination ZMM register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination\n   operand is updated according to the write-mask.\n\n   Software should ensure VSQRTSS is encoded with VEX.L=0. Encoding VSQRTSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["movshdup", "          MOVSHDUP \u2014 Replicate Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Move odd index single      \n   F3 0F 16 /r MOVSHDUP                            precision floating-point   \n   xmm1, xmm2/m128         A    V/V       SSE3     values from xmm2/mem and   \n                                                   duplicate each element     \n                                                   into xmm1.                 \n                                                   Move odd index single      \n   VEX.128.F3.0F.WIG 16 /r                         precision floating-point   \n   VMOVSHDUP xmm1,         A    V/V       AVX      values from xmm2/mem and   \n   xmm2/m128                                       duplicate each element     \n                                                   into xmm1.                 \n                                                   Move odd index single      \n   VEX.256.F3.0F.WIG 16 /r                         precision floating-point   \n   VMOVSHDUP ymm1,         A    V/V       AVX      values from ymm2/mem and   \n   ymm2/m256                                       duplicate each element     \n                                                   into ymm1.                 \n                                                   Move odd index single      \n   EVEX.128.F3.0F.W0 16 /r                AVX512VL precision floating-point   \n   VMOVSHDUP xmm1 {k1}{z}, B    V/V       AVX512F  values from xmm2/m128 and  \n   xmm2/m128                                       duplicate each element     \n                                                   into xmm1 under writemask. \n                                                   Move odd index single      \n   EVEX.256.F3.0F.W0 16 /r                AVX512VL precision floating-point   \n   VMOVSHDUP ymm1 {k1}{z}, B    V/V       AVX512F  values from ymm2/m256 and  \n   ymm2/m256                                       duplicate each element     \n                                                   into ymm1 under writemask. \n                                                   Move odd index single      \n   EVEX.512.F3.0F.W0 16 /r                         precision floating-point   \n   VMOVSHDUP zmm1 {k1}{z}, B    V/V       AVX512F  values from zmm2/m512 and  \n   zmm2/m512                                       duplicate each element     \n                                                   into zmm1 under writemask. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Duplicates odd-indexed single precision floating-point values from the\n   source operand (the second operand) to adjacent element pair in the\n   destination operand (the first operand). See Figure 4-3. The source\n   operand is an XMM, YMM or ZMM register or 128, 256 or 512-bit memory\n   location and the destination operand is an XMM, YMM or ZMM register.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed.\n\n   VEX.256 encoded version: Bits (MAXVL-1:256) of the destination register\n   are zeroed.\n\n   EVEX encoded version: The destination operand is updated at 32-bit\n   granularity according to the writemask.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   X7 X6 X5 X4 X3 X2 X1 X0 SRC DEST X7 X7 X5 X5 X3 X3 X1 X1 Figure 4-3.\n   MOVSHDUP Operation\n"],
	["dpps", "      DPPS \u2014 Dot Product of Packed Single Precision Floating-Point Values\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Selectively multiply       \n                                                   packed single precision    \n                                                   floating-point values from \n                                                   xmm1 with packed single    \n   66 0F 3A 40 /r ib DPPS  RMI   V/V       SSE4_1  precision floating-point   \n   xmm1, xmm2/m128, imm8                           values from xmm2, add and  \n                                                   selectively store the      \n                                                   packed single precision    \n                                                   floating-point values or   \n                                                   zero values to xmm1.       \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   VEX.128.66.0F3A.WIG 40                          values from xmm1 with      \n   /r ib VDPPS xmm1,xmm2,  RVMI  V/V       AVX     packed single precision    \n   xmm3/m128, imm8                                 floating-point values from \n                                                   xmm2/mem selectively add   \n                                                   and store to xmm1.         \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   VEX.256.66.0F3A.WIG 40                          values from ymm2 with      \n   /r ib VDPPS ymm1, ymm2, RVMI  V/V       AVX     packed single precision    \n   ymm3/m256, imm8                                 floating-point values from \n                                                   ymm3/mem, selectively add  \n                                                   pairs of elements and      \n                                                   store to ymm1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Conditionally multiplies the packed single precision floating-point values\n   in the destination operand (first operand) with the packed single\n   precision floats in the source (second operand) depending on a mask\n   extracted from the high 4 bits of the immediate byte (third operand). If a\n   condition mask bit in imm8[7:4] is zero, the corresponding multiplication\n   is replaced by a value of 0.0 in the manner described by Section 12.8.4 of\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n\n   The four resulting single precision values are summed into an intermediate\n   result. The intermediate result is conditionally broadcasted to the\n   destination using a broadcast mask specified by bits [3:0] of the\n   immediate byte.\n\n   If a broadcast mask bit is \u201c1\u201d, the intermediate result is copied to the\n   corresponding dword element in the destination operand. If a broadcast\n   mask bit is zero, the corresponding element in the destination is set to\n   zero.\n\n   DPPS follows the NaN forwarding rules stated in the Software Developer\u2019s\n   Manual, vol. 1, table 4-7. These rules do not cover horizontal\n   prioritization of NaNs. Horizontal propagation of NaNs to the destination\n   and the positioning of those NaNs in the destination is implementation\n   dependent. NaNs on the input sources or computationally generated NaNs\n   will have at least one NaN propagated to the destination.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["movdir64b", "                   MOVDIR64B \u2014 Move 64 Bytes as Direct Store\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature   Description\n                                Support   Flag      \n                                                    Move 64-bytes as          \n                                                    direct-store with         \n                                                    guaranteed 64-byte write  \n   66 0F 38 F8 /r                                   atomicity from the source \n   MOVDIR64B r16/r32/r64, A     V/V       MOVDIR64B memory operand address to \n   m512                                             destination memory        \n                                                    address specified as      \n                                                    offset to ES segment in   \n                                                    the register operand.     \n\nInstruction Operand Encoding^1 \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves 64-bytes as direct-store with 64-byte write atomicity from source\n   memory address to destination memory address. The source operand is a\n   normal memory operand. The destination operand is a memory location\n   specified in a general-purpose register. The register content is\n   interpreted as an offset into ES segment without any segment override. In\n   64-bit mode, the register operand width is 64-bits (32-bits with 67H\n   prefix). Outside of 64-bit mode, the register width is 32-bits when CS.D=1\n   (16-bits with 67H prefix), and 16-bits when CS.D=0 (32-bits with 67H\n   prefix). MOVDIR64B requires the destination address to be 64-byte aligned.\n   No alignment restriction is enforced for source operand.\n\n   MOVDIR64B first reads 64-bytes from the source memory address. It then\n   performs a 64-byte direct-store operation to the destination address. The\n   load operation follows normal read ordering based on source address\n   memory-type. The direct-store is implemented by using the write combining\n   (WC) memory type protocol for writing data. Using this protocol, the\n   processor does not write the data into the cache hierarchy, nor does it\n   fetch the corresponding cache line from memory into the cache hierarchy.\n   If the destination address is cached, the line is written-back (if\n   modified) and invalidated from the cache, before the direct-store.\n\n   Unlike stores with non-temporal hint which allow UC/WP memory-type for\n   destination to override the non-temporal hint, direct-stores always follow\n   WC memory type protocol irrespective of destination address memory type\n   (including UC/WP types). Unlike WC stores and stores with non-temporal\n   hint, direct-stores are eligible for immediate eviction from the\n   write-combining buffer, and thus not combined with younger stores\n   (including direct-stores) to the same address. Older WC and non-temporal\n   stores held in the write-combing buffer may be combined with younger\n   direct stores to the same address. Direct stores are weakly ordered\n   relative to other stores. Software that desires stronger ordering should\n   use a fencing instruction (MFENCE or SFENCE) before or after a direct\n   store to enforce the ordering desired.\n\n   There is no atomicity guarantee provided for the 64-byte load operation\n   from source address, and processor implementations may use multiple load\n   operations to read the 64-bytes. The 64-byte direct-store issued by\n   MOVDIR64B guarantees 64-byte write-completion atomicity. This means that\n   the data arrives at the destination in a single undivided 64-byte write\n   transaction.\n\n   Availability of the MOVDIR64B instruction is indicated by the presence of\n   the CPUID feature flag MOVDIR64B (bit 28 of the ECX register in leaf 07H,\n   see \u201cCPUID\u2014CPU Identification\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 2A).\n\n     1. The Mod field of the ModR/M byte cannot have value 11B.\n"],
	["eexit", "                            EEXIT \u2014 Exits an Enclave\n\n   Opcode/Op/En 64/32 CPUID Description Instruction bit Mode Feature Support  \n   Flag EAX = 04H IR V/V SGX1 This leaf function is used to exit an enclave.  \n   ENCLU[EEXIT]                                                               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX        RBX                            RCX                        \n   IR    EEXIT (In) Target address outside the     Address of the current AEP \n                    enclave (In)                   (Out)                      \n\n  Description \u00b6\n\n   The ENCLU[EEXIT] instruction exits the currently executing enclave and\n   branches to the location specified in RBX. RCX receives the current AEP.\n   If RBX is not within the CS (32-bit mode) or is not canonical (64-bit\n   mode) a #GP(0) results.\n\nEEXIT Memory Parameter Semantics \u00b6\n\n   Target Address                      \n   Non-Enclave read and execute access \n\n   If RBX specifies an address that is inside the enclave, the instruction\n   will complete normally. The fetch of the next instruction will occur in\n   non-enclave mode, but will attempt to fetch from inside the enclave. This\n   fetch returns a fixed data pattern.\n\n   If secrets are contained in any registers, it is responsibility of enclave\n   software to clear those registers.\n\n   If XCR0 was modified on enclave entry, it is restored to the value it had\n   at the time of the most recent EENTER or ERESUME.\n\n   If the enclave is opt-out, RFLAGS.TF is loaded from the value previously\n   saved on EENTER.\n\n   Code and data breakpoints are unsuppressed.\n\n   Performance monitoring counters are unsuppressed.\n\n  Concurrency Restrictions \u00b6\n\n   Leaf  Parameter Base Concurrency Restrictions\n                                 On Conflict   \n   EEXIT           Concurrent    \n\n   Table 38-64. Base Concurrency Restrictions of EEXIT\n\n                   Additional Concurrency Restrictions\n                   vs. EACCEPT, EACCEPTCOPY,                                 \n                   vs. EADD, EEXTEND, EINIT                                  \n                   vs. ETRACK, ETRACKC Access  vs. EADD, EEXTEND,\n                   vs. ETRACK, ETRACKC Access  EINIT vs. EADD,    vs. ETRACK,\n                   On Conflict Access vs.      EEXTEND, EINIT vs. ETRACKC\n   Leaf  Parameter ETRACK, ETRACKC Access On   ETRACK, ETRACKC\n                   Conflict EMODPE, EMODPR,  \n                   EMODT                     \n                   Access On Conflict Access \n                   On Conflict Access Access \n                   On Conflict Access On     \n                   Conflict                  \n   EEXIT           Concurrent                  Concurrent         Concurrent \n\n   Table 38-65. Additional Concurrency Restrictions of EEXIT\n\n  Flags Affected \u00b6\n\n   RFLAGS.TF is restored from the value previously saved in EENTER or\n   ERESUME.\n"],
	["vzeroall", "                  VZEROALL \u2014 Zero XMM, YMM, and ZMM Registers\n\n                             64/32 bit    CPUID                               \n   Opcode/Instruction Op /En Mode Support Feature Description\n                                          Flag    \n   VEX.256.0F.WIG 77  ZO     V/V          AVX     Zero some of the XMM, YMM,  \n   VZEROALL                                       and ZMM registers.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   In 64-bit mode, the instruction zeroes XMM0-XMM15, YMM0-YMM15, and\n   ZMM0-ZMM15. Outside 64-bit mode, it zeroes only XMM0-XMM7, YMM0-YMM7, and\n   ZMM0-ZMM7. VZEROALL does not modify ZMM16-ZMM31.\n\n   Note: VEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD. In Compatibility and legacy 32-bit mode only the lower 8 registers\n   are modified.\n"],
	["aesdeclast", "           AESDECLAST \u2014 Perform Last Round of an AES Decryption Flow\n\n                                   64/32-bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                             Flag     \n                                                      Perform the last round  \n                                                      of an AES decryption    \n                                                      flow, using the         \n   66 0F 38 DF /r AESDECLAST                          Equivalent Inverse      \n   xmm1, xmm2/m128           A     V/V       AES      Cipher, using one       \n                                                      128-bit data (state)    \n                                                      from xmm1 with one      \n                                                      128-bit round key from  \n                                                      xmm2/m128.              \n                                                      Perform the last round  \n                                                      of an AES decryption    \n                                                      flow, using the         \n   VEX.128.66.0F38.WIG DF /r                          Equivalent Inverse      \n   VAESDECLAST xmm1, xmm2,   B     V/V       AES AVX  Cipher, using one       \n   xmm3/m128                                          128-bit data (state)    \n                                                      from xmm2 with one      \n                                                      128-bit round key from  \n                                                      xmm3/m128; store the    \n                                                      result in xmm1.         \n                                                      Perform the last round  \n                                                      of an AES decryption    \n                                                      flow, using the         \n   VEX.256.66.0F38.WIG DF /r                          Equivalent Inverse      \n   VAESDECLAST ymm1, ymm2,   B     V/V       VAES     Cipher, using two       \n   ymm3/m256                                          128-bit data (state)    \n                                                      from ymm2 with two      \n                                                      128-bit round keys from \n                                                      ymm3/m256; store the    \n                                                      result in ymm1.         \n                                                      Perform the last round  \n                                                      of an AES decryption    \n                                                      flow, using the         \n   EVEX.128.66.0F38.WIG DF                            Equivalent Inverse      \n   /r VAESDECLAST xmm1,      C     V/V       VAES     Cipher, using one       \n   xmm2, xmm3/m128                           AVX512VL 128-bit data (state)    \n                                                      from xmm2 with one      \n                                                      128-bit round key from  \n                                                      xmm3/m128; store the    \n                                                      result in xmm1.         \n                                                      Perform the last round  \n                                                      of an AES decryption    \n                                                      flow, using the         \n   EVEX.256.66.0F38.WIG DF                            Equivalent Inverse      \n   /r VAESDECLAST ymm1,      C     V/V       VAES     Cipher, using two       \n   ymm2, ymm3/m256                           AVX512VL 128-bit data (state)    \n                                                      from ymm2 with two      \n                                                      128-bit round keys from \n                                                      ymm3/m256; store the    \n                                                      result in ymm1.         \n                                                      Perform the last round  \n                                                      of an AES decryption    \n                                                      flow, using the         \n   EVEX.512.66.0F38.WIG DF                            Equivalent Inverse      \n   /r VAESDECLAST zmm1,      C     V/V       VAES     Cipher, using           \n   zmm2, zmm3/m512                           AVX512F  four128-bit data        \n                                                      (state) from zmm2 with  \n                                                      four 128-bit round keys \n                                                      from zmm3/m512; store   \n                                                      the result in zmm1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A      ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A      ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   This instruction performs the last round of the AES decryption flow using\n   the Equivalent Inverse Cipher, using one/two/four (depending on vector\n   length) 128-bit data (state) from the first source operand with\n   one/two/four (depending on vector length) round key(s) from the second\n   source operand, and stores the result in the destination operand.\n\n   VEX and EVEX encoded versions of the instruction allow 3-operand\n   (non-destructive) operation. The legacy encoded versions of the\n   instruction require that the first source operand and the destination\n   operand are the same and must be an XMM register.\n\n   The EVEX encoded form of this instruction does not support memory fault\n   suppression.\n"],
	["pshuflw", "                       PSHUFLW \u2014 Shuffle Packed Low Words\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Shuffle the low words in \n   F2 0F 70 /r ib PSHUFLW                            xmm2/m128 based on the   \n   xmm1, xmm2/m128, imm8    A     V/V       SSE2     encoding in imm8 and     \n                                                     store the result in      \n                                                     xmm1.                    \n                                                     Shuffle the low words in \n   VEX.128.F2.0F.WIG 70 /r                           xmm2/m128 based on the   \n   ib VPSHUFLW xmm1,        A     V/V       AVX      encoding in imm8 and     \n   xmm2/m128, imm8                                   store the result in      \n                                                     xmm1.                    \n                                                     Shuffle the low words in \n   VEX.256.F2.0F.WIG 70 /r                           ymm2/m256 based on the   \n   ib VPSHUFLW ymm1,        A     V/V       AVX2     encoding in imm8 and     \n   ymm2/m256, imm8                                   store the result in      \n                                                     ymm1.                    \n                                                     Shuffle the low words in \n   EVEX.128.F2.0F.WIG 70 /r                 AVX512VL xmm2/m128 based on the   \n   ib VPSHUFLW xmm1         B     V/V       AVX512BW encoding in imm8 and     \n   {k1}{z}, xmm2/m128, imm8                          store the result in xmm1 \n                                                     under write mask k1.     \n                                                     Shuffle the low words in \n   EVEX.256.F2.0F.WIG 70 /r                 AVX512VL ymm2/m256 based on the   \n   ib VPSHUFLW ymm1         B     V/V       AVX512BW encoding in imm8 and     \n   {k1}{z}, ymm2/m256, imm8                          store the result in ymm1 \n                                                     under write mask k1.     \n                                                     Shuffle the low words in \n   EVEX.512.F2.0F.WIG 70 /r                          zmm2/m512 based on the   \n   ib VPSHUFLW zmm1         B     V/V       AVX512BW encoding in imm8 and     \n   {k1}{z}, zmm2/m512, imm8                          store the result in zmm1 \n                                                     under write mask k1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n   B     Full Mem   ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Copies words from the low quadword of a 128-bit lane of the source operand\n   and inserts them in the low quadword of the destination operand at word\n   locations (of the respective lane) selected with the immediate operand.\n   The 256-bit operation is similar to the in-lane operation used by the\n   256-bit VPSHUFD instruction, which is illustrated in Figure 4-16. For\n   128-bit operation, only the low 128-bit lane is operative. Each 2-bit\n   field in the immediate operand selects the contents of one word location\n   in the low quadword of the destination operand. The binary encodings of\n   the immediate operand fields select words (0, 1, 2 or 3) from the low\n   quadword of the source operand to be copied to the destination operand.\n   The high quadword of the source operand is copied to the high quadword of\n   the destination operand, for each 128-bit lane.\n\n   Note that this instruction permits a word in the low quadword of the\n   source operand to be copied to more than one word location in the low\n   quadword of the destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The destination operand is an XMM register.\n   The source operand can be an XMM register or a 128-bit memory location.\n   Bits (MAXVL-1:128) of the corresponding YMM destination register remain\n   unchanged.\n\n   VEX.128 encoded version: The destination operand is an XMM register. The\n   source operand can be an XMM register or a 128-bit memory location. Bits\n   (MAXVL-1:128) of the destination YMM register are zeroed.\n\n   VEX.256 encoded version: The destination operand is an YMM register. The\n   source operand can be an YMM register or a 256-bit memory location.\n\n   EVEX encoded version: The destination operand is a ZMM/YMM/XMM registers.\n   The source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location. The destination is updated according to the write-mask.\n\n   Note: In VEX encoded versions, VEX.vvvv is reserved and must be 1111b\n   otherwise instructions will #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpexpandd", "      VPEXPANDD \u2014 Load Sparse Packed Doubleword Integer Values From Dense\n                                Memory/Register\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Expand packed           \n   EVEX.128.66.0F38.W0 89 /r                 AVX512VL double-word integer     \n   VPEXPANDD xmm1 {k1}{z},   A     V/V       AVX512F  values from xmm2/m128   \n   xmm2/m128                                          to xmm1 using writemask \n                                                      k1.                     \n                                                      Expand packed           \n   EVEX.256.66.0F38.W0 89 /r                 AVX512VL double-word integer     \n   VPEXPANDD ymm1 {k1}{z},   A     V/V       AVX512F  values from ymm2/m256   \n   ymm2/m256                                          to ymm1 using writemask \n                                                      k1.                     \n                                                      Expand packed           \n   EVEX.512.66.0F38.W0 89 /r                          double-word integer     \n   VPEXPANDD zmm1 {k1}{z},   A     V/V       AVX512F  values from zmm2/m512   \n   zmm2/m512                                          to zmm1 using writemask \n                                                      k1.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Expand (load) up to 16 contiguous doubleword integer values of the input\n   vector in the source operand (the second operand) to sparse elements in\n   the destination operand (the first operand), selected by the writemask k1.\n   The destination operand is a ZMM register, the source operand can be a ZMM\n   register or memory location.\n\n   The input vector starts from the lowest element in the source operand. The\n   opmask register k1 selects the destination elements (a partial vector or\n   sparse elements if less than 8 elements) to be replaced by the ascending\n   elements in the input vector. Destination elements not selected by the\n   writemask k1 are either unmodified or zeroed, depending on EVEX.z.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["vrndscaleps", "VRNDSCALEPS \u2014 Round Packed Float32 Values to Include a Given Number of Fraction\n                                      Bits\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Rounds packed           \n                                                      single-precision        \n                                                      floating-point values   \n   EVEX.128.66.0F3A.W0 08 /r                          in xmm2/m128/m32bcst to \n   ib VRNDSCALEPS xmm1       A     V/V       AVX512VL a number of fraction    \n   {k1}{z},                                  AVX512F  bits specified by the   \n   xmm2/m128/m32bcst, imm8                            imm8 field. Stores the  \n                                                      result in xmm1          \n                                                      register. Under         \n                                                      writemask.              \n                                                      Rounds packed           \n                                                      single-precision        \n                                                      floating-point values   \n   EVEX.256.66.0F3A.W0 08 /r                          in ymm2/m256/m32bcst to \n   ib VRNDSCALEPS ymm1       A     V/V       AVX512VL a number of fraction    \n   {k1}{z},                                  AVX512F  bits specified by the   \n   ymm2/m256/m32bcst, imm8                            imm8 field. Stores the  \n                                                      result in ymm1          \n                                                      register. Under         \n                                                      writemask.              \n                                                      Rounds packed           \n                                                      single-precision        \n   EVEX.512.66.0F3A.W0 08 /r                          floating-point values   \n   ib VRNDSCALEPS zmm1                                in zmm2/m512/m32bcst to \n   {k1}{z},                  A     V/V       AVX512F  a number of fraction    \n   zmm2/m512/m32bcst{sae},                            bits specified by the   \n   imm8                                               imm8 field. Stores the  \n                                                      result in zmm1 register \n                                                      using writemask.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\n  Description \u00b6\n\n   Round the single-precision floating-point values in the source operand by\n   the rounding mode specified in the immediate operand (see Figure 5-29) and\n   places the result in the destination operand.\n\n   The destination operand (the first operand) is a ZMM register\n   conditionally updated according to the writemask. The source operand (the\n   second operand) can be a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 32-bit memory location.\n\n   The rounding process rounds the input to an integral value, plus number\n   bits of fraction that are specified by imm8[7:4] (to be included in the\n   result) and returns the result as a single-precision floating-point value.\n\n   It should be noticed that no overflow is induced while executing this\n   instruction (although the source is scaled by the imm8[7:4] value).\n\n   The immediate operand also specifies control fields for the rounding\n   operation, three bit fields are defined and shown in the \u201cImmediate\n   Control Description\u201d figure below. Bit 3 of the immediate byte controls\n   the processor behavior for a precision exception, bit 2 selects the source\n   of rounding mode control. Bits 1:0 specify a non-sticky rounding-mode\n   value (immediate control table below lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   The sign of the result of this instruction is preserved, including the\n   sign of zero.\n\n   The formula of the operation on each data element for VRNDSCALEPS is\n\n   ROUND(x) = 2^-M*Round_to_INT(x*2^M, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   M=imm[7:4];\n\n   The operation of x*2^M is computed as if the exponent range is unlimited\n   (i.e., no overflow ever occurs).\n\n   VRNDSCALEPS is a more general form of the VEX-encoded VROUNDPS\n   instruction. In VROUNDPS, the formula of the operation on each element is\n\n   ROUND(x) = Round_to_INT(x, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n\n   Handling of special case of input values are listed in Table 5-31.\n"],
	["vfmsubadd132ph:vfmsubadd213ph:vfmsubadd231ph", "              VFMSUBADD132PH/VFMSUBADD213PH/VFMSUBADD231PH \u2014 Fused\n             Multiply-AlternatingSubtract/Add of Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 97 /r               AVX512-FP16 xmm3/m128/m16bcst,     \n   VFMSUBADD132PH xmm1{k1}{z},   A V/V     AVX512VL    subtract/add elements  \n   xmm2, xmm3/m128/m16bcst                             in xmm2, and store the \n                                                       result in xmm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 97 /r               AVX512-FP16 ymm3/m256/m16bcst,     \n   VFMSUBADD132PH ymm1{k1}{z},   A V/V     AVX512VL    subtract/add elements  \n   ymm2, ymm3/m256/m16bcst                             in ymm2, and store the \n                                                       result in ymm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 97 /r                           zmm3/m512/m16bcst,     \n   VFMSUBADD132PH zmm1{k1}{z},   A V/V     AVX512-FP16 subtract/add elements  \n   zmm2, zmm3/m512/m16bcst {er}                        in zmm2, and store the \n                                                       result in zmm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 A7 /r                           xmm2, subtract/add     \n   VFMSUBADD213PH xmm1{k1}{z},   A V/V     AVX512-FP16 elements in            \n   xmm2, xmm3/m128/m16bcst                 AVX512VL    xmm3/m128/m16bcst, and \n                                                       store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 A7 /r                           ymm2, subtract/add     \n   VFMSUBADD213PH ymm1{k1}{z},   A V/V     AVX512-FP16 elements in            \n   ymm2, ymm3/m256/m16bcst                 AVX512VL    ymm3/m256/m16bcst, and \n                                                       store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 A7 /r                           zmm2, subtract/add     \n   VFMSUBADD213PH zmm1{k1}{z},   A V/V     AVX512-FP16 elements in            \n   zmm2, zmm3/m512/m16bcst {er}                        zmm3/m512/m16bcst, and \n                                                       store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from xmm2 and   \n   EVEX.128.66.MAP6.W0 B7 /r               AVX512-FP16 xmm3/m128/m16bcst,     \n   VFMSUBADD231PH xmm1{k1}{z},   A V/V     AVX512VL    subtract/add elements  \n   xmm2, xmm3/m128/m16bcst                             in xmm1, and store the \n                                                       result in xmm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from ymm2 and   \n   EVEX.256.66.MAP6.W0 B7 /r               AVX512-FP16 ymm3/m256/m16bcst,     \n   VFMSUBADD231PH ymm1{k1}{z},   A V/V     AVX512VL    subtract/add elements  \n   ymm2, ymm3/m256/m16bcst                             in ymm1, and store the \n                                                       result in ymm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from zmm2 and   \n   EVEX.512.66.MAP6.W0 B7 /r                           zmm3/m512/m16bcst,     \n   VFMSUBADD231PH zmm1{k1}{z},   A V/V     AVX512-FP16 subtract/add elements  \n   zmm2, zmm3/m512/m16bcst {er}                        in zmm1, and store the \n                                                       result in zmm1 subject \n                                                       to writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a packed multiply-add (even elements) or\n   multiply-subtract (odd elements) computation on FP16 values using three\n   source operands and writes the results in the destination operand. The\n   destination operand is also the first source operand. The notation \u201c132\u201d,\n   \u201c213\u201d and \u201c231\u201d indicate the use of the operands in A * B \u00b1 C, where each\n   digit corresponds to the operand number, with the destination being\n   operand 1; see Table 5-8.\n\n   The destination elements are updated according to the writemask.\n\n   Notation Odd Elements          Even Elements         \n   132      dest = dest*src3-src2 dest = dest*src3+src2 \n   231      dest = src2*src3-dest dest = src2*src3+dest \n   213      dest = src2*dest-src3 dest = src2*dest+src3 \n\n   Table 5-8. VFMSUBADD[132,213,231]PH Notation for Odd and Even Elements\n"],
	["umonitor", "                  UMONITOR \u2014 User Level Set Up Monitor Address\n\n   Opcode /          64/32 bit    CPUID                                       \n   Instruction Op/En Mode Support Feature Description\n                                  Flag    \n                                          Sets up a linear address range to   \n   F3 0F AE /6                            be monitored by hardware and        \n   UMONITOR    A     V/V          WAITPKG activates the monitor. The address  \n   r16/r32/r64                            range should be a write-back memory \n                                          caching type. The address is        \n                                          contained in r16/r32/r64.           \n\nInstruction Operand Encoding^1 \u00b6\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The UMONITOR instruction arms address monitoring hardware using an address\n   specified in the source register (the address range that the monitoring\n   hardware checks for store operations can be determined by using the CPUID\n   monitor leaf function, EAX=05H). A store to an address within the\n   specified address range triggers the monitoring hardware. The state of\n   monitor hardware is used by UMWAIT.\n\n   The content of the source register is an effective address. By default,\n   the DS segment is used to create a linear address that is monitored.\n   Segment overrides can be used. The address range must use memory of the\n   write-back type. Only write-back memory is guaranteed to correctly trigger\n   the monitoring hardware. Additional information on determining what\n   address range to use in order to prevent false wake-ups is described in\n   Chapter 9, \u201cMultipleProcessor Management\u201a\u201d of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3A.\n\n     1. The Mod field of the ModR/M byte must have value 11B.\n\n   The UMONITOR instruction is ordered as a load operation with respect to\n   other memory transactions. The instruction is subject to the permission\n   checking and faults associated with a byte load. Like a load, UMONITOR\n   sets the A-bit but not the D-bit in page tables.\n\n   UMONITOR and UMWAIT are available when CPUID.7.0:ECX.WAITPKG[bit 5] is\n   enumerated as 1. UMONITOR and UMWAIT may be executed at any privilege\n   level. Except for the width of the source register, the instruction\u2019s\n   operation is the same in non-64-bit modes and in 64-bit mode.\n\n   UMONITOR does not interoperate with the legacy MWAIT instruction. If\n   UMONITOR was executed prior to executing MWAIT and following the most\n   recent execution of the legacy MONITOR instruction, MWAIT will not enter\n   an optimized state. Execution will continue to the instruction following\n   MWAIT.\n\n   The UMONITOR instruction causes a transactional abort when used inside a\n   transactional region.\n\n   The width of the source register (16b, 32b or 64b) is determined by the\n   effective addressing width, which is affected in the standard way by the\n   machine mode settings and 67 prefix.\n"],
	["vcvtneps2bf16", "         VCVTNEPS2BF16 \u2014 Convert Packed Single Data to Packed BF16 Data\n\n                                64/32 Bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n   EVEX.128.F3.0F38.W0 72                               Convert packed single \n   /r VCVTNEPS2BF16                       AVX512VL      data from xmm2/m128   \n   xmm1{k1}{z},           A     V/V       AVX512_BF16   to packed BF16 data   \n   xmm2/m128/m32bcst                                    in xmm1 with          \n                                                        writemask k1.         \n   EVEX.256.F3.0F38.W0 72                               Convert packed single \n   /r VCVTNEPS2BF16                       AVX512VL      data from ymm2/m256   \n   xmm1{k1}{z},           A     V/V       AVX512_BF16   to packed BF16 data   \n   ymm2/m256/m32bcst                                    in xmm1 with          \n                                                        writemask k1.         \n   EVEX.512.F3.0F38.W0 72                               Convert packed single \n   /r VCVTNEPS2BF16                       AVX512F       data from zmm2/m512   \n   ymm1{k1}{z},           A     V/V       AVX512_BF16   to packed BF16 data   \n   zmm2/m512/m32bcst                                    in ymm1 with          \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts one SIMD register of packed single data into a single register of\n   packed BF16 data.\n\n   This instruction uses \u201cRound to nearest (even)\u201d rounding mode. Output\n   denormals are always flushed to zero and input denormals are always\n   treated as zero. MXCSR is not consulted nor updated.\n\n   As the instruction operand encoding table shows, the EVEX.vvvv field is\n   not used for encoding an operand. EVEX.vvvv is reserved and must be 0b1111\n   otherwise instructions will #UD.\n"],
	["div", "                             DIV \u2014 Unsigned Divide\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n                                                  Unsigned divide AX by r/m8, \n   F6 /6      DIV r/m8    M     Valid  Valid      with result stored in AL := \n                                                  Quotient, AH := Remainder.  \n   REX + F6                                       Unsigned divide AX by r/m8, \n   /6         DIV r/m8^1  M     Valid  N.E.       with result stored in AL := \n                                                  Quotient, AH := Remainder.  \n                                                  Unsigned divide DX:AX by    \n   F7 /6      DIV r/m16   M     Valid  Valid      r/m16, with result stored   \n                                                  in AX := Quotient, DX :=    \n                                                  Remainder.                  \n                                                  Unsigned divide EDX:EAX by  \n   F7 /6      DIV r/m32   M     Valid  Valid      r/m32, with result stored   \n                                                  in EAX := Quotient, EDX :=  \n                                                  Remainder.                  \n                                                  Unsigned divide RDX:RAX by  \n   REX.W + F7 DIV r/m64   M     Valid  N.E.       r/m64, with result stored   \n   /6                                             in RAX := Quotient, RDX :=  \n                                                  Remainder.                  \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Divides unsigned the value in the AX, DX:AX, EDX:EAX, or RDX:RAX registers\n   (dividend) by the source operand (divisor) and stores the result in the AX\n   (AH:AL), DX:AX, EDX:EAX, or RDX:RAX registers. The source operand can be a\n   general-purpose register or a memory location. The action of this\n   instruction depends on the operand size (dividend/divisor). Division using\n   64-bit operand is available only in 64-bit mode.\n\n   Non-integral results are truncated (chopped) towards 0. The remainder is\n   always less than the divisor in magnitude. Overflow is indicated with the\n   #DE (divide error) exception rather than with the CF flag.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. In 64-bit mode when\n   REX.W is applied, the instruction divides the unsigned value in RDX:RAX by\n   the source operand and stores the quotient in RAX, the remainder in RDX.\n\n   See the summary chart at the beginning of this section for encoding data\n   and limits. See Table 3-15.\n\n   Operand Size            Dividend Divisor Quotient Remainder Maximum        \n                                                               Quotient       \n   Word/byte               AX       r/m8    AL       AH        255            \n   Doubleword/word         DX:AX    r/m16   AX       DX        65,535         \n   Quadword/doubleword     EDX:EAX  r/m32   EAX      EDX       2^32 \u2212 1       \n   Doublequadword/quadword RDX:RAX  r/m64   RAX      RDX       2^64 \u2212 1       \n\n   Table 3-15. DIV Action\n\nFlags Affected \u00b6\n\n   The CF, OF, SF, ZF, AF, and PF flags are undefined.\n"],
	["rstorssp", "                 RSTORSSP \u2014 Restore Saved Shadow Stack Pointer\n\n   Opcode/Instruction            Op/En 64/32 bit    CPUID        Description  \n                                       Mode Support Feature Flag \n   F3 0F 01 /5 (mod!=11, /5,     M     V/V          CET_SS       Restore SSP. \n   memory only) RSTORSSP m64     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Restores SSP from the shadow-stack-restore token pointed to by m64. If the\n   SSP restore was successful then the instruction replaces the\n   shadow-stack-restore token with a previous-ssp token. The instruction sets\n   the CF flag to indicate whether the SSP address recorded in the\n   shadow-stack-restore token that was processed was 4 byte aligned, i.e.,\n   whether an alignment hole was created when the restore-shadow-stack token\n   was pushed on this shadow stack.\n\n   Following RSTORSSP if a restore-shadow-stack token needs to be saved on\n   the previous shadow stack, use the SAVEPREVSSP instruction.\n\n   If pushing a restore-shadow-stack token on the previous shadow stack is\n   not required, the previous-ssp token can be popped using the INCSSPQ\n   instruction. If the CF flag was set to indicate presence of an alignment\n   hole, an additional INCSSPD instruction is needed to advance the SSP past\n   the alignment hole.\n\nFlags Affected \u00b6\n\n   CF is set to indicate if the shadow stack pointer in the restore token was\n   4 byte aligned, else it is cleared. ZF, PF, AF, OF, and SF are cleared.\n"],
	["frstor", "                         FRSTOR \u2014 Restore x87 FPU State\n\n   Opcode  Mode Leg Mode Description                              \n   DD /4                 Load FPU state from m94byte or m108byte. \n\nDescription \u00b6\n\n   Loads the FPU state (operating environment and register stack) from the\n   memory area specified with the source operand. This state data is\n   typically written to the specified memory location by a previous\n   FSAVE/FNSAVE instruction.\n\n   The FPU operating environment consists of the FPU control word, status\n   word, tag word, instruction pointer, data pointer, and last opcode.\n   Figures 8-9 through 8-12 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, show the layout in memory of the\n   stored environment, depending on the operating mode of the processor\n   (protected or real) and the current operand-size attribute (16-bit or\n   32-bit). In virtual-8086 mode, the real mode layouts are used. The\n   contents of the FPU register stack are stored in the 80 bytes immediately\n   following the operating environment image.\n\n   The FRSTOR instruction should be executed in the same operating mode as\n   the corresponding FSAVE/FNSAVE instruction.\n\n   If one or more unmasked exception bits are set in the new FPU status word,\n   a floating-point exception will be generated upon execution of the next\n   floating-point instruction (except for the no-wait floating-point\n   instructions, see the section titled \u201cSoftware Exception Handling\u201d in\n   Chapter 8 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1). To avoid raising exceptions when loading a new\n   operating environment, clear all the exception flags in the FPU status\n   word that is being loaded.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   The C0, C1, C2, C3 flags are loaded.\n"],
	["cmpps", "         CMPPS \u2014 Compare Packed Single Precision Floating-Point Values\n\n                              Op / 64/32 bit CPUID                            \n   Opcode/Instruction         En   Mode      Feature  Description\n                                   Support   Flag     \n                                                      Compare packed single   \n                                                      precision               \n   NP 0F C2 /r ib CMPPS xmm1,                         floating-point values   \n   xmm2/m128, imm8            A    V/V       SSE      in xmm2/m128 and xmm1   \n                                                      using bits 2:0 of imm8  \n                                                      as a comparison         \n                                                      predicate.              \n                                                      Compare packed single   \n                                                      precision               \n   VEX.128.0F.WIG C2 /r ib                            floating-point values   \n   VCMPPS xmm1, xmm2,         B    V/V       AVX      in xmm3/m128 and xmm2   \n   xmm3/m128, imm8                                    using bits 4:0 of imm8  \n                                                      as a comparison         \n                                                      predicate.              \n                                                      Compare packed single   \n                                                      precision               \n   VEX.256.0F.WIG C2 /r ib                            floating-point values   \n   VCMPPS ymm1, ymm2,         B    V/V       AVX      in ymm3/m256 and ymm2   \n   ymm3/m256, imm8                                    using bits 4:0 of imm8  \n                                                      as a comparison         \n                                                      predicate.              \n                                                      Compare packed single   \n                                                      precision               \n                                                      floating-point values   \n   EVEX.128.0F.W0 C2 /r ib                            in xmm3/m128/m32bcst    \n   VCMPPS k1 {k2}, xmm2,      C    V/V       AVX512VL and xmm2 using bits 4:0 \n   xmm3/m128/m32bcst, imm8                   AVX512F  of imm8 as a comparison \n                                                      predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed single   \n                                                      precision               \n                                                      floating-point values   \n   EVEX.256.0F.W0 C2 /r ib                            in ymm3/m256/m32bcst    \n   VCMPPS k1 {k2}, ymm2,      C    V/V       AVX512VL and ymm2 using bits 4:0 \n   ymm3/m256/m32bcst, imm8                   AVX512F  of imm8 as a comparison \n                                                      predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed single   \n                                                      precision               \n                                                      floating-point values   \n   EVEX.512.0F.W0 C2 /r ib                            in zmm3/m512/m32bcst    \n   VCMPPS k1 {k2}, zmm2,      C    V/V       AVX512F  and zmm2 using bits 4:0 \n   zmm3/m512/m32bcst{sae},                            of imm8 as a comparison \n   imm8                                               predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed single precision floating-point\n   values in the second source operand and the first source operand and\n   returns the result of the comparison to the destination operand. The\n   comparison predicate operand (immediate byte) specifies the type of\n   comparison performed on each of the pairs of packed values.\n\n   EVEX encoded versions: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. The destination operand (first\n   operand) is an opmask register. Comparison results are written to the\n   destination operand under the writemask k2. Each comparison result is a\n   single mask bit of 1 (comparison true) or 0 (comparison false).\n\n   VEX.256 encoded version: The first source operand (second operand) is a\n   YMM register. The second source operand (third operand) can be a YMM\n   register or a 256-bit memory location. The destination operand (first\n   operand) is a YMM register. Eight comparisons are performed with results\n   written to the destination operand. The result of each comparison is a\n   doubleword mask of all 1s (comparison true) or all 0s (comparison false).\n\n   128-bit Legacy SSE version: The first source and destination operand\n   (first operand) is an XMM register. The second source operand (second\n   operand) can be an XMM register or 128-bit memory location. Bits\n   (MAXVL-1:128) of the corresponding ZMM destination register remain\n   unchanged. Four comparisons are performed with results written to bits\n   127:0 of the destination operand. The result of each comparison is a\n   doubleword mask of all 1s (comparison true) or all 0s (comparison false).\n\n   VEX.128 encoded version: The first source operand (second operand) is an\n   XMM register. The second source operand (third operand) can be an XMM\n   register or a 128-bit memory location. Bits (MAXVL-1:128) of the\n   destination ZMM register are zeroed. Four comparisons are performed with\n   results written to bits 127:0 of the destination operand.\n\n   The comparison predicate operand is an 8-bit immediate:\n\n     * For instructions encoded using the VEX prefix and EVEX prefix, bits\n       4:0 define the type of comparison to be performed (see Table 3-1).\n       Bits 5 through 7 of the immediate are reserved.\n     * For instruction encodings that do not use VEX prefix, bits 2:0 define\n       the type of comparison to be made (see the first 8 rows of Table 3-1).\n       Bits 3 through 7 of the immediate are reserved.\n\n   The unordered relationship is true when at least one of the two source\n   operands being compared is a NaN; the ordered relationship is true when\n   neither source operand is a NaN.\n\n   A subsequent computational instruction that uses the mask result in the\n   destination operand as an input operand will not generate an exception,\n   because a mask of all 0s corresponds to a floating-point value of +0.0 and\n   a mask of all 1s corresponds to a QNaN.\n\n   Note that processors with \u201cCPUID.1H:ECX.AVX =0\u201d do not implement the\n   \u201cgreater-than\u201d, \u201cgreater-than-or-equal\u201d, \u201cnot-greater than\u201d, and\n   \u201cnot-greater-than-or-equal relations\u201d predicates. These comparisons can be\n   made either by using the inverse relationship (that is, use the\n   \u201cnot-less-than-or-equal\u201d to make a \u201cgreater-than\u201d comparison) or by using\n   software emulation. When using software emulation, the program must swap\n   the operands (copying registers when necessary to protect the data that\n   will now be in the destination), and then perform the compare using a\n   different predicate. The predicate to be used for these emulations is\n   listed in the first 8 rows of Table 3-7 (Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 2A) under the heading\n   Emulation.\n\n   Compilers and assemblers may implement the following two-operand\n   pseudo-ops in addition to the three-operand CMPPS instruction, for\n   processors with \u201cCPUID.1H:ECX.AVX =0\u201d. See Table 3-4. The compiler should\n   treat reserved imm8 values as illegal syntax.\n\n   Pseudo-Op             CMPPS Implementation \n   CMPEQPS xmm1, xmm2    CMPPS xmm1, xmm2, 0  \n   CMPLTPS xmm1, xmm2    CMPPS xmm1, xmm2, 1  \n   CMPLEPS xmm1, xmm2    CMPPS xmm1, xmm2, 2  \n   CMPUNORDPS xmm1, xmm2 CMPPS xmm1, xmm2, 3  \n   CMPNEQPS xmm1, xmm2   CMPPS xmm1, xmm2, 4  \n   CMPNLTPS xmm1, xmm2   CMPPS xmm1, xmm2, 5  \n   CMPNLEPS xmm1, xmm2   CMPPS xmm1, xmm2, 6  \n   CMPORDPS xmm1, xmm2   CMPPS xmm1, xmm2, 7  \n\n   Table 3-4. Pseudo-Op and CMPPS Implementation\n\n   The greater-than relations that the processor does not implement require\n   more than one instruction to emulate in software and therefore should not\n   be implemented as pseudo-ops. (For these, the programmer should reverse\n   the operands of the corresponding less than relations and use move\n   instructions to ensure that the mask is moved to the correct destination\n   register and that the source operand is left intact.)\n\n   Processors with \u201cCPUID.1H:ECX.AVX =1\u201d implement the full complement of 32\n   predicates shown in Table 3-5, software emulation is no longer needed.\n   Compilers and assemblers may implement the following three-operand\n   pseudo-ops in addition to the four-operand VCMPPS instruction. See Table\n   3-5, where the notation of reg1 and reg2 represent either XMM registers or\n   YMM registers. The compiler should treat reserved imm8 values as illegal\n   syntax. Alternately, intrinsics can map the pseudo-ops to pre-defined\n   constants to support a simpler intrinsic interface. Compilers and\n   assemblers may implement three-operand pseudo-ops for EVEX encoded VCMPPS\n   instructions in a similar fashion by extending the syntax listed in Table\n   3-5.\n\n   :\n\n   Pseudo-Op                       CMPPS Implementation         \n   VCMPEQPS reg1, reg2, reg3       VCMPPS reg1, reg2, reg3, 0   \n   VCMPLTPS reg1, reg2, reg3       VCMPPS reg1, reg2, reg3, 1   \n   VCMPLEPS reg1, reg2, reg3       VCMPPS reg1, reg2, reg3, 2   \n   VCMPUNORDPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 3   \n   VCMPNEQPS reg1, reg2, reg3      VCMPPS reg1, reg2, reg3, 4   \n   VCMPNLTPS reg1, reg2, reg3      VCMPPS reg1, reg2, reg3, 5   \n   VCMPNLEPS reg1, reg2, reg3      VCMPPS reg1, reg2, reg3, 6   \n   VCMPORDPS reg1, reg2, reg3      VCMPPS reg1, reg2, reg3, 7   \n   VCMPEQ_UQPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 8   \n   VCMPNGEPS reg1, reg2, reg3      VCMPPS reg1, reg2, reg3, 9   \n   VCMPNGTPS reg1, reg2, reg3      VCMPPS reg1, reg2, reg3, 0AH \n   VCMPFALSEPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 0BH \n   VCMPNEQ_OQPS reg1, reg2, reg3   VCMPPS reg1, reg2, reg3, 0CH \n   VCMPGEPS reg1, reg2, reg3       VCMPPS reg1, reg2, reg3, 0DH \n   VCMPGTPS reg1, reg2, reg3       VCMPPS reg1, reg2, reg3, 0EH \n   VCMPTRUEPS reg1, reg2, reg3     VCMPPS reg1, reg2, reg3, 0FH \n   VCMPEQ_OSPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 10H \n   VCMPLT_OQPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 11H \n   VCMPLE_OQPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 12H \n   VCMPUNORD_SPS reg1, reg2, reg3  VCMPPS reg1, reg2, reg3, 13H \n   VCMPNEQ_USPS reg1, reg2, reg3   VCMPPS reg1, reg2, reg3, 14H \n   VCMPNLT_UQPS reg1, reg2, reg3   VCMPPS reg1, reg2, reg3, 15H \n   VCMPNLE_UQPS reg1, reg2, reg3   VCMPPS reg1, reg2, reg3, 16H \n   VCMPORD_SPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 17H \n   VCMPEQ_USPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 18H \n   VCMPNGE_UQPS reg1, reg2, reg3   VCMPPS reg1, reg2, reg3, 19H \n   VCMPNGT_UQPS reg1, reg2, reg3   VCMPPS reg1, reg2, reg3, 1AH \n   VCMPFALSE_OSPS reg1, reg2, reg3 VCMPPS reg1, reg2, reg3, 1BH \n   VCMPNEQ_OSPS reg1, reg2, reg3   VCMPPS reg1, reg2, reg3, 1CH \n   VCMPGE_OQPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 1DH \n   VCMPGT_OQPS reg1, reg2, reg3    VCMPPS reg1, reg2, reg3, 1EH \n   VCMPTRUE_USPS reg1, reg2, reg3  VCMPPS reg1, reg2, reg3, 1FH \n\n   Table 3-5. Pseudo-Op and VCMPPS Implementation\n"],
	["str", "                           STR \u2014 Store Task Register\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Mode Description              \n                              Mode   \n   0F 00 /1 STR r/m16   M     Valid  Valid           Stores segment selector  \n                                                     from TR in r/m16.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Stores the segment selector from the task register (TR) in the destination\n   operand. The destination operand can be a general-purpose register or a\n   memory location. The segment selector stored with this instruction points\n   to the task state segment (TSS) for the currently running task.\n\n   When the destination operand is a 32-bit register, the 16-bit segment\n   selector is copied into the lower 16 bits of the register and the upper 16\n   bits of the register are cleared. When the destination operand is a memory\n   location, the segment selector is written to memory as a 16-bit quantity,\n   regardless of operand size.\n\n   In 64-bit mode, operation is the same. The size of the memory operand is\n   fixed at 16 bits. In register stores, the 2-byte TR is zero extended if\n   stored to a 64-bit register.\n\n   The STR instruction is useful only in operating-system software. It can\n   only be executed in protected mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["emodpe", "                    EMODPE \u2014 Extend an EPC Page Permissions\n\n                                 64/32 bit    CPUID                           \n   Opcode/Instruction      Op/En Mode Support Feature Description\n                                              Flag    \n                                                      This leaf function      \n   EAX = 06H ENCLU[EMODPE] IR    V/V          SGX2    extends the access      \n                                                      rights of an existing   \n                                                      EPC page.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX         RBX                  RCX                                 \n   IR    EMODPE (In) Address of a SECINFO Address of the destination EPC page \n                     (In)                 (In)                                \n\n  Description \u00b6\n\n   This leaf function extends the access rights associated with an existing\n   EPC page in the running enclave. THE RWX bits of the SECINFO parameter are\n   treated as a permissions mask; supplying a value that does not extend the\n   page permissions will have no effect. This instruction leaf can only be\n   executed when inside the enclave.\n\n   RBX contains the effective address of a SECINFO structure while RCX\n   contains the effective address of an EPC page. The table below provides\n   additional information on the memory parameter of the EMODPE leaf\n   function.\n\nEMODPE Memory Parameter Semantics \u00b6\n\n   SECINFO                              EPCPAGE                          \n   Read access permitted by Non Enclave Read access permitted by Enclave \n\n   The instruction faults if any of the following:\n\nEMODPE Faulting Conditions \u00b6\n\n   The operands are not properly If security attributes of the SECINFO page   \n   aligned.                      make the page inaccessible.                  \n   The EPC page is locked by     RBX does not contain an effective address in \n   another thread.               an EPC page in the running enclave.          \n   The EPC page is not valid.    RCX does not contain an effective address of \n                                 an EPC page in the running enclave.          \n   SECINFO contains an invalid   \n   request.                      \n\n  Concurrency Restrictions \u00b6\n\n                           Base Concurrency Restrictions\n   Leaf   Parameter        Access     On Conflict SGX_CONFLICT VM Exit        \n                                                  Qualification               \n   EMODPE Target [DS:RCX]  Concurrent \n          SECINFO [DS:RBX] Concurrent \n\n   Table 38-70. Base Concurrency Restrictions of EMODPE\n\n                    Additional Concurrency Restrictions\n                    vs. EACCEPT,                                       \n                    EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\n   Leaf   Parameter EMODPE, EMODPR,     EINIT\n                    EMODT      \n                    Access     On       Access     On       Access     On       \n                               Conflict            Conflict            Conflict \n          Target    Exclusive  #GP      Concurrent          Concurrent \n   EMODPE [DS:RCX]  \n          SECINFO   Concurrent          Concurrent          Concurrent \n          [DS:RBX]  \n\n   Table 38-71. Additional Concurrency Restrictions of EMODPE\n\n  Flags Affected \u00b6\n\n   None\n"],
	["vaddsh", "                        VADDSH \u2014 Add Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En Bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Add the low FP16    \n                                                          value from xmm3/m16 \n                                                          to xmm2, and store  \n   EVEX.LLIG.F3.MAP5.W0 58 /r                             the result in xmm1  \n   VADDSH xmm1{k1}{z}, xmm2,        A V/V     AVX512-FP16 subject to          \n   xmm3/m16 {er}                                          writemask k1. Bits  \n                                                          127:16 of xmm2 are  \n                                                          copied to           \n                                                          xmm1[127:16].       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction adds the low FP16 value from the source operands and\n   stores the FP16 result in the destination operand.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n"],
	["vpshrd", "            VPSHRD \u2014 Concatenate and Shift Packed Data Right Logical\n\n                                 64/32 bit CPUID Feature                      \n   Opcode/Instruction      Op/En Mode      Flag          Description\n                                 Support   \n                                                         Concatenate          \n   EVEX.128.66.0F3A.W1 72                                destination and      \n   /r /ib VPSHRDW                          AVX512_VBMI2  source operands,     \n   xmm1{k1}{z}, xmm2,      A     V/V       AVX512VL      extract result       \n   xmm3/m128, imm8                                       shifted to the right \n                                                         by constant value in \n                                                         imm8 into xmm1.      \n                                                         Concatenate          \n   EVEX.256.66.0F3A.W1 72                                destination and      \n   /r /ib VPSHRDW                          AVX512_VBMI2  source operands,     \n   ymm1{k1}{z}, ymm2,      A     V/V       AVX512VL      extract result       \n   ymm3/m256, imm8                                       shifted to the right \n                                                         by constant value in \n                                                         imm8 into ymm1.      \n                                                         Concatenate          \n   EVEX.512.66.0F3A.W1 72                                destination and      \n   /r /ib VPSHRDW                                        source operands,     \n   zmm1{k1}{z}, zmm2,      A     V/V       AVX512_VBMI2  extract result       \n   zmm3/m512, imm8                                       shifted to the right \n                                                         by constant value in \n                                                         imm8 into zmm1.      \n                                                         Concatenate          \n   EVEX.128.66.0F3A.W0 73                                destination and      \n   /r /ib VPSHRDD                          AVX512_VBMI2  source operands,     \n   xmm1{k1}{z}, xmm2,      B     V/V       AVX512VL      extract result       \n   xmm3/m128/m32bcst, imm8                               shifted to the right \n                                                         by constant value in \n                                                         imm8 into xmm1.      \n                                                         Concatenate          \n   EVEX.256.66.0F3A.W0 73                                destination and      \n   /r /ib VPSHRDD                          AVX512_VBMI2  source operands,     \n   ymm1{k1}{z}, ymm2,      B     V/V       AVX512VL      extract result       \n   ymm3/m256/m32bcst, imm8                               shifted to the right \n                                                         by constant value in \n                                                         imm8 into ymm1.      \n                                                         Concatenate          \n   EVEX.512.66.0F3A.W0 73                                destination and      \n   /r /ib VPSHRDD                                        source operands,     \n   zmm1{k1}{z}, zmm2,      B     V/V       AVX512_VBMI2  extract result       \n   zmm3/m512/m32bcst, imm8                               shifted to the right \n                                                         by constant value in \n                                                         imm8 into zmm1.      \n                                                         Concatenate          \n   EVEX.128.66.0F3A.W1 73                                destination and      \n   /r /ib VPSHRDQ                          AVX512_VBMI2  source operands,     \n   xmm1{k1}{z}, xmm2,      B     V/V       AVX512VL      extract result       \n   xmm3/m128/m64bcst, imm8                               shifted to the right \n                                                         by constant value in \n                                                         imm8 into xmm1.      \n                                                         Concatenate          \n   EVEX.256.66.0F3A.W1 73                                destination and      \n   /r /ib VPSHRDQ                          AVX512_VBMI2  source operands,     \n   ymm1{k1}{z}, ymm2,      B     V/V       AVX512VL      extract result       \n   ymm3/m256/m64bcst, imm8                               shifted to the right \n                                                         by constant value in \n                                                         imm8 into ymm1.      \n                                                         Concatenate          \n   EVEX.512.66.0F3A.W1 73                                destination and      \n   /r /ib VPSHRDQ                                        source operands,     \n   zmm1{k1}{z}, zmm2,      B     V/V       AVX512_VBMI2  extract result       \n   zmm3/m512/m64bcst, imm8                               shifted to the right \n                                                         by constant value in \n                                                         imm8 into zmm1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n   B     Full     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   Concatenate packed data, extract result shifted to the right by constant\n   value.\n\n   This instruction supports memory fault suppression.\n"],
	["pblendw", "                          PBLENDW \u2014 Blend Packed Words\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n                                                     Select words from xmm1   \n   66 0F 3A 0E /r ib PBLENDW                         and xmm2/m128 from mask  \n   xmm1, xmm2/m128, imm8     RMI   V/V       SSE4_1  specified in imm8 and    \n                                                     store the values into    \n                                                     xmm1.                    \n                                                     Select words from xmm2   \n   VEX.128.66.0F3A.WIG 0E /r                         and xmm3/m128 from mask  \n   ib VPBLENDW xmm1, xmm2,   RVMI  V/V       AVX     specified in imm8 and    \n   xmm3/m128, imm8                                   store the values into    \n                                                     xmm1.                    \n                                                     Select words from ymm2   \n   VEX.256.66.0F3A.WIG 0E /r                         and ymm3/m256 from mask  \n   ib VPBLENDW ymm1, ymm2,   RVMI  V/V       AVX2    specified in imm8 and    \n   ymm3/m256, imm8                                   store the values into    \n                                                     ymm1.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Words from the source operand (second operand) are conditionally written\n   to the destination operand (first operand) depending on bits in the\n   immediate operand (third operand). The immediate bits (bits 7:0) form a\n   mask that determines whether the corresponding word in the destination is\n   copied from the source. If a bit in the mask, corresponding to a word, is\n   \u201c1\", then the word is copied, else the word element in the destination\n   operand is unchanged.\n\n   128-bit Legacy SSE version: The second source operand can be an XMM\n   register or a 128-bit memory location. The first source and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand can be an XMM register\n   or a 128-bit memory location. The first source and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM register\n   are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vmxoff", "                          VMXOFF \u2014 Leave VMX Operation\n\n   Opcode/Instruction Op/En Description           \n   0F 01 C4 VMXOFF    ZO    Leaves VMX operation. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    NA        NA        NA        NA        \n\nDescription \u00b6\n\n   Takes the logical processor out of VMX operation, unblocks INIT signals,\n   conditionally re-enables A20M, and clears any address-range monitoring.^1\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["lea", "                          LEA \u2014 Load Effective Address\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   8D /r      LEA r16,m   RM    Valid  Valid      Store effective address for \n                                                  m in register r16.          \n   8D /r      LEA r32,m   RM    Valid  Valid      Store effective address for \n                                                  m in register r32.          \n   REX.W + 8D LEA r64,m   RM    Valid  N.E.       Store effective address for \n   /r                                             m in register r64.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Computes the effective address of the second operand (the source operand)\n   and stores it in the first operand (destination operand). The source\n   operand is a memory address (offset part) specified with one of the\n   processors addressing modes; the destination operand is a general-purpose\n   register. The address-size and operand-size attributes affect the action\n   performed by this instruction, as shown in the following table. The\n   operand-size attribute of the instruction is determined by the chosen\n   register; the address-size attribute is determined by the attribute of the\n   code segment.\n\n   Operand Size Address Size Action Performed                                 \n   16           16           16-bit effective address is calculated and       \n                             stored in requested 16-bit register destination. \n                             32-bit effective address is calculated. The      \n   16           32           lower 16 bits of the address are stored in the   \n                             requested 16-bit register destination.           \n                             16-bit effective address is calculated. The      \n   32           16           16-bit address is zero-extended and stored in    \n                             the requested 32-bit register destination.       \n                             32-bit effective address is calculated and       \n   32           32           stored in the requested 32-bit register          \n                             destination.                                     \n\n   Table 3-54. Non-64-bit Mode LEA Operation with Address and Operand Size\n   Attributes\n\n   Different assemblers may use different algorithms based on the size\n   attribute and symbolic reference of the source operand.\n\n   In 64-bit mode, the instruction\u2019s destination operand is governed by\n   operand size attribute, the default operand size is 32 bits. Address\n   calculation is governed by address size attribute, the default address\n   size is 64-bits. In 64-bit mode, address size of 16 bits is not encodable.\n   See Table 3-55.\n\n   Operand Size Address Size Action Performed                                 \n                             32-bit effective address is calculated (using    \n   16           32           67H prefix). The lower 16 bits of the address    \n                             are stored in the requested 16-bit register      \n                             destination (using 66H prefix).                  \n                             64-bit effective address is calculated (default  \n   16           64           address size). The lower 16 bits of the address  \n                             are stored in the requested 16-bit register      \n                             destination (using 66H prefix).                  \n                             32-bit effective address is calculated (using    \n   32           32           67H prefix) and stored in the requested 32-bit   \n                             register destination.                            \n                             64-bit effective address is calculated (default  \n   32           64           address size) and the lower 32 bits of the       \n                             address are stored in the requested 32-bit       \n                             register destination.                            \n                             32-bit effective address is calculated (using    \n   64           32           67H prefix), zero-extended to 64-bits, and       \n                             stored in the requested 64-bit register          \n                             destination (using REX.W).                       \n                             64-bit effective address is calculated (default  \n   64           64           address size) and all 64-bits of the address are \n                             stored in the requested 64-bit register          \n                             destination (using REX.W).                       \n\n   Table 3-55. 64-bit Mode LEA Operation with Address and Operand Size\n   Attributes\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vexp2ps", "   VEXP2PS \u2014 Approximation to the Exponential 2^x of Packed Single Precision\n            Floating-PointValues With Less Than 2^-23 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes approximations   \n                                                    to the exponential 2^x    \n                                                    (with less than 2^-23 of  \n   EVEX.512.66.0F38.W0 C8                           maximum relative error)   \n   /r VEXP2PS zmm1                                  of the packed             \n   {k1}{z},                A     V/V       AVX512ER single-precision          \n   zmm2/m512/m32bcst {sae}                          floating-point values     \n                                                    from zmm2/m512/m32bcst    \n                                                    and stores the            \n                                                    floating-point result in  \n                                                    zmm1with writemask k1.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4 \n   A Full ModRM:reg (r, w) ModRM:r/m (r) N/A N/A            \n\n  Description \u00b6\n\n   Computes the approximate base-2 exponential evaluation of the\n   single-precision floating-point values in the source operand (the second\n   operand) and store the results in the destination operand (the first\n   operand) using the write-mask k1. The approximate base-2 exponential is\n   evaluated with less than 2^-23 of relative error.\n\n   Denormal input values are treated as zeros and do not signal #DE,\n   irrespective of MXCSR.DAZ. Denormal results are flushed to zeros and do\n   not signal #UE, irrespective of MXCSR.FTZ.\n\n   The source operand is a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n  A numerically exact implementation of VEXP2xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["vpshrdv", "       VPSHRDV \u2014 Concatenate and Variable Shift Packed Data Right Logical\n\n                                  64/32 bit CPUID Feature                     \n   Opcode/Instruction       Op/En Mode      Flag          Description\n                                  Support   \n                                                          Concatenate xmm1    \n   EVEX.128.66.0F38.W1 72                                 and xmm2, extract   \n   /r VPSHRDVW xmm1{k1}{z}, A     V/V       AVX512_VBMI2  result shifted to   \n   xmm2, xmm3/m128                          AVX512VL      the right by value  \n                                                          in xmm3/m128 into   \n                                                          xmm1.               \n                                                          Concatenate ymm1    \n   EVEX.256.66.0F38.W1 72                                 and ymm2, extract   \n   /r VPSHRDVW ymm1{k1}{z}, A     V/V       AVX512_VBMI2  result shifted to   \n   ymm2, ymm3/m256                          AVX512VL      the right by value  \n                                                          in xmm3/m256 into   \n                                                          ymm1.               \n                                                          Concatenate zmm1    \n   EVEX.512.66.0F38.W1 72                                 and zmm2, extract   \n   /r VPSHRDVW zmm1{k1}{z}, A     V/V       AVX512_VBMI2  result shifted to   \n   zmm2, zmm3/m512                                        the right by value  \n                                                          in zmm3/m512 into   \n                                                          zmm1.               \n                                                          Concatenate xmm1    \n   EVEX.128.66.0F38.W0 73                                 and xmm2, extract   \n   /r VPSHRDVD xmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   xmm2, xmm3/m128/m32bcst                  AVX512VL      the right by value  \n                                                          in xmm3/m128 into   \n                                                          xmm1.               \n                                                          Concatenate ymm1    \n   EVEX.256.66.0F38.W0 73                                 and ymm2, extract   \n   /r VPSHRDVD ymm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   ymm2, ymm3/m256/m32bcst                  AVX512VL      the right by value  \n                                                          in xmm3/m256 into   \n                                                          ymm1.               \n                                                          Concatenate zmm1    \n   EVEX.512.66.0F38.W0 73                                 and zmm2, extract   \n   /r VPSHRDVD zmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   zmm2, zmm3/m512/m32bcst                                the right by value  \n                                                          in zmm3/m512 into   \n                                                          zmm1.               \n                                                          Concatenate xmm1    \n   EVEX.128.66.0F38.W1 73                                 and xmm2, extract   \n   /r VPSHRDVQ xmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   xmm2, xmm3/m128/m64bcst                  AVX512VL      the right by value  \n                                                          in xmm3/m128 into   \n                                                          xmm1.               \n                                                          Concatenate ymm1    \n   EVEX.256.66.0F38.W1 73                                 and ymm2, extract   \n   /r VPSHRDVQ ymm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   ymm2, ymm3/m256/m64bcst                  AVX512VL      the right by value  \n                                                          in xmm3/m256 into   \n                                                          ymm1.               \n                                                          Concatenate zmm1    \n   EVEX.512.66.0F38.W1 73                                 and zmm2, extract   \n   /r VPSHRDVQ zmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   zmm2, zmm3/m512/m64bcst                                the right by value  \n                                                          in zmm3/m512 into   \n                                                          zmm1.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full Mem ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   B     Full     ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Concatenate packed data, extract result shifted to the right by variable\n   value.\n\n   This instruction supports memory fault suppression.\n"],
	["fcos", "                                 FCOS \u2014 Cosine\n\n   Opcode  Mode Leg Mode Description                                \n   D9 FF                 Replace ST(0) with its approximate cosine. \n\nDescription \u00b6\n\n   Computes the approximate cosine of the source operand in register ST(0)\n   and stores the result in ST(0). The source operand must be given in\n   radians and must be within the range \u22122^63 to +2^63. The following table\n   shows the results obtained when taking the cosine of various classes of\n   numbers.\n\n   ST(0) SRC ST(0) DEST \n   \u2212\u221e        *          \n   \u2212F        \u22121 to +1   \n   \u22120        +1         \n   +0        +1         \n   +F        \u2212 1 to + 1 \n   +\u221e        *          \n   NaN       NaN        \n\n   Table 3-23. FCOS Results\n\n     F Meansfinitefloating-pointvalue.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   If the source operand is outside the acceptable range, the C2 flag in the\n   FPU status word is set, and the value in register ST(0) remains unchanged.\n   The instruction does not raise an exception when the source operand is out\n   of range. It is up to the program to check the C2 flag for out-of-range\n   conditions. Source values outside the range \u2212 2^63 to +2^63 can be reduced\n   to the range of the instruction by subtracting an appropriate integer\n   multiple of 2\u03c0. However, even within the range -2^63 to +2^63, inaccurate\n   results can occur because the finite approximation of \u03c0 used internally\n   for argument reduction is not sufficient in all cases. Therefore, for\n   accurate results it is safe to apply FCOS only to arguments reduced\n   accurately in software, to a value smaller in absolute value than 3\u03c0/8.\n   See the sections titled \u201cApproximation of Pi\u201d and \u201cTranscendental\n   Instruction Accuracy\u201d in Chapter 8 of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a discussion of\n   the proper value to use for \u03c0 in performing such reductions.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n          Set to 0 if stack underflow occurred.                               \n          Set if result was rounded up; cleared otherwise.                    \n   C1     Undefined if C2 is 1.                                               \n          Set to 1 if outside range (\u2212263 < source operand < +263);           \n          otherwise, set to 0.                                                \n   C2     \n   C0, C3 Undefined.                                                          \n"],
	["vcvtph2qq", "    VCVTPH2QQ \u2014 Convert Packed FP16 Values to Signed Quadword Integer Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert two packed    \n                                                        FP16 values in        \n   EVEX.128.66.MAP5.W0 7B /r                            xmm2/m32/m16bcst to   \n   VCVTPH2QQ xmm1{k1}{z},         A V/V     AVX512-FP16 two signed quadword   \n   xmm2/m32/m16bcst                         AVX512VL    integers, and store   \n                                                        the result in xmm1    \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert four packed   \n                                                        FP16 values in        \n   EVEX.256.66.MAP5.W0 7B /r                            xmm2/m64/m16bcst to   \n   VCVTPH2QQ ymm1{k1}{z},         A V/V     AVX512-FP16 four signed quadword  \n   xmm2/m64/m16bcst                         AVX512VL    integers, and store   \n                                                        the result in ymm1    \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert eight packed  \n                                                        FP16 values in        \n   EVEX.512.66.MAP5.W0 7B /r                            xmm2/m128/m16bcst to  \n   VCVTPH2QQ zmm1{k1}{z},         A V/V     AVX512-FP16 eight signed quadword \n   xmm2/m128/m16bcst {er}                               integers, and store   \n                                                        the result in zmm1    \n                                                        subject to writemask  \n                                                        k1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Quarter ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   signed quadword integers in destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["movlpd", "         MOVLPD \u2014 Move Low Packed Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Move double precision      \n   66 0F 12 /r MOVLPD xmm1, A    V/V       SSE2    floating-point value from  \n   m64                                             m64 to low quadword of     \n                                                   xmm1.                      \n                                                   Merge double precision     \n   VEX.128.66.0F.WIG 12 /r  B    V/V       AVX     floating-point value from  \n   VMOVLPD xmm2, xmm1, m64                         m64 and the high quadword  \n                                                   of xmm1.                   \n                                                   Merge double precision     \n   EVEX.128.66.0F.W1 12 /r  D    V/V       AVX512F floating-point value from  \n   VMOVLPD xmm2, xmm1, m64                         m64 and the high quadword  \n                                                   of xmm1.                   \n                                                   Move double precision      \n   66 0F 13/r MOVLPD m64,   C    V/V       SSE2    floating-point value from  \n   xmm1                                            low quadword of xmm1 to    \n                                                   m64.                       \n                                                   Move double precision      \n   VEX.128.66.0F.WIG 13/r   C    V/V       AVX     floating-point value from  \n   VMOVLPD m64, xmm1                               low quadword of xmm1 to    \n                                                   m64.                       \n                                                   Move double precision      \n   EVEX.128.66.0F.W1 13/r   E    V/V       AVX512F floating-point value from  \n   VMOVLPD m64, xmm1                               low quadword of xmm1 to    \n                                                   m64.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:r/m (r)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     N/A           ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n   D     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   E     Tuple1 Scalar ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n\nDescription \u00b6\n\n   This instruction cannot be used for register to register or memory to\n   memory moves.\n\n   128-bit Legacy SSE load:\n\n   Moves a double precision floating-point value from the source 64-bit\n   memory operand and stores it in the low 64-bits of the destination XMM\n   register. The upper 64bits of the XMM register are preserved. Bits\n   (MAXVL-1:128) of the corresponding destination register are preserved.\n\n   VEX.128 & EVEX encoded load:\n\n   Loads a double precision floating-point value from the source 64-bit\n   memory operand (third operand), merges it with the upper 64-bits of the\n   first source XMM register (second operand), and stores it in the low\n   128-bits of the destination XMM register (first operand). Bits\n   (MAXVL-1:128) of the corresponding destination register are zeroed.\n\n   128-bit store:\n\n   Stores a double precision floating-point value from the low 64-bits of the\n   XMM register source (second operand) to the 64-bit memory location (first\n   operand).\n\n   Note: VMOVLPD (store) (VEX.128.66.0F 13 /r) is legal and has the same\n   behavior as the existing 66 0F 13 store. For VMOVLPD (store) VEX.vvvv and\n   EVEX.vvvv are reserved and must be 1111b otherwise instruction will #UD.\n\n   If VMOVLPD is encoded with VEX.L or EVEX.L\u2019L= 1, an attempt to execute the\n   instruction encoded with VEX.L or EVEX.L\u2019L= 1 will cause an #UD exception.\n"],
	["movlhps", "    MOVLHPS \u2014 Move Packed Single Precision Floating-Point Values Low to High\n\n                        Op / 64/32 bit CPUID                                  \n   Opcode/Instruction   En   Mode      Feature Description\n                             Support   Flag    \n                                               Move two packed single         \n   NP 0F 16 /r MOVLHPS  RM   V/V       SSE     precision floating-point       \n   xmm1, xmm2                                  values from low quadword of    \n                                               xmm2 to high quadword of xmm1. \n   VEX.128.0F.WIG 16 /r                        Merge two packed single        \n   VMOVLHPS xmm1, xmm2, RVM  V/V       AVX     precision floating-point       \n   xmm3                                        values from low quadword of    \n                                               xmm3 and low quadword of xmm2. \n   EVEX.128.0F.W0 16 /r                        Merge two packed single        \n   VMOVLHPS xmm1, xmm2, RVM  V/V       AVX512F precision floating-point       \n   xmm3                                        values from low quadword of    \n                                               xmm3 and low quadword of xmm2. \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. ModRM.MOD = 011B required\n\n   Op/En Operand 1     Operand 2                    Operand 3     Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r)                N/A           N/A       \n   RVM   ModRM:reg (w) VEX.vvvv (r) / EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   This instruction cannot be used for memory to register moves.\n\n   128-bit two-argument form:\n\n   Moves two packed single precision floating-point values from the low\n   quadword of the second XMM argument (second operand) to the high quadword\n   of the first XMM register (first argument). The low quadword of the\n   destination operand is left unchanged. Bits (MAXVL-1:128) of the\n   corresponding destination register are unmodified.\n\n   128-bit three-argument forms:\n\n   Moves two packed single precision floating-point values from the low\n   quadword of the third XMM argument (third operand) to the high quadword of\n   the destination (first operand). Copies the low quadword from the second\n   XMM argument (second operand) to the low quadword of the destination\n   (first operand). Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   If VMOVLHPS is encoded with VEX.L or EVEX.L\u2019L= 1, an attempt to execute\n   the instruction encoded with VEX.L or EVEX.L\u2019L= 1 will cause an #UD\n   exception.\n"],
	["vcmpph", "                      VCMPPH \u2014 Compare Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Compare packed FP16    \n                                                       values in              \n                                                       xmm3/m128/m16bcst and  \n   EVEX.128.NP.0F3A.W0 C2 /r /ib           AVX512-FP16 xmm2 using bits 4:0 of \n   VCMPPH k1{k2}, xmm2,          A V/V     AVX512VL    imm8 as a comparison   \n   xmm3/m128/m16bcst, imm8                             predicate subject to   \n                                                       writemask k2, and      \n                                                       store the result in    \n                                                       mask register k1.      \n                                                       Compare packed FP16    \n                                                       values in              \n                                                       ymm3/m256/m16bcst and  \n   EVEX.256.NP.0F3A.W0 C2 /r /ib           AVX512-FP16 ymm2 using bits 4:0 of \n   VCMPPH k1{k2}, ymm2,          A V/V     AVX512VL    imm8 as a comparison   \n   ymm3/m256/m16bcst, imm8                             predicate subject to   \n                                                       writemask k2, and      \n                                                       store the result in    \n                                                       mask register k1.      \n                                                       Compare packed FP16    \n                                                       values in              \n                                                       zmm3/m512/m16bcst and  \n   EVEX.512.NP.0F3A.W0 C2 /r /ib                       zmm2 using bits 4:0 of \n   VCMPPH k1{k2}, zmm2,          A V/V     AVX512-FP16 imm8 as a comparison   \n   zmm3/m512/m16bcst {sae}, imm8                       predicate subject to   \n                                                       writemask k2, and      \n                                                       store the result in    \n                                                       mask register k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   This instruction compares packed FP16 values from source operands and\n   stores the result in the destination mask operand. The comparison\n   predicate operand (immediate byte bits 4:0) specifies the type of\n   comparison performed on each of the pairs of packed values. The\n   destination elements are updated according to the writemask.\n"],
	["vrcp14ss", "       VRCP14SS \u2014 Compute Approximate Reciprocal of Scalar Float32 Value\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Computes the approximate   \n                                                   reciprocal of the scalar   \n                                                   single-precision           \n                                                   floating-point value in    \n   EVEX.LLIG.66.0F38.W0 4D                         xmm3/m32 and stores the    \n   /r VRCP14SS xmm1        A     V/V       AVX512F results in xmm1 using      \n   {k1}{z}, xmm2, xmm3/m32                         writemask k1. Also, upper  \n                                                   double precision           \n                                                   floating-point value       \n                                                   (bits[127:32]) from xmm2   \n                                                   is copied to xmm1[127:32]. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate reciprocal\n   of the low single-precision floating-point value in the second source\n   operand (the third operand) and stores the result in the low quadword\n   element of the destination operand (the first operand) according to the\n   writemask k1. Bits (127:32) of the XMM register destination are copied\n   from corresponding bits in the first source operand (the second operand).\n   The maximum relative error for this approximation is less than 2^-14. The\n   source operand can be an XMM register or a 32-bit memory location. The\n   destination operand is an XMM register.\n\n   The VRCP14SS instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. A denormal source value will be treated as\n   zero only in case of DAZ bit set in MXCSR. Otherwise it is treated\n   correctly (i.e., not as a 0.0). Underflow results are flushed to zero only\n   in case of FTZ bit set in MXCSR. Otherwise it will be treated correctly\n   (i.e., correct underflow result is written) with the sign of the operand.\n   When a source value is a SNaN or QNaN, the SNaN is converted to a QNaN or\n   the source QNaN is returned. See Table 5-27 for special-case input values.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n  A numerically exact implementation of VRCP14xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["v4fmaddss:v4fnmaddss", "      V4FMADDSS/V4FNMADDSS \u2014 Scalar Single Precision Floating-Point Fused\n                           Multiply-Add(4-Iterations)\n\n                                 64/32 bit CPUID Feature                      \n   Opcode/Instruction      Op/En Mode      Flag          Description\n                                 Support   \n                                                         Multiply scalar      \n                                                         single-precision     \n   EVEX.LLIG.F2.0F38.W0 9B                               floating-point       \n   /r V4FMADDSS                                          values from source   \n   xmm1{k1}{z}, xmm2+3,    A     V/V       AVX512_4FMAPS register block       \n   m128                                                  indicated by xmm2 by \n                                                         values from m128 and \n                                                         accumulate the       \n                                                         result in xmm1.      \n                                                         Multiply and negate  \n                                                         scalar               \n                                                         single-precision     \n   EVEX.LLIG.F2.0F38.W0 AB                               floating-point       \n   /r V4FNMADDSS           A     V/V       AVX512_4FMAPS values from source   \n   xmm1{k1}{z}, xmm2+3,                                  register block       \n   m128                                                  indicated by xmm2 by \n                                                         values from m128 and \n                                                         accumulate the       \n                                                         result in xmm1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4          \n   A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   This instruction computes 4 sequential scalar fused single-precision\n   floating-point multiply-add instructions with a sequentially selected\n   memory operand in each of the four steps.\n\n   In the above box, the notation of \u201c+3\u201d is used to denote that the\n   instruction accesses 4 source registers based that operand; sources are\n   consecutive, start in a multiple of 4 boundary, and contain the encoded\n   register operand.\n\n   This instruction supports memory fault suppression. The entire memory\n   operand is loaded if the least significant mask bit is set to 1 or if a\n   \u201cno masking\u201d encoding is used.\n\n   The tuple type Tuple1_4X implies that four 32-bit elements (16 bytes) are\n   referenced by the memory operation portion of this instruction.\n\n   Rounding is performed at every FMA boundary. Exceptions are also taken\n   sequentially. Pre- and post-computational exceptions of the first FMA take\n   priority over the pre- and post-computational exceptions of the second\n   FMA, etc.\n"],
	["aesenc", "              AESENC \u2014 Perform One Round of an AES Encryption Flow\n\n                                   64/32-bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                             Flag     \n                                                      Perform one round of an \n                                                      AES encryption flow,    \n   66 0F 38 DC /r AESENC     A     V/V       AES      using one 128-bit data  \n   xmm1, xmm2/m128                                    (state) from xmm1 with  \n                                                      one 128-bit round key   \n                                                      from xmm2/m128.         \n                                                      Perform one round of an \n                                                      AES encryption flow,    \n   VEX.128.66.0F38.WIG DC /r                          using one 128-bit data  \n   VAESENC xmm1, xmm2,       B     V/V       AES AVX  (state) from xmm2 with  \n   xmm3/m128                                          one 128-bit round key   \n                                                      from the xmm3/m128;     \n                                                      store the result in     \n                                                      xmm1.                   \n                                                      Perform one round of an \n                                                      AES encryption flow,    \n   VEX.256.66.0F38.WIG DC /r                          using two 128-bit data  \n   VAESENC ymm1, ymm2,       B     V/V       VAES     (state) from ymm2 with  \n   ymm3/m256                                          two 128-bit round keys  \n                                                      from the ymm3/m256;     \n                                                      store the result in     \n                                                      ymm1.                   \n                                                      Perform one round of an \n                                                      AES encryption flow,    \n   EVEX.128.66.0F38.WIG DC                            using one 128-bit data  \n   /r VAESENC xmm1, xmm2,    C     V/V       VAES     (state) from xmm2 with  \n   xmm3/m128                                 AVX512VL one 128-bit round key   \n                                                      from the xmm3/m128;     \n                                                      store the result in     \n                                                      xmm1.                   \n                                                      Perform one round of an \n                                                      AES encryption flow,    \n   EVEX.256.66.0F38.WIG DC                            using two 128-bit data  \n   /r VAESENC ymm1, ymm2,    C     V/V       VAES     (state) from ymm2 with  \n   ymm3/m256                                 AVX512VL two 128-bit round keys  \n                                                      from the ymm3/m256;     \n                                                      store the result in     \n                                                      ymm1.                   \n                                                      Perform one round of an \n                                                      AES encryption flow,    \n   EVEX.512.66.0F38.WIG DC                            using four 128-bit data \n   /r VAESENC zmm1, zmm2,    C     V/V       VAES     (state) from zmm2 with  \n   zmm3/m512                                 AVX512F  four 128-bit round keys \n                                                      from the zmm3/m512;     \n                                                      store the result in     \n                                                      zmm1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A      ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A      ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   This instruction performs a single round of an AES encryption flow using\n   one/two/four (depending on vector length) 128-bit data (state) from the\n   first source operand with one/two/four (depending on vector length) round\n   key(s) from the second source operand, and stores the result in the\n   destination operand.\n\n   Use the AESENC instruction for all but the last encryption rounds. For the\n   last encryption round, use the AESENCCLAST instruction.\n\n   VEX and EVEX encoded versions of the instruction allow 3-operand\n   (non-destructive) operation. The legacy encoded versions of the\n   instruction require that the first source operand and the destination\n   operand are the same and must be an XMM register.\n\n   The EVEX encoded form of this instruction does not support memory fault\n   suppression.\n"],
	["vcvtss2usi", " VCVTSS2USI \u2014 Convert Scalar Single Precision Floating-Point Value to Unsigned\n                               DoublewordInteger\n\n                               64/32 Bit    CPUID                             \n   Opcode/Instruction    Op/En Mode Support Feature Description\n                                            Flag    \n                                                    Convert one single        \n   EVEX.LLIG.F3.0F.W0 79                            precision floating-point  \n   /r VCVTSS2USI r32,    A     V/V          AVX512F value from xmm1/m32 to    \n   xmm1/m32{er}                                     one unsigned doubleword   \n                                                    integer in r32.           \n                                                    Convert one single        \n   EVEX.LLIG.F3.0F.W1 79                            precision floating-point  \n   /r VCVTSS2USI r64,    A     V/N.E.^1     AVX512F value from xmm1/m32 to    \n   xmm1/m32{er}                                     one unsigned quadword     \n                                                    integer in r64.           \n\n     1. EVEX.W1 in non-64 bit is ignored; the instruction behaves as if the\n     W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts a single precision floating-point value in the source operand\n   (the second operand) to an unsigned double-word integer (or unsigned\n   quadword integer if operand size is 64 bits) in the destination operand\n   (the first operand). The source operand can be an XMM register or a memory\n   location. The destination operand is a general-purpose register. When the\n   source operand is an XMM register, the single precision floating-point\n   value is contained in the low doubleword of the register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   VEX.W1 and EVEX.W1 versions: promotes the instruction to produce 64-bit\n   data in 64-bit mode.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["movntq", "               MOVNTQ \u2014 Store of Quadword Using Non-Temporal Hint\n\n   Opcode   Instruction    Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   NP 0F E7                                        Move quadword from mm to   \n   /r       MOVNTQ m64, mm MR    Valid  Valid      m64 using non-temporal     \n                                                   hint.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the quadword in the source operand (second operand) to the\n   destination operand (first operand) using a non-temporal hint to minimize\n   cache pollution during the write to memory. The source operand is an MMX\n   technology register, which is assumed to contain packed integer data\n   (packed bytes, words, or doublewords). The destination operand is a 64-bit\n   memory location.\n\n   The non-temporal hint is implemented by using a write combining (WC)\n   memory type protocol when writing the data to memory. Using this protocol,\n   the processor does not write the data into the cache hierarchy, nor does\n   it fetch the corresponding cache line from memory into the cache\n   hierarchy. The memory type of the region being written to can override the\n   non-temporal hint, if the memory address specified for the non-temporal\n   store is in an uncacheable (UC) or write protected (WP) memory region. For\n   more information on non-temporal stores, see \u201cCaching of Temporal vs.\n   Non-Temporal Data\u201d in Chapter 10 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1.\n\n   Because the WC protocol uses a weakly-ordered memory consistency model, a\n   fencing operation implemented with the SFENCE or MFENCE instruction should\n   be used in conjunction with MOVNTQ instructions if multiple processors\n   might use different memory types to read/write the destination memory\n   locations.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n"],
	["rcpss", "  RCPSS \u2014 Compute Reciprocal of Scalar Single Precision Floating-Point Values\n\n                                 64/32 bit CPUID                              \n   Opcode*/Instruction     Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Computes the approximate   \n                                                   reciprocal of the scalar   \n   F3 0F 53 /r RCPSS xmm1, RM    V/V       SSE     single precision           \n   xmm2/m32                                        floating-point value in    \n                                                   xmm2/m32 and stores the    \n                                                   result in xmm1.            \n                                                   Computes the approximate   \n                                                   reciprocal of the scalar   \n                                                   single precision           \n                                                   floating-point value in    \n   VEX.LIG.F3.0F.WIG 53 /r                         xmm3/m32 and stores the    \n   VRCPSS xmm1, xmm2,      RVM   V/V       AVX     result in xmm1. Also,      \n   xmm3/m32                                        upper single precision     \n                                                   floating-point values      \n                                                   (bits[127:32]) from xmm2   \n                                                   are copied to              \n                                                   xmm1[127:32].              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Computes of an approximate reciprocal of the low single precision\n   floating-point value in the source operand (second operand) and stores the\n   single precision floating-point result in the destination operand. The\n   source operand can be an XMM register or a 32-bit memory location. The\n   destination operand is an XMM register. The three high-order doublewords\n   of the destination operand remain unchanged. See Figure 10-6 in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1,\n   for an illustration of a scalar single precision floating-point operation.\n\n   The relative error for this approximation is:\n\n   |Relative Error| \u2264 1.5 \u2217 2^\u221212\n\n   The RCPSS instruction is not affected by the rounding control bits in the\n   MXCSR register. When a source value is a 0.0, an \u221e of the sign of the\n   source value is returned. A denormal source value is treated as a 0.0 (of\n   the same sign). Tiny results (see Section 4.9.1.5, \u201cNumeric Underflow\n   Exception (#U)\u201d in Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1) are always flushed to 0.0, with the sign of the operand.\n   (Input values greater than or equal to |1.11111111110100000000000B\u22172^125|\n   are guaranteed to not produce tiny results; input values less than or\n   equal to |1.00000000000110000000001B*2^126| are guaranteed to produce tiny\n   results, which are in turn flushed to 0.0; and input values in between\n   this range may or may not produce tiny results, depending on the\n   implementation.) When a source value is an SNaN or QNaN, the SNaN is\n   converted to a QNaN or the source QNaN is returned.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:32) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n"],
	["pabsb:pabsw:pabsd:pabsq", "                PABSB/PABSW/PABSD/PABSQ \u2014 Packed Absolute Value\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Compute the absolute      \n   NP 0F 38 1C /r^1 PABSB  A     V/V       SSSE3    value of bytes in mm2/m64 \n   mm1, mm2/m64                                     and store UNSIGNED result \n                                                    in mm1.                   \n                                                    Compute the absolute      \n   66 0F 38 1C /r PABSB    A     V/V       SSSE3    value of bytes in         \n   xmm1, xmm2/m128                                  xmm2/m128 and store       \n                                                    UNSIGNED result in xmm1.  \n                                                    Compute the absolute      \n   NP 0F 38 1D /r^1 PABSW  A     V/V       SSSE3    value of 16-bit integers  \n   mm1, mm2/m64                                     in mm2/m64 and store      \n                                                    UNSIGNED result in mm1.   \n                                                    Compute the absolute      \n   66 0F 38 1D /r PABSW    A     V/V       SSSE3    value of 16-bit integers  \n   xmm1, xmm2/m128                                  in xmm2/m128 and store    \n                                                    UNSIGNED result in xmm1.  \n                                                    Compute the absolute      \n   NP 0F 38 1E /r^1 PABSD  A     V/V       SSSE3    value of 32-bit integers  \n   mm1, mm2/m64                                     in mm2/m64 and store      \n                                                    UNSIGNED result in mm1.   \n                                                    Compute the absolute      \n   66 0F 38 1E /r PABSD    A     V/V       SSSE3    value of 32-bit integers  \n   xmm1, xmm2/m128                                  in xmm2/m128 and store    \n                                                    UNSIGNED result in xmm1.  \n   VEX.128.66.0F38.WIG 1C                           Compute the absolute      \n   /r VPABSB xmm1,         A     V/V       AVX      value of bytes in         \n   xmm2/m128                                        xmm2/m128 and store       \n                                                    UNSIGNED result in xmm1.  \n   VEX.128.66.0F38.WIG 1D                           Compute the absolute      \n   /r VPABSW xmm1,         A     V/V       AVX      value of 16- bit integers \n   xmm2/m128                                        in xmm2/m128 and store    \n                                                    UNSIGNED result in xmm1.  \n   VEX.128.66.0F38.WIG 1E                           Compute the absolute      \n   /r VPABSD xmm1,         A     V/V       AVX      value of 32- bit integers \n   xmm2/m128                                        in xmm2/m128 and store    \n                                                    UNSIGNED result in xmm1.  \n   VEX.256.66.0F38.WIG 1C                           Compute the absolute      \n   /r VPABSB ymm1,         A     V/V       AVX2     value of bytes in         \n   ymm2/m256                                        ymm2/m256 and store       \n                                                    UNSIGNED result in ymm1.  \n   VEX.256.66.0F38.WIG 1D                           Compute the absolute      \n   /r VPABSW ymm1,         A     V/V       AVX2     value of 16-bit integers  \n   ymm2/m256                                        in ymm2/m256 and store    \n                                                    UNSIGNED result in ymm1.  \n   VEX.256.66.0F38.WIG 1E                           Compute the absolute      \n   /r VPABSD ymm1,         A     V/V       AVX2     value of 32-bit integers  \n   ymm2/m256                                        in ymm2/m256 and store    \n                                                    UNSIGNED result in ymm1.  \n                                                    Compute the absolute      \n   EVEX.128.66.0F38.WIG 1C                 AVX512VL value of bytes in         \n   /r VPABSB xmm1 {k1}{z}, B     V/V       AVX512BW xmm2/m128 and store       \n   xmm2/m128                                        UNSIGNED result in xmm1   \n                                                    using writemask k1.       \n                                                    Compute the absolute      \n   EVEX.256.66.0F38.WIG 1C                 AVX512VL value of bytes in         \n   /r VPABSB ymm1 {k1}{z}, B     V/V       AVX512BW ymm2/m256 and store       \n   ymm2/m256                                        UNSIGNED result in ymm1   \n                                                    using writemask k1.       \n                                                    Compute the absolute      \n   EVEX.512.66.0F38.WIG 1C                          value of bytes in         \n   /r VPABSB zmm1 {k1}{z}, B     V/V       AVX512BW zmm2/m512 and store       \n   zmm2/m512                                        UNSIGNED result in zmm1   \n                                                    using writemask k1.       \n                                                    Compute the absolute      \n   EVEX.128.66.0F38.WIG 1D                 AVX512VL value of 16-bit integers  \n   /r VPABSW xmm1 {k1}{z}, B     V/V       AVX512BW in xmm2/m128 and store    \n   xmm2/m128                                        UNSIGNED result in xmm1   \n                                                    using writemask k1.       \n                                                    Compute the absolute      \n   EVEX.256.66.0F38.WIG 1D                 AVX512VL value of 16-bit integers  \n   /r VPABSW ymm1 {k1}{z}, B     V/V       AVX512BW in ymm2/m256 and store    \n   ymm2/m256                                        UNSIGNED result in ymm1   \n                                                    using writemask k1.       \n                                                    Compute the absolute      \n   EVEX.512.66.0F38.WIG 1D                          value of 16-bit integers  \n   /r VPABSW zmm1 {k1}{z}, B     V/V       AVX512BW in zmm2/m512 and store    \n   zmm2/m512                                        UNSIGNED result in zmm1   \n                                                    using writemask k1.       \n                                                    Compute the absolute      \n   EVEX.128.66.0F38.W0 1E                  AVX512VL value of 32-bit integers  \n   /r VPABSD xmm1 {k1}{z}, C     V/V       AVX512F  in xmm2/m128/m32bcst and  \n   xmm2/m128/m32bcst                                store UNSIGNED result in  \n                                                    xmm1 using writemask k1.  \n                                                    Compute the absolute      \n   EVEX.256.66.0F38.W0 1E                  AVX512VL value of 32-bit integers  \n   /r VPABSD ymm1 {k1}{z}, C     V/V       AVX512F  in ymm2/m256/m32bcst and  \n   ymm2/m256/m32bcst                                store UNSIGNED result in  \n                                                    ymm1 using writemask k1.  \n                                                    Compute the absolute      \n   EVEX.512.66.0F38.W0 1E                           value of 32-bit integers  \n   /r VPABSD zmm1 {k1}{z}, C     V/V       AVX512F  in zmm2/m512/m32bcst and  \n   zmm2/m512/m32bcst                                store UNSIGNED result in  \n                                                    zmm1 using writemask k1.  \n                                                    Compute the absolute      \n   EVEX.128.66.0F38.W1 1F                  AVX512VL value of 64-bit integers  \n   /r VPABSQ xmm1 {k1}{z}, C     V/V       AVX512F  in xmm2/m128/m64bcst and  \n   xmm2/m128/m64bcst                                store UNSIGNED result in  \n                                                    xmm1 using writemask k1.  \n                                                    Compute the absolute      \n   EVEX.256.66.0F38.W1 1F                  AVX512VL value of 64-bit integers  \n   /r VPABSQ ymm1 {k1}{z}, C     V/V       AVX512F  in ymm2/m256/m64bcst and  \n   ymm2/m256/m64bcst                                store UNSIGNED result in  \n                                                    ymm1 using writemask k1.  \n                                                    Compute the absolute      \n   EVEX.512.66.0F38.W1 1F                           value of 64-bit integers  \n   /r VPABSQ zmm1 {k1}{z}, C     V/V       AVX512F  in zmm2/m512/m64bcst and  \n   zmm2/m512/m64bcst                                store UNSIGNED result in  \n                                                    zmm1 using writemask k1.  \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   C     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   PABSB/W/D computes the absolute value of each data element of the source\n   operand (the second operand) and stores the UNSIGNED results in the\n   destination operand (the first operand). PABSB operates on signed bytes,\n   PABSW operates on signed 16-bit words, and PABSD operates on signed 32-bit\n   integers.\n\n   EVEX encoded VPABSD/Q: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 32/64-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register updated according to the writemask.\n\n   EVEX encoded VPABSB/W: The source operand is a ZMM/YMM/XMM register, or a\n   512/256/128-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register updated according to the writemask.\n\n   VEX.256 encoded versions: The source operand is a YMM register or a\n   256-bit memory location. The destination operand is a YMM register. The\n   upper bits (MAXVL-1:256) of the corresponding register destination are\n   zeroed.\n\n   VEX.128 encoded versions: The source operand is an XMM register or 128-bit\n   memory location. The destination operand is an XMM register. The upper\n   bits (MAXVL-1:128) of the corresponding register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand can be an XMM register or\n   an 128-bit memory location. The destination is an XMM register. The upper\n   bits (VL_MAX-1:128) of the corresponding register destination are\n   unmodified.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["ucomisd", " UCOMISD \u2014 Unordered Compare Scalar Double Precision Floating-Point Values and\n                                   Set EFLAGS\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Compare low double          \n   66 0F 2E /r UCOMISD                            precision floating-point    \n   xmm1, xmm2/m64          A    V/V       SSE2    values in xmm1 and          \n                                                  xmm2/mem64 and set the      \n                                                  EFLAGS flags accordingly.   \n                                                  Compare low double          \n   VEX.LIG.66.0F.WIG 2E /r                        precision floating-point    \n   VUCOMISD xmm1, xmm2/m64 A    V/V       AVX     values in xmm1 and          \n                                                  xmm2/mem64 and set the      \n                                                  EFLAGS flags accordingly.   \n                                                  Compare low double          \n   EVEX.LLIG.66.0F.W1 2E                          precision floating-point    \n   /r VUCOMISD xmm1,       B    V/V       AVX512F values in xmm1 and xmm2/m64 \n   xmm2/m64{sae}                                  and set the EFLAGS flags    \n                                                  accordingly.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs an unordered compare of the double precision floating-point\n   values in the low quadwords of operand 1 (first operand) and operand 2\n   (second operand), and sets the ZF, PF, and CF flags in the EFLAGS register\n   according to the result (unordered, greater than, less than, or equal).\n   The OF, SF, and AF flags in the EFLAGS register are set to 0. The\n   unordered result is returned if either source operand is a NaN (QNaN or\n   SNaN).\n\n   Operand 1 is an XMM register; operand 2 can be an XMM register or a 64 bit\n   memory\n\n   location.\n\n   The UCOMISD instruction differs from the COMISD instruction in that it\n   signals a SIMD floating-point invalid operation exception (#I) only when a\n   source operand is an SNaN. The COMISD instruction signals an invalid\n   operation exception only if a source operand is either an SNaN or a QNaN.\n\n   The EFLAGS register is not updated if an unmasked SIMD floating-point\n   exception is generated.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCOMISD is encoded with VEX.L=0. Encoding VCOMISD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["vgetmantsh", "       VGETMANTSH \u2014 Extract FP16 of Normalized Mantissa from FP16 Scalar\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Extract the           \n                                                        normalized mantissa   \n                                                        of the low FP16       \n                                                        element in xmm3/m16   \n                                                        using imm8 for sign   \n                                                        control and mantissa  \n   EVEX.LLIG.NP.0F3A.W0 27 /r /ib                       interval              \n   VGETMANTSH xmm1{k1}{z}, xmm2,  A V/V     AVX512-FP16 normalization. Store  \n   xmm3/m16 {sae}, imm8                                 the mantissa to xmm1  \n                                                        subject to writemask  \n                                                        k1 and merge with the \n                                                        other elements of     \n                                                        xmm2. Bits 127:16 of  \n                                                        xmm2 are copied to    \n                                                        xmm1[127:16].         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   This instruction converts the FP16 value in the low element of the second\n   source operand to FP16 values with the mantissa normalization and sign\n   control specified by the imm8 byte, see Table 5-19. The converted result\n   is written to the low element of the destination operand using writemask\n   k1. The normalized mantissa is specified by interv (imm8[1:0]) and the\n   sign control (SC) is specified by bits 3:2 of the immediate byte.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   For each input FP16 value x, The conversion operation is:\n\n   GetMant(x) = \u00b12^k|x.significand|\n\n   where:\n\n   1 \u2264 |x.significand| < 2\n\n   Unbiased exponent k depends on the interval range defined by interv and\n   whether the exponent of the source is even or odd. The sign of the final\n   result is determined by the sign control and the source sign and the\n   leading fraction bit.\n\n   The encoded value of imm8[1:0] and sign control are shown in Table 5-19.\n\n   Each converted FP16 result is encoded according to the sign control, the\n   unbiased exponent k (adding bias) and a mantissa normalized to the range\n   specified by interv.\n\n   The GetMant() function follows Table 5-20 when dealing with floating-point\n   special numbers.\n"],
	["vmulsh", "                      VMULSH \u2014 Multiply Scalar FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   bit Mode Flag 64/32 CPUID       \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Multiply the low     \n                                                         FP16 value in        \n                                                         xmm3/m16 by low FP16 \n   EVEX.LLIG.F3.MAP5.W0 59 /r                            value in xmm2, and   \n   VMULSH xmm1{k1}{z}, xmm2,       A V/V     AVX512-FP16 store the result in  \n   xmm3/m16 {er}                                         xmm1 subject to      \n                                                         writemask k1. Bits   \n                                                         127:16 of xmm2 are   \n                                                         copied to            \n                                                         xmm1[127:16].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction multiplies the low FP16 value from the source operands\n   and stores the FP16 result in the destination operand. Bits 127:16 of the\n   destination operand are copied from the corresponding bits of the first\n   source operand. Bits MAXVL-1:128 of the destination operand are zeroed.\n   The low FP16 element of the destination is updated according to the\n   writemask.\n"],
	["vpermb", "                     VPERMB \u2014 Permute Packed Bytes Elements\n\n                                 64/32 bit CPUID Feature                      \n   Opcode/Instruction      Op/En Mode      Flag          Description\n                                 Support   \n                                                         Permute bytes in     \n   EVEX.128.66.0F38.W0 8D                                xmm3/m128 using byte \n   /r VPERMB xmm1 {k1}{z}, A     V/V       AVX512VL      indexes in xmm2 and  \n   xmm2, xmm3/m128                         AVX512_VBMI   store the result in  \n                                                         xmm1 using writemask \n                                                         k1.                  \n                                                         Permute bytes in     \n   EVEX.256.66.0F38.W0 8D                                ymm3/m256 using byte \n   /r VPERMB ymm1 {k1}{z}, A     V/V       AVX512VL      indexes in ymm2 and  \n   ymm2, ymm3/m256                         AVX512_VBMI   store the result in  \n                                                         ymm1 using writemask \n                                                         k1.                  \n                                                         Permute bytes in     \n   EVEX.512.66.0F38.W0 8D                                zmm3/m512 using byte \n   /r VPERMB zmm1 {k1}{z}, A     V/V       AVX512_VBMI   indexes in zmm2 and  \n   zmm2, zmm3/m512                                       store the result in  \n                                                         zmm1 using writemask \n                                                         k1.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Copies bytes from the second source operand (the third operand) to the\n   destination operand (the first operand) according to the byte indices in\n   the first source operand (the second operand). Note that this instruction\n   permits a byte in the source operand to be copied to more than one\n   location in the destination operand.\n\n   Only the low 6(EVEX.512)/5(EVEX.256)/4(EVEX.128) bits of each byte index\n   is used to select the location of the source byte from the second source\n   operand.\n\n   The first source operand is a ZMM/YMM/XMM register. The second source\n   operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location.\n   The destination operand is a ZMM/YMM/XMM register updated at byte\n   granularity by the writemask k1.\n"],
	["vfnmsub132sd:vfnmsub213sd:vfnmsub231sd", "   VFNMSUB132SD/VFNMSUB213SD/VFNMSUB231SD \u2014 Fused Negative Multiply-Subtract\n                ofScalar Double Precision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Multiply scalar double    \n                                                    precision floating-point  \n   VEX.LIG.66.0F38.W1 9F /r                         value from xmm1 and       \n   VFNMSUB132SD xmm1, xmm2, A     V/V       FMA     xmm3/mem, negate the      \n   xmm3/m64                                         multiplication result and \n                                                    subtract xmm2 and put     \n                                                    result in xmm1.           \n                                                    Multiply scalar double    \n                                                    precision floating-point  \n   VEX.LIG.66.0F38.W1 AF /r                         value from xmm1 and xmm2, \n   VFNMSUB213SD xmm1, xmm2, A     V/V       FMA     negate the multiplication \n   xmm3/m64                                         result and subtract       \n                                                    xmm3/mem and put result   \n                                                    in xmm1.                  \n                                                    Multiply scalar double    \n                                                    precision floating-point  \n   VEX.LIG.66.0F38.W1 BF /r                         value from xmm2 and       \n   VFNMSUB231SD xmm1, xmm2, A     V/V       FMA     xmm3/mem, negate the      \n   xmm3/m64                                         multiplication result and \n                                                    subtract xmm1 and put     \n                                                    result in xmm1.           \n                                                    Multiply scalar double    \n   EVEX.LLIG.66.0F38.W1 9F                          precision floating-point  \n   /r VFNMSUB132SD xmm1                             value from xmm1 and       \n   {k1}{z}, xmm2,           B     V/V       AVX512F xmm3/m64, negate the      \n   xmm3/m64{er}                                     multiplication result and \n                                                    subtract xmm2 and put     \n                                                    result in xmm1.           \n                                                    Multiply scalar double    \n   EVEX.LLIG.66.0F38.W1 AF                          precision floating-point  \n   /r VFNMSUB213SD xmm1                             value from xmm1 and xmm2, \n   {k1}{z}, xmm2,           B     V/V       AVX512F negate the multiplication \n   xmm3/m64{er}                                     result and subtract       \n                                                    xmm3/m64 and put result   \n                                                    in xmm1.                  \n                                                    Multiply scalar double    \n   EVEX.LLIG.66.0F38.W1 BF                          precision floating-point  \n   /r VFNMSUB231SD xmm1                             value from xmm2 and       \n   {k1}{z}, xmm2,           B     V/V       AVX512F xmm3/m64, negate the      \n   xmm3/m64{er}                                     multiplication result and \n                                                    subtract xmm1 and put     \n                                                    result in xmm1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMSUB132SD: Multiplies the low packed double precision floating-point\n   value from the first source operand to the low packed double precision\n   floating-point value in the third source operand. From negated infinite\n   precision intermediate result, subtracts the low double precision\n   floating-point value in the second source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VFNMSUB213SD: Multiplies the low packed double precision floating-point\n   value from the second source operand to the low packed double precision\n   floating-point value in the first source operand. From negated infinite\n   precision intermediate result, subtracts the low double precision\n   floating-point value in the third source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VFNMSUB231SD: Multiplies the low packed double precision floating-point\n   value from the second source to the low packed double precision\n   floating-point value in the third source operand. From negated infinite\n   precision intermediate result, subtracts the low double precision\n   floating-point value in the first source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:64 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination is\n   updated according to the writemask.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["vfnmsub132ss:vfnmsub213ss:vfnmsub231ss", "   VFNMSUB132SS/VFNMSUB213SS/VFNMSUB231SS \u2014 Fused Negative Multiply-Subtract\n                ofScalar Single Precision Floating-Point Values\n\n                            Op / 64/32 Bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Multiply scalar            \n                                                   single-precision           \n   VEX.LIG.66.0F38.W0 9F /r                        floating-point value from  \n   VFNMSUB132SS xmm1, xmm2, A    V/V       FMA     xmm1 and xmm3/m32, negate  \n   xmm3/m32                                        the multiplication result  \n                                                   and subtract xmm2 and put  \n                                                   result in xmm1.            \n                                                   Multiply scalar            \n                                                   single-precision           \n   VEX.LIG.66.0F38.W0 AF /r                        floating-point value from  \n   VFNMSUB213SS xmm1, xmm2, A    V/V       FMA     xmm1 and xmm2, negate the  \n   xmm3/m32                                        multiplication result and  \n                                                   subtract xmm3/m32 and put  \n                                                   result in xmm1.            \n                                                   Multiply scalar            \n                                                   single-precision           \n   VEX.LIG.66.0F38.W0 BF /r                        floating-point value from  \n   VFNMSUB231SS xmm1, xmm2, A    V/V       FMA     xmm2 and xmm3/m32, negate  \n   xmm3/m32                                        the multiplication result  \n                                                   and subtract xmm1 and put  \n                                                   result in xmm1.            \n                                                   Multiply scalar            \n   EVEX.LLIG.66.0F38.W0 9F                         single-precision           \n   /r VFNMSUB132SS xmm1                            floating-point value from  \n   {k1}{z}, xmm2,           B    V/V       AVX512F xmm1 and xmm3/m32, negate  \n   xmm3/m32{er}                                    the multiplication result  \n                                                   and subtract xmm2 and put  \n                                                   result in xmm1.            \n                                                   Multiply scalar            \n   EVEX.LLIG.66.0F38.W0 AF                         single-precision           \n   /r VFNMSUB213SS xmm1                            floating-point value from  \n   {k1}{z}, xmm2,           B    V/V       AVX512F xmm1 and xmm2, negate the  \n   xmm3/m32{er}                                    multiplication result and  \n                                                   subtract xmm3/m32 and put  \n                                                   result in xmm1.            \n                                                   Multiply scalar            \n   EVEX.LLIG.66.0F38.W0 BF                         single-precision           \n   /r VFNMSUB231SS xmm1                            floating-point value from  \n   {k1}{z}, xmm2,           B    V/V       AVX512F xmm2 and xmm3/m32, negate  \n   xmm3/m32{er}                                    the multiplication result  \n                                                   and subtract xmm1 and put  \n                                                   result in xmm1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMSUB132SS: Multiplies the low packed single-precision floating-point\n   value from the first source operand to the low packed single-precision\n   floating-point value in the third source operand. From negated infinite\n   precision intermediate result, the low single-precision floating-point\n   value in the second source operand, performs rounding and stores the\n   resulting packed single-precision floating-point value to the destination\n   operand (first source operand).\n\n   VFNMSUB213SS: Multiplies the low packed single-precision floating-point\n   value from the second source operand to the low packed single-precision\n   floating-point value in the first source operand. From negated infinite\n   precision intermediate result, the low single-precision floating-point\n   value in the third source operand, performs rounding and stores the\n   resulting packed single-precision floating-point value to the destination\n   operand (first source operand).\n\n   VFNMSUB231SS: Multiplies the low packed single-precision floating-point\n   value from the second source to the low packed single-precision\n   floating-point value in the third source operand. From negated infinite\n   precision intermediate result, the low single-precision floating-point\n   value in the first source operand, performs rounding and stores the\n   resulting packed single-precision floating-point value to the destination\n   operand (first source operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:32 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination is\n   updated according to the writemask.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["vmovsh", "                        VMOVSH \u2014 Move Scalar FP16 Value\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En bit Mode Flag     \n   CPUID Feature Instruction En bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En bit Mode Flag     \n   CPUID Feature Instruction En bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Move FP16 value     \n   EVEX.LLIG.F3.MAP5.W0 10 /r       A V/V     AVX512-FP16 from m16 to xmm1    \n   VMOVSH xmm1{k1}{z}, m16                                subject to          \n                                                          writemask k1.       \n                                                          Move low FP16 value \n   EVEX.LLIG.F3.MAP5.W0 11 /r       B V/V     AVX512-FP16 from xmm1 to m16    \n   VMOVSH m16{k1}, xmm1                                   subject to          \n                                                          writemask k1.       \n                                                          Move low FP16       \n                                                          values from xmm3 to \n   EVEX.LLIG.F3.MAP5.W0 10 /r                             xmm1 subject to     \n   VMOVSH xmm1{k1}{z}, xmm2, xmm3   C V/V     AVX512-FP16 writemask k1. Bits  \n                                                          127:16 of xmm2 are  \n                                                          copied to           \n                                                          xmm1[127:16].       \n                                                          Move low FP16       \n                                                          values from xmm3 to \n   EVEX.LLIG.F3.MAP5.W0 11 /r                             xmm1 subject to     \n   VMOVSH xmm1{k1}{z}, xmm2, xmm3   D V/V     AVX512-FP16 writemask k1. Bits  \n                                                          127:16 of xmm2 are  \n                                                          copied to           \n                                                          xmm1[127:16].       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   B     Scalar ModRM:r/m (w) ModRM:reg (r) N/A           N/A       \n   C     N/A    ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   D     N/A    ModRM:r/m (w) VEX.vvvv (r)  ModRM:reg (r) N/A       \n\n  Description \u00b6\n\n   This instruction moves a FP16 value to a register or memory location.\n\n   The two register-only forms are aliases and differ only in where their\n   operands are encoded; this is a side effect of the encodings selected.\n"],
	["aesdec128kl", " AESDEC128KL \u2014 Perform Ten Rounds of AES Decryption Flow With Key Locker Using\n                                   128-BitKey\n\n                               64/32-bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                                         Flag    \n   F3 0F 38 DD                                   Decrypt xmm using 128-bit    \n   !(11):rrr:bbb         A     V/V       AESKLE  AES key indicated by handle  \n   AESDEC128KL xmm, m384                         at m384 and store result in  \n                                                 xmm.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   The AESDEC128KL^1 instruction performs 10 rounds of AES to decrypt the\n   first operand using the 128-bit key indicated by the handle from the\n   second operand. It stores the result in the first operand if the operation\n   succeeds (e.g., does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n"],
	["vpdpwssd", "                VPDPWSSD \u2014 Multiply and Add Signed Word Integers\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply groups of 2  \n                                                        pairs signed words in \n                                                        xmm3/m128 with        \n   VEX.128.66.0F38.W0 52                                corresponding signed  \n   /r VPDPWSSD xmm1,      A     V/V       AVX-VNNI      words of xmm2,        \n   xmm2, xmm3/m128                                      summing those         \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result in xmm1.       \n                                                        Multiply groups of 2  \n                                                        pairs signed words in \n                                                        ymm3/m256 with        \n   VEX.256.66.0F38.W0 52                                corresponding signed  \n   /r VPDPWSSD ymm1,      A     V/V       AVX-VNNI      words of ymm2,        \n   ymm2, ymm3/m256                                      summing those         \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result in ymm1.       \n                                                        Multiply groups of 2  \n                                                        pairs signed words in \n                                                        xmm3/m128/m32bcst     \n   EVEX.128.66.0F38.W0 52                               with corresponding    \n   /r VPDPWSSD            B     V/V       AVX512_VNNI   signed words of xmm2, \n   xmm1{k1}{z}, xmm2,                     AVX512VL      summing those         \n   xmm3/m128/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in xmm1, under \n                                                        writemask k1.         \n                                                        Multiply groups of 2  \n                                                        pairs signed words in \n                                                        ymm3/m256/m32bcst     \n   EVEX.256.66.0F38.W0 52                               with corresponding    \n   /r VPDPWSSD            B     V/V       AVX512_VNNI   signed words of ymm2, \n   ymm1{k1}{z}, ymm2,                     AVX512VL      summing those         \n   ymm3/m256/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in ymm1, under \n                                                        writemask k1.         \n                                                        Multiply groups of 2  \n                                                        pairs signed words in \n                                                        zmm3/m512/m32bcst     \n   EVEX.512.66.0F38.W0 52                               with corresponding    \n   /r VPDPWSSD            B     V/V       AVX512_VNNI   signed words of zmm2, \n   zmm1{k1}{z}, zmm2,                                   summing those         \n   zmm3/m512/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in zmm1, under \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A   ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full  ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Multiplies the individual signed words of the first source operand by the\n   corresponding signed words of the second source operand, producing\n   intermediate signed, doubleword results. The adjacent doubleword results\n   are then summed and accumulated in the destination operand.\n\n   This instruction supports memory fault suppression.\n"],
	["clflushopt", "                    CLFLUSHOPT \u2014 Flush Cache Line Optimized\n\n   Opcode /        Op/En 64-bit Mode Compat/Leg Mode Description              \n   Instruction     \n   NFx 66 0F AE /7 M     Valid       Valid           Flushes cache line       \n   CLFLUSHOPT m8                                     containing m8.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Invalidates from every level of the cache hierarchy in the cache coherence\n   domain the cache line that contains the linear address specified with the\n   memory operand. If that cache line contains modified data at any level of\n   the cache hierarchy, that data is written back to memory. The source\n   operand is a byte memory location.\n\n   The availability of CLFLUSHOPT is indicated by the presence of the CPUID\n   feature flag CLFLUSHOPT (CPUID.(EAX=07H,ECX=0H):EBX[bit 23]). The aligned\n   cache line size affected is also indicated with the CPUID instruction\n   (bits 8 through 15 of the EBX register when the initial value in the EAX\n   register is 1).\n\n   The memory attribute of the page containing the affected line has no\n   effect on the behavior of this instruction. It should be noted that\n   processors are free to speculatively fetch and cache data from system\n   memory regions assigned a memory-type allowing for speculative reads (such\n   as, the WB, WC, and WT memory types). PREFETCHh instructions can be used\n   to provide the processor with hints for this speculative behavior. Because\n   this speculative fetching can occur at any time and is not tied to\n   instruction execution, the CLFLUSH instruction is not ordered with respect\n   to PREFETCHh instructions or any of the speculative fetching mechanisms\n   (that is, data can be speculatively loaded into a cache line just before,\n   during, or after the execution of a CLFLUSH instruction that references\n   the cache line).\n\n   Executions of the CLFLUSHOPT instruction are ordered with respect to fence\n   instructions and to locked read-modify-write instructions; they are also\n   ordered with respect to older writes to the cache line being invalidated.\n   They are not ordered with respect to other executions of CLFLUSHOPT, to\n   executions of CLFLUSH and CLWB, or to younger writes to the cache line\n   being invalidated. Software can use the SFENCE instruction to order an\n   execution of CLFLUSHOPT relative to one of those operations.\n\n   The CLFLUSHOPT instruction can be used at all privilege levels and is\n   subject to all permission checking and faults associated with a byte load\n   (and in addition, a CLFLUSHOPT instruction is allowed to flush a linear\n   address in an execute-only segment). Like a load, the CLFLUSHOPT\n   instruction sets the A bit but not the D bit in the page tables.\n\n   In some implementations, the CLFLUSHOPT instruction may always cause\n   transactional abort with Transactional Synchronization Extensions (TSX).\n   The CLFLUSHOPT instruction is not expected to be commonly used inside\n   typical transactional regions. However, programmers must not rely on\n   CLFLUSHOPT instruction to force a transactional abort, since whether they\n   cause transactional abort is implementation dependent.\n\n   CLFLUSHOPT operation is the same in non-64-bit modes and 64-bit mode.\n"],
	["encodekey128", "               ENCODEKEY128 \u2014 Encode 128-Bit Key With Key Locker\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                          Flag    \n   F3 0F 38 FA 11:rrr:bbb                         Wrap a 128-bit AES key from \n   ENCODEKEY128 r32, r32, A     V/V       AESKLE  XMM0 into a key handle and  \n   <XMM0-2>, <XMM4-6>                             output handle in XMM0\u20142.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3            Operands   Operands   \n                                                        4\u20145        6\u20147        \n   A     N/A   ModRM:reg ModRM:r/m Implicit XMM0 (r, w) Implicit   Implicit   \n               (w)       (r)                            XMM1\u20142 (w) XMM4\u20146 (w) \n\nDescription \u00b6\n\n   The ENCODEKEY128^1 instruction wraps a 128-bit AES key from the implicit\n   operand XMM0 into a key handle that is then stored in the implicit\n   destination operands XMM0-2.\n\n   The explicit source operand specifies handle restrictions, if any.\n\n   The explicit destination operand is populated with information on the\n   source of the key and its attributes. XMM4 through XMM6 are reserved for\n   future usages and software should not rely upon them being zeroed.\n\nFlags Affected \u00b6\n\n   All arithmetic flags (OF, SF, ZF, AF, PF, CF) are cleared to 0. Although\n   they are cleared for the currently defined operations, future extensions\n   may report information in the flags.\n\n   1. Further details on Key Locker and usage of this instruction can be\n   found here:\n\n  https://software.intel.com/content/www/us/en/develop/download/intel-key-locker-specification.html.\n  \u00b6\n"],
	["minsd", "      MINSD \u2014 Return Minimum Scalar Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Return the minimum scalar  \n   F2 0F 5D /r MINSD xmm1,  A    V/V       SSE2    double precision           \n   xmm2/m64                                        floating-point value       \n                                                   between xmm2/m64 and xmm1. \n   VEX.LIG.F2.0F.WIG 5D /r                         Return the minimum scalar  \n   VMINSD xmm1, xmm2,       B    V/V       AVX     double precision           \n   xmm3/m64                                        floating-point value       \n                                                   between xmm3/m64 and xmm2. \n   EVEX.LLIG.F2.0F.W1 5D /r                        Return the minimum scalar  \n   VMINSD xmm1 {k1}{z},     C    V/V       AVX512F double precision           \n   xmm2, xmm3/m64{sae}                             floating-point value       \n                                                   between xmm3/m64 and xmm2. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Compares the low double precision floating-point values in the first\n   source operand and the second source operand, and returns the minimum\n   value to the low quadword of the destination operand. When the source\n   operand is a memory operand, only the 64 bits are accessed.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second source operand is returned. If a value in the second source\n   operand is an SNaN, then SNaN is returned unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   source operand, either a NaN or a valid floating-point value, is written\n   to the result. If instead of this behavior, it is required that the NaN\n   source operand (from either the first or second source) be returned, the\n   action of MINSD can be emulated using a sequence of instructions, such as,\n   a comparison followed by AND, ANDN, and OR.\n\n   The second source operand can be an XMM register or a 64-bit memory\n   location. The first source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The destination and first source operand are\n   the same. Bits (MAXVL-1:64) of the corresponding destination register\n   remain unchanged.\n\n   VEX.128 and EVEX encoded version: Bits (127:64) of the XMM register\n   destination are copied from corresponding bits in the first source\n   operand. Bits (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination operand\n   is updated according to the writemask.\n\n   Software should ensure VMINSD is encoded with VEX.L=0. Encoding VMINSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["fdecstp", "                     FDECSTP \u2014 Decrement Stack-Top Pointer\n\n   Opcode  Mode Leg Mode Description                             \n   D9 F6                 Decrement TOP field in FPU status word. \n\nDescription \u00b6\n\n   Subtracts one from the TOP field of the FPU status word (decrements the\n   top-of-stack pointer). If the TOP field contains a 0, it is set to 7. The\n   effect of this instruction is to rotate the stack by one position. The\n   contents of the FPU data registers and tag register are not affected.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   The C1 flag is set to 0. The C0, C2, and C3 flags are undefined.\n"],
	["aaa", "                       AAA \u2014 ASCII Adjust After Addition\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description           \n   37     AAA         ZO    Invalid     Valid           ASCII adjust AL after \n                                                        addition.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Adjusts the sum of two unpacked BCD values to create an unpacked BCD\n   result. The AL register is the implied source and destination operand for\n   this instruction. The AAA instruction is only useful when it follows an\n   ADD instruction that adds (binary addition) two unpacked BCD values and\n   stores a byte result in the AL register. The AAA instruction then adjusts\n   the contents of the AL register to contain the correct 1-digit unpacked\n   BCD result.\n\n   If the addition produces a decimal carry, the AH register increments by 1,\n   and the CF and AF flags are set. If there was no decimal carry, the CF and\n   AF flags are cleared and the AH register is unchanged. In either case,\n   bits 4 through 7 of the AL register are set to 0.\n\n   This instruction executes as described in compatibility mode and legacy\n   mode. It is not valid in 64-bit mode.\n\nFlags Affected \u00b6\n\n   The AF and CF flags are set to 1 if the adjustment results in a decimal\n   carry; otherwise they are set to 0. The OF, SF, ZF, and PF flags are\n   undefined.\n"],
	["imul", "                             IMUL \u2014 Signed Multiply\n\n   Opcode   Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   F6 /5    IMUL r/m8^1     M     Valid  Valid      AX:= AL \u2217 r/m byte.       \n   F7 /5    IMUL r/m16      M     Valid  Valid      DX:AX := AX \u2217 r/m word.   \n   F7 /5    IMUL r/m32      M     Valid  Valid      EDX:EAX := EAX \u2217 r/m32.   \n   REX.W +  IMUL r/m64      M     Valid  N.E.       RDX:RAX := RAX \u2217 r/m64.   \n   F7 /5    \n   0F AF /r IMUL r16, r/m16 RM    Valid  Valid      word register := word     \n                                                    register \u2217 r/m16.         \n                                                    doubleword register :=    \n   0F AF /r IMUL r32, r/m32 RM    Valid  Valid      doubleword register \u2217     \n                                                    r/m32.                    \n   REX.W +                                          Quadword register :=      \n   0F AF /r IMUL r64, r/m64 RM    Valid  N.E.       Quadword register \u2217       \n                                                    r/m64.                    \n            IMUL r16,                               word register := r/m16 \u2217  \n   6B /r ib r/m16, imm8     RMI   Valid  Valid      sign-extended immediate   \n                                                    byte.                     \n            IMUL r32,                               doubleword register :=    \n   6B /r ib r/m32, imm8     RMI   Valid  Valid      r/m32 \u2217 sign-extended     \n                                                    immediate byte.           \n   REX.W +  IMUL r64,                               Quadword register :=      \n   6B /r ib r/m64, imm8     RMI   Valid  N.E.       r/m64 \u2217 sign-extended     \n                                                    immediate byte.           \n   69 /r iw IMUL r16,       RMI   Valid  Valid      word register := r/m16 \u2217  \n            r/m16, imm16                            immediate word.           \n            IMUL r32,                               doubleword register :=    \n   69 /r id r/m32, imm32    RMI   Valid  Valid      r/m32 \u2217 immediate         \n                                                    doubleword.               \n   REX.W +  IMUL r64,                               Quadword register :=      \n   69 /r id r/m64, imm32    RMI   Valid  N.E.       r/m64 \u2217 immediate         \n                                                    doubleword.               \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3  Operand 4 \n   M     ModRM:r/m (r, w) N/A           N/A        N/A       \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A        N/A       \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8/16/32 N/A       \n\nDescription \u00b6\n\n   Performs a signed multiplication of two operands. This instruction has\n   three forms, depending on the number of operands.\n\n     * One-operand form \u2014 This form is identical to that used by the MUL\n       instruction. Here, the source operand (in a general-purpose register\n       or memory location) is multiplied by the value in the AL, AX, EAX, or\n       RAX register (depending on the operand size) and the product (twice\n       the size of the input operand) is stored in the AX, DX:AX, EDX:EAX, or\n       RDX:RAX registers, respectively.\n     * Two-operand form \u2014 With this form the destination operand (the first\n       operand) is multiplied by the source operand (second operand). The\n       destination operand is a general-purpose register and the source\n       operand is an immediate value, a general-purpose register, or a memory\n       location. The intermediate product (twice the size of the input\n       operand) is truncated and stored in the destination operand location.\n     * Three-operand form \u2014 This form requires a destination operand (the\n       first operand) and two source operands (the second and the third\n       operands). Here, the first source operand (which can be a\n       general-purpose register or a memory location) is multiplied by the\n       second source operand (an immediate value). The intermediate product\n       (twice the size of the first source operand) is truncated and stored\n       in the destination operand (a general-purpose register).\n\n   When an immediate value is used as an operand, it is sign-extended to the\n   length of the destination operand format.\n\n   The CF and OF flags are set when the signed integer value of the\n   intermediate product differs from the sign extended operand-size-truncated\n   product, otherwise the CF and OF flags are cleared.\n\n   The three forms of the IMUL instruction are similar in that the length of\n   the product is calculated to twice the length of the operands. With the\n   one-operand form, the product is stored exactly in the destination. With\n   the two- and three- operand forms, however, the result is truncated to the\n   length of the destination before it is stored in the destination register.\n   Because of this truncation, the CF or OF flag should be tested to ensure\n   that no significant bits are lost.\n\n   The two- and three-operand forms may also be used with unsigned operands\n   because the lower half of the product is the same regardless if the\n   operands are signed or unsigned. The CF and OF flags, however, cannot be\n   used to determine if the upper half of the result is non-zero.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. Use of REX.W modifies\n   the three forms of the instruction as follows.\n\n     * One-operand form \u2014The source operand (in a 64-bit general-purpose\n       register or memory location) is multiplied by the value in the RAX\n       register and the product is stored in the RDX:RAX registers.\n     * Two-operand form \u2014 The source operand is promoted to 64 bits if it is\n       a register or a memory location. The destination operand is promoted\n       to 64 bits.\n     * Three-operand form \u2014 The first source operand (either a register or a\n       memory location) and destination operand are promoted to 64 bits. If\n       the source operand is an immediate, it is sign extended to 64 bits.\n\nFlags Affected \u00b6\n\n   For the one operand form of the instruction, the CF and OF flags are set\n   when significant bits are carried into the upper half of the result and\n   cleared when the result fits exactly in the lower half of the result. For\n   the two- and three-operand forms of the instruction, the CF and OF flags\n   are set when the result must be truncated to fit in the destination\n   operand size and cleared when the result fits exactly in the destination\n   operand size. The SF, ZF, AF, and PF flags are undefined.\n"],
	["vreduceph", "       VREDUCEPH \u2014 Perform Reduction Transformation on Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En bit    \n   Mode Flag CPUID Feature       \n   Instruction En bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En bit Mode Flag  \n   CPUID Feature Instruction En  \n   bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed FP16 values in  \n   EVEX.128.NP.0F3A.W0 56 /r /ib                       xmm2/m128/m16bcst by   \n   VREDUCEPH xmm1{k1}{z},        A V/V     AVX512-FP16 subtracting a number   \n   xmm2/m128/m16bcst, imm8                 AVX512VL    of fraction bits       \n                                                       specified by the imm8  \n                                                       field. Store the       \n                                                       result in xmm1 subject \n                                                       to writemask k1.       \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed FP16 values in  \n   EVEX.256.NP.0F3A.W0 56 /r /ib                       ymm2/m256/m16bcst by   \n   VREDUCEPH ymm1{k1}{z},        A V/V     AVX512-FP16 subtracting a number   \n   ymm2/m256/m16bcst, imm8                 AVX512VL    of fraction bits       \n                                                       specified by the imm8  \n                                                       field. Store the       \n                                                       result in ymm1 subject \n                                                       to writemask k1.       \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed FP16 values in  \n   EVEX.512.NP.0F3A.W0 56 /r /ib                       zmm2/m512/m16bcst by   \n   VREDUCEPH zmm1{k1}{z},        A V/V     AVX512-FP16 subtracting a number   \n   zmm2/m512/m16bcst {sae}, imm8                       of fraction bits       \n                                                       specified by the imm8  \n                                                       field. Store the       \n                                                       result in zmm1 subject \n                                                       to writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) imm8 (r)  N/A       \n\n  Description \u00b6\n\n   This instruction performs a reduction transformation of the packed binary\n   encoded FP16 values in the source operand (the second operand) and store\n   the reduced results in binary FP format to the destination operand (the\n   first operand) under the writemask k1.\n\n   The reduction transformation subtracts the integer part and the leading M\n   fractional bits from the binary FP source value, where M is a unsigned\n   integer specified by imm8[7:4]. Specifically, the reduction transformation\n   can be expressed as:\n\n   dest = src \u2212 (ROUND(2^M * src)) * 2^\u2212M\n\n   where ROUND() treats src, 2^M, and their product as binary FP numbers with\n   normalized significand and biased exponents.\n\n   The magnitude of the reduced result can be expressed by considering src =\n   2^p * man2, where \u2018man2\u2019 is the normalized significand and \u2018p\u2019 is the\n   unbiased exponent.\n\n   Then if RC=RNE: 0 \u2264 |ReducedResult| \u2264 2^\u2212M\u22121.\n\n   Then if RC =\u0338 RNE: 0 \u2264 |ReducedResult| < 2^\u2212M.\n\n   This instruction might end up with a precision exception set. However, in\n   case of SPE set (i.e., Suppress Precision Exception, which is imm8[3]=1),\n   no precision exception is reported.\n\n   This instruction may generate tiny non-zero result. If it does so, it does\n   not report underflow exception, even if underflow exceptions are unmasked\n   (UM flag in MXCSR register is 0).\n\n   For special cases, see Table 5-30.\n\n   Input value                        Round Mode   Returned Value        \n   |Src1| < 2^\u2212^M^\u2212^1                 RNE          Src1                  \n                                      RU, Src1 > 0 Round(Src1 \u2212 2^\u2212^M)^1 \n   |Src1| < 2^\u2212M                      RU, Src1 \u2264 0 Src1                  \n                                      RD, Src1 \u2265 0 Src1                  \n                                      RD, Src1 < 0 Round(Src1 + 2^\u2212^M)   \n   Src1 = \u00b10 or Dest = \u00b10 (Src1 =\u0338 \u221e) NOT RD       +0.0                  \n                                      RD           \u22120.0                  \n   Src1 = \u00b1\u221e                          Any          +0.0                  \n   Src1 = \u00b1NAN                        Any          QNaN (Src1)           \n\n   Table 5-30. VREDUCEPH/VREDUCESH Special Cases\n\n     1. The Round(.) function uses rounding controls specified by (imm8[2]?\n     MXCSR.RC: imm8[1:0]).\n"],
	["vpconflictd:vpconflictq", "VPCONFLICTD/VPCONFLICTQ \u2014 Detect Conflicts Within a Vector of Packed Dword/Qword\n                       Values Into DenseMemory/ Register\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n   EVEX.128.66.0F38.W0 C4                          Detect duplicate           \n   /r VPCONFLICTD xmm1    A     V/V       AVX512VL double-word values in      \n   {k1}{z},                               AVX512CD xmm2/m128/m32bcst using    \n   xmm2/m128/m32bcst                               writemask k1.              \n   EVEX.256.66.0F38.W0 C4                          Detect duplicate           \n   /r VPCONFLICTD ymm1    A     V/V       AVX512VL double-word values in      \n   {k1}{z},                               AVX512CD ymm2/m256/m32bcst using    \n   ymm2/m256/m32bcst                               writemask k1.              \n   EVEX.512.66.0F38.W0 C4                          Detect duplicate           \n   /r VPCONFLICTD zmm1    A     V/V       AVX512CD double-word values in      \n   {k1}{z},                                        zmm2/m512/m32bcst using    \n   zmm2/m512/m32bcst                               writemask k1.              \n   EVEX.128.66.0F38.W1 C4                          Detect duplicate quad-word \n   /r VPCONFLICTQ xmm1    A     V/V       AVX512VL values in                  \n   {k1}{z},                               AVX512CD xmm2/m128/m64bcst using    \n   xmm2/m128/m64bcst                               writemask k1.              \n   EVEX.256.66.0F38.W1 C4                          Detect duplicate quad-word \n   /r VPCONFLICTQ ymm1    A     V/V       AVX512VL values in                  \n   {k1}{z},                               AVX512CD ymm2/m256/m64bcst using    \n   ymm2/m256/m64bcst                               writemask k1.              \n   EVEX.512.66.0F38.W1 C4                          Detect duplicate quad-word \n   /r VPCONFLICTQ zmm1    A     V/V       AVX512CD values in                  \n   {k1}{z},                                        zmm2/m512/m64bcst using    \n   zmm2/m512/m64bcst                               writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Test each dword/qword element of the source operand (the second operand)\n   for equality with all other elements in the source operand closer to the\n   least significant element. Each element\u2019s comparison results form a bit\n   vector, which is then zero extended and written to the destination\n   according to the writemask.\n\n   EVEX.512 encoded version: The source operand is a ZMM register, a 512-bit\n   memory location, or a 512-bit vector broadcasted from a 32/64-bit memory\n   location. The destination operand is a ZMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.256 encoded version: The source operand is a YMM register, a 256-bit\n   memory location, or a 256-bit vector broadcasted from a 32/64-bit memory\n   location. The destination operand is a YMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.128 encoded version: The source operand is a XMM register, a 128-bit\n   memory location, or a 128-bit vector broadcasted from a 32/64-bit memory\n   location. The destination operand is a XMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["dppd", "      DPPD \u2014 Dot Product of Packed Double Precision Floating-Point Values\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                          Flag    \n                                                  Selectively multiply packed \n                                                  double precision            \n                                                  floating-point values from  \n                                                  xmm1 with packed double     \n   66 0F 3A 41 /r ib DPPD RMI   V/V       SSE4_1  precision floating-point    \n   xmm1, xmm2/m128, imm8                          values from xmm2, add and   \n                                                  selectively store the       \n                                                  packed double precision     \n                                                  floating-point values to    \n                                                  xmm1.                       \n                                                  Selectively multiply packed \n                                                  double precision            \n                                                  floating-point values from  \n   VEX.128.66.0F3A.WIG 41                         xmm2 with packed double     \n   /r ib VDPPD xmm1,xmm2, RVMI  V/V       AVX     precision floating-point    \n   xmm3/m128, imm8                                values from xmm3, add and   \n                                                  selectively store the       \n                                                  packed double precision     \n                                                  floating-point values to    \n                                                  xmm1.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Conditionally multiplies the packed double precision floating-point values\n   in the destination operand (first operand) with the packed double\n   precision floating-point values in the source (second operand) depending\n   on a mask extracted from bits [5:4] of the immediate operand (third\n   operand). If a condition mask bit is zero, the corresponding\n   multiplication is replaced by a value of 0.0 in the manner described by\n   Section 12.8.4 of Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1.\n\n   The two resulting double precision values are summed into an intermediate\n   result. The intermediate result is conditionally broadcasted to the\n   destination using a broadcast mask specified by bits [1:0] of the\n   immediate byte.\n\n   If a broadcast mask bit is \u201c1\u201d, the intermediate result is copied to the\n   corresponding qword element in the destination operand. If a broadcast\n   mask bit is zero, the corresponding element in the destination is set to\n   zero.\n\n   DPPD follows the NaN forwarding rules stated in the Software Developer\u2019s\n   Manual, vol. 1, table 4-7. These rules do not cover horizontal\n   prioritization of NaNs. Horizontal propagation of NaNs to the destination\n   and the positioning of those NaNs in the destination is implementation\n   dependent. NaNs on the input sources or computationally generated NaNs\n   will have at least one NaN propagated to the destination.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   If VDPPD is encoded with VEX.L= 1, an attempt to execute the instruction\n   encoded with VEX.L= 1 will cause an #UD exception.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["sal:sar:shl:shr", "                            SAL/SAR/SHL/SHR \u2014 Shift\n\n   Opcode^1\n\n            Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   D0 /4    SAL r/m8, 1     M1    Valid  Valid      Multiply r/m8 by 2, once. \n   REX + D0 SAL r/m8^2, 1   M1    Valid  N.E.       Multiply r/m8 by 2, once. \n   /4       \n   D2 /4    SAL r/m8, CL    MC    Valid  Valid      Multiply r/m8 by 2, CL    \n                                                    times.                    \n   REX + D2 SAL r/m8^2, CL  MC    Valid  N.E.       Multiply r/m8 by 2, CL    \n   /4                                               times.                    \n   C0 /4 ib SAL r/m8, imm8  MI    Valid  Valid      Multiply r/m8 by 2, imm8  \n                                                    times.                    \n   REX + C0 SAL r/m8^2,     MI    Valid  N.E.       Multiply r/m8 by 2, imm8  \n   /4 ib    imm8                                    times.                    \n   D1 /4    SAL r/m16, 1    M1    Valid  Valid      Multiply r/m16 by 2,      \n                                                    once.                     \n   D3 /4    SAL r/m16, CL   MC    Valid  Valid      Multiply r/m16 by 2, CL   \n                                                    times.                    \n   C1 /4 ib SAL r/m16, imm8 MI    Valid  Valid      Multiply r/m16 by 2, imm8 \n                                                    times.                    \n   D1 /4    SAL r/m32, 1    M1    Valid  Valid      Multiply r/m32 by 2,      \n                                                    once.                     \n   REX.W +  SAL r/m64, 1    M1    Valid  N.E.       Multiply r/m64 by 2,      \n   D1 /4                                            once.                     \n   D3 /4    SAL r/m32, CL   MC    Valid  Valid      Multiply r/m32 by 2, CL   \n                                                    times.                    \n   REX.W +  SAL r/m64, CL   MC    Valid  N.E.       Multiply r/m64 by 2, CL   \n   D3 /4                                            times.                    \n   C1 /4 ib SAL r/m32, imm8 MI    Valid  Valid      Multiply r/m32 by 2, imm8 \n                                                    times.                    \n   REX.W +  SAL r/m64, imm8 MI    Valid  N.E.       Multiply r/m64 by 2, imm8 \n   C1 /4 ib                                         times.                    \n   D0 /7    SAR r/m8, 1     M1    Valid  Valid      Signed divide^3 r/m8 by   \n                                                    2, once.                  \n   REX + D0 SAR r/m8^2, 1   M1    Valid  N.E.       Signed divide^3 r/m8 by   \n   /7                                               2, once.                  \n   D2 /7    SAR r/m8, CL    MC    Valid  Valid      Signed divide^3 r/m8 by   \n                                                    2, CL times.              \n   REX + D2 SAR r/m8^2, CL  MC    Valid  N.E.       Signed divide^3 r/m8 by   \n   /7                                               2, CL times.              \n   C0 /7 ib SAR r/m8, imm8  MI    Valid  Valid      Signed divide^3 r/m8 by   \n                                                    2, imm8 times.            \n   REX + C0 SAR r/m8^2,     MI    Valid  N.E.       Signed divide^3 r/m8 by   \n   /7 ib    imm8                                    2, imm8 times.            \n   D1 /7    SAR r/m16,1     M1    Valid  Valid      Signed divide^3 r/m16 by  \n                                                    2, once.                  \n   D3 /7    SAR r/m16, CL   MC    Valid  Valid      Signed divide^3 r/m16 by  \n                                                    2, CL times.              \n   C1 /7 ib SAR r/m16, imm8 MI    Valid  Valid      Signed divide^3 r/m16 by  \n                                                    2, imm8 times.            \n   D1 /7    SAR r/m32, 1    M1    Valid  Valid      Signed divide^3 r/m32 by  \n                                                    2, once.                  \n   REX.W +  SAR r/m64, 1    M1    Valid  N.E.       Signed divide^3 r/m64 by  \n   D1 /7                                            2, once.                  \n   D3 /7    SAR r/m32, CL   MC    Valid  Valid      Signed divide^3 r/m32 by  \n                                                    2, CL times.              \n   REX.W +  SAR r/m64, CL   MC    Valid  N.E.       Signed divide^3 r/m64 by  \n   D3 /7                                            2, CL times.              \n   C1 /7 ib SAR r/m32, imm8 MI    Valid  Valid      Signed divide^3 r/m32 by  \n                                                    2, imm8 times.            \n   REX.W +  SAR r/m64, imm8 MI    Valid  N.E.       Signed divide^3 r/m64 by  \n   C1 /7 ib                                         2, imm8 times             \n   D0 /4    SHL r/m8, 1     M1    Valid  Valid      Multiply r/m8 by 2, once. \n   REX + D0 SHL r/m8^2, 1   M1    Valid  N.E.       Multiply r/m8 by 2, once. \n   /4       \n   D2 /4    SHL r/m8, CL    MC    Valid  Valid      Multiply r/m8 by 2, CL    \n                                                    times.                    \n   REX + D2 SHL r/m8^2, CL  MC    Valid  N.E.       Multiply r/m8 by 2, CL    \n   /4                                               times.                    \n   C0 /4 ib SHL r/m8, imm8  MI    Valid  Valid      Multiply r/m8 by 2, imm8  \n                                                    times.                    \n   REX + C0 SHL r/m8^2,     MI    Valid  N.E.       Multiply r/m8 by 2, imm8  \n   /4 ib    imm8                                    times.                    \n   D1 /4    SHL r/m16,1     M1    Valid  Valid      Multiply r/m16 by 2,      \n                                                    once.                     \n   D3 /4    SHL r/m16, CL   MC    Valid  Valid      Multiply r/m16 by 2, CL   \n                                                    times.                    \n   C1 /4 ib SHL r/m16, imm8 MI    Valid  Valid      Multiply r/m16 by 2, imm8 \n                                                    times.                    \n   D1 /4    SHL r/m32,1     M1    Valid  Valid      Multiply r/m32 by 2,      \n                                                    once.                     \n\n   Opcode^1\n\n            Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   REX.W +  SHL r/m64,1     M1    Valid  N.E.       Multiply r/m64 by 2,      \n   D1 /4                                            once.                     \n   D3 /4    SHL r/m32, CL   MC    Valid  Valid      Multiply r/m32 by 2, CL   \n                                                    times.                    \n   REX.W +  SHL r/m64, CL   MC    Valid  N.E.       Multiply r/m64 by 2, CL   \n   D3 /4                                            times.                    \n   C1 /4 ib SHL r/m32, imm8 MI    Valid  Valid      Multiply r/m32 by 2, imm8 \n                                                    times.                    \n   REX.W +  SHL r/m64, imm8 MI    Valid  N.E.       Multiply r/m64 by 2, imm8 \n   C1 /4 ib                                         times.                    \n   D0 /5    SHR r/m8,1      M1    Valid  Valid      Unsigned divide r/m8 by   \n                                                    2, once.                  \n   REX + D0 SHR r/m8^2, 1   M1    Valid  N.E.       Unsigned divide r/m8 by   \n   /5                                               2, once.                  \n   D2 /5    SHR r/m8, CL    MC    Valid  Valid      Unsigned divide r/m8 by   \n                                                    2, CL times.              \n   REX + D2 SHR r/m8^2, CL  MC    Valid  N.E.       Unsigned divide r/m8 by   \n   /5                                               2, CL times.              \n   C0 /5 ib SHR r/m8, imm8  MI    Valid  Valid      Unsigned divide r/m8 by   \n                                                    2, imm8 times.            \n   REX + C0 SHR r/m8^2,     MI    Valid  N.E.       Unsigned divide r/m8 by   \n   /5 ib    imm8                                    2, imm8 times.            \n   D1 /5    SHR r/m16, 1    M1    Valid  Valid      Unsigned divide r/m16 by  \n                                                    2, once.                  \n   D3 /5    SHR r/m16, CL   MC    Valid  Valid      Unsigned divide r/m16 by  \n                                                    2, CL times               \n   C1 /5 ib SHR r/m16, imm8 MI    Valid  Valid      Unsigned divide r/m16 by  \n                                                    2, imm8 times.            \n   D1 /5    SHR r/m32, 1    M1    Valid  Valid      Unsigned divide r/m32 by  \n                                                    2, once.                  \n   REX.W +  SHR r/m64, 1    M1    Valid  N.E.       Unsigned divide r/m64 by  \n   D1 /5                                            2, once.                  \n   D3 /5    SHR r/m32, CL   MC    Valid  Valid      Unsigned divide r/m32 by  \n                                                    2, CL times.              \n   REX.W +  SHR r/m64, CL   MC    Valid  N.E.       Unsigned divide r/m64 by  \n   D3 /5                                            2, CL times.              \n   C1 /5 ib SHR r/m32, imm8 MI    Valid  Valid      Unsigned divide r/m32 by  \n                                                    2, imm8 times.            \n   REX.W +  SHR r/m64, imm8 MI    Valid  N.E.       Unsigned divide r/m64 by  \n   C1 /5 ib                                         2, imm8 times.            \n\n     1. See the IA-32 Architecture Compatibility section below.\n\n     2. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\n     3. Not the same form of division as IDIV; rounding is toward negative\n     infinity.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2 Operand 3 Operand 4 \n   M1    ModRM:r/m (r, w) 1         N/A       N/A       \n   MC    ModRM:r/m (r, w) CL        N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8      N/A       N/A       \n\nDescription \u00b6\n\n   Shifts the bits in the first operand (destination operand) to the left or\n   right by the number of bits specified in the second operand (count\n   operand). Bits shifted beyond the destination operand boundary are first\n   shifted into the CF flag, then discarded. At the end of the shift\n   operation, the CF flag contains the last bit shifted out of the\n   destination operand.\n\n   The destination operand can be a register or a memory location. The count\n   operand can be an immediate value or the CL register. The count is masked\n   to 5 bits (or 6 bits with a 64-bit operand). The count range is limited to\n   0 to 31 (or 63 with a 64-bit operand). A special opcode encoding is\n   provided for a count of 1.\n\n   The shift arithmetic left (SAL) and shift logical left (SHL) instructions\n   perform the same operation; they shift the bits in the destination operand\n   to the left (toward more significant bit locations). For each shift count,\n   the most significant bit of the destination operand is shifted into the CF\n   flag, and the least significant bit is cleared (see Figure 7-7 in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1).\n\n   The shift arithmetic right (SAR) and shift logical right (SHR)\n   instructions shift the bits of the destination operand to the right\n   (toward less significant bit locations). For each shift count, the least\n   significant bit of the destination operand is shifted into the CF flag,\n   and the most significant bit is either set or cleared depending on the\n   instruction type. The SHR instruction clears the most significant bit (see\n   Figure 7-8 in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1); the SAR instruction sets or clears the most significant\n   bit to correspond to the sign (most significant bit) of the original value\n   in the destination operand. In effect, the SAR instruction fills the empty\n   bit position\u2019s shifted value with the sign of the unshifted value (see\n   Figure 7-9 in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1).\n\n   The SAR and SHR instructions can be used to perform signed or unsigned\n   division, respectively, of the destination operand by powers of 2. For\n   example, using the SAR instruction to shift a signed integer 1 bit to the\n   right divides the value by 2.\n\n   Using the SAR instruction to perform a division operation does not produce\n   the same result as the IDIV instruction. The quotient from the IDIV\n   instruction is rounded toward zero, whereas the \u201cquotient\u201d of the SAR\n   instruction is rounded toward negative infinity. This difference is\n   apparent only for negative numbers. For example, when the IDIV instruction\n   is used to divide -9 by 4, the result is -2 with a remainder of -1. If the\n   SAR instruction is used to shift -9 right by two bits, the result is -3\n   and the \u201cremainder\u201d is +3; however, the SAR instruction stores only the\n   most significant bit of the remainder (in the CF flag).\n\n   The OF flag is affected only on 1-bit shifts. For left shifts, the OF flag\n   is set to 0 if the most-significant bit of the result is the same as the\n   CF flag (that is, the top two bits of the original operand were the same);\n   otherwise, it is set to 1. For the SAR instruction, the OF flag is cleared\n   for all 1-bit shifts. For the SHR instruction, the OF flag is set to the\n   most-significant bit of the original operand.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits and\n   the mask width for CL is 5 bits. Using a REX prefix in the form of REX.R\n   permits access to additional registers (R8-R15). Using a REX prefix in the\n   form of REX.W promotes operation to 64-bits and sets the mask width for CL\n   to 6 bits. See the summary chart at the beginning of this section for\n   encoding data and limits.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The 8086 does not mask the shift count. However, all other IA-32\n   processors (starting with the Intel 286 processor) do mask the shift count\n   to 5 bits, resulting in a maximum count of 31. This masking is done in all\n   operating modes (including the virtual-8086 mode) to reduce the maximum\n   execution time of the instructions.\n\nFlags Affected \u00b6\n\n   The CF flag contains the value of the last bit shifted out of the\n   destination operand; it is undefined for SHL and SHR instructions where\n   the count is greater than or equal to the size (in bits) of the\n   destination operand. The OF flag is affected only for 1-bit shifts (see\n   \u201cDescription\u201d above); otherwise, it is undefined. The SF, ZF, and PF flags\n   are set according to the result. If the count is 0, the flags are not\n   affected. For a non-zero count, the AF flag is undefined.\n"],
	["ltr", "                            LTR \u2014 Load Task Register\n\n   Opcode   Instruction Op/En 64-Bit Mode Compat/Leg Mode Description         \n   0F 00 /3 LTR r/m16   M     Valid       Valid           Load r/m16 into     \n                                                          task register.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the source operand into the segment selector field of the task\n   register. The source operand (a general-purpose register or a memory\n   location) contains a segment selector that points to a task state segment\n   (TSS). After the segment selector is loaded in the task register, the\n   processor uses the segment selector to locate the segment descriptor for\n   the TSS in the global descriptor table (GDT). It then loads the segment\n   limit and base address for the TSS from the segment descriptor into the\n   task register. The task pointed to by the task register is marked busy,\n   but a switch to the task does not occur.\n\n   The LTR instruction is provided for use in operating-system software; it\n   should not be used in application programs. It can only be executed in\n   protected mode when the CPL is 0. It is commonly used in initialization\n   code to establish the first task to be executed.\n\n   The operand-size attribute has no effect on this instruction.\n\n   In 64-bit mode, the operand size is still fixed at 16 bits. The\n   instruction references a 16-byte descriptor to load the 64-bit base.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpgatherqd:vpgatherqq", "  VPGATHERQD/VPGATHERQQ \u2014 Gather Packed Dword, Packed Qword with Signed Qword\n                                    Indices\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Using signed qword         \n   EVEX.128.66.0F38.W0 91                 AVX512VL indices, gather dword      \n   /vsib VPGATHERQD xmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm64x                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed qword         \n   EVEX.256.66.0F38.W0 91                 AVX512VL indices, gather dword      \n   /vsib VPGATHERQD xmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm64y                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed qword         \n   EVEX.512.66.0F38.W0 91                          indices, gather dword      \n   /vsib VPGATHERQD ymm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm64z                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed qword         \n   EVEX.128.66.0F38.W1 91                 AVX512VL indices, gather quadword   \n   /vsib VPGATHERQQ xmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm64x                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed qword         \n   EVEX.256.66.0F38.W1 91                 AVX512VL indices, gather quadword   \n   /vsib VPGATHERQQ ymm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm64y                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed qword         \n   EVEX.512.66.0F38.W1 91                          indices, gather quadword   \n   /vsib VPGATHERQQ zmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm64z                                     writemask k1 for           \n                                                   merging-masking.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2               Operand 3 Operand 4 \n         Tuple1                   BaseReg (R): VSIB:base,                     \n   A     Scalar     ModRM:reg (w) VectorReg(R):           N/A       N/A\n                                  VSIB:index              \n\n  Description \u00b6\n\n   A set of 8 doubleword/quadword memory locations pointed to by base address\n   BASE_ADDR and index vector VINDEX with scale SCALE are gathered. The\n   result is written into a vector register. The elements are specified via\n   the VSIB (i.e., the index register is a vector register, holding packed\n   indices). Elements will only be loaded if their corresponding mask bit is\n   one. If an element\u2019s mask bit is not set, the corresponding element of the\n   destination register is left unchanged. The entire mask register will be\n   set to zero by this instruction unless it triggers an exception.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask register (k1) are partially updated;\n   those elements that have been gathered are placed into the destination\n   register and have their mask bits set to zero. If any traps or interrupts\n   are pending from already gathered elements, they will be delivered in lieu\n   of the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data element size is less than the index element size, the higher\n   part of the destination register and the mask register do not correspond\n   to any elements being gathered. This instruction sets those higher parts\n   to zero. It may update these unused elements to one or both of those\n   registers even if the instruction triggers an exception, and even if the\n   instruction triggers the exception before gathering any elements.\n\n   Note that:\n\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination zmm will be completed (and non-faulting).\n       Individual elements closer to the MSB may or may not be completed. If\n       a given element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to-left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n     * These instructions do not accept zeroing-masking since the 0 values in\n       k1 are used to determine completion.\n\n   Note that the presence of VSIB byte is enforced in this instruction.\n   Hence, the instruction will #UD fault if ModRM.rm is different than 100b.\n\n   This instruction has the same disp8*N and alignment rules as for scalar\n   instructions (Tuple 1).\n\n   The instruction will #UD fault if the destination vector zmm1 is the same\n   as index vector VINDEX. The instruction will #UD fault if the k0 mask\n   register is specified.\n\n   The scaled index may require more bits to represent than the address bits\n   used by the processor (e.g., in 32-bit mode, if the scale is greater than\n   one). In this case, the most significant bits beyond the number of address\n   bits are ignored.\n"],
	["vcvttph2uw", "       VCVTTPH2UW \u2014 Convert Packed FP16 Values to Unsigned Word Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Convert eight packed   \n                                                       FP16 values in         \n                                                       xmm2/m128/m16bcst to   \n   EVEX.128.NP.MAP5.W0 7C /r               AVX512-FP16 eight unsigned word    \n   VCVTTPH2UW xmm1{k1}{z},       A V/V     AVX512VL    integers, and store    \n   xmm2/m128/m16bcst                                   the result in xmm1     \n                                                       using truncation       \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Convert sixteen packed \n                                                       FP16 values in         \n                                                       ymm2/m256/m16bcst to   \n   EVEX.256.NP.MAP5.W0 7C /r               AVX512-FP16 sixteen unsigned word  \n   VCVTTPH2UW ymm1{k1}{z},       A V/V     AVX512VL    integers, and store    \n   ymm2/m256/m16bcst                                   the result in ymm1     \n                                                       using truncation       \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Convert thirty-two     \n                                                       packed FP16 values in  \n                                                       zmm2/m512/m16bcst to   \n   EVEX.512.NP.MAP5.W0 7C /r                           thirty-two unsigned    \n   VCVTTPH2UW zmm1{k1}{z},       A V/V     AVX512-FP16 word integers, and     \n   zmm2/m512/m16bcst {sae}                             store the result in    \n                                                       zmm1 using truncation  \n                                                       subject to writemask   \n                                                       k1.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   unsigned word integers in the destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer indefinite value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["eresume", "                         ERESUME \u2014 Re-Enters an Enclave\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n   EAX = 03H                                     This leaf function is used   \n   ENCLU[ERESUME]     IR    V/V          SGX1    to re-enter an enclave after \n                                                 an interrupt.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En RAX          RBX                   RCX                 \n   IR    ERESUME (In) Address of a TCS (In) Address of AEP (In) \n\n  Description \u00b6\n\n   The ENCLU[ERESUME] instruction resumes execution of an enclave that was\n   interrupted due to an exception or interrupt, using the machine state\n   previously stored in the SSA.\n\nERESUME Memory Parameter Semantics \u00b6\n\n   TCS                       \n   Enclave read/write access \n\n   The instruction faults if any of the following occurs:\n\n   Address in RBX is not      Any TCS.FLAGS\u2019s must-be-zero bit is not zero.   \n   properly aligned.          \n   TCS pointed to by RBX is   Current 32/64 mode does not match the enclave   \n   not valid or available or  mode in SECS.ATTRIBUTES.MODE64.                 \n   locked.                    \n   The SECS is in use by      Either of TCS-specified FS and GS segment is    \n   another enclave.           not a subset of the current DS segment.         \n   Any one of DS, ES, CS, SS  If XSAVE available, CR4.OSXSAVE = 0, but        \n   is not zero.               SECS.ATTRIBUTES.XFRM =\u0338 3.                      \n   CR4.OSFXSR =\u0338 1.           If CR4.OSXSAVE = 1, SECS.ATTRIBUTES.XFRM is not \n                              a subset of XCR0.                               \n   Offsets 520-535 of the     The bit vector stored at offset 512 of the      \n   XSAVE area not 0.          XSAVE area must be a subset of                  \n                              SECS.ATTRIBUTES.XFRM.                           \n   The SSA frame is not valid If SECS.ATTRIBUTES.AEXNOTIFY =\u0338                 \n   or in use.                 TCS.FLAGS.AEXNOTIFY and TCS.FLAGS.DBGOPTIN = 0. \n\n   The following operations are performed by ERESUME:\n\n     * RSP and RBP are saved in the current SSA frame on EENTER and are\n       automatically restored on EEXIT or an asynchronous exit due to any\n       Interrupt event.\n     * The AEP contained in RCX is stored into the TCS for use by AEXs.FS and\n       GS (including hidden portions) are saved and new values are\n       constructed using TCS.OFSBASE/GSBASE (32 and 64-bit mode) and\n       TCS.OFSLIMIT/GSLIMIT (32-bit mode only). The resulting segments must\n       be a subset of the DS segment.\n     * If CR4.OSXSAVE == 1, XCR0 is saved and replaced by\n       SECS.ATTRIBUTES.XFRM. The effect of RFLAGS.TF depends on whether the\n       enclave entry is opt-in or opt-out (see Section 40.1.2):\n          * On opt-out entry, TF is saved and cleared (it is restored on\n            EEXIT or AEX). Any attempt to set TF via a POPF instruction while\n            inside the enclave clears TF (see Section 40.2.5).\n          * On opt-out entry, TF is saved and cleared (it is restored on\n            EEXIT or AEX). Any attempt to set TF via a POPF instruction while\n            inside the enclave clears TF (see Section 40.2.5).\n          * On opt-in entry, a single-step debug exception is pended on the\n            instruction boundary immediately after EENTER (see Section\n            40.2.3).\n          * On opt-in entry, a single-step debug exception is pended on the\n            instruction boundary immediately after EENTER (see Section\n            40.2.3).\n     * All code breakpoints that do not overlap with ELRANGE are also\n       suppressed. If the entry is an opt-out entry, all code and data\n       breakpoints that overlap with the ELRANGE are suppressed.\n     * On opt-out entry, a number of performance monitoring counters and\n       behaviors are modified or suppressed (see Section 40.2.3):\n          * All performance monitoring activity on the current thread is\n            suppressed except for incrementing and firing of FIXED_CTR1 and\n            FIXED_CTR2.\n          * All performance monitoring activity on the current thread is\n            suppressed except for incrementing and firing of FIXED_CTR1 and\n            FIXED_CTR2.\n          * PEBS is suppressed.\n          * PEBS is suppressed.\n          * AnyThread counting on other threads is demoted to MyThread mode\n            and IA32_PERF_GLOBAL_STATUS[60] on that thread is set.\n          * AnyThread counting on other threads is demoted to MyThread mode\n            and IA32_PERF_GLOBAL_STATUS[60] on that thread is set.\n          * If the opt-out entry on a hardware thread results in suppression\n            of any performance monitoring, then the processor sets\n            IA32_PERF_GLOBAL_STATUS[60] and IA32_PERF_GLOBAL_STATUS[63].\n          * If the opt-out entry on a hardware thread results in suppression\n            of any performance monitoring, then the processor sets\n            IA32_PERF_GLOBAL_STATUS[60] and IA32_PERF_GLOBAL_STATUS[63].\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                            Parameter    Base Concurrency Restrictions\n                                                       On Conflict      \n   ERESUME ERESUME TCS [DS:RBX]    TCS [DS:RBX] \n   Shared ERESUME TCS [DS:RBX]     \n\n   Table 38-74. Base Concurrency Restrictions of ERESUME\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT, EACCEPTCOPY, vs. vs. EADD,                 \n                     EADD, EEXTEND, EINIT vs.      EEXTEND, EINIT            \n                     ETRACK, ETRACKC Access vs.    vs. EADD,      vs. ETRACK,\n                     ETRACK, ETRACKC Access On     EEXTEND, EINIT ETRACKC\n   Leaf    Parameter Conflict Access vs. ETRACK,   vs. ETRACK,  \n                     ETRACKC Access On Conflict    ETRACKC      \n                     EMODPE, EMODPR, EMODT      \n                     Access On Conflict Access  \n                     On Conflict Access Access  \n                     On Conflict Access On      \n                     Conflict                   \n   ERESUME TCS       Concurrent                    Concurrent     Concurrent \n           [DS:RBX]  \n\n   Table 38-75. Additional Concurrency Restrictions of ERESUME\n\n  Flags Affected \u00b6\n\n   RFLAGS.TF is cleared on opt-out entry\n"],
	["vcvtuqq2pd", "    VCVTUQQ2PD \u2014 Convert Packed Unsigned Quadword Integers to Packed Double\n                         PrecisionFloating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     unsigned quadword        \n   EVEX.128.F3.0F.W1 7A /r                  AVX512VL integers from            \n   VCVTUQQ2PD xmm1 {k1}{z}, A     V/V       AVX512DQ xmm2/m128/m64bcst to two \n   xmm2/m128/m64bcst                                 packed double precision  \n                                                     floating-point values in \n                                                     xmm1 with writemask k1.  \n                                                     Convert four packed      \n                                                     unsigned quadword        \n   EVEX.256.F3.0F.W1 7A /r                  AVX512VL integers from            \n   VCVTUQQ2PD ymm1 {k1}{z}, A     V/V       AVX512DQ ymm2/m256/m64bcst to     \n   ymm2/m256/m64bcst                                 packed double precision  \n                                                     floating-point values in \n                                                     ymm1 with writemask k1.  \n                                                     Convert eight packed     \n                                                     unsigned quadword        \n   EVEX.512.F3.0F.W1 7A /r                           integers from            \n   VCVTUQQ2PD zmm1 {k1}{z}, A     V/V       AVX512DQ zmm2/m512/m64bcst to     \n   zmm2/m512/m64bcst{er}                             eight packed double      \n                                                     precision floating-point \n                                                     values in zmm1 with      \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed unsigned quadword integers in the source operand (second\n   operand) to packed double precision floating-point values in the\n   destination operand (first operand).\n\n   The source operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location or a 512/256/128-bit vector broadcasted from a 64-bit memory\n   location. The destination operand is a ZMM/YMM/XMM register conditionally\n   updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["pmaddwd", "                   PMADDWD \u2014 Multiply and Add Packed Integers\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply the packed      \n                                                     words in mm by the       \n   NP 0F F5 /r^1 PMADDWD    A     V/V       MMX      packed words in mm/m64,  \n   mm, mm/m64                                        add adjacent doubleword  \n                                                     results, and store in    \n                                                     mm.                      \n                                                     Multiply the packed word \n                                                     integers in xmm1 by the  \n   66 0F F5 /r PMADDWD      A     V/V       SSE2     packed word integers in  \n   xmm1, xmm2/m128                                   xmm2/m128, add adjacent  \n                                                     doubleword results, and  \n                                                     store in xmm1.           \n                                                     Multiply the packed word \n   VEX.128.66.0F.WIG F5 /r                           integers in xmm2 by the  \n   VPMADDWD xmm1, xmm2,     B     V/V       AVX      packed word integers in  \n   xmm3/m128                                         xmm3/m128, add adjacent  \n                                                     doubleword results, and  \n                                                     store in xmm1.           \n                                                     Multiply the packed word \n   VEX.256.66.0F.WIG F5 /r                           integers in ymm2 by the  \n   VPMADDWD ymm1, ymm2,     B     V/V       AVX2     packed word integers in  \n   ymm3/m256                                         ymm3/m256, add adjacent  \n                                                     doubleword results, and  \n                                                     store in ymm1.           \n                                                     Multiply the packed word \n                                                     integers in xmm2 by the  \n   EVEX.128.66.0F.WIG F5 /r                 AVX512VL packed word integers in  \n   VPMADDWD xmm1 {k1}{z},   C     V/V       AVX512BW xmm3/m128, add adjacent  \n   xmm2, xmm3/m128                                   doubleword results, and  \n                                                     store in xmm1 under      \n                                                     writemask k1.            \n                                                     Multiply the packed word \n                                                     integers in ymm2 by the  \n   EVEX.256.66.0F.WIG F5 /r                 AVX512VL packed word integers in  \n   VPMADDWD ymm1 {k1}{z},   C     V/V       AVX512BW ymm3/m256, add adjacent  \n   ymm2, ymm3/m256                                   doubleword results, and  \n                                                     store in ymm1 under      \n                                                     writemask k1.            \n                                                     Multiply the packed word \n                                                     integers in zmm2 by the  \n   EVEX.512.66.0F.WIG F5 /r                          packed word integers in  \n   VPMADDWD zmm1 {k1}{z},   C     V/V       AVX512BW zmm3/m512, add adjacent  \n   zmm2, zmm3/m512                                   doubleword results, and  \n                                                     store in zmm1 under      \n                                                     writemask k1.            \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Multiplies the individual signed words of the destination operand (first\n   operand) by the corresponding signed words of the source operand (second\n   operand), producing temporary signed, doubleword results. The adjacent\n   double-word results are then summed and stored in the destination operand.\n   For example, the corresponding low-order words (15-0) and (31-16) in the\n   source and destination operands are multiplied by one another and the\n   double-word results are added together and stored in the low doubleword of\n   the destination register (31-0). The same operation is performed on the\n   other pairs of adjacent words. (Figure 4-11 shows this operation when\n   using 64-bit operands).\n\n   The (V)PMADDWD instruction wraps around only in one situation: when the 2\n   pairs of words being operated on in a group are all 8000H. In this case,\n   the result wraps around to 80000000H.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version: The first source and destination operands are MMX\n   registers. The second source operand is an MMX register or a 64-bit memory\n   location.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX.512 encoded version: The second source operand can be an ZMM register\n   or a 512-bit memory location. The first source and destination operands\n   are ZMM registers.\n\n   SRC X3 X2 X1 X0 DEST Y3 Y2 Y1 Y0 X3 \u2217 Y3 X2 \u2217 Y2 X1 \u2217 Y1 X0 \u2217 Y0 TEMP DEST\n   (X1\u2217Y1)+(X0\u2217Y0) (X3\u2217Y3)+(X2\u2217Y2) Figure 4-11. PMADDWD Execution Model Using\n   64-bit Operands\n\nFlags Affected \u00b6\n\n   None.\n"],
	["uiret", "                         UIRET \u2014 User-Interrupt Return\n\n   Opcode/Instruction Op/En 64/32 bit Mode CPUID Feature Description          \n                            Support        Flag          \n   F3 0F 01 EC UIRET  ZO    V/I            UINTR         Return from handling \n                                                         a user interrupt.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   UIRET returns from the handling of a user interrupt. It can be executed\n   regardless of CPL.\n\n   Execution of UIRET inside a transactional region causes a transactional\n   abort; the abort loads EAX as it would have had it been due to an\n   execution of IRET.\n\n   UIRET can be tracked by Architectural Last Branch Records (LBRs), Intel\n   Processor Trace (Intel PT), and Performance Monitoring. For both Intel PT\n   and LBRs, UIRET is recorded in precisely the same manner as IRET. Hence\n   for LBRs, UIRETs fall into the OTHER_BRANCH category, which implies that\n   IA32_LBR_CTL.OTHER_BRANCH[bit 22] must be set to record user-interrupt\n   delivery, and that the IA32_LBR_x_INFO.BR_TYPE field will indicate\n   OTHER_BRANCH for any recorded user interrupt. For Intel PT, control flow\n   tracing must be enabled by setting IA32_RTIT_CTL.BranchEn[bit 13].\n\n   UIRET will also increment performance counters for which counting\n   BR_INST_RETIRED.FAR_BRANCH is enabled.\n\nFlags Affected \u00b6\n\n   See the Operation section.\n"],
	["vfixupimmpd", "               VFIXUPIMMPD \u2014 Fix Up Special Packed Float64 Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Fix up special numbers  \n   EVEX.128.66.0F3A.W1 54 /r                          in float64 vector xmm1, \n   ib VFIXUPIMMPD xmm1                       AVX512VL float64 vector xmm2 and \n   {k1}{z}, xmm2,            A     V/V       AVX512F  int64 vector            \n   xmm3/m128/m64bcst, imm8                            xmm3/m128/m64bcst and   \n                                                      store the result in     \n                                                      xmm1, under writemask.  \n                                                      Fix up special numbers  \n   EVEX.256.66.0F3A.W1 54 /r                          in float64 vector ymm1, \n   ib VFIXUPIMMPD ymm1                       AVX512VL float64 vector ymm2 and \n   {k1}{z}, ymm2,            A     V/V       AVX512F  int64 vector            \n   ymm3/m256/m64bcst, imm8                            ymm3/m256/m64bcst and   \n                                                      store the result in     \n                                                      ymm1, under writemask.  \n                                                      Fix up elements of      \n                                                      float64 vector in zmm2  \n   EVEX.512.66.0F3A.W1 54 /r                          using int64 vector      \n   ib VFIXUPIMMPD zmm1                                table in                \n   {k1}{z}, zmm2,            A     V/V       AVX512F  zmm3/m512/m64bcst,      \n   zmm3/m512/m64bcst{sae},                            combine with preserved  \n   imm8                                               elements from zmm1, and \n                                                      store the result in     \n                                                      zmm1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Perform fix-up of quad-word elements encoded in double precision\n   floating-point format in the first source operand (the second operand)\n   using a 32-bit, two-level look-up table specified in the corresponding\n   quadword element of the second source operand (the third operand) with\n   exception reporting specifier imm8. The elements that are fixed-up are\n   selected by mask bits of 1 specified in the opmask k1. Mask bits of 0 in\n   the opmask k1 or table response action of 0000b preserves the\n   corresponding element of the first operand. The fixed-up elements from the\n   first source operand and the preserved element in the first operand are\n   combined as the final results in the destination operand (the first\n   operand).\n\n   The destination and the first source operands are ZMM/YMM/XMM registers.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 64-bit\n   memory location.\n\n   The two-level look-up table perform a fix-up of each double precision\n   floating-point input data in the first source operand by decoding the\n   input data encoding into 8 token types. A response table is defined for\n   each token type that converts the input encoding in the first source\n   operand with one of 16 response actions.\n\n   This instruction is specifically intended for use in fixing up the results\n   of arithmetic calculations involving one source so that they match the\n   spec, although it is generally useful for fixing up the results of\n   multiple-instruction sequences to reflect special-number inputs. For\n   example, consider rcp(0). Input 0 to rcp, and you should get INF according\n   to the DX10 spec. However, evaluating rcp via Newton-Raphson, where\n   x=approx(1/0), yields an incorrect result. To deal with this, VFIXUPIMMPD\n   can be used after the N-R reciprocal sequence to set the result to the\n   correct value (i.e., INF when the input is 0).\n\n   If MXCSR.DAZ is not set, denormal input elements in the first source\n   operand are considered as normal inputs and do not trigger any fixup nor\n   fault reporting.\n\n   Imm8 is used to set the required flags reporting. It supports #ZE and #IE\n   fault reporting (see details below).\n\n   MXCSR mask bits are ignored and are treated as if all mask bits are set to\n   masked response). If any of the imm8 bits is set and the condition met for\n   fault reporting, MXCSR.IE or MXCSR.ZE might be updated.\n\n   This instruction is writemasked, so only those elements with the\n   corresponding bit set in vector mask register k1 are computed and stored\n   into zmm1. Elements in the destination with the corresponding bit clear in\n   k1 retain their previous values or are set to 0.\n"],
	["minps", "        MINPS \u2014 Minimum of Packed Single Precision Floating-Point Values\n\n                              Op 64/32 bit CPUID                              \n   Opcode/Instruction         /  Mode      Feature  Description\n                              En Support   Flag     \n                                                    Return the minimum single \n   NP 0F 5D /r MINPS xmm1,    A  V/V       SSE      precision floating-point  \n   xmm2/m128                                        values between xmm1 and   \n                                                    xmm2/mem.                 \n   VEX.128.0F.WIG 5D /r                             Return the minimum single \n   VMINPS xmm1, xmm2,         B  V/V       AVX      precision floating-point  \n   xmm3/m128                                        values between xmm2 and   \n                                                    xmm3/mem.                 \n                                                    Return the minimum single \n   VEX.256.0F.WIG 5D /r                             double precision          \n   VMINPS ymm1, ymm2,         B  V/V       AVX      floating-point values     \n   ymm3/m256                                        between ymm2 and          \n                                                    ymm3/mem.                 \n                                                    Return the minimum packed \n                                                    single precision          \n   EVEX.128.0F.W0 5D /r                    AVX512VL floating-point values     \n   VMINPS xmm1 {k1}{z}, xmm2, C  V/V       AVX512F  between xmm2 and          \n   xmm3/m128/m32bcst                                xmm3/m128/m32bcst and     \n                                                    store result in xmm1      \n                                                    subject to writemask k1.  \n                                                    Return the minimum packed \n                                                    single precision          \n   EVEX.256.0F.W0 5D /r                    AVX512VL floating-point values     \n   VMINPS ymm1 {k1}{z}, ymm2, C  V/V       AVX512F  between ymm2 and          \n   ymm3/m256/m32bcst                                ymm3/m256/m32bcst and     \n                                                    store result in ymm1      \n                                                    subject to writemask k1.  \n                                                    Return the minimum packed \n                                                    single precision          \n   EVEX.512.0F.W0 5D /r                             floating-point values     \n   VMINPS zmm1 {k1}{z}, zmm2, C  V/V       AVX512F  between zmm2 and          \n   zmm3/m512/m32bcst{sae}                           zmm3/m512/m32bcst and     \n                                                    store result in zmm1      \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed single precision floating-point\n   values in the first source operand and the second source operand and\n   returns the minimum value for each pair of values to the destination\n   operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of MINPS can be emulated using a sequence of\n   instructions, such as, a comparison followed by AND, ANDN, and OR.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. The upper bits (MAXVL-1:256) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["loop:loopcc", "                  LOOP/LOOPcc \u2014 Loop According to ECX Counter\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n   E2 cb  LOOP rel8   D     Valid       Valid           Decrement count; jump \n                                                        short if count =\u0338 0.  \n                                                        Decrement count; jump \n   E1 cb  LOOPE rel8  D     Valid       Valid           short if count =\u0338 0   \n                                                        and ZF = 1.           \n                                                        Decrement count; jump \n   E0 cb  LOOPNE rel8 D     Valid       Valid           short if count =\u0338 0   \n                                                        and ZF = 0.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3    Operand 4 \n   D Offset N/A N/A                       N/A       \n\nDescription \u00b6\n\n   Performs a loop operation using the RCX, ECX or CX register as a counter\n   (depending on whether address size is 64 bits, 32 bits, or 16 bits). Note\n   that the LOOP instruction ignores REX.W; but 64-bit address size can be\n   over-ridden using a 67H prefix.\n\n   Each time the LOOP instruction is executed, the count register is\n   decremented, then checked for 0. If the count is 0, the loop is terminated\n   and program execution continues with the instruction following the LOOP\n   instruction. If the count is not zero, a near jump is performed to the\n   destination (target) operand, which is presumably the instruction at the\n   beginning of the loop.\n\n   The target instruction is specified with a relative offset (a signed\n   offset relative to the current value of the instruction pointer in the\n   IP/EIP/RIP register). This offset is generally specified as a label in\n   assembly code, but at the machine code level, it is encoded as a signed,\n   8-bit immediate value, which is added to the instruction pointer. Offsets\n   of \u2013128 to +127 are allowed with this instruction.\n\n   Some forms of the loop instruction (LOOPcc) also accept the ZF flag as a\n   condition for terminating the loop before the count reaches zero. With\n   these forms of the instruction, a condition code (cc) is associated with\n   each instruction to indicate the condition being tested for. Here, the\n   LOOPcc instruction itself does not affect the state of the ZF flag; the ZF\n   flag is changed by other instructions in the loop.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["roundsd", "         ROUNDSD \u2014 Round Scalar Double Precision Floating-Point Values\n\n                                 64/32 bit CPUID                              \n   Opcode*/Instruction     Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Round the low packed       \n                                                   double precision           \n   66 0F 3A 0B /r ib                               floating-point value in    \n   ROUNDSD xmm1, xmm2/m64, RMI   V/V       SSE4_1  xmm2/m64 and place the     \n   imm8                                            result in xmm1. The        \n                                                   rounding mode is           \n                                                   determined by imm8.        \n                                                   Round the low packed       \n                                                   double precision           \n                                                   floating-point value in    \n                                                   xmm3/m64 and place the     \n   VEX.LIG.66.0F3A.WIG 0B                          result in xmm1. The        \n   /r ib VROUNDSD xmm1,    RVMI  V/V       AVX     rounding mode is           \n   xmm2, xmm3/m64, imm8                            determined by imm8. Upper  \n                                                   packed double precision    \n                                                   floating-point value       \n                                                   (bits[127:64]) from xmm2   \n                                                   is copied to xmm1[127:64]. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Round the double precision floating-point value in the lower qword of the\n   source operand (second operand) using the rounding mode specified in the\n   immediate operand (third operand) and place the result in the destination\n   operand (first operand). The rounding process rounds a double precision\n   floating-point input to an integer value and returns the integer result as\n   a double precision floating-point value in the lowest position. The upper\n   double precision floating-point value in the destination is retained.\n\n   The immediate operand specifies control fields for the rounding operation,\n   three bit fields are defined and shown in Figure 4-24. Bit 3 of the\n   immediate byte controls processor behavior for a precision exception, bit\n   2 selects the source of rounding mode control. Bits 1:0 specify a\n   non-sticky rounding-mode value (Table 4-18 lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:64) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n"],
	["unpckhps", "  UNPCKHPS \u2014 Unpack and Interleave High Packed Single Precision Floating-Point\n                                     Values\n\n                         Op / 64/32 bit CPUID                                 \n   Opcode/Instruction    En   Mode      Feature  Description\n                              Support   Flag     \n                                                 Unpacks and Interleaves      \n   NP 0F 15 /r UNPCKHPS                          single precision             \n   xmm1, xmm2/m128       A    V/V       SSE      floating-point values from   \n                                                 high quadwords of xmm1 and   \n                                                 xmm2/m128.                   \n                                                 Unpacks and Interleaves      \n   VEX.128.0F.WIG 15 /r                          single precision             \n   VUNPCKHPS xmm1, xmm2, B    V/V       AVX      floating-point values from   \n   xmm3/m128                                     high quadwords of xmm2 and   \n                                                 xmm3/m128.                   \n                                                 Unpacks and Interleaves      \n   VEX.256.0F.WIG 15 /r                          single precision             \n   VUNPCKHPS ymm1, ymm2, B    V/V       AVX      floating-point values from   \n   ymm3/m256                                     high quadwords of ymm2 and   \n                                                 ymm3/m256.                   \n                                                 Unpacks and Interleaves      \n   EVEX.128.0F.W0 15 /r                          single precision             \n   VUNPCKHPS xmm1                       AVX512VL floating-point values from   \n   {k1}{z}, xmm2,        C    V/V       AVX512F  high quadwords of xmm2 and   \n   xmm3/m128/m32bcst                             xmm3/m128/m32bcst and write  \n                                                 result to xmm1 subject to    \n                                                 writemask k1.                \n                                                 Unpacks and Interleaves      \n   EVEX.256.0F.W0 15 /r                          single precision             \n   VUNPCKHPS ymm1                       AVX512VL floating-point values from   \n   {k1}{z}, ymm2,        C    V/V       AVX512F  high quadwords of ymm2 and   \n   ymm3/m256/m32bcst                             ymm3/m256/m32bcst and write  \n                                                 result to ymm1 subject to    \n                                                 writemask k1.                \n                                                 Unpacks and Interleaves      \n   EVEX.512.0F.W0 15 /r                          single precision             \n   VUNPCKHPS zmm1                                floating-point values from   \n   {k1}{z}, zmm2,        C    V/V       AVX512F  high quadwords of zmm2 and   \n   zmm3/m512/m32bcst                             zmm3/m512/m32bcst and write  \n                                                 result to zmm1 subject to    \n                                                 writemask k1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs an interleaved unpack of the high single precision floating-point\n   values from the first source operand and the second source operand.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified. When unpacking from a memory\n   operand, an implementation may fetch only the appropriate 64 bits;\n   however, alignment to 16-byte boundary and normal segment checking will\n   still be enforced.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.256 encoded version: The second source operand is an YMM register or\n   an 256-bit memory location. The first source operand and destination\n   operands are YMM registers.\n\n   X7 X6 X5 X4 X3 X2 X1 X0 SRC2 Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 DEST Y7 X7 Y6 X6 Y3\n   X3 Y2 X2 Figure 4-27. VUNPCKHPS Operation\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand is a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register, a 256-bit memory location, or a\n   256-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a YMM register, conditionally updated using writemask k1.\n\n   EVEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand is a XMM register, a 128-bit memory location, or a\n   128-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a XMM register, conditionally updated using writemask k1.\n"],
	["wrpkru", "                 WRPKRU \u2014 Write Data to User Page Key Register\n\n   Opcode/Instruction Op/En 64/32bit Mode       CPUID Feature Description     \n                            Support             Flag          \n   NP 0F 01 EF WRPKRU ZO    V/V                 OSPKE         Writes EAX into \n                                                              PKRU.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Writes the value of EAX into PKRU. ECX and EDX must be 0 when WRPKRU is\n   executed; otherwise, a general-protection exception (#GP) occurs.\n\n   WRPKRU can be executed only if CR4.PKE = 1; otherwise, an invalid-opcode\n   exception (#UD) occurs. Software can discover the value of CR4.PKE by\n   examining CPUID.(EAX=07H,ECX=0H):ECX.OSPKE [bit 4].\n\n   On processors that support the Intel 64 Architecture, the high-order\n   32-bits of RCX, RDX, and RAX are ignored.\n\n   WRPKRU will never execute speculatively. Memory accesses affected by PKRU\n   register will not execute (even speculatively) until all prior executions\n   of WRPKRU have completed execution and updated the PKRU register.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["tzcnt", "                 TZCNT \u2014 Count the Number of Trailing Zero Bits\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Count the number of        \n   F3 0F BC /r TZCNT r16,  A     V/V       BMI1    trailing zero bits in      \n   r/m16                                           r/m16, return result in    \n                                                   r16.                       \n                                                   Count the number of        \n   F3 0F BC /r TZCNT r32,  A     V/V       BMI1    trailing zero bits in      \n   r/m32                                           r/m32, return result in    \n                                                   r32.                       \n                                                   Count the number of        \n   F3 REX.W 0F BC /r TZCNT A     V/N.E.    BMI1    trailing zero bits in      \n   r64, r/m64                                      r/m64, return result in    \n                                                   r64.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   A     ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   TZCNT counts the number of trailing least significant zero bits in source\n   operand (second operand) and returns the result in destination operand\n   (first operand). TZCNT is an extension of the BSF instruction. The key\n   difference between TZCNT and BSF instruction is that TZCNT provides\n   operand size as output when source operand is zero while in the case of\n   BSF instruction, if source operand is zero, the content of destination\n   operand are undefined. On processors that do not support TZCNT, the\n   instruction byte encoding is executed as BSF.\n\nFlags Affected \u00b6\n\n   ZF is set to 1 in case of zero output (least significant bit of the source\n   is set), and to 0 otherwise, CF is set to 1 if the input was zero and\n   cleared otherwise. OF, SF, PF, and AF flags are undefined.\n"],
	["mul", "                            MUL \u2014 Unsigned Multiply\n\n   Opcode      Instruction Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   F6 /4       MUL r/m8    M     Valid  Valid      Unsigned multiply (AX :=   \n                                                   AL \u2217 r/m8).                \n   REX + F6 /4 MUL r/m8^1  M     Valid  N.E.       Unsigned multiply (AX :=   \n                                                   AL \u2217 r/m8).                \n   F7 /4       MUL r/m16   M     Valid  Valid      Unsigned multiply (DX:AX   \n                                                   := AX \u2217 r/m16).            \n   F7 /4       MUL r/m32   M     Valid  Valid      Unsigned multiply (EDX:EAX \n                                                   := EAX \u2217 r/m32).           \n   REX.W + F7  MUL r/m64   M     Valid  N.E.       Unsigned multiply (RDX:RAX \n   /4                                              := RAX \u2217 r/m64).           \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs an unsigned multiplication of the first operand (destination\n   operand) and the second operand (source operand) and stores the result in\n   the destination operand. The destination operand is an implied operand\n   located in register AL, AX or EAX (depending on the size of the operand);\n   the source operand is located in a general-purpose register or a memory\n   location. The action of this instruction and the location of the result\n   depends on the opcode and the operand size as shown in Table 4-9.\n\n   The result is stored in register AX, register pair DX:AX, or register pair\n   EDX:EAX (depending on the operand size), with the high-order bits of the\n   product contained in register AH, DX, or EDX, respectively. If the\n   high-order bits of the product are 0, the CF and OF flags are cleared;\n   otherwise, the flags are set.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits.\n\n   See the summary chart at the beginning of this section for encoding data\n   and limits.\n\n   Operand Size Source 1 Source 2 Destination \n   Byte         AL       r/m8     AX          \n   Word         AX       r/m16    DX:AX       \n   Doubleword   EAX      r/m32    EDX:EAX     \n   Quadword     RAX      r/m64    RDX:RAX     \n\n   Table 4-9. MUL Results\n\nFlags Affected \u00b6\n\n   The OF and CF flags are set to 0 if the upper half of the result is 0;\n   otherwise, they are set to 1. The SF, ZF, AF, and PF flags are undefined.\n"],
	["psllw:pslld:psllq", "               PSLLW/PSLLD/PSLLQ \u2014 Shift Packed Data Left Logical\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F F1 /r^1 PSLLW mm,                          Shift words in mm left    \n   mm/m64                  A     V/V       MMX      mm/m64 while shifting in  \n                                                    0s.                       \n   66 0F F1 /r PSLLW xmm1,                          Shift words in xmm1 left  \n   xmm2/m128               A     V/V       SSE2     by xmm2/m128 while        \n                                                    shifting in 0s.           \n   NP 0F 71 /6 ib PSLLW                             Shift words in mm left by \n   mm1, imm8               B     V/V       MMX      imm8 while shifting in    \n                                                    0s.                       \n   66 0F 71 /6 ib PSLLW                             Shift words in xmm1 left  \n   xmm1, imm8              B     V/V       SSE2     by imm8 while shifting in \n                                                    0s.                       \n   NP 0F F2 /r^1 PSLLD mm,                          Shift doublewords in mm   \n   mm/m64                  A     V/V       MMX      left by mm/m64 while      \n                                                    shifting in 0s.           \n   66 0F F2 /r PSLLD xmm1,                          Shift doublewords in xmm1 \n   xmm2/m128               A     V/V       SSE2     left by xmm2/m128 while   \n                                                    shifting in 0s.           \n   NP 0F 72 /6 ib^1 PSLLD                           Shift doublewords in mm   \n   mm, imm8                B     V/V       MMX      left by imm8 while        \n                                                    shifting in 0s.           \n   66 0F 72 /6 ib PSLLD                             Shift doublewords in xmm1 \n   xmm1, imm8              B     V/V       SSE2     left by imm8 while        \n                                                    shifting in 0s.           \n   NP 0F F3 /r^1 PSLLQ mm,                          Shift quadword in mm left \n   mm/m64                  A     V/V       MMX      by mm/m64 while shifting  \n                                                    in 0s.                    \n   66 0F F3 /r PSLLQ xmm1,                          Shift quadwords in xmm1   \n   xmm2/m128               A     V/V       SSE2     left by xmm2/m128 while   \n                                                    shifting in 0s.           \n   NP 0F 73 /6 ib^1 PSLLQ                           Shift quadword in mm left \n   mm, imm8                B     V/V       MMX      by imm8 while shifting in \n                                                    0s.                       \n   66 0F 73 /6 ib PSLLQ                             Shift quadwords in xmm1   \n   xmm1, imm8              B     V/V       SSE2     left by imm8 while        \n                                                    shifting in 0s.           \n   VEX.128.66.0F.WIG F1 /r                          Shift words in xmm2 left  \n   VPSLLW xmm1, xmm2,      C     V/V       AVX      by amount specified in    \n   xmm3/m128                                        xmm3/m128 while shifting  \n                                                    in 0s.                    \n   VEX.128.66.0F.WIG 71 /6                          Shift words in xmm2 left  \n   ib VPSLLW xmm1, xmm2,   D     V/V       AVX      by imm8 while shifting in \n   imm8                                             0s.                       \n   VEX.128.66.0F.WIG F2 /r                          Shift doublewords in xmm2 \n   VPSLLD xmm1, xmm2,      C     V/V       AVX      left by amount specified  \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.128.66.0F.WIG 72 /6                          Shift doublewords in xmm2 \n   ib VPSLLD xmm1, xmm2,   D     V/V       AVX      left by imm8 while        \n   imm8                                             shifting in 0s.           \n   VEX.128.66.0F.WIG F3 /r                          Shift quadwords in xmm2   \n   VPSLLQ xmm1, xmm2,      C     V/V       AVX      left by amount specified  \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.128.66.0F.WIG 73 /6                          Shift quadwords in xmm2   \n   ib VPSLLQ xmm1, xmm2,   D     V/V       AVX      left by imm8 while        \n   imm8                                             shifting in 0s.           \n   VEX.256.66.0F.WIG F1 /r                          Shift words in ymm2 left  \n   VPSLLW ymm1, ymm2,      C     V/V       AVX2     by amount specified in    \n   xmm3/m128                                        xmm3/m128 while shifting  \n                                                    in 0s.                    \n   VEX.256.66.0F.WIG 71 /6                          Shift words in ymm2 left  \n   ib VPSLLW ymm1, ymm2,   D     V/V       AVX2     by imm8 while shifting in \n   imm8                                             0s.                       \n   VEX.256.66.0F.WIG F2 /r                          Shift doublewords in ymm2 \n   VPSLLD ymm1, ymm2,      C     V/V       AVX2     left by amount specified  \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.256.66.0F.WIG 72 /6                          Shift doublewords in ymm2 \n   ib VPSLLD ymm1, ymm2,   D     V/V       AVX2     left by imm8 while        \n   imm8                                             shifting in 0s.           \n   VEX.256.66.0F.WIG F3 /r                          Shift quadwords in ymm2   \n   VPSLLQ ymm1, ymm2,      C     V/V       AVX2     left by amount specified  \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.256.66.0F.WIG 73 /6                          Shift quadwords in ymm2   \n   ib VPSLLQ ymm1, ymm2,   D     V/V       AVX2     left by imm8 while        \n   imm8                                             shifting in 0s.           \n   EVEX.128.66.0F.WIG F1                            Shift words in xmm2 left  \n   /r VPSLLW xmm1 {k1}{z}, G     V/V       AVX512VL by amount specified in    \n   xmm2, xmm3/m128                         AVX512BW xmm3/m128 while shifting  \n                                                    in 0s using writemask k1. \n   EVEX.256.66.0F.WIG F1                            Shift words in ymm2 left  \n   /r VPSLLW ymm1 {k1}{z}, G     V/V       AVX512VL by amount specified in    \n   ymm2, xmm3/m128                         AVX512BW xmm3/m128 while shifting  \n                                                    in 0s using writemask k1. \n   EVEX.512.66.0F.WIG F1                            Shift words in zmm2 left  \n   /r VPSLLW zmm1 {k1}{z}, G     V/V       AVX512BW by amount specified in    \n   zmm2, xmm3/m128                                  xmm3/m128 while shifting  \n                                                    in 0s using writemask k1. \n   EVEX.128.66.0F.WIG 71                            Shift words in xmm2/m128  \n   /6 ib VPSLLW xmm1       E     V/V       AVX512VL left by imm8 while        \n   {k1}{z}, xmm2/m128,                     AVX512BW shifting in 0s using      \n   imm8                                             writemask k1.             \n   EVEX.256.66.0F.WIG 71                            Shift words in ymm2/m256  \n   /6 ib VPSLLW ymm1       E     V/V       AVX512VL left by imm8 while        \n   {k1}{z}, ymm2/m256,                     AVX512BW shifting in 0s using      \n   imm8                                             writemask k1.             \n   EVEX.512.66.0F.WIG 71                            Shift words in zmm2/m512  \n   /6 ib VPSLLW zmm1       E     V/V       AVX512BW left by imm8 while        \n   {k1}{z}, zmm2/m512,                              shifting in 0 using       \n   imm8                                             writemask k1.             \n                                                    Shift doublewords in xmm2 \n   EVEX.128.66.0F.W0 F2 /r                 AVX512VL left by amount specified  \n   VPSLLD xmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   xmm2, xmm3/m128                                  shifting in 0s under      \n                                                    writemask k1.             \n                                                    Shift doublewords in ymm2 \n   EVEX.256.66.0F.W0 F2 /r                 AVX512VL left by amount specified  \n   VPSLLD ymm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   ymm2, xmm3/m128                                  shifting in 0s under      \n                                                    writemask k1.             \n                                                    Shift doublewords in zmm2 \n   EVEX.512.66.0F.W0 F2 /r                          left by amount specified  \n   VPSLLD zmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   zmm2, xmm3/m128                                  shifting in 0s under      \n                                                    writemask k1.             \n   EVEX.128.66.0F.W0 72 /6                          Shift doublewords in      \n   ib VPSLLD xmm1 {k1}{z}, F     V/V       AVX512VL xmm2/m128/m32bcst left by \n   xmm2/m128/m32bcst, imm8                 AVX512F  imm8 while shifting in 0s \n                                                    using writemask k1.       \n   EVEX.256.66.0F.W0 72 /6                          Shift doublewords in      \n   ib VPSLLD ymm1 {k1}{z}, F     V/V       AVX512VL ymm2/m256/m32bcst left by \n   ymm2/m256/m32bcst, imm8                 AVX512F  imm8 while shifting in 0s \n                                                    using writemask k1.       \n   EVEX.512.66.0F.W0 72 /6                          Shift doublewords in      \n   ib VPSLLD zmm1 {k1}{z}, F     V/V       AVX512F  zmm2/m512/m32bcst left by \n   zmm2/m512/m32bcst, imm8                          imm8 while shifting in 0s \n                                                    using writemask k1.       \n                                                    Shift quadwords in xmm2   \n   EVEX.128.66.0F.W1 F3 /r                 AVX512VL left by amount specified  \n   VPSLLQ xmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   xmm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift quadwords in ymm2   \n   EVEX.256.66.0F.W1 F3 /r                 AVX512VL left by amount specified  \n   VPSLLQ ymm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   ymm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift quadwords in zmm2   \n   EVEX.512.66.0F.W1 F3 /r                          left by amount specified  \n   VPSLLQ zmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   zmm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n   EVEX.128.66.0F.W1 73 /6                          Shift quadwords in        \n   ib VPSLLQ xmm1 {k1}{z}, F     V/V       AVX512VL xmm2/m128/m64bcst left by \n   xmm2/m128/m64bcst, imm8                 AVX512F  imm8 while shifting in 0s \n                                                    using writemask k1.       \n   EVEX.256.66.0F.W1 73 /6                          Shift quadwords in        \n   ib VPSLLQ ymm1 {k1}{z}, F     V/V       AVX512VL ymm2/m256/m64bcst left by \n   ymm2/m256/m64bcst, imm8                 AVX512F  imm8 while shifting in 0s \n                                                    using writemask k1.       \n   EVEX.512.66.0F.W1 73 /6                          Shift quadwords in        \n   ib VPSLLQ zmm1 {k1}{z}, F     V/V       AVX512F  zmm2/m512/m64bcst left by \n   zmm2/m512/m64bcst, imm8                          imm8 while shifting in 0s \n                                                    using writemask k1.       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:r/m (r, w) imm8          N/A           N/A       \n   C     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   D     N/A        VEX.vvvv (w)     ModRM:r/m (r) imm8          N/A       \n   E     Full Mem   EVEX.vvvv (w)    ModRM:r/m (r) imm8          N/A       \n   F     Full       EVEX.vvvv (w)    ModRM:r/m (r) imm8          N/A       \n   G     Mem128     ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Shifts the bits in the individual data elements (words, doublewords, or\n   quadword) in the destination operand (first operand) to the left by the\n   number of bits specified in the count operand (second operand). As the\n   bits in the data elements are shifted left, the empty low-order bits are\n   cleared (set to 0). If the value specified by the count operand is greater\n   than 15 (for words), 31 (for doublewords), or 63 (for a quadword), then\n   the destination operand is set to all 0s. Figure 4-17 gives an example of\n   shifting words in a 64-bit operand.\n\n   Pre-Shift X3 X2 X1 X0 DEST Shift Left with Zero Extension Post-Shift X0 <<\n   COUNT X3 << COUNT X2 << COUNT X1 << COUNT DEST Figure 4-17. PSLLW, PSLLD,\n   and PSLLQ Instruction Operation Using 64-bit Operand\n\n   The (V)PSLLW instruction shifts each of the words in the destination\n   operand to the left by the number of bits specified in the count operand;\n   the (V)PSLLD instruction shifts each of the doublewords in the destination\n   operand; and the (V)PSLLQ instruction shifts the quadword (or quadwords)\n   in the destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions 64-bit operand: The destination operand is an MMX\n   technology register; the count operand can be either an MMX technology\n   register or an 64-bit memory location.\n\n   128-bit Legacy SSE version: The destination and first source operands are\n   XMM registers. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged. The count operand can be either an XMM register\n   or a 128-bit memory location or an 8-bit immediate. If the count operand\n   is a memory address, 128 bits are loaded but the upper 64 bits are\n   ignored.\n\n   VEX.128 encoded version: The destination and first source operands are XMM\n   registers. Bits (MAXVL-1:128) of the destination YMM register are zeroed.\n   The count operand can be either an XMM register or a 128-bit memory\n   location or an 8-bit immediate. If the count operand is a memory address,\n   128 bits are loaded but the upper 64 bits are ignored.\n\n   VEX.256 encoded version: The destination operand is a YMM register. The\n   source operand is a YMM register or a memory location. The count operand\n   can come either from an XMM register or a memory location or an 8-bit\n   immediate. Bits (MAXVL-1:256) of the corresponding ZMM register are\n   zeroed.\n\n   EVEX encoded versions: The destination operand is a ZMM register updated\n   according to the writemask. The count operand is either an 8-bit immediate\n   (the immediate count version) or an 8-bit value from an XMM register or a\n   memory location (the variable count version). For the immediate count\n   version, the source operand (the second operand) can be a ZMM register, a\n   512-bit memory location or a 512-bit vector broadcasted from a 32/64-bit\n   memory location. For the variable count version, the first source operand\n   (the second operand) is a ZMM register, the second source operand (the\n   third operand, 8-bit variable count) can be an XMM register or a memory\n   location.\n\n   Note: In VEX/EVEX encoded versions of shifts with an immediate count, vvvv\n   of VEX/EVEX encode the destination register, and VEX.B/EVEX.B + ModRM.r/m\n   encodes the source register.\n\n   Note: For shifts with an immediate count (VEX.128.66.0F 71-73 /6, or\n   EVEX.128.66.0F 71-73 /6), VEX.vvvv/EVEX.vvvv encodes the destination\n   register.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["rcpps", "  RCPPS \u2014 Compute Reciprocals of Packed Single Precision Floating-Point Values\n\n                                 64/32 bit CPUID                              \n   Opcode*/Instruction     Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Computes the approximate   \n                                                   reciprocals of the packed  \n   NP 0F 53 /r RCPPS xmm1, RM    V/V       SSE     single precision           \n   xmm2/m128                                       floating-point values in   \n                                                   xmm2/m128 and stores the   \n                                                   results in xmm1.           \n                                                   Computes the approximate   \n   VEX.128.0F.WIG 53 /r                            reciprocals of packed      \n   VRCPPS xmm1, xmm2/m128  RM    V/V       AVX     single precision values in \n                                                   xmm2/mem and stores the    \n                                                   results in xmm1.           \n                                                   Computes the approximate   \n   VEX.256.0F.WIG 53 /r                            reciprocals of packed      \n   VRCPPS ymm1, ymm2/m256  RM    V/V       AVX     single precision values in \n                                                   ymm2/mem and stores the    \n                                                   results in ymm1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs a SIMD computation of the approximate reciprocals of the four\n   packed single precision floating-point values in the source operand\n   (second operand) stores the packed single precision floating-point results\n   in the destination operand. The source operand can be an XMM register or a\n   128-bit memory location. The destination operand is an XMM register. See\n   Figure 10-5 in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1, for an illustration of a SIMD single precision\n   floating-point operation.\n\n   The relative error for this approximation is:\n\n   |Relative Error| \u2264 1.5 \u2217 2^\u221212\n\n   The RCPPS instruction is not affected by the rounding control bits in the\n   MXCSR register. When a source value is a 0.0, an \u221e of the sign of the\n   source value is returned. A denormal source value is treated as a 0.0 (of\n   the same sign). Tiny results (see Section 4.9.1.5, \u201cNumeric Underflow\n   Exception (#U)\u201d in Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1) are always flushed to 0.0, with the sign of the operand.\n   (Input values greater than or equal to |1.11111111110100000000000B\u22172^125|\n   are guaranteed to not produce tiny results; input values less than or\n   equal to |1.00000000000110000000001B*2^126| are guaranteed to produce tiny\n   results, which are in turn flushed to 0.0; and input values in between\n   this range may or may not produce tiny results, depending on the\n   implementation.) When a source value is an SNaN or QNaN, the SNaN is\n   converted to a QNaN or the source QNaN is returned.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["pxor", "                          PXOR \u2014 Logical Exclusive OR\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F EF /r^1 PXOR mm,  A     V/V       MMX      Bitwise XOR of mm/m64 and \n   mm/m64                                           mm.                       \n   66 0F EF /r PXOR xmm1,  A     V/V       SSE2     Bitwise XOR of xmm2/m128  \n   xmm2/m128                                        and xmm1.                 \n   VEX.128.66.0F.WIG EF /r                          Bitwise XOR of xmm3/m128  \n   VPXOR xmm1, xmm2,       B     V/V       AVX      and xmm2.                 \n   xmm3/m128               \n   VEX.256.66.0F.WIG EF /r                          Bitwise XOR of ymm3/m256  \n   VPXOR ymm1, ymm2,       B     V/V       AVX2     and ymm2.                 \n   ymm3/m256               \n   EVEX.128.66.0F.W0 EF /r                          Bitwise XOR of packed     \n   VPXORD xmm1 {k1}{z},    C     V/V       AVX512VL doubleword integers in    \n   xmm2, xmm3/m128/m32bcst                 AVX512F  xmm2 and xmm3/m128 using  \n                                                    writemask k1.             \n   EVEX.256.66.0F.W0 EF /r                          Bitwise XOR of packed     \n   VPXORD ymm1 {k1}{z},    C     V/V       AVX512VL doubleword integers in    \n   ymm2, ymm3/m256/m32bcst                 AVX512F  ymm2 and ymm3/m256 using  \n                                                    writemask k1.             \n                                                    Bitwise XOR of packed     \n   EVEX.512.66.0F.W0 EF /r                          doubleword integers in    \n   VPXORD zmm1 {k1}{z},    C     V/V       AVX512F  zmm2 and                  \n   zmm2, zmm3/m512/m32bcst                          zmm3/m512/m32bcst using   \n                                                    writemask k1.             \n   EVEX.128.66.0F.W1 EF /r                          Bitwise XOR of packed     \n   VPXORQ xmm1 {k1}{z},    C     V/V       AVX512VL quadword integers in xmm2 \n   xmm2, xmm3/m128/m64bcst                 AVX512F  and xmm3/m128 using       \n                                                    writemask k1.             \n   EVEX.256.66.0F.W1 EF /r                          Bitwise XOR of packed     \n   VPXORQ ymm1 {k1}{z},    C     V/V       AVX512VL quadword integers in ymm2 \n   ymm2, ymm3/m256/m64bcst                 AVX512F  and ymm3/m256 using       \n                                                    writemask k1.             \n   EVEX.512.66.0F.W1 EF /r                          Bitwise XOR of packed     \n   VPXORQ zmm1 {k1}{z},    C     V/V       AVX512F  quadword integers in zmm2 \n   zmm2, zmm3/m512/m64bcst                          and zmm3/m512/m64bcst     \n                                                    using writemask k1.       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical exclusive-OR (XOR) operation on the source\n   operand (second operand) and the destination operand (first operand) and\n   stores the result in the destination operand. Each bit of the result is 1\n   if the corresponding bits of the two operands are different; each bit is 0\n   if the corresponding bits of the operands are the same.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions 64-bit operand: The source operand can be an MMX\n   technology register or a 64-bit memory location. The destination operand\n   is an MMX technology register.\n\n   128-bit Legacy SSE version: The second source operand is an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand is an XMM register or a\n   128-bit memory location. The first source operand and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding register destination are zeroed.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with write-mask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["xgetbv", "                XGETBV \u2014 Get Value of Extended Control Register\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n   NP 0F 01 XGETBV      ZO    Valid  Valid      Reads an XCR specified by ECX \n   D0                                           into EDX:EAX.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reads the contents of the extended control register (XCR) specified in the\n   ECX register into registers EDX:EAX. (On processors that support the Intel\n   64 architecture, the high-order 32 bits of RCX are ignored.) The EDX\n   register is loaded with the high-order 32 bits of the XCR and the EAX\n   register is loaded with the low-order 32 bits. (On processors that support\n   the Intel 64 architecture, the high-order 32 bits of each of RAX and RDX\n   are cleared.) If fewer than 64 bits are implemented in the XCR being read,\n   the values returned to EDX:EAX in unimplemented bit locations are\n   undefined.\n\n   XCR0 is supported on any processor that supports the XGETBV instruction.\n   If CPUID.(EAX=0DH,ECX=1):EAX.XG1[bit 2] = 1, executing XGETBV with ECX = 1\n   returns in EDX:EAX the logicalAND of XCR0 and the current value of the\n   XINUSE state-component bitmap. This allows software to discover the state\n   of the init optimization used by XSAVEOPT and XSAVES. See Chapter 13,\n   \u201cManaging State Using the XSAVE Feature Set\u201a\u201d in Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1.\n\n   Use of any other value for ECX results in a general-protection (#GP)\n   exception.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cmc", "                          CMC \u2014 Complement Carry Flag\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description         \n   F5     CMC         ZO    Valid       Valid           Complement CF flag. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Complements the CF flag in the EFLAGS register. CMC operation is the same\n   in non-64-bit modes and 64-bit mode.\n\nFlags Affected \u00b6\n\n   The CF flag contains the complement of its original value. The OF, ZF, SF,\n   AF, and PF flags are unaffected.\n"],
	["mulx", "                MULX \u2014 Unsigned Multiply Without Affecting Flags\n\n                                  64/32-bit CPUID                             \n   Opcode/Instruction      Op/ En Mode      Feature Description\n                                            Flag    \n                                                    Unsigned multiply of      \n   VEX.LZ.F2.0F38.W0 F6 /r RVM    V/V       BMI2    r/m32 with EDX without    \n   MULX r32a, r32b, r/m32                           affecting arithmetic      \n                                                    flags.                    \n                                                    Unsigned multiply of      \n   VEX.LZ.F2.0F38.W1 F6 /r RVM    V/N.E.    BMI2    r/m64 with RDX without    \n   MULX r64a, r64b, r/m64                           affecting arithmetic      \n                                                    flags.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4                   \n   RVM   ModRM:reg (w) VEX.vvvv (w) ModRM:r/m (r) RDX/EDX is implied 64/32    \n                                                  bits source                 \n\nDescription \u00b6\n\n   Performs an unsigned multiplication of the implicit source operand\n   (EDX/RDX) and the specified source operand (the third operand) and stores\n   the low half of the result in the second destination (second operand), the\n   high half of the result in the first destination operand (first operand),\n   without reading or writing the arithmetic flags. This enables efficient\n   programming where the software can interleave add with carry operations\n   and multiplications.\n\n   If the first and second operand are identical, it will contain the high\n   half of the multiplication result.\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["kxnorw:kxnorb:kxnorq:kxnord", "            KXNORW/KXNORB/KXNORQ/KXNORD \u2014 Bitwise Logical XNOR Masks\n\n                               64/32 bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Flag Description\n                               Support   \n   VEX.L1.0F.W0 46 /r                                 Bitwise XNOR 16-bit     \n   KXNORW k1, k2, k3     RVR   V/V       AVX512F      masks k2 and k3 and     \n                                                      place result in k1.     \n   VEX.L1.66.0F.W0 46 /r                              Bitwise XNOR 8-bit      \n   KXNORB k1, k2, k3     RVR   V/V       AVX512DQ     masks k2 and k3 and     \n                                                      place result in k1.     \n   VEX.L1.0F.W1 46 /r                                 Bitwise XNOR 64-bit     \n   KXNORQ k1, k2, k3     RVR   V/V       AVX512BW     masks k2 and k3 and     \n                                                      place result in k1.     \n   VEX.L1.66.0F.W1 46 /r                              Bitwise XNOR 32-bit     \n   KXNORD k1, k2, k3     RVR   V/V       AVX512BW     masks k2 and k3 and     \n                                                      place result in k1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3                              \n   RVR   ModRM:reg (w) VEX.1vvv (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise XNOR between the vector mask k2 and the vector mask k3,\n   and writes the result into vector mask k1 (three-operand form).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfmadd132pd:vfmadd213pd:vfmadd231pd", "       VFMADD132PD/VFMADD213PD/VFMADD231PD \u2014 Fused Multiply-Add of Packed\n                     DoublePrecision Floating-Point Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Multiply packed double  \n   VEX.128.66.0F38.W1 98 /r                           precision               \n   VFMADD132PD xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm1 and xmm3/mem, \n                                                      add to xmm2 and put     \n                                                      result in xmm1.         \n                                                      Multiply packed double  \n   VEX.128.66.0F38.W1 A8 /r                           precision               \n   VFMADD213PD xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm1 and xmm2, add \n                                                      to xmm3/mem and put     \n                                                      result in xmm1.         \n                                                      Multiply packed double  \n   VEX.128.66.0F38.W1 B8 /r                           precision               \n   VFMADD231PD xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm2 and xmm3/mem, \n                                                      add to xmm1 and put     \n                                                      result in xmm1.         \n                                                      Multiply packed double  \n   VEX.256.66.0F38.W1 98 /r                           precision               \n   VFMADD132PD ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm1 and ymm3/mem, \n                                                      add to ymm2 and put     \n                                                      result in ymm1.         \n                                                      Multiply packed double  \n   VEX.256.66.0F38.W1 A8 /r                           precision               \n   VFMADD213PD ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm1 and ymm2, add \n                                                      to ymm3/mem and put     \n                                                      result in ymm1.         \n                                                      Multiply packed double  \n   VEX.256.66.0F38.W1 B8 /r                           precision               \n   VFMADD231PD ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm2 and ymm3/mem, \n                                                      add to ymm1 and put     \n                                                      result in ymm1.         \n                                                      Multiply packed double  \n                                                      precision               \n   EVEX.128.66.0F38.W1 98 /r                 AVX512VL floating-point values   \n   VFMADD132PD xmm1 {k1}{z}, B     V/V       AVX512F  from xmm1 and           \n   xmm2, xmm3/m128/m64bcst                            xmm3/m128/m64bcst, add  \n                                                      to xmm2 and put result  \n                                                      in xmm1.                \n                                                      Multiply packed double  \n   EVEX.128.66.0F38.W1 A8 /r                          precision               \n   VFMADD213PD xmm1 {k1}{z}, B     V/V       AVX512VL floating-point values   \n   xmm2, xmm3/m128/m64bcst                   AVX512F  from xmm1 and xmm2, add \n                                                      to xmm3/m128/m64bcst    \n                                                      and put result in xmm1. \n                                                      Multiply packed double  \n                                                      precision               \n   EVEX.128.66.0F38.W1 B8 /r                 AVX512VL floating-point values   \n   VFMADD231PD xmm1 {k1}{z}, B     V/V       AVX512F  from xmm2 and           \n   xmm2, xmm3/m128/m64bcst                            xmm3/m128/m64bcst, add  \n                                                      to xmm1 and put result  \n                                                      in xmm1.                \n                                                      Multiply packed double  \n                                                      precision               \n   EVEX.256.66.0F38.W1 98 /r                 AVX512VL floating-point values   \n   VFMADD132PD ymm1 {k1}{z}, B     V/V       AVX512F  from ymm1 and           \n   ymm2, ymm3/m256/m64bcst                            ymm3/m256/m64bcst, add  \n                                                      to ymm2 and put result  \n                                                      in ymm1.                \n                                                      Multiply packed double  \n   EVEX.256.66.0F38.W1 A8 /r                          precision               \n   VFMADD213PD ymm1 {k1}{z}, B     V/V       AVX512VL floating-point values   \n   ymm2, ymm3/m256/m64bcst                   AVX512F  from ymm1 and ymm2, add \n                                                      to ymm3/m256/m64bcst    \n                                                      and put result in ymm1. \n                                                      Multiply packed double  \n                                                      precision               \n   EVEX.256.66.0F38.W1 B8 /r                 AVX512VL floating-point values   \n   VFMADD231PD ymm1 {k1}{z}, B     V/V       AVX512F  from ymm2 and           \n   ymm2, ymm3/m256/m64bcst                            ymm3/m256/m64bcst, add  \n                                                      to ymm1 and put result  \n                                                      in ymm1.                \n                                                      Multiply packed double  \n   EVEX.512.66.0F38.W1 98 /r                          precision               \n   VFMADD132PD zmm1 {k1}{z},                          floating-point values   \n   zmm2,                     B     V/V       AVX512F  from zmm1 and           \n   zmm3/m512/m64bcst{er}                              zmm3/m512/m64bcst, add  \n                                                      to zmm2 and put result  \n                                                      in zmm1.                \n                                                      Multiply packed double  \n   EVEX.512.66.0F38.W1 A8 /r                          precision               \n   VFMADD213PD zmm1 {k1}{z}, B     V/V       AVX512F  floating-point values   \n   zmm2,                                              from zmm1 and zmm2, add \n   zmm3/m512/m64bcst{er}                              to zmm3/m512/m64bcst    \n                                                      and put result in zmm1. \n                                                      Multiply packed double  \n   EVEX.512.66.0F38.W1 B8 /r                          precision               \n   VFMADD231PD zmm1 {k1}{z},                          floating-point values   \n   zmm2,                     B     V/V       AVX512F  from zmm2 and           \n   zmm3/m512/m64bcst{er}                              zmm3/m512/m64bcst, add  \n                                                      to zmm1 and put result  \n                                                      in zmm1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a set of SIMD multiply-add computation on packed double precision\n   floating-point values using three source operands and writes the\n   multiply-add results in the destination operand. The destination operand\n   is also the first source operand. The second operand must be a SIMD\n   register. The third source operand can be a SIMD register or a memory\n   location.\n\n   VFMADD132PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the first source operand to the two, four or\n   eight packed double precision floating-point values in the third source\n   operand, adds the infinite precision intermediate result to the two, four\n   or eight packed double precision floating-point values in the second\n   source operand, performs rounding and stores the resulting two, four or\n   eight packed double precision floating-point values to the destination\n   operand (first source operand).\n\n   VFMADD213PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source operand to the two, four or\n   eight packed double precision floating-point values in the first source\n   operand, adds the infinite precision intermediate result to the two, four\n   or eight packed double precision floating-point values in the third source\n   operand, performs rounding and stores the resulting two, four or eight\n   packed double precision floating-point values to the destination operand\n   (first source operand).\n\n   VFMADD231PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source to the two, four or eight\n   packed double precision floating-point values in the third source operand,\n   adds the infinite precision intermediate result to the two, four or eight\n   packed double precision floating-point values in the first source operand,\n   performs rounding and stores the resulting two, four or eight packed\n   double precision floating-point values to the destination operand (first\n   source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   is a ZMM register and encoded in reg_field. The second source operand is a\n   ZMM register and encoded in EVEX.vvvv. The third source operand is a ZMM\n   register, a 512-bit memory location, or a 512-bit vector broadcasted from\n   a 64-bit memory location. The destination operand is conditionally updated\n   with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["tilezero", "                              TILEZERO \u2014 Zero Tile\n\n                                           64/32 bit CPUID                    \n   Opcode/Instruction                Op/En Mode      Feature Flag Description\n                                           Support   \n   VEX.128.F2.0F38.W0 49 11:rrr:000                               Zero the    \n   TILEZERO tmm1                     A     V/N.E.    AMX-TILE     destination \n                                                                  tile.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:reg (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   This instruction zeroes the destination tile.\n\n   Any attempt to execute the TILEZERO instruction inside an Intel TSX\n   transaction will result in a transaction abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvttph2qq", "   VCVTTPH2QQ \u2014 Convert with Truncation Packed FP16 Values to Signed Quadword\n                                    Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert two packed    \n                                                        FP16 values in        \n                                                        xmm2/m32/m16bcst to   \n   EVEX.128.66.MAP5.W0 7A /r                AVX512-FP16 two signed quadword   \n   VCVTTPH2QQ xmm1{k1}{z},        A V/V     AVX512VL    integers, and store   \n   xmm2/m32/m16bcst                                     the result in xmm1    \n                                                        using truncation      \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert four packed   \n                                                        FP16 values in        \n                                                        xmm2/m64/m16bcst to   \n   EVEX.256.66.MAP5.W0 7A /r                AVX512-FP16 four signed quadword  \n   VCVTTPH2QQ ymm1{k1}{z},        A V/V     AVX512VL    integers, and store   \n   xmm2/m64/m16bcst                                     the result in ymm1    \n                                                        using truncation      \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert eight packed  \n                                                        FP16 values in        \n                                                        xmm2/m128/m16bcst to  \n   EVEX.512.66.MAP5.W0 7A /r                            eight signed quadword \n   VCVTTPH2QQ zmm1{k1}{z},        A V/V     AVX512-FP16 integers, and store   \n   xmm2/m128/m16bcst {sae}                              the result in zmm1    \n                                                        using truncation      \n                                                        subject to writemask  \n                                                        k1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Quarter ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   signed quadword integers in the destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["vmaskmov", "              VMASKMOV \u2014 Conditional SIMD Packed Loads and Stores\n\n                               64/32-bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                                         Flag    \n   VEX.128.66.0F38.W0 2C                         Conditionally load packed    \n   /r VMASKMOVPS xmm1,   RV M  V/V       AVX     single-precision values from \n   xmm2, m128                                    m128 using mask in xmm2 and  \n                                                 store in xmm1.               \n   VEX.256.66.0F38.W0 2C                         Conditionally load packed    \n   /r VMASKMOVPS ymm1,   RV M  V/V       AVX     single-precision values from \n   ymm2, m256                                    m256 using mask in ymm2 and  \n                                                 store in ymm1.               \n   VEX.128.66.0F38.W0 2D                         Conditionally load packed    \n   /r VMASKMOVPD xmm1,   RV M  V/V       AVX     double precision values from \n   xmm2, m128                                    m128 using mask in xmm2 and  \n                                                 store in xmm1.               \n   VEX.256.66.0F38.W0 2D                         Conditionally load packed    \n   /r VMASKMOVPD ymm1,   RV M  V/V       AVX     double precision values from \n   ymm2, m256                                    m256 using mask in ymm2 and  \n                                                 store in ymm1.               \n   VEX.128.66.0F38.W0 2E                         Conditionally store packed   \n   /r VMASKMOVPS m128,   MV R  V/V       AVX     single-precision values from \n   xmm1, xmm2                                    xmm2 using mask in xmm1.     \n   VEX.256.66.0F38.W0 2E                         Conditionally store packed   \n   /r VMASKMOVPS m256,   MV R  V/V       AVX     single-precision values from \n   ymm1, ymm2                                    ymm2 using mask in ymm1.     \n   VEX.128.66.0F38.W0 2F                         Conditionally store packed   \n   /r VMASKMOVPD m128,   MV R  V/V       AVX     double precision values from \n   xmm1, xmm2                                    xmm2 using mask in xmm1.     \n   VEX.256.66.0F38.W0 2F                         Conditionally store packed   \n   /r VMASKMOVPD m256,   MV R  V/V       AVX     double precision values from \n   ymm1, ymm2                                    ymm2 using mask in ymm1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVM   ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n   MVR   ModRM:r/m (w) VEX.vvvv (r) ModRM:reg (r) N/A       \n\nDescription \u00b6\n\n   Conditionally moves packed data elements from the second source operand\n   into the corresponding data element of the destination operand, depending\n   on the mask bits associated with each data element. The mask bits are\n   specified in the first source operand.\n\n   The mask bit for each data element is the most significant bit of that\n   element in the first source operand. If a mask is 1, the corresponding\n   data element is copied from the second source operand to the destination\n   operand. If the mask is 0, the corresponding data element is set to zero\n   in the load form of these instructions, and unmodified in the store form.\n\n   The second source operand is a memory address for the load form of these\n   instruction. The destination operand is a memory address for the store\n   form of these instructions. The other operands are both XMM registers (for\n   VEX.128 version) or YMM registers (for VEX.256 version).\n\n   Faults occur only due to mask-bit required memory accesses that caused the\n   faults. Faults will not occur due to referencing any memory location if\n   the corresponding mask bit for that memory location is 0. For example, no\n   faults will be detected if the mask bits are all zero.\n\n   Unlike previous MASKMOV instructions (MASKMOVQ and MASKMOVDQU), a\n   nontemporal hint is not applied to these instructions.\n\n   Instruction behavior on alignment check reporting with mask bits of less\n   than all 1s are the same as with mask bits of all 1s.\n\n   VMASKMOV should not be used to access memory mapped I/O and un-cached\n   memory as the access and the ordering of the individual loads or stores it\n   does is implementation specific.\n\n   In cases where mask bits indicate data should not be loaded or stored\n   paging A and D bits will be set in an implementation dependent way.\n   However, A and D bits are always set for pages where data is actually\n   loaded/stored.\n\n   Note: for load forms, the first source (the mask) is encoded in VEX.vvvv;\n   the second source is encoded in rm_field, and the destination register is\n   encoded in reg_field.\n\n   Note: for store forms, the first source (the mask) is encoded in VEX.vvvv;\n   the second source register is encoded in reg_field, and the destination\n   memory location is encoded in rm_field.\n"],
	["wakeup", "      GETSEC[WAKEUP] \u2014 Wake Up Sleeping Processors in Measured Environment\n\n   Opcode           Instruction    Description                                \n   NP 0F 37 (EAX=8) GETSEC[WAKEUP] Wake up the responding logical processors  \n                                   from the SENTER sleep state.               \n\nDescription \u00b6\n\n   The GETSEC[WAKEUP] leaf function broadcasts a wake-up message to all\n   logical processors currently in the SENTER sleep state. This GETSEC leaf\n   must be executed only by the ILP, in order to wake-up the RLPs. Responding\n   logical processors (RLPs) enter the SENTER sleep state after completion of\n   the SENTER rendezvous sequence.\n\n   The GETSEC[WAKEUP] instruction may only be executed:\n\n     * In a measured environment as initiated by execution of GETSEC[SENTER].\n     * Outside of authenticated code execution mode.\n     * Execution is not allowed unless the processor is in protected mode\n       with CPL = 0 and EFLAGS.VM = 0.\n     * In addition, the logical processor must be designated as the\n       boot-strap processor as configured by setting IA32_APIC_BASE.BSP = 1.\n\n   If these conditions are not met, attempts to execute GETSEC[WAKEUP] result\n   in a general protection violation.\n\n   An RLP exits the SENTER sleep state and start execution in response to a\n   WAKEUP signal initiated by ILP\u2019s execution of GETSEC[WAKEUP]. The RLP\n   retrieves a pointer to a data structure that contains information to\n   enable execution from a defined entry point. This data structure is\n   located using a physical address held in the Intel^\u00ae TXT-capable chipset\n   configuration register LT.MLE.JOIN. The register is publicly writable in\n   the chipset by all processors and is not restricted by the Intel^\u00ae\n   TXT-capable chipset configuration register lock status. The format of this\n   data structure is defined in Table 7-12.\n\n   Offset Field                        \n   0      GDT limit                    \n   4      GDT base pointer             \n   8      Segment selector initializer \n   12     EIP                          \n\n   Table 7-12. RLP MVMM JOIN Data Structure\n\n   The MLE JOIN data structure contains the information necessary to\n   initialize RLP processor state and permit the processor to join the\n   measured environment. The GDTR, LIP, and CS, DS, SS, and ES selector\n   values are initialized using this data structure. The CS selector index is\n   derived directly from the segment selector initializer field; DS, SS, and\n   ES selectors are initialized to CS+8. The segment descriptor fields are\n   initialized implicitly with BASE = 0, LIMIT = FFFFFH, G = 1, D = 1, P = 1,\n   S = 1; read/write/access for DS, SS, and ES; and execute/read/access for\n   CS. It is the responsibility of external software to establish a GDT\n   pointed to by the MLE JOIN data structure that contains descriptor entries\n   consistent with the implicit settings initialized by the processor (see\n   Table 7-6). Certain states from the content of Table 7-12 are checked for\n   consistency by the processor prior to execution. A failure of any\n   consistency check results in the RLP aborting entry into the protected\n   environment and signaling an Intel\u00ae TXT shutdown condition. The specific\n   checks performed are documented later in this section. After successful\n   completion of processor consistency checks and subsequent initialization,\n   RLP execution in the measured environment begins from the entry point at\n   offset 12 (as indicated in Table 7-12).\n\nFlags Affected \u00b6\n\n   None.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX Ignored.\n\nVM-exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["psubusb:psubusw", "  PSUBUSB/PSUBUSW \u2014 Subtract Packed Unsigned Integers With Unsigned Saturation\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Subtract unsigned packed \n   NP 0F D8 /r^1 PSUBUSB    A     V/V       MMX      bytes in mm/m64 from     \n   mm, mm/m64                                        unsigned packed bytes in \n                                                     mm and saturate result.  \n                                                     Subtract packed unsigned \n                                                     byte integers in         \n   66 0F D8 /r PSUBUSB      A     V/V       SSE2     xmm2/m128 from packed    \n   xmm1, xmm2/m128                                   unsigned byte integers   \n                                                     in xmm1 and saturate     \n                                                     result.                  \n                                                     Subtract unsigned packed \n   NP 0F D9 /r^1 PSUBUSW    A     V/V       MMX      words in mm/m64 from     \n   mm, mm/m64                                        unsigned packed words in \n                                                     mm and saturate result.  \n                                                     Subtract packed unsigned \n                                                     word integers in         \n   66 0F D9 /r PSUBUSW      A     V/V       SSE2     xmm2/m128 from packed    \n   xmm1, xmm2/m128                                   unsigned word integers   \n                                                     in xmm1 and saturate     \n                                                     result.                  \n                                                     Subtract packed unsigned \n   VEX.128.66.0F.WIG D8 /r                           byte integers in         \n   VPSUBUSB xmm1, xmm2,     B     V/V       AVX      xmm3/m128 from packed    \n   xmm3/m128                                         unsigned byte integers   \n                                                     in xmm2 and saturate     \n                                                     result.                  \n                                                     Subtract packed unsigned \n   VEX.128.66.0F.WIG D9 /r                           word integers in         \n   VPSUBUSW xmm1, xmm2,     B     V/V       AVX      xmm3/m128 from packed    \n   xmm3/m128                                         unsigned word integers   \n                                                     in xmm2 and saturate     \n                                                     result.                  \n                                                     Subtract packed unsigned \n   VEX.256.66.0F.WIG D8 /r                           byte integers in         \n   VPSUBUSB ymm1, ymm2,     B     V/V       AVX2     ymm3/m256 from packed    \n   ymm3/m256                                         unsigned byte integers   \n                                                     in ymm2 and saturate     \n                                                     result.                  \n                                                     Subtract packed unsigned \n   VEX.256.66.0F.WIG D9 /r                           word integers in         \n   VPSUBUSW ymm1, ymm2,     B     V/V       AVX2     ymm3/m256 from packed    \n   ymm3/m256                                         unsigned word integers   \n                                                     in ymm2 and saturate     \n                                                     result.                  \n                                                     Subtract packed unsigned \n                                                     byte integers in         \n   EVEX.128.66.0F.WIG D8 /r                 AVX512VL xmm3/m128 from packed    \n   VPSUBUSB xmm1 {k1}{z},   C     V/V       AVX512BW unsigned byte integers   \n   xmm2, xmm3/m128                                   in xmm2, saturate        \n                                                     results and store in     \n                                                     xmm1 using writemask k1. \n                                                     Subtract packed unsigned \n                                                     byte integers in         \n   EVEX.256.66.0F.WIG D8 /r                 AVX512VL ymm3/m256 from packed    \n   VPSUBUSB ymm1 {k1}{z},   C     V/V       AVX512BW unsigned byte integers   \n   ymm2, ymm3/m256                                   in ymm2, saturate        \n                                                     results and store in     \n                                                     ymm1 using writemask k1. \n                                                     Subtract packed unsigned \n                                                     byte integers in         \n   EVEX.512.66.0F.WIG D8 /r                          zmm3/m512 from packed    \n   VPSUBUSB zmm1 {k1}{z},   C     V/V       AVX512BW unsigned byte integers   \n   zmm2, zmm3/m512                                   in zmm2, saturate        \n                                                     results and store in     \n                                                     zmm1 using writemask k1. \n                                                     Subtract packed unsigned \n                                                     word integers in         \n   EVEX.128.66.0F.WIG D9 /r                 AVX512VL xmm3/m128 from packed    \n   VPSUBUSW xmm1 {k1}{z},   C     V/V       AVX512BW unsigned word integers   \n   xmm2, xmm3/m128                                   in xmm2 and saturate     \n                                                     results and store in     \n                                                     xmm1 using writemask k1. \n                                                     Subtract packed unsigned \n                                                     word integers in         \n   EVEX.256.66.0F.WIG D9 /r                 AVX512VL ymm3/m256 from packed    \n   VPSUBUSW ymm1 {k1}{z},   C     V/V       AVX512BW unsigned word integers   \n   ymm2, ymm3/m256                                   in ymm2, saturate        \n                                                     results and store in     \n                                                     ymm1 using writemask k1. \n                                                     Subtract packed unsigned \n                                                     word integers in         \n   EVEX.512.66.0F.WIG D9 /r                          zmm3/m512 from packed    \n   VPSUBUSW zmm1 {k1}{z},   C     V/V       AVX512BW unsigned word integers   \n   zmm2, zmm3/m512                                   in zmm2, saturate        \n                                                     results and store in     \n                                                     zmm1 using writemask k1. \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD subtract of the packed unsigned integers of the source\n   operand (second operand) from the packed unsigned integers of the\n   destination operand (first operand), and stores the packed unsigned\n   integer results in the destination operand. See Figure 9-4 in the Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for an\n   illustration of a SIMD operation. Overflow is handled with unsigned\n   saturation, as described in the following paragraphs.\n\n   These instructions can operate on either 64-bit or 128-bit operands.\n\n   The (V)PSUBUSB instruction subtracts packed unsigned byte integers. When\n   an individual byte result is less than zero, the saturated value of 00H is\n   written to the destination operand.\n\n   The (V)PSUBUSW instruction subtracts packed unsigned word integers. When\n   an individual word result is less than zero, the saturated value of 0000H\n   is written to the destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The destination operand must be an MMX\n   technology register and the source operand can be either an MMX technology\n   register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The second source operand is an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand is an XMM register or a\n   128-bit memory location. The first source operand and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded versions: The second source operand is an YMM register or\n   an 256-bit memory location. The first source operand and destination\n   operands are YMM registers. Bits (MAXVL-1:256) of the corresponding ZMM\n   register are zeroed.\n\n   EVEX encoded version: The second source operand is an ZMM/YMM/XMM register\n   or an 512/256/128-bit memory location. The first source operand and\n   destination operands are ZMM/YMM/XMM registers. The destination is\n   conditionally updated with writemask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pminud:pminuq", "              PMINUD/PMINUQ \u2014 Minimum of Packed Unsigned Integers\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction     Op/E n Mode      Feature  Description\n                                 Support   Flag     \n                                                    Compare packed unsigned   \n   66 0F 38 3B /r PMINUD                            dword integers in xmm1    \n   xmm1, xmm2/m128        A      V/V       SSE4_1   and xmm2/m128 and store   \n                                                    packed minimum values in  \n                                                    xmm1.                     \n                                                    Compare packed unsigned   \n   VEX.128.66.0F38.WIG 3B                           dword integers in xmm2    \n   /r VPMINUD xmm1, xmm2, B      V/V       AVX      and xmm3/m128 and store   \n   xmm3/m128                                        packed minimum values in  \n                                                    xmm1.                     \n                                                    Compare packed unsigned   \n   VEX.256.66.0F38.WIG 3B                           dword integers in ymm2    \n   /r VPMINUD ymm1, ymm2, B      V/V       AVX2     and ymm3/m256 and store   \n   ymm3/m256                                        packed minimum values in  \n                                                    ymm1.                     \n                                                    Compare packed unsigned   \n   EVEX.128.66.0F38.W0 3B                           dword integers in xmm2    \n   /r VPMINUD xmm1        C      V/V       AVX512VL and xmm3/m128/m32bcst and \n   {k1}{z}, xmm2,                          AVX512F  store packed minimum      \n   xmm3/m128/m32bcst                                values in xmm1 under      \n                                                    writemask k1.             \n                                                    Compare packed unsigned   \n   EVEX.256.66.0F38.W0 3B                           dword integers in ymm2    \n   /r VPMINUD ymm1        C      V/V       AVX512VL and ymm3/m256/m32bcst and \n   {k1}{z}, ymm2,                          AVX512F  store packed minimum      \n   ymm3/m256/m32bcst                                values in ymm1 under      \n                                                    writemask k1.             \n                                                    Compare packed unsigned   \n   EVEX.512.66.0F38.W0 3B                           dword integers in zmm2    \n   /r VPMINUD zmm1        C      V/V       AVX512F  and zmm3/m512/m32bcst and \n   {k1}{z}, zmm2,                                   store packed minimum      \n   zmm3/m512/m32bcst                                values in zmm1 under      \n                                                    writemask k1.             \n                                                    Compare packed unsigned   \n   EVEX.128.66.0F38.W1 3B                           qword integers in xmm2    \n   /r VPMINUQ xmm1        C      V/V       AVX512VL and xmm3/m128/m64bcst and \n   {k1}{z}, xmm2,                          AVX512F  store packed minimum      \n   xmm3/m128/m64bcst                                values in xmm1 under      \n                                                    writemask k1.             \n                                                    Compare packed unsigned   \n   EVEX.256.66.0F38.W1 3B                           qword integers in ymm2    \n   /r VPMINUQ ymm1        C      V/V       AVX512VL and ymm3/m256/m64bcst and \n   {k1}{z}, ymm2,                          AVX512F  store packed minimum      \n   ymm3/m256/m64bcst                                values in ymm1 under      \n                                                    writemask k1.             \n                                                    Compare packed unsigned   \n   EVEX.512.66.0F38.W1 3B                           qword integers in zmm2    \n   /r VPMINUQ zmm1        C      V/V       AVX512F  and zmm3/m512/m64bcst and \n   {k1}{z}, zmm2,                                   store packed minimum      \n   zmm3/m512/m64bcst                                values in zmm1 under      \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed unsigned dword/qword integers in the\n   second source operand and the first source operand and returns the minimum\n   value for each pair of integers to the destination operand.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers. Bits (MAXVL-1:256) of the corresponding destination\n   register are zeroed.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register;\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n"],
	["incsspd:incsspq", "                INCSSPD/INCSSPQ \u2014 Increment Shadow Stack Pointer\n\n                             Op /  64/32 bit    CPUID                         \n   Opcode/Instruction        En    Mode Support Feature     Description\n                                                Flag        \n   F3 0F AE /05 INCSSPD r32  R     V/V          CET_SS      Increment SSP by  \n                                                            4 * r32[7:0].     \n   F3 REX.W 0F AE /05        R     V/N.E.       CET_SS      Increment SSP by  \n   INCSSPQ r64                                              8 * r64[7:0].     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2 Operand 3 Operand 4 \n   R     N/A        ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   This instruction can be used to increment the current shadow stack pointer\n   by the operand size of the instruction times the unsigned 8-bit value\n   specified by bits 7:0 in the source operand. The instruction performs a\n   pop and discard of the first and last element on the shadow stack in the\n   range specified by the unsigned 8-bit value in bits 7:0 of the source\n   operand.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vrsqrt14pd", " VRSQRT14PD \u2014 Compute Approximate Reciprocals of Square Roots of Packed Float64\n                                     Values\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Computes the approximate   \n                                                   reciprocal square roots of \n   EVEX.128.66.0F38.W1 4E                          the packed double          \n   /r VRSQRT14PD xmm1     A     V/V       AVX512VL precision floating-point   \n   {k1}{z},                               AVX512F  values in                  \n   xmm2/m128/m64bcst                               xmm2/m128/m64bcst and      \n                                                   stores the results in      \n                                                   xmm1. Under writemask.     \n                                                   Computes the approximate   \n                                                   reciprocal square roots of \n   EVEX.256.66.0F38.W1 4E                          the packed double          \n   /r VRSQRT14PD ymm1     A     V/V       AVX512VL precision floating-point   \n   {k1}{z},                               AVX512F  values in                  \n   ymm2/m256/m64bcst                               ymm2/m256/m64bcst and      \n                                                   stores the results in      \n                                                   ymm1. Under writemask.     \n                                                   Computes the approximate   \n                                                   reciprocal square roots of \n   EVEX.512.66.0F38.W1 4E                          the packed double          \n   /r VRSQRT14PD zmm1     A     V/V       AVX512F  precision floating-point   \n   {k1}{z},                                        values in                  \n   zmm2/m512/m64bcst                               zmm2/m512/m64bcst and      \n                                                   stores the results in zmm1 \n                                                   under writemask.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate\n   reciprocals of the square roots of the eight packed double precision\n   floating-point values in the source operand (the second operand) and\n   stores the packed double precision floating-point results in the\n   destination operand (the first operand) according to the writemask. The\n   maximum relative error for this approximation is less than 2^-14.\n\n   EVEX.512 encoded version: The source operand can be a ZMM register, a\n   512-bit memory location, or a 512-bit vector broadcasted from a 64-bit\n   memory location. The destination operand is a ZMM register, conditionally\n   updated using writemask k1.\n\n   EVEX.256 encoded version: The source operand is a YMM register, a 256-bit\n   memory location, or a 256-bit vector broadcasted from a 64-bit memory\n   location. The destination operand is a YMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.128 encoded version: The source operand is a XMM register, a 128-bit\n   memory location, or a 128-bit vector broadcasted from a 64-bit memory\n   location. The destination operand is a XMM register, conditionally updated\n   using writemask k1.\n\n   The VRSQRT14PD instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. When the source operand is an +\u221e then +ZERO\n   value is returned. A denormal source value is treated as zero only if DAZ\n   bit is set in MXCSR. Otherwise it is treated correctly and performs the\n   approximation with the specified masked response. When a source value is a\n   negative value (other than 0.0) a floating-point QNaN_indefinite is\n   returned. When a source value is an SNaN or QNaN, the SNaN is converted to\n   a QNaN or the source QNaN is returned.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n\n  A numerically exact implementation of VRSQRT14xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["cvtsi2ss", "CVTSI2SS \u2014 Convert Doubleword Integer to Scalar Single Precision Floating-Point\n                                     Value\n\n                          Op / 64/32 bit    CPUID                             \n   Opcode/Instruction     En   Mode Support Feature Description\n                                            Flag    \n                                                    Convert one signed        \n   F3 0F 2A /r CVTSI2SS                             doubleword integer from   \n   xmm1, r/m32            A    V/V          SSE     r/m32 to one single       \n                                                    precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   F3 REX.W 0F 2A /r                                quadword integer from     \n   CVTSI2SS xmm1, r/m64   A    V/N.E.       SSE     r/m64 to one single       \n                                                    precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   VEX.LIG.F3.0F.W0 2A /r                           doubleword integer from   \n   VCVTSI2SS xmm1, xmm2,  B    V/V          AVX     r/m32 to one single       \n   r/m32                                            precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   VEX.LIG.F3.0F.W1 2A /r                           quadword integer from     \n   VCVTSI2SS xmm1, xmm2,  B    V/N.E.^1     AVX     r/m64 to one single       \n   r/m64                                            precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   EVEX.LLIG.F3.0F.W0 2A                            doubleword integer from   \n   /r VCVTSI2SS xmm1,     C    V/V          AVX512F r/m32 to one single       \n   xmm2, r/m32{er}                                  precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   EVEX.LLIG.F3.0F.W1 2A                            quadword integer from     \n   /r VCVTSI2SS xmm1,     C    V/N.E.^1     AVX512F r/m64 to one single       \n   xmm2, r/m64{er}                                  precision floating-point  \n                                                    value in xmm1.            \n\n     1. VEX.W1/EVEX.W1 in non-64 bit is ignored; the instructions behaves as\n     if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Converts a signed doubleword integer (or signed quadword integer if\n   operand size is 64 bits) in the \u201cconvert-from\u201d source operand to a single\n   precision floating-point value in the destination operand (first operand).\n   The \u201cconvert-from\u201d source operand can be a general-purpose register or a\n   memory location. The destination operand is an XMM register. The result is\n   stored in the low doubleword of the destination operand, and the upper\n   three doublewords are left unchanged. When a conversion is inexact, the\n   value returned is rounded according to the rounding control bits in the\n   MXCSR register or the embedded rounding control bits.\n\n   128-bit Legacy SSE version: In 64-bit mode, Use of the REX.W prefix\n   promotes the instruction to use 64-bit input value. The \u201cconvert-from\u201d\n   source operand (the second operand) is a general-purpose register or\n   memory location. Bits (MAXVL-1:32) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 and EVEX encoded versions: The \u201cconvert-from\u201d source operand (the\n   third operand) can be a general-purpose register or a memory location. The\n   first source and destination operands are XMM registers. Bits (127:32) of\n   the XMM register destination are copied from corresponding bits in the\n   first source operand. Bits (MAXVL-1:128) of the destination register are\n   zeroed.\n\n   EVEX encoded version: the converted result in written to the low\n   doubleword element of the destination under the writemask.\n\n   Software should ensure VCVTSI2SS is encoded with VEX.L=0. Encoding\n   VCVTSI2SS with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["vpermi2b", "     VPERMI2B \u2014 Full Permute of Bytes From Two Tables Overwriting the Index\n\n                                  64/32 bit CPUID Feature                     \n   Opcode/Instruction       Op/En Mode      Flag          Description\n                                  Support   \n                                                          Permute bytes in    \n                                                          xmm3/m128 and xmm2  \n   EVEX.128.66.0F38.W0 75                   AVX512VL      using byte indexes  \n   /r VPERMI2B xmm1         A     V/V       AVX512_VBMI   in xmm1 and store   \n   {k1}{z}, xmm2, xmm3/m128                               the byte results in \n                                                          xmm1 using          \n                                                          writemask k1.       \n                                                          Permute bytes in    \n                                                          ymm3/m256 and ymm2  \n   EVEX.256.66.0F38.W0 75                   AVX512VL      using byte indexes  \n   /r VPERMI2B ymm1         A     V/V       AVX512_VBMI   in ymm1 and store   \n   {k1}{z}, ymm2, ymm3/m256                               the byte results in \n                                                          ymm1 using          \n                                                          writemask k1.       \n                                                          Permute bytes in    \n                                                          zmm3/m512 and zmm2  \n   EVEX.512.66.0F38.W0 75                                 using byte indexes  \n   /r VPERMI2B zmm1         A     V/V       AVX512_VBMI   in zmm1 and store   \n   {k1}{z}, zmm2, zmm3/m512                               the byte results in \n                                                          zmm1 using          \n                                                          writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Permutes byte values in the second operand (the first source operand) and\n   the third operand (the second source operand) using the byte indices in\n   the first operand (the destination operand) to select byte elements from\n   the second or third source operands. The selected byte elements are\n   written to the destination at byte granularity under the writemask k1.\n\n   The first and second operands are ZMM/YMM/XMM registers. The first operand\n   contains input indices to select elements from the two input tables in the\n   2nd and 3rd operands. The first operand is also the destination of the\n   result. The third operand can be a ZMM/YMM/XMM register, or a\n   512/256/128-bit memory location. In each index byte, the id bit for table\n   selection is bit 6/5/4, and bits [5:0]/[4:0]/[3:0] selects element within\n   each input table.\n\n   Note that these instructions permit a byte value in the source operands to\n   be copied to more than one location in the destination operand. Also, the\n   same tables can be reused in subsequent iterations, but the index elements\n   are overwritten.\n\n   Bits (MAX_VL-1:256/128) of the destination are zeroed for VL=256,128.\n"],
	["popa:popad", "                 POPA/POPAD \u2014 Pop All General-Purpose Registers\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n   61     POPA        ZO    Invalid     Valid           Pop DI, SI, BP, BX,   \n                                                        DX, CX, and AX.       \n                                                        Pop EDI, ESI, EBP,    \n   61     POPAD       ZO    Invalid     Valid           EBX, EDX, ECX, and    \n                                                        EAX.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Pops doublewords (POPAD) or words (POPA) from the stack into the\n   general-purpose registers. The registers are loaded in the following\n   order: EDI, ESI, EBP, EBX, EDX, ECX, and EAX (if the operand-size\n   attribute is 32) and DI, SI, BP, BX, DX, CX, and AX (if the operand-size\n   attribute is 16). (These instructions reverse the operation of the\n   PUSHA/PUSHAD instructions.) The value on the stack for the ESP or SP\n   register is ignored. Instead, the ESP or SP register is incremented after\n   each register is loaded.\n\n   The POPA (pop all) and POPAD (pop all double) mnemonics reference the same\n   opcode. The POPA instruction is intended for use when the operand-size\n   attribute is 16 and the POPAD instruction for when the operand-size\n   attribute is 32. Some assemblers may force the operand size to 16 when\n   POPA is used and to 32 when POPAD is used (using the operand-size override\n   prefix [66H] if necessary). Others may treat these mnemonics as synonyms\n   (POPA/POPAD) and use the current setting of the operand-size attribute to\n   determine the size of values to be popped from the stack, regardless of\n   the mnemonic used. (The D flag in the current code segment\u2019s segment\n   descriptor determines the operand-size attribute.)\n\n   This instruction executes as described in non-64-bit modes. It is not\n   valid in 64-bit mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["maxps", "        MAXPS \u2014 Maximum of Packed Single Precision Floating-Point Values\n\n                              Op 64/32 bit CPUID                              \n   Opcode/Instruction         /  Mode      Feature  Description\n                              En Support   Flag     \n                                                    Return the maximum single \n   NP 0F 5F /r MAXPS xmm1,    A  V/V       SSE      precision floating-point  \n   xmm2/m128                                        values between xmm1 and   \n                                                    xmm2/mem.                 \n   VEX.128.0F.WIG 5F /r                             Return the maximum single \n   VMAXPS xmm1, xmm2,         B  V/V       AVX      precision floating-point  \n   xmm3/m128                                        values between xmm2 and   \n                                                    xmm3/mem.                 \n   VEX.256.0F.WIG 5F /r                             Return the maximum single \n   VMAXPS ymm1, ymm2,         B  V/V       AVX      precision floating-point  \n   ymm3/m256                                        values between ymm2 and   \n                                                    ymm3/mem.                 \n                                                    Return the maximum packed \n                                                    single precision          \n   EVEX.128.0F.W0 5F /r                    AVX512VL floating-point values     \n   VMAXPS xmm1 {k1}{z}, xmm2, C  V/V       AVX512F  between xmm2 and          \n   xmm3/m128/m32bcst                                xmm3/m128/m32bcst and     \n                                                    store result in xmm1      \n                                                    subject to writemask k1.  \n                                                    Return the maximum packed \n                                                    single precision          \n   EVEX.256.0F.W0 5F /r                    AVX512VL floating-point values     \n   VMAXPS ymm1 {k1}{z}, ymm2, C  V/V       AVX512F  between ymm2 and          \n   ymm3/m256/m32bcst                                ymm3/m256/m32bcst and     \n                                                    store result in ymm1      \n                                                    subject to writemask k1.  \n                                                    Return the maximum packed \n                                                    single precision          \n   EVEX.512.0F.W0 5F /r                             floating-point values     \n   VMAXPS zmm1 {k1}{z}, zmm2, C  V/V       AVX512F  between zmm2 and          \n   zmm3/m512/m32bcst{sae}                           zmm3/m512/m32bcst and     \n                                                    store result in zmm1      \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed single precision floating-point\n   values in the first source operand and the second source operand and\n   returns the maximum value for each pair of values to the destination\n   operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of MAXPS can be emulated using a sequence of\n   instructions, such as, a comparison followed by AND, ANDN, and OR.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. The upper bits (MAXVL-1:256) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["vcvtne2ps2bf16", "    VCVTNE2PS2BF16 \u2014 Convert Two Packed Single Data to One Packed BF16 Data\n\n                                64/32 Bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Flag Description\n                                Support   \n                                                       Convert packed single  \n   EVEX.128.F2.0F38.W0 72                              data from xmm2 and     \n   /r VCVTNE2PS2BF16      A     V/V       AVX512VL     xmm3/m128/m32bcst to   \n   xmm1{k1}{z}, xmm2,                     AVX512_BF16  packed BF16 data in    \n   xmm3/m128/m32bcst                                   xmm1 with writemask    \n                                                       k1.                    \n                                                       Convert packed single  \n   EVEX.256.F2.0F38.W0 72                              data from ymm2 and     \n   /r VCVTNE2PS2BF16      A     V/V       AVX512VL     ymm3/m256/m32bcst to   \n   ymm1{k1}{z}, ymm2,                     AVX512_BF16  packed BF16 data in    \n   ymm3/m256/m32bcst                                   ymm1 with writemask    \n                                                       k1.                    \n                                                       Convert packed single  \n   EVEX.512.F2.0F38.W0 72                              data from zmm2 and     \n   /r VCVTNE2PS2BF16      A     V/V       AVX512F      zmm3/m512/m32bcst to   \n   zmm1{k1}{z}, zmm2,                     AVX512_BF16  packed BF16 data in    \n   zmm3/m512/m32bcst                                   zmm1 with writemask    \n                                                       k1.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Converts two SIMD registers of packed single data into a single register\n   of packed BF16 data.\n\n   This instruction does not support memory fault suppression.\n\n   This instruction uses \u201cRound to nearest (even)\u201d rounding mode. Output\n   denormals are always flushed to zero and input denormals are always\n   treated as zero. MXCSR is not consulted nor updated. No floating-point\n   exceptions are generated.\n"],
	["vrsqrtsh", " VRSQRTSH \u2014 Compute Approximate Reciprocal of Square Root of Scalar FP16 Value\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   bit Mode Flag 64/32 CPUID       \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Compute the          \n                                                         approximate          \n                                                         reciprocal square    \n                                                         root of the FP16     \n   EVEX.LLIG.66.MAP6.W0 4F /r                            value in xmm3/m16    \n   VRSQRTSH xmm1{k1}{z}, xmm2,     A V/V     AVX512-FP16 and store the result \n   xmm3/m16                                              in the low word      \n                                                         element of xmm1      \n                                                         subject to writemask \n                                                         k1. Bits 127:16 of   \n                                                         xmm2 are copied to   \n                                                         xmm1[127:16].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs the computation of the approximate reciprocal\n   square-root of the low FP16 value in the second source operand (the third\n   operand) and stores the result in the low word element of the destination\n   operand (the first operand) according to the writemask k1.\n\n   The maximum relative error for this approximation is less than 2^\u221211 +\n   2^\u221214.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL\u22121:128 of the destination\n   operand are zeroed.\n\n   For special cases, see Table 5-38.\n"],
	["umwait", "                        UMWAIT \u2014 User Level Monitor Wait\n\n   Opcode /           64/32 bit CPUID                                         \n   Instruction  Op/En Mode      Feature Description\n                      Support   Flag    \n                                        A hint that allows the processor to   \n   F2 0F AE /6                          stop instruction execution and enter  \n   UMWAIT r32,  A     V/V       WAITPKG an implementation-dependent optimized \n   <edx>, <eax>                         state until occurrence of a class of  \n                                        events.                               \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. The Mod field of the ModR/M byte must have value 11B.\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   UMWAIT instructs the processor to enter an implementation-dependent\n   optimized state while monitoring a range of addresses. The optimized state\n   may be either a light-weight power/performance optimized state or an\n   improved power/performance optimized state. The selection between the two\n   states is governed by the explicit input register bit[0] source operand.\n\n   UMWAIT is available when CPUID.7.0:ECX.WAITPKG[bit 5] is enumerated as 1.\n   UMWAIT may be executed at any privilege level. This instruction\u2019s\n   operation is the same in non-64-bit modes and in 64-bit mode.\n\n   The input register contains information such as the preferred optimized\n   state the processor should enter as described in the following table. Bits\n   other than bit 0 are reserved and will result in #GP if nonzero.\n\n   Bit Value  State Name Wakeup Time Power Savings Other Benefits             \n                                                   Improves performance of    \n   bit[0] = 0 C0.2       Slower      Larger        the other SMT thread(s) on \n                                                   the same core.             \n   bit[0] = 1 C0.1       Faster      Smaller       N/A                        \n   bits[31:1] N/A        N/A         N/A           Reserved                   \n\n   Table 4-21. UMWAIT Input Register Bit Definitions\n\n   The instruction wakes up when the time-stamp counter reaches or exceeds\n   the implicit EDX:EAX 64-bit input value (if the monitoring hardware did\n   not trigger beforehand).\n\n   Prior to executing the UMWAIT instruction, an operating system may specify\n   the maximum delay it allows the processor to suspend its operation. It can\n   do so by writing TSC-quanta value to the following 32bit MSR\n   (IA32_UM-WAIT_CONTROL at MSR index E1H):\n\n     * IA32_UMWAIT_CONTROL[31:2] \u2014 Determines the maximum time in TSC-quanta\n       that the processor can reside in either C0.1 or C0.2. A zero value\n       indicates no maximum time. The maximum time value is a 32-bit value\n       where the upper 30 bits come from this field and the lower two bits\n       are zero.\n     * IA32_UMWAIT_CONTROL[1] \u2014 Reserved.\n     * IA32_UMWAIT_CONTROL[0] \u2014 C0.2 is not allowed by the OS. Value of \u201c1\u201d\n       means all C0.2 requests revert to C0.1.\n\n   If the processor that executed a UMWAIT instruction wakes due to the\n   expiration of the operating system timelimit, the instructions sets\n   RFLAGS.CF; otherwise, that flag is cleared.\n\n   The UMWAIT instruction causes a transactional abort when used inside a\n   transactional region.\n\n   The UMWAIT instruction operates with the UMONITOR instruction. The two\n   instructions allow the definition of an address at which to wait\n   (UMONITOR) and an implementation-dependent optimized operation to perform\n   while waiting (UMWAIT). The execution of UMWAIT is a hint to the processor\n   that it can enter an implementation-dependent-optimized state while\n   waiting for an event or a store operation to the address range armed by\n   UMONITOR. The UMWAIT instruction will not wait (will not enter an\n   implementation-dependent optimized state) if any of the\n\n   following instructions were executed before UMWAIT and after the most\n   recent execution of UMONITOR: IRET, MONITOR, SYSEXIT, SYSRET, and far RET\n   (the last if it is changing CPL).\n\n   The following additional events cause the processor to exit the\n   implementation-dependent optimized state: a store to the address range\n   armed by the UMONITOR instruction, an NMI or SMI, a debug exception, a\n   machine check exception, the BINIT# signal, the INIT# signal, and the\n   RESET# signal. Other implementation-dependent events may also cause the\n   processor to exit the implementation-dependent optimized state.\n\n   In addition, an external interrupt causes the processor to exit the\n   implementation-dependent optimized state regardless of whether\n   maskable-interrupts are inhibited (EFLAGS.IF =0).\n\n   Following exit from the implementation-dependent-optimized state, control\n   passes to the instruction after the UMWAIT instruction. A pending\n   interrupt that is not masked (including an NMI or an SMI) may be delivered\n   before execution of that instruction.\n\n   Unlike the HLT instruction, the UMWAIT instruction does not restart at the\n   UMWAIT instruction following the handling of an SMI.\n\n   If the preceding UMONITOR instruction did not successfully arm an address\n   range or if UMONITOR was not executed prior to executing UMWAIT and\n   following the most recent execution of the legacy MONITOR instruction\n   (UMWAIT does not interoperate with MONITOR), then the processor will not\n   enter an optimized state. Execution will continue to the instruction\n   following UMWAIT.\n\n   A store to the address range armed by the UMONITOR instruction will cause\n   the processor to exit UMWAIT if either the store was originated by other\n   processor agents or the store was originated by a non-processor agent.\n"],
	["clflush", "                           CLFLUSH \u2014 Flush Cache Line\n\n   Opcode /    Op/En 64-bit Mode Compat/Leg Mode Description                  \n   Instruction \n   NP 0F AE /7 M     Valid       Valid           Flushes cache line           \n   CLFLUSH m8                                    containing m8.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Invalidates from every level of the cache hierarchy in the cache coherence\n   domain the cache line that contains the linear address specified with the\n   memory operand. If that cache line contains modified data at any level of\n   the cache hierarchy, that data is written back to memory. The source\n   operand is a byte memory location.\n\n   The availability of CLFLUSH is indicated by the presence of the CPUID\n   feature flag CLFSH (CPUID.01H:EDX[bit 19]). The aligned cache line size\n   affected is also indicated with the CPUID instruction (bits 8 through 15\n   of the EBX register when the initial value in the EAX register is 1).\n\n   The memory attribute of the page containing the affected line has no\n   effect on the behavior of this instruction. It should be noted that\n   processors are free to speculatively fetch and cache data from system\n   memory regions assigned a memory-type allowing for speculative reads (such\n   as, the WB, WC, and WT memory types). PREFETCHh instructions can be used\n   to provide the processor with hints for this speculative behavior. Because\n   this speculative fetching can occur at any time and is not tied to\n   instruction execution, the CLFLUSH instruction is not ordered with respect\n   to PREFETCHh instructions or any of the speculative fetching mechanisms\n   (that is, data can be speculatively loaded into a cache line just before,\n   during, or after the execution of a CLFLUSH instruction that references\n   the cache line).\n\n   Executions of the CLFLUSH instruction are ordered with respect to each\n   other and with respect to writes, locked read-modify-write instructions,\n   and fence instructions.^1 They are not ordered with respect to executions\n   of CLFLUSHOPT and CLWB. Software can use the SFENCE instruction to order\n   an execution of CLFLUSH relative to one of those operations.\n\n     1. Earlier versions of this manual specified that executions of the\n     CLFLUSH instruction were ordered only by the MFENCE instruction. All\n     processors implementing the CLFLUSH instruction also order it relative\n     to the other operations enumerated above.\n\n   The CLFLUSH instruction can be used at all privilege levels and is subject\n   to all permission checking and faults associated with a byte load (and in\n   addition, a CLFLUSH instruction is allowed to flush a linear address in an\n   execute-only segment). Like a load, the CLFLUSH instruction sets the A bit\n   but not the D bit in the page tables.\n\n   In some implementations, the CLFLUSH instruction may always cause\n   transactional abort with Transactional Synchronization Extensions (TSX).\n   The CLFLUSH instruction is not expected to be commonly used inside typical\n   transactional regions. However, programmers must not rely on CLFLUSH\n   instruction to force a transactional abort, since whether they cause\n   transactional abort is implementation dependent.\n\n   The CLFLUSH instruction was introduced with the SSE2 extensions; however,\n   because it has its own CPUID feature flag, it can be implemented in IA-32\n   processors that do not include the SSE2 extensions. Also, detecting the\n   presence of the SSE2 extensions with the CPUID instruction does not\n   guarantee that the CLFLUSH instruction is implemented in the processor.\n\n   CLFLUSH operation is the same in non-64-bit modes and 64-bit mode.\n"],
	["vmptrst", "          VMPTRST \u2014 Store Pointer to Virtual-Machine Control Structure\n\n   Opcode/Instruction      Op/En Description                                  \n   NP 0F C7 /7 VMPTRST m64 M     Stores the current VMCS pointer into memory. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) NA        NA        NA        \n\nDescription \u00b6\n\n   Stores the current-VMCS pointer into a specified memory address. The\n   operand of this instruction is always 64 bits and is always in memory.\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["vmwrite", "           VMWRITE \u2014 Write Field to Virtual-Machine Control Structure\n\n   Opcode/Instruction          Op/En Description                              \n   NP 0F 79 VMWRITE r64, r/m64 RM    Writes a specified VMCS field (in 64-bit \n                                     mode).                                   \n   NP 0F 79 VMWRITE r32, r/m32 RM    Writes a specified VMCS field (outside   \n                                     64-bit mode).                            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) NA        NA        \n\nDescription \u00b6\n\n   Writes the contents of a primary source operand (register or memory) to a\n   specified field in a VMCS. In VMX root operation, the instruction writes\n   to the current VMCS. If executed in VMX non-root operation, the\n   instruction writes to the VMCS referenced by the VMCS link pointer field\n   in the current VMCS.\n\n   The VMCS field is specified by the VMCS-field encoding contained in the\n   register secondary source operand. Outside IA-32e mode, the secondary\n   source operand is always 32 bits, regardless of the value of CS.D. In\n   64-bit mode, the secondary source operand has 64 bits.\n\n   The effective size of the primary source operand, which may be a register\n   or in memory, is always 32 bits outside IA-32e mode (the setting of CS.D\n   is ignored with respect to operand size) and 64 bits in 64-bit mode. If\n   the VMCS field specified by the secondary source operand is shorter than\n   this effective operand size, the high bits of the primary source operand\n   are ignored. If the VMCS field is longer, then the high bits of the field\n   are cleared to 0.\n\n   Note that any faults resulting from accessing a memory source operand\n   occur after determining, in the operation section below, that the relevant\n   VMCS pointer is valid but before determining if the destination VMCS field\n   is supported.\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["vrcp14sd", "       VRCP14SD \u2014 Compute Approximate Reciprocal of Scalar Float64 Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Computes the approximate    \n                                                  reciprocal of the scalar    \n                                                  double precision            \n                                                  floating-point value in     \n   EVEX.LLIG.66.0F38.W1 4D                        xmm3/m64 and stores the     \n   /r VRCP14SD xmm1        A    V/V       AVX512F result in xmm1 using        \n   {k1}{z}, xmm2, xmm3/m64                        writemask k1. Also, upper   \n                                                  double precision            \n                                                  floating-point value        \n                                                  (bits[127:64]) from xmm2 is \n                                                  copied to xmm1[127:64].     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate reciprocal\n   of the low double precision floating-point value in the second source\n   operand (the third operand) stores the result in the low quadword element\n   of the destination operand (the first operand) according to the writemask\n   k1. Bits (127:64) of the XMM register destination are copied from\n   corresponding bits in the first source operand (the second operand). The\n   maximum relative error for this approximation is less than 2^-14. The\n   source operand can be an XMM register or a 64-bit memory location. The\n   destination operand is an XMM register.\n\n   The VRCP14SD instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. A denormal source value will be treated as\n   zero only in case of DAZ bit set in MXCSR. Otherwise it is treated\n   correctly (i.e., not as a 0.0). Underflow results are flushed to zero only\n   in case of FTZ bit set in MXCSR. Otherwise it will be treated correctly\n   (i.e., correct underflow result is written) with the sign of the operand.\n   When a source value is a SNaN or QNaN, the SNaN is converted to a QNaN or\n   the source QNaN is returned. See Table 5-26 for special-case input values.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n   A numerically exact implementation of VRCP14xx can be found at:\n\n  https://software.intel.com/en-us/articles/reference-implementations-for-IA-approximation-instructions-vrcp14-\n  \u00b6\n\n  vrsqrt14-vrcp28-vrsqrt28-vexp2. \u00b6\n"],
	["vmresume", "                       VMRESUME \u2014 Resume Virtual Machine\n\n   See VMLAUNCH/VMRESUME\u2014Launch/Resume Virtual Machine.\n"],
	["vgatherdpd:vgatherqpd", "  VGATHERDPD/VGATHERQPD \u2014 Gather Packed Double Precision Floating-Point Values\n                        UsingSigned Dword/Qword Indices\n\n                               64/32 Bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                               Support   Flag    \n                                                 Using dword indices          \n                                                 specified in vm32x, gather   \n                                                 double precision             \n   VEX.128.66.0F38.W1 92                         floating-point values from   \n   /r VGATHERDPD xmm1,   RMV   V/V       AVX2    memory conditioned on mask   \n   vm32x, xmm2                                   specified by xmm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 xmm1.                        \n                                                 Using qword indices          \n                                                 specified in vm64x, gather   \n                                                 double precision             \n   VEX.128.66.0F38.W1 93                         floating-point values from   \n   /r VGATHERQPD xmm1,   RMV   V/V       AVX2    memory conditioned on mask   \n   vm64x, xmm2                                   specified by xmm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 xmm1.                        \n                                                 Using dword indices          \n                                                 specified in vm32x, gather   \n                                                 double precision             \n   VEX.256.66.0F38.W1 92                         floating-point values from   \n   /r VGATHERDPD ymm1,   RMV   V/V       AVX2    memory conditioned on mask   \n   vm32x, ymm2                                   specified by ymm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 ymm1.                        \n                                                 Using qword indices          \n                                                 specified in vm64y, gather   \n                                                 double precision             \n   VEX.256.66.0F38.W1 93                         floating-point values from   \n   /r VGATHERQPD ymm1,   RMV   V/V       AVX2    memory conditioned on mask   \n   vm64y, ymm2                                   specified by ymm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 ymm1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1       Operand 2                  Operand 3       Operand 4 \n   RMV   ModRM:reg (r,w) BaseReg (R): VSIB:base,    VEX.vvvv (r, w) N/A       \n                         VectorReg(R): VSIB:index   \n\nDescription \u00b6\n\n   The instruction conditionally loads up to 2 or 4 double precision\n   floating-point values from memory addresses specified by the memory\n   operand (the second operand) and using qword indices. The memory operand\n   uses the VSIB form of the SIB byte to specify a general purpose register\n   operand as the common base, a vector register for an array of indices\n   relative to the base and a constant scale factor.\n\n   The mask operand (the third operand) specifies the conditional load\n   operation from each memory address and the corresponding update of each\n   data element of the destination operand (the first operand).\n   Conditionality is specified by the most significant bit of each data\n   element of the mask register. If an element\u2019s mask bit is not set, the\n   corresponding element of the destination register is left unchanged. The\n   width of data element in the destination register and mask register are\n   identical. The entire mask register will be set to zero by this\n   instruction unless the instruction causes an exception.\n\n   Using dword indices in the lower half of the mask register, the\n   instruction conditionally loads up to 2 or 4 double precision\n   floating-point values from the VSIB addressing memory operand, and updates\n   the destination register.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask operand are partially updated; those\n   elements that have been gathered are placed into the destination register\n   and have their mask bits set to zero. If any traps or interrupts are\n   pending from already gathered elements, they will be delivered in lieu of\n   the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data size and index size are different, part of the destination\n   register and part of the mask register do not correspond to any elements\n   being gathered. This instruction sets those parts to zero. It may do this\n   to one or both of those registers even if the instruction triggers an\n   exception, and even if the instruction triggers the exception before\n   gathering any elements.\n\n   VEX.128 version: The instruction will gather two double precision\n   floating-point values. For dword indices, only the lower two indices in\n   the vector index register are used.\n\n   VEX.256 version: The instruction will gather four double precision\n   floating-point values. For dword indices, only the lower four indices in\n   the vector index register are used.\n\n   Note that:\n\n     * If any pair of the index, mask, or destination registers are the same,\n       this instruction results a #UD fault.\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination will be completed (and non-faulting). Individual\n       elements closer to the MSB may or may not be completed. If a given\n       element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to-left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * This instruction will cause a #UD if the address size attribute is\n       16-bit.\n     * This instruction will cause a #UD if the memory operand is encoded\n       without the SIB byte.\n     * This instruction should not be used to access memory mapped I/O as the\n       ordering of the individual loads it does is implementation specific,\n       and some implementations may use loads larger than the data element\n       size or load elements an indeterminate number of times.\n     * The scaled index may require more bits to represent than the address\n       bits used by the processor (e.g., in 32-bit mode, if the scale is\n       greater than one). In this case, the most significant bits beyond the\n       number of address bits are ignored.\n"],
	["pminsb:pminsw", "               PMINSB/PMINSW \u2014 Minimum of Packed Signed Integers\n\n                              Op / 64/32 bit CPUID                            \n   Opcode/Instruction         En   Mode      Feature  Description\n                                   Support   Flag     \n                                                      Compare signed word     \n   NP 0F EA /r^1 PMINSW mm1,  A    V/V       SSE      integers in mm2/m64 and \n   mm2/m64                                            mm1 and return minimum  \n                                                      values.                 \n                                                      Compare packed signed   \n   66 0F 38 38 /r PMINSB                              byte integers in xmm1   \n   xmm1, xmm2/m128            A    V/V       SSE4_1   and xmm2/m128 and store \n                                                      packed minimum values   \n                                                      in xmm1.                \n                                                      Compare packed signed   \n   66 0F EA /r PMINSW xmm1,                           word integers in        \n   xmm2/m128                  A    V/V       SSE2     xmm2/m128 and xmm1 and  \n                                                      store packed minimum    \n                                                      values in xmm1.         \n                                                      Compare packed signed   \n   VEX.128.66.0F38 38 /r                              byte integers in xmm2   \n   VPMINSB xmm1, xmm2,        B    V/V       AVX      and xmm3/m128 and store \n   xmm3/m128                                          packed minimum values   \n                                                      in xmm1.                \n                                                      Compare packed signed   \n   VEX.128.66.0F EA /r                                word integers in        \n   VPMINSW xmm1, xmm2,        B    V/V       AVX      xmm3/m128 and xmm2 and  \n   xmm3/m128                                          return packed minimum   \n                                                      values in xmm1.         \n                                                      Compare packed signed   \n   VEX.256.66.0F38 38 /r                              byte integers in ymm2   \n   VPMINSB ymm1, ymm2,        B    V/V       AVX2     and ymm3/m256 and store \n   ymm3/m256                                          packed minimum values   \n                                                      in ymm1.                \n                                                      Compare packed signed   \n   VEX.256.66.0F EA /r                                word integers in        \n   VPMINSW ymm1, ymm2,        B    V/V       AVX2     ymm3/m256 and ymm2 and  \n   ymm3/m256                                          return packed minimum   \n                                                      values in ymm1.         \n                                                      Compare packed signed   \n   EVEX.128.66.0F38.WIG 38 /r                         byte integers in xmm2   \n   VPMINSB xmm1{k1}{z}, xmm2, C    V/V       AVX512VL and xmm3/m128 and store \n   xmm3/m128                                 AVX512BW packed minimum values   \n                                                      in xmm1 under writemask \n                                                      k1.                     \n                                                      Compare packed signed   \n   EVEX.256.66.0F38.WIG 38 /r                         byte integers in ymm2   \n   VPMINSB ymm1{k1}{z}, ymm2, C    V/V       AVX512VL and ymm3/m256 and store \n   ymm3/m256                                 AVX512BW packed minimum values   \n                                                      in ymm1 under writemask \n                                                      k1.                     \n                                                      Compare packed signed   \n   EVEX.512.66.0F38.WIG 38 /r                         byte integers in zmm2   \n   VPMINSB zmm1{k1}{z}, zmm2, C    V/V       AVX512BW and zmm3/m512 and store \n   zmm3/m512                                          packed minimum values   \n                                                      in zmm1 under writemask \n                                                      k1.                     \n                                                      Compare packed signed   \n   EVEX.128.66.0F.WIG EA /r                           word integers in xmm2   \n   VPMINSW xmm1{k1}{z}, xmm2, C    V/V       AVX512VL and xmm3/m128 and store \n   xmm3/m128                                 AVX512BW packed minimum values   \n                                                      in xmm1 under writemask \n                                                      k1.                     \n                                                      Compare packed signed   \n   EVEX.256.66.0F.WIG EA /r                           word integers in ymm2   \n   VPMINSW ymm1{k1}{z}, ymm2, C    V/V       AVX512VL and ymm3/m256 and store \n   ymm3/m256                                 AVX512BW packed minimum values   \n                                                      in ymm1 under writemask \n                                                      k1.                     \n                                                      Compare packed signed   \n   EVEX.512.66.0F.WIG EA /r                           word integers in zmm2   \n   VPMINSW zmm1{k1}{z}, zmm2, C    V/V       AVX512BW and zmm3/m512 and store \n   zmm3/m512                                          packed minimum values   \n                                                      in zmm1 under writemask \n                                                      k1.                     \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed signed byte, word, or dword integers\n   in the second source operand and the first source operand and returns the\n   minimum value for each pair of integers to the destination operand.\n\n   Legacy SSE version PMINSW: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register;\n   The second source operand is a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n"],
	["ptest", "                            PTEST \u2014 Logical Compare\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n                                                     Set ZF if xmm2/m128 AND  \n   66 0F 38 17 /r PTEST                              xmm1 result is all 0s.   \n   xmm1, xmm2/m128           RM    V/V       SSE4_1  Set CF if xmm2/m128 AND  \n                                                     NOT xmm1 result is all   \n                                                     0s.                      \n   VEX.128.66.0F38.WIG 17 /r                         Set ZF and CF depending  \n   VPTEST xmm1, xmm2/m128    RM    V/V       AVX     on bitwise AND and ANDN  \n                                                     of sources.              \n   VEX.256.66.0F38.WIG 17 /r                         Set ZF and CF depending  \n   VPTEST ymm1, ymm2/m256    RM    V/V       AVX     on bitwise AND and ANDN  \n                                                     of sources.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   PTEST and VPTEST set the ZF flag if all bits in the result are 0 of the\n   bitwise AND of the first source operand (first operand) and the second\n   source operand (second operand). VPTEST sets the CF flag if all bits in\n   the result are 0 of the bitwise AND of the second source operand (second\n   operand) and the logical NOT of the destination operand.\n\n   The first source register is specified by the ModR/M reg field.\n\n   128-bit versions: The first source register is an XMM register. The second\n   source register can be an XMM register or a 128-bit memory location. The\n   destination register is not modified.\n\n   VEX.256 encoded version: The first source register is a YMM register. The\n   second source register can be a YMM register or a 256-bit memory location.\n   The destination register is not modified.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n\nFlags Affected \u00b6\n\n   The OF, AF, PF, SF flags are cleared and the ZF, CF flags are set\n   according to the operation.\n"],
	["movntps", "MOVNTPS \u2014 Store Packed Single Precision Floating-Point Values Using Non-Temporal\n                                      Hint\n\n                        Op / 64/32 bit CPUID                                  \n   Opcode/Instruction   En   Mode      Feature  Description\n                             Support   Flag     \n   NP 0F 2B /r MOVNTPS                          Move packed single precision  \n   m128, xmm1           A    V/V       SSE      values xmm1 to mem using      \n                                                non-temporal hint.            \n   VEX.128.0F.WIG 2B /r                         Move packed single precision  \n   VMOVNTPS m128, xmm1  A    V/V       AVX      values xmm1 to mem using      \n                                                non-temporal hint.            \n   VEX.256.0F.WIG 2B /r                         Move packed single precision  \n   VMOVNTPS m256, ymm1  A    V/V       AVX      values ymm1 to mem using      \n                                                non-temporal hint.            \n   EVEX.128.0F.W0 2B /r                AVX512VL Move packed single precision  \n   VMOVNTPS m128, xmm1  B    V/V       AVX512F  values in xmm1 to m128 using  \n                                                non-temporal hint.            \n   EVEX.256.0F.W0 2B /r                AVX512VL Move packed single precision  \n   VMOVNTPS m256, ymm1  B    V/V       AVX512F  values in ymm1 to m256 using  \n                                                non-temporal hint.            \n   EVEX.512.0F.W0 2B /r                         Move packed single precision  \n   VMOVNTPS m512, zmm1  B    V/V       AVX512F  values in zmm1 to m512 using  \n                                                non-temporal hint.            \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. ModRM.MOD != 011B\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   B     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the packed single precision floating-point values in the source\n   operand (second operand) to the destination operand (first operand) using\n   a non-temporal hint to prevent caching of the data during the write to\n   memory. The source operand is an XMM register, YMM register or ZMM\n   register, which is assumed to contain packed single precision,\n   floating-pointing. The destination operand is a 128-bit, 256-bit or\n   512-bit memory location. The memory operand must be aligned on a 16-byte\n   (128-bit version), 32-byte (VEX.256 encoded version) or 64-byte (EVEX.512\n   encoded version) boundary otherwise a general-protection exception (#GP)\n   will be generated.\n\n   The non-temporal hint is implemented by using a write combining (WC)\n   memory type protocol when writing the data to memory. Using this protocol,\n   the processor does not write the data into the cache hierarchy, nor does\n   it fetch the corresponding cache line from memory into the cache\n   hierarchy. The memory type of the region being written to can override the\n   non-temporal hint, if the memory address specified for the non-temporal\n   store is in an uncacheable (UC) or write protected (WP) memory region. For\n   more information on non-temporal stores, see \u201cCaching of Temporal vs.\n   Non-Temporal Data\u201d in Chapter 10 in the IA-32 Intel Architecture Software\n   Developer\u2019s Manual, Volume 1.\n\n   Because the WC protocol uses a weakly-ordered memory consistency model, a\n   fencing operation implemented with the SFENCE or MFENCE instruction should\n   be used in conjunction with MOVNTPS instructions if multiple processors\n   might use different memory types to read/write the destination memory\n   locations.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["fabs", "                             FABS \u2014 Absolute Value\n\n   Opcode  Mode Leg Mode Description                         \n   D9 E1                 Replace ST with its absolute value. \n\nDescription \u00b6\n\n   Clears the sign bit of ST(0) to create the absolute value of the operand.\n   The following table shows the results obtained when creating the absolute\n   value of various classes of numbers.\n\n   ST(0) SRC ST(0) DEST \n   \u2212\u221e        +\u221e         \n   \u2212F        +F         \n   \u22120        +0         \n   +0        +0         \n   +F        +F         \n   +\u221e        +\u221e         \n   NaN       NaN        \n\n   Table 3-17. Results Obtained from FABS\n\n     F Meansfinitefloating-pointvalue.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0.  \n   C0, C2, C3 Undefined. \n"],
	["invept", "               INVEPT \u2014 Invalidate Translations Derived from EPT\n\n   Opcode/Instruction           Op/En Description                             \n                                      Invalidates EPT-derived entries in the  \n   66 0F 38 80 INVEPT r64, m128 RM    TLBs and paging-structure caches (in    \n                                      64-bit mode).                           \n                                      Invalidates EPT-derived entries in the  \n   66 0F 38 80 INVEPT r32, m128 RM    TLBs and paging-structure caches        \n                                      (outside 64-bit mode).                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) NA        NA        \n\nDescription \u00b6\n\n   Invalidates mappings in the translation lookaside buffers (TLBs) and\n   paging-structure caches that were derived from extended page tables (EPT).\n   (See Chapter 29, \u201cVMX Support for Address Translation.\u201d) Invalidation is\n   based on the INVEPT type specified in the register operand and the INVEPT\n   descriptor specified in the memory operand.\n\n   Outside IA-32e mode, the register operand is always 32 bits, regardless of\n   the value of CS.D; in 64-bit mode, the register operand has 64 bits (the\n   instruction cannot be executed in compatibility mode).\n\n   The INVEPT types supported by a logical processors are reported in the\n   IA32_VMX_EPT_VPID_CAP MSR (see Appendix A, \u201cVMX Capability Reporting\n   Facility\u201d). There are two INVEPT types currently defined:\n\n     * Single-context invalidation. If the INVEPT type is 1, the logical\n       processor invalidates all mappings associated with bits 51:12 of the\n       EPT pointer (EPTP) specified in the INVEPT descriptor. It may\n       invalidate other mappings as well.\n     * Global invalidation: If the INVEPT type is 2, the logical processor\n       invalidates mappings associated with all EPTPs.\n\n   If an unsupported INVEPT type is specified, the instruction fails.\n\n   INVEPT invalidates all the specified mappings for the indicated EPTP(s)\n   regardless of the VPID and PCID values with which those mappings may be\n   associated.\n\n   The INVEPT descriptor comprises 128 bits and contains a 64-bit EPTP value\n   in bits 63:0 (see Figure 31-1).\n\n   127 6463 0 Reserved (must be zero) EPT pointer (EPTP) Figure 31-1. INVEPT\n   Descriptor\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["movhps", "        MOVHPS \u2014 Move High Packed Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Move two packed single      \n   NP 0F 16 /r MOVHPS      A    V/V       SSE     precision floating-point    \n   xmm1, m64                                      values from m64 to high     \n                                                  quadword of xmm1.           \n                                                  Merge two packed single     \n   VEX.128.0F.WIG 16 /r    B    V/V       AVX     precision floating-point    \n   VMOVHPS xmm2, xmm1, m64                        values from m64 and the low \n                                                  quadword of xmm1.           \n                                                  Merge two packed single     \n   EVEX.128.0F.W0 16 /r    D    V/V       AVX512F precision floating-point    \n   VMOVHPS xmm2, xmm1, m64                        values from m64 and the low \n                                                  quadword of xmm1.           \n                                                  Move two packed single      \n   NP 0F 17 /r MOVHPS m64, C    V/V       SSE     precision floating-point    \n   xmm1                                           values from high quadword   \n                                                  of xmm1 to m64.             \n                                                  Move two packed single      \n   VEX.128.0F.WIG 17 /r    C    V/V       AVX     precision floating-point    \n   VMOVHPS m64, xmm1                              values from high quadword   \n                                                  of xmm1 to m64.             \n                                                  Move two packed single      \n   EVEX.128.0F.W0 17 /r    E    V/V       AVX512F precision floating-point    \n   VMOVHPS m64, xmm1                              values from high quadword   \n                                                  of xmm1 to m64.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     N/A        ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n   D     Tuple2     ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   E     Tuple2     ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n\nDescription \u00b6\n\n   This instruction cannot be used for register to register or memory to\n   memory moves.\n\n   128-bit Legacy SSE load:\n\n   Moves two packed single precision floating-point values from the source\n   64-bit memory operand and stores them in the high 64-bits of the\n   destination XMM register. The lower 64bits of the XMM register are\n   preserved. Bits (MAXVL-1:128) of the corresponding destination register\n   are preserved.\n\n   VEX.128 & EVEX encoded load:\n\n   Loads two single precision floating-point values from the source 64-bit\n   memory operand (the third operand) and stores it in the upper 64-bits of\n   the destination XMM register (first operand). The low 64-bits from the\n   first source operand (the second operand) are copied to the lower 64-bits\n   of the destination. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   128-bit store:\n\n   Stores two packed single precision floating-point values from the high\n   64-bits of the XMM register source (second operand) to the 64-bit memory\n   location (first operand).\n\n   Note: VMOVHPS (store) (VEX.128.0F 17 /r) is legal and has the same\n   behavior as the existing 0F 17 store. For VMOVHPS (store) VEX.vvvv and\n   EVEX.vvvv are reserved and must be 1111b otherwise instruction will #UD.\n\n   If VMOVHPS is encoded with VEX.L or EVEX.L\u2019L= 1, an attempt to execute the\n   instruction encoded with VEX.L or EVEX.L\u2019L= 1 will cause an #UD exception.\n"],
	["aesencwide128kl", "AESENCWIDE128KL \u2014 Perform Ten Rounds of AES Encryption Flow With Key Locker on 8\n                            BlocksUsing 128-Bit Key\n\n                               64/32-bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                                         Flag    \n   F3 0F 38 D8                                   Encrypt XMM0-7 using 128-bit \n   !(11):000:bbb                         AESKLE  AES key indicated by handle  \n   AESENCWIDE128KL m384, A     V/V       WIDE_KL at m384 and store each       \n   <XMM0-7>                                      resultant block back to its  \n                                                 corresponding register.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operands 2\u20149           \n   A     N/A   ModRM:r/m (r) Implicit XMM0-7 (r, w) \n\nDescription \u00b6\n\n   The AESENCWIDE128KL^1 instruction performs ten rounds of AES to encrypt\n   each of the eight blocks in XMM0-7 using the 128-bit key indicated by the\n   handle from the second operand. It replaces each input block in XMM0-7\n   with its corresponding encrypted block if the operation succeeds (e.g.,\n   does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n"],
	["korw:korb:korq:kord", "                 KORW/KORB/KORQ/KORD \u2014 Bitwise Logical OR Masks\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Flag Description\n                                 Support   \n   VEX.L1.0F.W0 45 /r KORW                              Bitwise OR 16 bits    \n   k1, k2, k3              RVR   V/V       AVX512F      masks k2 and k3 and   \n                                                        place result in k1.   \n   VEX.L1.66.0F.W0 45 /r                                Bitwise OR 8 bits     \n   KORB k1, k2, k3         RVR   V/V       AVX512DQ     masks k2 and k3 and   \n                                                        place result in k1.   \n   VEX.L1.0F.W1 45 /r KORQ                              Bitwise OR 64 bits    \n   k1, k2, k3              RVR   V/V       AVX512BW     masks k2 and k3 and   \n                                                        place result in k1.   \n   VEX.L1.66.0F.W1 45 /r                                Bitwise OR 32 bits    \n   KORD k1, k2, k3         RVR   V/V       AVX512BW     masks k2 and k3 and   \n                                                        place result in k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3                              \n   RVR   ModRM:reg (w) VEX.1vvv (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise OR between the vector mask k2 and the vector mask k3,\n   and writes the result into vector mask k1 (three-operand form).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["sexit", "                   GETSEC[SEXIT] \u2014 Exit Measured Environment\n\n   Opcode           Instruction   Description                \n   NP 0F 37 (EAX=5) GETSEC[SEXIT] Exit measured environment. \n\nDescription \u00b6\n\n   The GETSEC[SEXIT] instruction initiates an exit of a measured environment\n   established by GETSEC[SENTER]. The SEXIT leaf of GETSEC is selected with\n   EAX set to 5 at execution. This instruction leaf sends a message to all\n   logical processors in the platform to signal the measured environment\n   exit.\n\n   There are restrictions enforced by the processor for the execution of the\n   GETSEC[SEXIT] instruction:\n\n     * Execution is not allowed unless the processor is in protected mode\n       (CR0.PE = 1) with CPL = 0 and EFLAGS.VM = 0.\n     * The processor must be in a measured environment as launched by a\n       previous GETSEC[SENTER] instruction, but not still in authenticated\n       code execution mode.\n     * To avoid potential interoperability conflicts between modes, the\n       processor is not allowed to execute this instruction if it currently\n       is in SMM or in VMX operation.\n     * To ensure consistent handling of SIPI messages, the processor\n       executing the GETSEC[SEXIT] instruction must also be designated the\n       BSP (bootstrap processor) as defined by the register bit\n       IA32_APIC_BASE.BSP (bit 8).\n\n   Failure to abide by the above conditions results in the processor\n   signaling a general protection violation.\n\n   This instruction initiates a sequence to rendezvous the RLPs with the ILP.\n   It then clears the internal processor flag indicating the processor is\n   operating in a measured environment.\n\n   In response to a message signaling the completion of rendezvous, all RLPs\n   restart execution with the instruction that was to be executed at the time\n   GETSEC[SEXIT] was recognized. This applies to all processor conditions,\n   with the following exceptions:\n\n     * If an RLP executed HLT and was in this halt state at the time of the\n       message initiated by GETSEC[SEXIT], then execution resumes in the halt\n       state.\n     * If an RLP was executing MWAIT, then a message initiated by\n       GETSEC[SEXIT] causes an exit of the MWAIT state, falling through to\n       the next instruction.\n     * If an RLP was executing an intermediate iteration of a string\n       instruction, then the processor resumes execution of the string\n       instruction at the point which the message initiated by GETSEC[SEXIT]\n       was recognized.\n     * If an RLP is still in the SENTER sleep state (never awakened with\n       GETSEC[WAKEUP]), it will be sent to the wait-for-SIPI state after\n       first clearing the bootstrap processor indicator flag\n       (IA32_APIC_BASE.BSP) and any pending SIPI state. In this case, such\n       RLPs are initialized to an architectural state consistent with having\n       taken a soft reset using the INIT# pin.\n\n   Prior to completion of the GETSEC[SEXIT] operation, both the ILP and any\n   active RLPs unmask the response of the external event signals INIT#, A20M,\n   NMI#, and SMI#. This unmasking is performed unconditionally to recognize\n   pin events which are masked after a GETSEC[SENTER]. The state of A20M is\n   unmasked, as the A20M pin is not recognized while the measured environment\n   is active.\n\n   On a successful exit of the measured environment, the ILP re-locks the\n   Intel\u00ae TXT-capable chipset private configuration space. GETSEC[SEXIT] does\n   not affect the content of any PCR.\n\n   At completion of GETSEC[SEXIT] by the ILP, execution proceeds to the next\n   instruction. Since EFLAGS and the debug register state are not modified by\n   this instruction, a pending trap condition is free to be signaled if\n   previously enabled.\n\nOperation in a Uni-Processor Platform \u00b6\n\n   (* The state of the internal flag ACMODEFLAG and SENTERFLAG persist across\n   instruction boundary *)\n\n   GETSEC[SEXIT] (ILP Only):\n\n   IF (CR4.SMXE=0)\n\n   THEN #UD;\n\n   ELSE IF (in VMX non-root operation)\n\n   THEN VM Exit (reason=\u201dGETSEC instruction\u201d);\n\n   ELSE IF (GETSEC leaf unsupported)\n\n   THEN #UD;\n\n   ELSE IF ((in VMX root operation) or\n\n   (CR0.PE=0) or (CPL>0) or (EFLAGS.VM=1) or\n\n   (IA32_APIC_BASE.BSP=0) or\n\n   (TXT chipset not present) or\n\n   (SENTERFLAG=0) or (ACMODEFLAG=1) or (IN_SMM=1))\n\n   THEN #GP(0);\n\n   SignalTXTMsg(SEXIT);\n\n   DO\n\n   WHILE (no SignalSEXIT message);\n\n   TXT_SEXIT_MSG_EVENT (ILP & RLP):\n\n   Mask and clear SignalSEXIT event;\n\n   Clear MONITOR FSM;\n\n   Unmask SignalSENTER event;\n\n   IF (in VMX operation)\n\n   THEN TXT-SHUTDOWN(#IllegalEvent);\n\n   SignalTXTMsg(SEXITAck);\n\n   IF (logical processor is not ILP)\n\n   THEN GOTO RLP_SEXIT_ROUTINE;\n\n   (* ILP waits for all logical processors to ACK *)\n\n   DO\n\n   DONE := READ(LT.STS);\n\n   WHILE (NOT DONE);\n\n   SignalTXTMsg(SEXITContinue);\n\n   SignalTXTMsg(ClosePrivate);\n\n   SENTERFLAG := 0;\n\n   Unmask SMI, INIT, A20M, and NMI external pin events;\n\n   END;\n\n   RLP_SEXIT_ROUTINE (RLPs Only):\n\n   Wait for SignalSEXITContinue message;\n\n   Unmask SMI, INIT, A20M, and NMI external pin events;\n\n   IF (prior execution state = HLT)\n\n   THEN reenter HLT state;\n\n   IF (prior execution state = SENTER sleep)\n\n   THEN\n\n   IA32_APIC_BASE.BSP := 0;\n\n   Clear pending SIPI state;\n\n   Call INIT_PROCESSOR_STATE;\n\n   Unmask SIPI event;\n\n   GOTO WAIT-FOR-SIPI;\n\n   FI;\n\n   END;\n\nFlags Affected \u00b6\n\n   ILP: None.\n\n   RLPs: All flags are modified for an RLP. returning to wait-for-SIPI state,\n   none otherwise.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX Ignored.\n\nVM-Exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["clwb", "                          CLWB \u2014 Cache Line Write Back\n\n                             64/32 bit    CPUID                               \n   Opcode/Instruction  Op/En Mode Support Feature Description\n                                          Flag    \n                                                  Writes back modified cache  \n                                                  line containing m8, and may \n   66 0F AE /6 CLWB m8 M     V/V          CLWB    retain the line in cache    \n                                                  hierarchy in non-modified   \n                                                  state.                      \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. The Mod field of the ModR/M byte cannot have value 11B.\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Writes back to memory the cache line (if modified) that contains the\n   linear address specified with the memory operand from any level of the\n   cache hierarchy in the cache coherence domain. The line may be retained in\n   the cache hierarchy in non-modified state. Retaining the line in the cache\n   hierarchy is a performance optimization (treated as a hint by hardware) to\n   reduce the possibility of cache miss on a subsequent access. Hardware may\n   choose to retain the line at any of the levels in the cache hierarchy, and\n   in some cases, may invalidate the line from the cache hierarchy. The\n   source operand is a byte memory location.\n\n   The availability of CLWB instruction is indicated by the presence of the\n   CPUID feature flag CLWB (bit 24 of the EBX register, see \u201cCPUID \u2014 CPU\n   Identification\u201d in this chapter). The aligned cache line size affected is\n   also indicated with the CPUID instruction (bits 8 through 15 of the EBX\n   register when the initial value in the EAX register is 1).\n\n   The memory attribute of the page containing the affected line has no\n   effect on the behavior of this instruction. It should be noted that\n   processors are free to speculatively fetch and cache data from system\n   memory regions that are assigned a memory-type allowing for speculative\n   reads (such as, the WB, WC, and WT memory types). PREFETCHh instructions\n   can be used to provide the processor with hints for this speculative\n   behavior. Because this speculative fetching can occur at any time and is\n   not tied to instruction execution, the CLWB instruction is not ordered\n   with respect to PREFETCHh instructions or any of the speculative fetching\n   mechanisms (that is, data can be speculatively loaded into a cache line\n   just before, during, or after the execution of a CLWB instruction that\n   references the cache line).\n\n   Executions of the CLWB instruction are ordered with respect to fence\n   instructions and to locked read-modify-write instructions; they are also\n   ordered with respect to older writes to the cache line being written back.\n   They are not ordered with respect to other executions of CLWB, to\n   executions of CLFLUSH and CLFLUSHOPT, or to younger writes to the cache\n   line being written back. Software can use the SFENCE instruction to order\n   an execution of CLWB relative to one of those operations.\n\n   For usages that require only writing back modified data from cache lines\n   to memory (do not require the line to be invalidated), and expect to\n   subsequently access the data, software is recommended to use CLWB (with\n   appropriate fencing) instead of CLFLUSH or CLFLUSHOPT for improved\n   performance.\n\n   The CLWB instruction can be used at all privilege levels and is subject to\n   all permission checking and faults associated with a byte load. Like a\n   load, the CLWB instruction sets the accessed flag but not the dirty flag\n   in the page tables.\n\n   In some implementations, the CLWB instruction may always cause\n   transactional abort with Transactional Synchronization Extensions (TSX).\n   CLWB instruction is not expected to be commonly used inside typical\n   transactional regions. However, programmers must not rely on CLWB\n   instruction to force a transactional abort, since whether they cause\n   transactional abort is implementation dependent.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cwd:cdq:cqo", "    CWD/CDQ/CQO \u2014 Convert Word to Doubleword/Convert Doubleword to Quadword\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Mode Description            \n                                Mode   \n   99         CWD         ZO    Valid  Valid           DX:AX := sign-extend   \n                                                       of AX.                 \n   99         CDQ         ZO    Valid  Valid           EDX:EAX := sign-extend \n                                                       of EAX.                \n   REX.W + 99 CQO         ZO    Valid  N.E.            RDX:RAX:= sign-extend  \n                                                       of RAX.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Doubles the size of the operand in register AX, EAX, or RAX (depending on\n   the operand size) by means of sign extension and stores the result in\n   registers DX:AX, EDX:EAX, or RDX:RAX, respectively. The CWD instruction\n   copies the sign (bit 15) of the value in the AX register into every bit\n   position in the DX register. The CDQ instruction copies the sign (bit 31)\n   of the value in the EAX register into every bit position in the EDX\n   register. The CQO instruction (available in 64-bit mode only) copies the\n   sign (bit 63) of the value in the RAX register into every bit position in\n   the RDX register.\n\n   The CWD instruction can be used to produce a doubleword dividend from a\n   word before word division. The CDQ instruction can be used to produce a\n   quadword dividend from a doubleword before doubleword division. The CQO\n   instruction can be used to produce a double quadword dividend from a\n   quadword before a quadword division.\n\n   The CWD and CDQ mnemonics reference the same opcode. The CWD instruction\n   is intended for use when the operand-size attribute is 16 and the CDQ\n   instruction for when the operand-size attribute is 32. Some assemblers may\n   force the operand size to 16 when CWD is used and to 32 when CDQ is used.\n   Others may treat these mnemonics as synonyms (CWD/CDQ) and use the current\n   setting of the operand-size attribute to determine the size of values to\n   be converted, regardless of the mnemonic used.\n\n   In 64-bit mode, use of the REX.W prefix promotes operation to 64 bits. The\n   CQO mnemonics reference the same opcode as CWD/CDQ. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vgatherpf0dps:vgatherpf0qps:vgatherpf0dpd:vgatherpf0qpd", "VGATHERPF0DPS/VGATHERPF0QPS/VGATHERPF0DPD/VGATHERPF0QPD \u2014 Sparse PrefetchPacked\n    SP/DP Data Values With Signed Dword, Signed Qword Indices Using T0 Hint\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Using signed dword         \n                                                   indices, prefetch sparse   \n   EVEX.512.66.0F38.W0 C6                          byte memory locations      \n   /1 /vsib VGATHERPF0DPS A     V/V       AVX512PF containing                 \n   vm32z {k1}                                      single-precision data      \n                                                   using opmask k1 and T0     \n                                                   hint.                      \n                                                   Using signed qword         \n                                                   indices, prefetch sparse   \n   EVEX.512.66.0F38.W0 C7                          byte memory locations      \n   /1 /vsib VGATHERPF0QPS A     V/V       AVX512PF containing                 \n   vm64z {k1}                                      single-precision data      \n                                                   using opmask k1 and T0     \n                                                   hint.                      \n                                                   Using signed dword         \n   EVEX.512.66.0F38.W1 C6                          indices, prefetch sparse   \n   /1 /vsib VGATHERPF0DPD A     V/V       AVX512PF byte memory locations      \n   vm32y {k1}                                      containing double          \n                                                   precision data using       \n                                                   opmask k1 and T0 hint.     \n                                                   Using signed qword         \n   EVEX.512.66.0F38.W1 C7                          indices, prefetch sparse   \n   /1 /vsib VGATHERPF0QPD A     V/V       AVX512PF byte memory locations      \n   vm64z {k1}                                      containing double          \n                                                   precision data using       \n                                                   opmask k1 and T0 hint.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1                   Operand 2 Operand 3 Operand 4 \n   A     Tuple1     BaseReg (R): VSIB:base,     N/A       N/A       N/A       \n         Scalar     VectorReg(R): VSIB:index    \n\n  Description \u00b6\n\n   The instruction conditionally prefetches up to sixteen 32-bit or eight\n   64-bit integer byte data elements. The elements are specified via the VSIB\n   (i.e., the index register is an zmm, holding packed indices). Elements\n   will only be prefetched if their corresponding mask bit is one.\n\n   Lines prefetched are loaded into to a location in the cache hierarchy\n   specified by a locality hint (T0):\n\n     * T0 (temporal data)\u2014prefetch data into the first level cache.\n\n   [PS data] For dword indices, the instruction will prefetch sixteen memory\n   locations. For qword indices, the instruction will prefetch eight values.\n\n   [PD data] For dword and qword indices, the instruction will prefetch eight\n   memory locations.\n\n   Note that:\n\n   (1) The prefetches may happen in any order (or not at all). The\n   instruction is a hint.\n\n   (2) The mask is left unchanged.\n\n   (3) Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n\n   (4) No FP nor memory faults may be produced by this instruction.\n\n   (5) Prefetches do not handle cache line splits\n\n   (6) A #UD is signaled if the memory operand is encoded without the SIB\n   byte.\n"],
	["vcvtph2uw", "        VCVTPH2UW \u2014 Convert Packed FP16 Values to Unsigned Word Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert packed FP16  \n   EVEX.128.NP.MAP5.W0 7D /r                             values in            \n   VCVTPH2UW xmm1{k1}{z},          A V/V     AVX512-FP16 xmm2/m128/m16bcst to \n   xmm2/m128/m16bcst                         AVX512VL    unsigned word        \n                                                         integers, and store  \n                                                         the result in xmm1.  \n                                                         Convert packed FP16  \n   EVEX.256.NP.MAP5.W0 7D /r                             values in            \n   VCVTPH2UW ymm1{k1}{z},          A V/V     AVX512-FP16 ymm2/m256/m16bcst to \n   ymm2/m256/m16bcst                         AVX512VL    unsigned word        \n                                                         integers, and store  \n                                                         the result in ymm1.  \n                                                         Convert packed FP16  \n   EVEX.512.NP.MAP5.W0 7D /r                             values in            \n   VCVTPH2UW zmm1{k1}{z},          A V/V     AVX512-FP16 zmm2/m512/m16bcst to \n   zmm2/m512/m16bcst {er}                                unsigned word        \n                                                         integers, and store  \n                                                         the result in zmm1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   unsigned word integers in the destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["idiv", "                              IDIV \u2014 Signed Divide\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n                                                  Signed divide AX by r/m8,   \n   F6 /7      IDIV r/m8   M     Valid  Valid      with result stored in: AL   \n                                                  := Quotient, AH :=          \n                                                  Remainder.                  \n   REX + F6                                       Signed divide AX by r/m8,   \n   /7         IDIV r/m8^1 M     Valid  N.E.       with result stored in AL := \n                                                  Quotient, AH := Remainder.  \n                                                  Signed divide DX:AX by      \n   F7 /7      IDIV r/m16  M     Valid  Valid      r/m16, with result stored   \n                                                  in AX := Quotient, DX :=    \n                                                  Remainder.                  \n                                                  Signed divide EDX:EAX by    \n   F7 /7      IDIV r/m32  M     Valid  Valid      r/m32, with result stored   \n                                                  in EAX := Quotient, EDX :=  \n                                                  Remainder.                  \n                                                  Signed divide RDX:RAX by    \n   REX.W + F7 IDIV r/m64  M     Valid  N.E.       r/m64, with result stored   \n   /7                                             in RAX := Quotient, RDX :=  \n                                                  Remainder.                  \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Divides the (signed) value in the AX, DX:AX, or EDX:EAX (dividend) by the\n   source operand (divisor) and stores the result in the AX (AH:AL), DX:AX,\n   or EDX:EAX registers. The source operand can be a general-purpose register\n   or a memory location. The action of this instruction depends on the\n   operand size (dividend/divisor).\n\n   Non-integral results are truncated (chopped) towards 0. The remainder is\n   always less than the divisor in magnitude. Overflow is indicated with the\n   #DE (divide error) exception rather than with the CF flag.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. In 64-bit mode when\n   REX.W is applied, the instruction divides the signed value in RDX:RAX by\n   the source operand. RAX contains a 64-bit quotient; RDX contains a 64-bit\n   remainder.\n\n   See the summary chart at the beginning of this section for encoding data\n   and limits. See Table 3-51.\n\n   Operand Size               Dividend Divisor Quotient  Remainder Quotient   \n                                                                   Range      \n                                                                   \u2212128 to    \n                                                                   +127       \n   Word/byte Doubleword/word  AX DX:AX r/m8                        \u221232,768 to \n   Quadword/doubleword        EDX:EAX  r/m16   AL AX EAX AH DX EDX +32,767    \n   Doublequadword/ quadword   RDX:RAX  r/m32   RAX       RDX       \u22122^31 to   \n                                       r/m64                       2^31 \u2212 1   \n                                                                   \u22122^63 to   \n                                                                   2^63 \u2212 1   \n\n   Table 3-51. IDIV Results\n\nFlags Affected \u00b6\n\n   The CF, OF, SF, ZF, AF, and PF flags are undefined.\n"],
	["dec", "                              DEC \u2014 Decrement by 1\n\n   Opcode      Instruction Op/En 64-Bit Compat/Leg Mode Description           \n                                 Mode   \n   FE /1       DEC r/m8    M     Valid  Valid           Decrement r/m8 by 1.  \n   REX + FE /1 DEC r/m8^*  M     Valid  N.E.            Decrement r/m8 by 1.  \n   FF /1       DEC r/m16   M     Valid  Valid           Decrement r/m16 by 1. \n   FF /1       DEC r/m32   M     Valid  Valid           Decrement r/m32 by 1. \n   REX.W + FF  DEC r/m64   M     Valid  N.E.            Decrement r/m64 by 1. \n   /1          \n   48+rw       DEC r16     O     N.E.   Valid           Decrement r16 by 1.   \n   48+rd       DEC r32     O     N.E.   Valid           Decrement r32 by 1.   \n\n     *\n     In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1          Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w)   N/A       N/A       N/A       \n   O     opcode + rd (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Subtracts 1 from the destination operand, while preserving the state of\n   the CF flag. The destination operand can be a register or a memory\n   location. This instruction allows a loop counter to be updated without\n   disturbing the CF flag. (To perform a decrement operation that updates the\n   CF flag, use a SUB instruction with an immediate operand of 1.)\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, DEC r16 and DEC r32 are not encodable (because opcodes 48H\n   through 4FH are REX prefixes). Otherwise, the instruction\u2019s 64-bit mode\n   default operation size is 32 bits. Use of the REX.R prefix permits access\n   to additional registers (R8-R15). Use of the REX.W prefix promotes\n   operation to 64 bits.\n\n   See the summary chart at the beginning of this section for encoding data\n   and limits.\n\nFlags Affected \u00b6\n\n   The CF flag is not affected. The OF, SF, ZF, AF, and PF flags are set\n   according to the result.\n"],
	["punpcklbw:punpcklwd:punpckldq:punpcklqdq", "           PUNPCKLBW/PUNPCKLWD/PUNPCKLDQ/PUNPCKLQDQ \u2014 Unpack Low Data\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F 60 /r^1 PUNPCKLBW                          Interleave low-order      \n   mm, mm/m32              A     V/V       MMX      bytes from mm and mm/m32  \n                                                    into mm.                  \n   66 0F 60 /r PUNPCKLBW                            Interleave low-order      \n   xmm1, xmm2/m128         A     V/V       SSE2     bytes from xmm1 and       \n                                                    xmm2/m128 into xmm1.      \n   NP 0F 61 /r^1 PUNPCKLWD                          Interleave low-order      \n   mm, mm/m32              A     V/V       MMX      words from mm and mm/m32  \n                                                    into mm.                  \n   66 0F 61 /r PUNPCKLWD                            Interleave low-order      \n   xmm1, xmm2/m128         A     V/V       SSE2     words from xmm1 and       \n                                                    xmm2/m128 into xmm1.      \n   NP 0F 62 /r^1 PUNPCKLDQ                          Interleave low-order      \n   mm, mm/m32              A     V/V       MMX      doublewords from mm and   \n                                                    mm/m32 into mm.           \n   66 0F 62 /r PUNPCKLDQ                            Interleave low-order      \n   xmm1, xmm2/m128         A     V/V       SSE2     doublewords from xmm1 and \n                                                    xmm2/m128 into xmm1.      \n                                                    Interleave low-order      \n   66 0F 6C /r PUNPCKLQDQ  A     V/V       SSE2     quadword from xmm1 and    \n   xmm1, xmm2/m128                                  xmm2/m128 into xmm1       \n                                                    register.                 \n   VEX.128.66.0F.WIG 60/r                           Interleave low-order      \n   VPUNPCKLBW xmm1,xmm2,   B     V/V       AVX      bytes from xmm2 and       \n   xmm3/m128                                        xmm3/m128 into xmm1.      \n   VEX.128.66.0F.WIG 61/r                           Interleave low-order      \n   VPUNPCKLWD xmm1,xmm2,   B     V/V       AVX      words from xmm2 and       \n   xmm3/m128                                        xmm3/m128 into xmm1.      \n   VEX.128.66.0F.WIG 62/r                           Interleave low-order      \n   VPUNPCKLDQ xmm1, xmm2,  B     V/V       AVX      doublewords from xmm2 and \n   xmm3/m128                                        xmm3/m128 into xmm1.      \n   VEX.128.66.0F.WIG 6C/r                           Interleave low-order      \n   VPUNPCKLQDQ xmm1, xmm2, B     V/V       AVX      quadword from xmm2 and    \n   xmm3/m128                                        xmm3/m128 into xmm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 60 /r                          Interleave low-order      \n   VPUNPCKLBW ymm1, ymm2,  B     V/V       AVX2     bytes from ymm2 and       \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 61 /r                          Interleave low-order      \n   VPUNPCKLWD ymm1, ymm2,  B     V/V       AVX2     words from ymm2 and       \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 62 /r                          Interleave low-order      \n   VPUNPCKLDQ ymm1, ymm2,  B     V/V       AVX2     doublewords from ymm2 and \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 6C /r                          Interleave low-order      \n   VPUNPCKLQDQ ymm1, ymm2, B     V/V       AVX2     quadword from ymm2 and    \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   EVEX.128.66.0F.WIG 60                            Interleave low-order      \n   /r VPUNPCKLBW xmm1                      AVX512VL bytes from xmm2 and       \n   {k1}{z}, xmm2,          C     V/V       AVX512BW xmm3/m128 into xmm1       \n   xmm3/m128                                        register subject to write \n                                                    mask k1.                  \n   EVEX.128.66.0F.WIG 61                            Interleave low-order      \n   /r VPUNPCKLWD xmm1                      AVX512VL words from xmm2 and       \n   {k1}{z}, xmm2,          C     V/V       AVX512BW xmm3/m128 into xmm1       \n   xmm3/m128                                        register subject to write \n                                                    mask k1.                  \n   EVEX.128.66.0F.W0 62 /r                          Interleave low-order      \n   VPUNPCKLDQ xmm1                         AVX512VL doublewords from xmm2 and \n   {k1}{z}, xmm2,          D     V/V       AVX512F  xmm3/m128/m32bcst into    \n   xmm3/m128/m32bcst                                xmm1 register subject to  \n                                                    write mask k1.            \n   EVEX.128.66.0F.W1 6C /r                          Interleave low-order      \n   VPUNPCKLQDQ xmm1                        AVX512VL quadword from zmm2 and    \n   {k1}{z}, xmm2,          D     V/V       AVX512F  zmm3/m512/m64bcst into    \n   xmm3/m128/m64bcst                                zmm1 register subject to  \n                                                    write mask k1.            \n   EVEX.256.66.0F.WIG 60                            Interleave low-order      \n   /r VPUNPCKLBW ymm1                      AVX512VL bytes from ymm2 and       \n   {k1}{z}, ymm2,          C     V/V       AVX512BW ymm3/m256 into ymm1       \n   ymm3/m256                                        register subject to write \n                                                    mask k1.                  \n   EVEX.256.66.0F.WIG 61                            Interleave low-order      \n   /r VPUNPCKLWD ymm1                      AVX512VL words from ymm2 and       \n   {k1}{z}, ymm2,          C     V/V       AVX512BW ymm3/m256 into ymm1       \n   ymm3/m256                                        register subject to write \n                                                    mask k1.                  \n   EVEX.256.66.0F.W0 62 /r                          Interleave low-order      \n   VPUNPCKLDQ ymm1                         AVX512VL doublewords from ymm2 and \n   {k1}{z}, ymm2,          D     V/V       AVX512F  ymm3/m256/m32bcst into    \n   ymm3/m256/m32bcst                                ymm1 register subject to  \n                                                    write mask k1.            \n   EVEX.256.66.0F.W1 6C /r                          Interleave low-order      \n   VPUNPCKLQDQ ymm1                        AVX512VL quadword from ymm2 and    \n   {k1}{z}, ymm2,          D     V/V       AVX512F  ymm3/m256/m64bcst into    \n   ymm3/m256/m64bcst                                ymm1 register subject to  \n                                                    write mask k1.            \n   EVEX.512.66.0F.WIG 60/r                          Interleave low-order      \n   VPUNPCKLBW zmm1                                  bytes from zmm2 and       \n   {k1}{z}, zmm2,          C     V/V       AVX512BW zmm3/m512 into zmm1       \n   zmm3/m512                                        register subject to write \n                                                    mask k1.                  \n   EVEX.512.66.0F.WIG 61/r                          Interleave low-order      \n   VPUNPCKLWD zmm1                                  words from zmm2 and       \n   {k1}{z}, zmm2,          C     V/V       AVX512BW zmm3/m512 into zmm1       \n   zmm3/m512                                        register subject to write \n                                                    mask k1.                  \n   EVEX.512.66.0F.W0 62 /r                          Interleave low-order      \n   VPUNPCKLDQ zmm1                                  doublewords from zmm2 and \n   {k1}{z}, zmm2,          D     V/V       AVX512F  zmm3/m512/m32bcst into    \n   zmm3/m512/m32bcst                                zmm1 register subject to  \n                                                    write mask k1.            \n   EVEX.512.66.0F.W1 6C /r                          Interleave low-order      \n   VPUNPCKLQDQ zmm1                                 quadword from zmm2 and    \n   {k1}{z}, zmm2,          D     V/V       AVX512F  zmm3/m512/m64bcst into    \n   zmm3/m512/m64bcst                                zmm1 register subject to  \n                                                    write mask k1.            \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Unpacks and interleaves the low-order data elements (bytes, words,\n   doublewords, and quadwords) of the destination operand (first operand) and\n   source operand (second operand) into the destination operand. (Figure 4-22\n   shows the unpack operation for bytes in 64-bit operands.). The high-order\n   data elements are ignored.\n\n   SRC Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 X7 X6 X5 X4 X3 X2 X1 X0 DEST DEST Y3 X3 Y2 X2\n   Y1 X1 Y0 X0 Figure 4-22. PUNPCKLBW Instruction Operation Using 64-bit\n   Operands\n\n   255 ^31 0 255 31 0\n\n   SRC Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 X7 X6 X5 X4 X3 X2 X1 X0 255 0 DEST Y5 X5 Y4 X4\n   Y1 X1 Y0 X0 Figure 4-23. 256-bit VPUNPCKLDQ Instruction Operation\n\n   When the source data comes from a 128-bit memory operand, an\n   implementation may fetch only the appropriate 64 bits; however, alignment\n   to a 16-byte boundary and normal segment checking will still be enforced.\n\n   The (V)PUNPCKLBW instruction interleaves the low-order bytes of the source\n   and destination operands, the (V)PUNPCKLWD instruction interleaves the\n   low-order words of the source and destination operands, the (V)PUNPCKLDQ\n   instruction interleaves the low-order doubleword (or doublewords) of the\n   source and destination operands, and the (V)PUNPCKLQDQ instruction\n   interleaves the low-order quadwords of the source and destination\n   operands.\n\n   These instructions can be used to convert bytes to words, words to\n   doublewords, doublewords to quadwords, and quadwords to double quadwords,\n   respectively, by placing all 0s in the source operand. Here, if the source\n   operand contains all 0s, the result (stored in the destination operand)\n   contains zero extensions of the high-order data elements from the original\n   value in the destination operand. For example, with the (V)PUNPCKLBW\n   instruction the high-order bytes are zero extended (that is, unpacked into\n   unsigned word integers), and with the (V)PUNPCKLWD instruction, the\n   high-order words are zero extended (unpacked into unsigned doubleword\n   integers).\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE versions 64-bit operand: The source operand can be an MMX\n   technology register or a 32-bit memory location. The destination operand\n   is an MMX technology register.\n\n   128-bit Legacy SSE versions: The second source operand is an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded versions: The second source operand is an XMM register or\n   a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand is an YMM register or\n   an 256-bit memory location. The first source operand and destination\n   operands are YMM registers. Bits (MAXVL-1:256) of the corresponding ZMM\n   register are zeroed.\n\n   EVEX encoded VPUNPCKLDQ/QDQ: The second source operand is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32/64-bit memory location. The first source\n\n   operand and destination operands are ZMM/YMM/XMM registers. The\n   destination is conditionally updated with writemask k1.\n\n   EVEX encoded VPUNPCKLWD/BW: The second source operand is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location. The first source operand and\n   destination operands are ZMM/YMM/XMM registers. The destination is\n   conditionally updated with writemask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpsrlvw:vpsrlvd:vpsrlvq", "           VPSRLVW/VPSRLVD/VPSRLVQ \u2014 Variable Bit Shift Right Logical\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Shift doublewords in xmm2  \n   VEX.128.66.0F38.W0 45                           right by amount specified  \n   /r VPSRLVD xmm1, xmm2, A     V/V       AVX2     in the corresponding       \n   xmm3/m128                                       element of xmm3/m128 while \n                                                   shifting in 0s.            \n                                                   Shift quadwords in xmm2    \n   VEX.128.66.0F38.W1 45                           right by amount specified  \n   /r VPSRLVQ xmm1, xmm2, A     V/V       AVX2     in the corresponding       \n   xmm3/m128                                       element of xmm3/m128 while \n                                                   shifting in 0s.            \n                                                   Shift doublewords in ymm2  \n   VEX.256.66.0F38.W0 45                           right by amount specified  \n   /r VPSRLVD ymm1, ymm2, A     V/V       AVX2     in the corresponding       \n   ymm3/m256                                       element of ymm3/m256 while \n                                                   shifting in 0s.            \n                                                   Shift quadwords in ymm2    \n   VEX.256.66.0F38.W1 45                           right by amount specified  \n   /r VPSRLVQ ymm1, ymm2, A     V/V       AVX2     in the corresponding       \n   ymm3/m256                                       element of ymm3/m256 while \n                                                   shifting in 0s.            \n   EVEX.128.66.0F38.W1 10                          Shift words in xmm2 right  \n   /r VPSRLVW xmm1                        AVX512VL by amount specified in the \n   {k1}{z}, xmm2,         B     V/V       AVX512BW corresponding element of   \n   xmm3/m128                                       xmm3/m128 while shifting   \n                                                   in 0s using writemask k1.  \n   EVEX.256.66.0F38.W1 10                          Shift words in ymm2 right  \n   /r VPSRLVW ymm1                        AVX512VL by amount specified in the \n   {k1}{z}, ymm2,         B     V/V       AVX512BW corresponding element of   \n   ymm3/m256                                       ymm3/m256 while shifting   \n                                                   in 0s using writemask k1.  \n   EVEX.512.66.0F38.W1 10                          Shift words in zmm2 right  \n   /r VPSRLVW zmm1                                 by amount specified in the \n   {k1}{z}, zmm2,         B     V/V       AVX512BW corresponding element of   \n   zmm3/m512                                       zmm3/m512 while shifting   \n                                                   in 0s using writemask k1.  \n                                                   Shift doublewords in xmm2  \n   EVEX.128.66.0F38.W0 45                          right by amount specified  \n   /r VPSRLVD xmm1                        AVX512VL in the corresponding       \n   {k1}{z}, xmm2,         C     V/V       AVX512F  element of                 \n   xmm3/m128/m32bcst                               xmm3/m128/m32bcst while    \n                                                   shifting in 0s using       \n                                                   writemask k1.              \n                                                   Shift doublewords in ymm2  \n   EVEX.256.66.0F38.W0 45                          right by amount specified  \n   /r VPSRLVD ymm1                        AVX512VL in the corresponding       \n   {k1}{z}, ymm2,         C     V/V       AVX512F  element of                 \n   ymm3/m256/m32bcst                               ymm3/m256/m32bcst while    \n                                                   shifting in 0s using       \n                                                   writemask k1.              \n                                                   Shift doublewords in zmm2  \n   EVEX.512.66.0F38.W0 45                          right by amount specified  \n   /r VPSRLVD zmm1                                 in the corresponding       \n   {k1}{z}, zmm2,         C     V/V       AVX512F  element of                 \n   zmm3/m512/m32bcst                               zmm3/m512/m32bcst while    \n                                                   shifting in 0s using       \n                                                   writemask k1.              \n                                                   Shift quadwords in xmm2    \n   EVEX.128.66.0F38.W1 45                          right by amount specified  \n   /r VPSRLVQ xmm1                        AVX512VL in the corresponding       \n   {k1}{z}, xmm2,         C     V/V       AVX512F  element of                 \n   xmm3/m128/m64bcst                               xmm3/m128/m64bcst while    \n                                                   shifting in 0s using       \n                                                   writemask k1.              \n                                                   Shift quadwords in ymm2    \n   EVEX.256.66.0F38.W1 45                          right by amount specified  \n   /r VPSRLVQ ymm1                        AVX512VL in the corresponding       \n   {k1}{z}, ymm2,         C     V/V       AVX512F  element of                 \n   ymm3/m256/m64bcst                               ymm3/m256/m64bcst while    \n                                                   shifting in 0s using       \n                                                   writemask k1.              \n                                                   Shift quadwords in zmm2    \n   EVEX.512.66.0F38.W1 45                          right by amount specified  \n   /r VPSRLVQ zmm1                                 in the corresponding       \n   {k1}{z}, zmm2,         C     V/V       AVX512F  element of                 \n   zmm3/m512/m64bcst                               zmm3/m512/m64bcst while    \n                                                   shifting in 0s using       \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Shifts the bits in the individual data elements (words, doublewords or\n   quadword) in the first source operand to the right by the count value of\n   respective data elements in the second source operand. As the bits in the\n   data elements are shifted right, the empty high-order bits are cleared\n   (set to 0).\n\n   The count values are specified individually in each data element of the\n   second source operand. If the unsigned integer value specified in the\n   respective data element of the second source operand is greater than 15\n   (for word), 31 (for doublewords), or 63 (for a quadword), then the\n   destination data element are written with 0.\n\n   VEX.128 encoded version: The destination and first source operands are XMM\n   registers. The count operand can be either an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The destination and first source operands are YMM\n   registers. The count operand can be either an YMM register or a 256-bit\n   memory. Bits (MAXVL-1:256) of the corresponding ZMM register are zeroed.\n\n   EVEX encoded VPSRLVD/Q: The destination and first source operands are\n   ZMM/YMM/XMM registers. The count operand can be either a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512-bit vector\n   broadcasted from a 32/64-bit memory location. The destination is\n   conditionally updated with writemask k1.\n\n   EVEX encoded VPSRLVW: The destination and first source operands are\n   ZMM/YMM/XMM registers. The count operand can be either a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location. The destination is\n   conditionally updated with writemask k1.\n"],
	["fadd:faddp:fiadd", "                             FADD/FADDP/FIADD \u2014 Add\n\n   Opcode  Instruction  64-Bit Compat/Leg Mode Description                    \n                        Mode   \n   D8 /0   FADD m32fp   Valid  Valid           Add m32fp to ST(0) and store   \n                                               result in ST(0).               \n   DC /0   FADD m64fp   Valid  Valid           Add m64fp to ST(0) and store   \n                                               result in ST(0).               \n   D8 C0+i FADD ST(0),  Valid  Valid           Add ST(0) to ST(i) and store   \n           ST(i)                               result in ST(0).               \n   DC C0+i FADD ST(i),  Valid  Valid           Add ST(i) to ST(0) and store   \n           ST(0)                               result in ST(i).               \n           FADDP ST(i),                        Add ST(0) to ST(i), store      \n   DE C0+i ST(0)        Valid  Valid           result in ST(i), and pop the   \n                                               register stack.                \n                                               Add ST(0) to ST(1), store      \n   DE C1   FADDP        Valid  Valid           result in ST(1), and pop the   \n                                               register stack.                \n   DA /0   FIADD m32int Valid  Valid           Add m32int to ST(0) and store  \n                                               result in ST(0).               \n   DE /0   FIADD m16int Valid  Valid           Add m16int to ST(0) and store  \n                                               result in ST(0).               \n\nDescription \u00b6\n\n   Adds the destination and source operands and stores the sum in the\n   destination location. The destination operand is always an FPU register;\n   the source operand can be a register or a memory location. Source operands\n   in memory can be in single precision or double precision floating-point\n   format or in word or doubleword integer format.\n\n   The no-operand version of the instruction adds the contents of the ST(0)\n   register to the ST(1) register. The one-operand version adds the contents\n   of a memory location (either a floating-point or an integer value) to the\n   contents of the ST(0) register. The two-operand version, adds the contents\n   of the ST(0) register to the ST(i) register or vice versa. The value in\n   ST(0) can be doubled by coding:\n\n   FADD ST(0), ST(0);\n\n   The FADDP instructions perform the additional operation of popping the FPU\n   register stack after storing the result. To pop the register stack, the\n   processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1. (The no-operand version of the floating-point add\n   instructions always results in the register stack being popped. In some\n   assemblers, the mnemonic for this instruction is FADD rather than FADDP.)\n\n   The FIADD instructions convert an integer source operand to double\n   extended-precision floating-point format before performing the addition.\n\n   The table on the following page shows the results obtained when adding\n   various classes of numbers, assuming that neither overflow nor underflow\n   occurs.\n\n   When the sum of two operands with opposite signs is 0, the result is +0,\n   except for the round toward \u2212\u221e mode, in which case the result is \u22120. When\n   the source operand is an integer 0, it is treated as a +0.\n\n   When both operand are infinities of the same sign, the result is \u221e of the\n   expected sign. If both operands are infinities of opposite signs, an\n   invalid-operation exception is generated. See Table 3-18.\n\n   DEST\n                  \u2212\u221e  \u2212F         \u22120  +0  +F         +\u221e  NaN \n       \u2212\u221e         \u2212\u221e  \u2212\u221e         \u2212\u221e  \u2212\u221e  \u2212\u221e         *   NaN \n       \u2212 F or \u2212 I \u2212\u221e  \u2212F         SRC SRC \u00b1 F or \u00b1 0 +\u221e  NaN \n   SRC \u22120         \u2212\u221e  DEST       \u22120  \u00b10  DEST       +\u221e  NaN \n       +0         \u2212\u221e  DEST       \u00b10  +0  DEST       +\u221e  NaN \n       + F or + I \u2212\u221e  \u00b1 F or \u00b1 0 SRC SRC +F         +\u221e  NaN \n       +\u221e         *   +\u221e         +\u221e  +\u221e  +\u221e         +\u221e  NaN \n       NaN        NaN NaN        NaN NaN NaN        NaN NaN \n\n   Table 3-18. FADD/FADDP/FIADD Results\n\n     F Means finite floating-point value.\n\n     I Means integer.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["tileloadd:tileloaddt1", "                       TILELOADD/TILELOADDT1 \u2014 Load Tile\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n   VEX.128.F2.0F38.W0 4B                             Load data into tmm1 as   \n   !(11):rrr:100 TILELOADD  A     V/N.E.    AMX-TILE specified by information \n   tmm1, sibmem                                      in sibmem.               \n   VEX.128.66.0F38.W0 4B                             Load data into tmm1 as   \n   !(11):rrr:100            A     V/N.E.    AMX-TILE specified by information \n   TILELOADDT1 tmm1, sibmem                          in sibmem with hint to   \n                                                     optimize data caching.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   This instruction is required to use SIB addressing. The index register\n   serves as a stride indicator. If the SIB encoding omits an index register,\n   the value zero is assumed for the content of the index register.\n\n   This instruction loads a tile destination with rows and columns as\n   specified by the tile configuration. The \u201cT1\u201d version provides a hint to\n   the implementation that the data would be reused but does not need to be\n   resident in the nearest cache levels.\n\n   The TILECFG.start_row in the TILECFG data should be initialized to '0' in\n   order to load the entire tile and is set to zero on successful completion\n   of the TILELOADD instruction. TILELOADD is a restartable instruction and\n   the TILECFG.start_row will be non-zero when restartable events occur\n   during the instruction execution.\n\n   Only memory operands are supported and they can only be accessed using a\n   SIB addressing mode, similar to the V[P]GATHER*/V[P]SCATTER* instructions.\n\n   Any attempt to execute the TILELOADD/TILELOADDT1 instructions inside an\n   Intel TSX transaction will result in a transaction abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["xsave", "                     XSAVE \u2014 Save Processor Extended States\n\n   Opcode /            Op/En 64/32 bit    CPUID        Description            \n   Instruction               Mode Support Feature Flag \n   NP 0F AE /4 XSAVE                                   Save state components  \n   mem                 M     V/V          XSAVE        specified by EDX:EAX   \n                                                       to mem.                \n   NP REX.W + 0F AE /4                                 Save state components  \n   XSAVE64 mem         M     V/N.E.       XSAVE        specified by EDX:EAX   \n                                                       to mem.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a full or partial save of processor state components to the XSAVE\n   area located at the memory address specified by the destination operand.\n   The implicit EDX:EAX register pair specifies a 64-bit instruction mask.\n   The specific state components saved correspond to the bits set in the\n   requested-feature bitmap (RFBM), which is the logical-AND of EDX:EAX and\n   XCR0.\n\n   The format of the XSAVE area is detailed in Section 13.4, \u201cXSAVE Area,\u201d of\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n   Like FXRSTOR and FXSAVE, the memory format used for x87 state depends on a\n   REX.W prefix; see Section 13.5.1, \u201cx87 State\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1.\n\n   Section 13.7, \u201cOperation of XSAVE,\u201d of Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1 provides a detailed description of\n   the operation of the XSAVE instruction. The following items provide a\n   high-level outline:\n\n     * XSAVE saves state component i if and only if RFBM[i] = 1.^1\n     * XSAVE does not modify bytes 511:464 of the legacy region of the XSAVE\n       area (see Section 13.4.1, \u201cLegacy Region of an XSAVE Area\u201d of Intel^\u00ae\n       64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1).\n     * XSAVE reads the XSTATE_BV field of the XSAVE header (see Section\n       13.4.2, \u201cXSAVE Header\u201d of Intel^\u00ae 64 and IA-32 Architectures Software\n       Developer\u2019s Manual, Volume 1) and writes a modified value back to\n       memory as follows. If RFBM[i] = 1, XSAVE writes XSTATE_BV[i] with the\n       value of XINUSE[i]. (XINUSE is a bitmap by which the processor tracks\n       the status of various state components. See Section 13.6, \u201cProcessor\n       Tracking of XSAVEManaged State\u201d of Intel^\u00ae 64 and IA-32 Architectures\n       Software Developer\u2019s Manual, Volume 1.) If RFBM[i] = 0, XSAVE writes\n       XSTATE_BV[i] with the value that it read from memory (it does not\n       modify the bit). XSAVE does not write to any part of the XSAVE header\n       other than the XSTATE_BV field.\n     * XSAVE always uses the standard format of the extended region of the\n       XSAVE area (see Section 13.4.3, \u201cExtended Region of an XSAVE Area\u201d of\n       Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n       1).\n\n     1. An exception is made for MXCSR and MXCSR_MASK, which belong to state\n     component 1 \u2014 SSE. XSAVE saves these values to memory if either RFBM[1]\n     or RFBM[2] is 1.\n\n   Use of a destination operand not aligned to 64-byte boundary (in either\n   64-bit or 32-bit modes) results in a general-protection (#GP) exception.\n   In 64-bit mode, the upper 32 bits of RDX and RAX are ignored.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["intn:into:int3:int1", "               INT n/INTO/INT3/INT1 \u2014 Call to Interrupt Procedure\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n   CC     INT3        ZO    Valid       Valid           Generate breakpoint   \n                                                        trap.                 \n                                                        Generate software     \n   CD ib  INT imm8    I     Valid       Valid           interrupt with vector \n                                                        specified by          \n                                                        immediate byte.       \n                                                        Generate overflow     \n   CE     INTO        ZO    Invalid     Valid           trap if overflow flag \n                                                        is 1.                 \n   F1     INT1        ZO    Valid       Valid           Generate debug trap.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n   I     imm8      N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The INT n instruction generates a call to the interrupt or exception\n   handler specified with the destination operand (see the section titled\n   \u201cInterrupts and Exceptions\u201d in Chapter 6 of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1). The destination\n   operand specifies a vector from 0 to 255, encoded as an 8-bit unsigned\n   intermediate value. Each vector provides an index to a gate descriptor in\n   the IDT. The first 32 vectors are reserved by Intel for system use. Some\n   of these vectors are used for internally generated exceptions.\n\n   The INT n instruction is the general mnemonic for executing a\n   software-generated call to an interrupt handler. The INTO instruction is a\n   special mnemonic for calling overflow exception (#OF), exception 4. The\n   overflow interrupt checks the OF flag in the EFLAGS register and calls the\n   overflow interrupt handler if the OF flag is set to 1. (The INTO\n   instruction cannot be used in 64-bit mode.)\n\n   The INT3 instruction uses a one-byte opcode (CC) and is intended for\n   calling the debug exception handler with a breakpoint exception (#BP).\n   (This one-byte form is useful because it can replace the first byte of any\n   instruction at which a breakpoint is desired, including other one-byte\n   instructions, without overwriting other instructions.)\n\n   The INT1 instruction also uses a one-byte opcode (F1) and generates a\n   debug exception (#DB) without setting any bits in DR6.^1 Hardware vendors\n   may use the INT1 instruction for hardware debug. For that reason, Intel\n   recommends software vendors instead use the INT3 instruction for software\n   breakpoints.\n\n     1. The mnemonic ICEBP has also been used for the instruction with opcode\n     F1.\n\n   An interrupt generated by the INTO, INT3, or INT1 instruction differs from\n   one generated by INT n in the following ways:\n\n     * The normal IOPL checks do not occur in virtual-8086 mode. The\n       interrupt is taken (without fault) with any IOPL value.\n     * The interrupt redirection enabled by the virtual-8086 mode extensions\n       (VME) does not occur. The interrupt is always handled by a\n       protected-mode handler.\n\n   (These features do not pertain to CD03, the \u201cnormal\u201d 2-byte opcode for INT\n   3. Intel and Microsoft assemblers will not generate the CD03 opcode from\n   any mnemonic, but this opcode can be created by direct numeric code\n   definition or by self-modifying code.)\n\n   The action of the INT n instruction (including the INTO, INT3, and INT1\n   instructions) is similar to that of a far call made with the CALL\n   instruction. The primary difference is that with the INT n instruction,\n   the EFLAGS register is pushed onto the stack before the return address.\n   (The return address is a far address consisting of the current values of\n   the CS and EIP registers.) Returns from interrupt procedures are handled\n   with the IRET instruction, which pops the EFLAGS information and return\n   address from the stack.\n\n   Each of the INT n, INTO, and INT3 instructions generates a\n   general-protection exception (#GP) if the CPL is greater than the DPL\n   value in the selected gate descriptor in the IDT. In contrast, the INT1\n   instruction can deliver a #DB\n\n   even if the CPL is greater than the DPL of descriptor 1 in the IDT. (This\n   behavior supports the use of INT1 by hardware vendors performing hardware\n   debug.)\n\n   The vector specifies an interrupt descriptor in the interrupt descriptor\n   table (IDT); that is, it provides index into the IDT. The selected\n   interrupt descriptor in turn contains a pointer to an interrupt or\n   exception handler procedure. In protected mode, the IDT contains an array\n   of 8-byte descriptors, each of which is an interrupt gate, trap gate, or\n   task gate. In real-address mode, the IDT is an array of 4-byte far\n   pointers (2-byte code segment selector and a 2-byte instruction pointer),\n   each of which point directly to a procedure in the selected segment. (Note\n   that in real-address mode, the IDT is called the interrupt vector table,\n   and its pointers are called interrupt vectors.)\n\n   The following decision table indicates which action in the lower portion\n   of the table is taken given the conditions in the upper portion of the\n   table. Each Y in the lower section of the decision table represents a\n   procedure defined in the \u201cOperation\u201d section for this instruction (except\n   #GP).\n\nPE                               0 1    1    1         1         1         1         1         \nVM                               \u2013 \u2013    \u2013    \u2013         \u2013         0         1         1         \nIOPL                             \u2013 \u2013    \u2013    \u2013         \u2013         \u2013         <3        =3        \nDPL/CPL RELATIONSHIP             \u2013 DPL< \u2013    DPL> CPL  DPL= CPL  DPL< CPL  \u2013         \u2013         \n                                   CPL                 or C      & NC      \nINTERRUPT TYPE                   \u2013 S/W  \u2013    \u2013         \u2013         \u2013         \u2013         \u2013         \nGATE TYPE                        \u2013 \u2013    Task Trap or   Trap or   Trap or   Trap or   Trap or   \n                                             Interrupt Interrupt Interrupt Interrupt Interrupt \nREAL-ADDRESS-MODE                Y \nPROTECTED-MODE                     Y    Y    Y         Y         Y         Y         Y         \nTRAP-OR-INTERRUPTGATE                        Y         Y         Y         Y         Y         \nINTER-PRIVILEGE-LEVELINTERRUPT                                   Y         \nINTRA-PRIVILEGE-LEVELINTERRUPT                         Y         \nINTERRUPT-FROM-VIRTUAL-8086-MODE                                                     Y         \nTASK-GATE                               Y    \n#GP                                Y         Y                             Y         \n\n   Table 3-52. Decision Table\n\n     \u2212 Don't Care.\n\n     Y Yes, action taken.\n\n     Blank Action not taken.\n\n     S/W Applies to INT n, INT3, and INTO, but not to INT1.\n\n   When the processor is executing in virtual-8086 mode, the IOPL determines\n   the action of the INT n instruction. If the IOPL is less than 3, the\n   processor generates a #GP(selector) exception; if the IOPL is 3, the\n   processor executes a protected mode interrupt to privilege level 0. The\n   interrupt gate's DPL must be set to 3 and the target CPL of the interrupt\n   handler procedure must be 0 to execute the protected mode interrupt to\n   privilege level 0.\n\n   The interrupt descriptor table register (IDTR) specifies the base linear\n   address and limit of the IDT. The initial base address value of the IDTR\n   after the processor is powered up or reset is 0.\n\n   Refer to Chapter 6, \u201cProcedure Calls, Interrupts, and Exceptions\u201d and\n   Chapter 17, \u201cControl-flow Enforcement Technology (CET)\u201d in the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for CET\n   details.\n\n   Instruction ordering. Instructions following an INT n may be fetched from\n   memory before earlier instructions complete execution, but they will not\n   execute (even speculatively) until all instructions prior to the INT n\n   have completed execution (the later instructions may execute before data\n   stored by the earlier instructions have become globally visible). This\n   applies also to the INTO, INT3, and INT1 instructions, but not to\n   executions of INTO when EFLAGS.OF = 0.\n\nFlags Affected \u00b6\n\n   The EFLAGS register is pushed onto the stack. The IF, TF, NT, AC, RF, and\n   VM flags may be cleared, depending on the mode of operation of the\n   processor when the INT instruction is executed (see the \u201cOperation\u201d\n   section). If the interrupt uses a task gate, any flags may be set or\n   cleared, controlled by the EFLAGS image in the new task\u2019s TSS.\n"],
	["psrldq", "                  PSRLDQ \u2014 Shift Double Quadword Right Logical\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Flag Description\n                                  Support   \n   66 0F 73 /3 ib PSRLDQ                                 Shift xmm1 right by  \n   xmm1, imm8               A     V/V       SSE2         imm8 while shifting  \n                                                         in 0s.               \n   VEX.128.66.0F.WIG 73 /3                               Shift xmm2 right by  \n   ib VPSRLDQ xmm1, xmm2,   B     V/V       AVX          imm8 bytes while     \n   imm8                                                  shifting in 0s.      \n   VEX.256.66.0F.WIG 73 /3                               Shift ymm1 right by  \n   ib VPSRLDQ ymm1, ymm2,   B     V/V       AVX2         imm8 bytes while     \n   imm8                                                  shifting in 0s.      \n                                                         Shift xmm2/m128      \n   EVEX.128.66.0F.WIG 73 /3                 AVX512VL     right by imm8 bytes  \n   ib VPSRLDQ xmm1,         C     V/V       AVX512BW     while shifting in 0s \n   xmm2/m128, imm8                                       and store result in  \n                                                         xmm1.                \n                                                         Shift ymm2/m256      \n   EVEX.256.66.0F.WIG 73 /3                 AVX512VL     right by imm8 bytes  \n   ib VPSRLDQ ymm1,         C     V/V       AVX512BW     while shifting in 0s \n   ymm2/m256, imm8                                       and store result in  \n                                                         ymm1.                \n                                                         Shift zmm2/m512      \n   EVEX.512.66.0F.WIG 73 /3                              right by imm8 bytes  \n   ib VPSRLDQ zmm1,         C     V/V       AVX512BW     while shifting in 0s \n   zmm2/m512, imm8                                       and store result in  \n                                                         zmm1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (r, w) imm8          N/A       N/A       \n   B     N/A        VEX.vvvv (w)     ModRM:r/m (r) imm8      N/A       \n   C     Full Mem   EVEX.vvvv (w)    ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Shifts the destination operand (first operand) to the right by the number\n   of bytes specified in the count operand (second operand). The empty\n   high-order bytes are cleared (set to all 0s). If the value specified by\n   the count operand is greater than 15, the destination operand is set to\n   all 0s. The count operand is an 8-bit immediate.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The source and destination operands are the\n   same. Bits (MAXVL-1:128) of the corresponding YMM destination register\n   remain unchanged.\n\n   VEX.128 encoded version: The source and destination operands are XMM\n   registers. Bits (MAXVL-1:128) of the destination YMM register are zeroed.\n\n   VEX.256 encoded version: The source operand is a YMM register. The\n   destination operand is a YMM register. The count operand applies to both\n   the low and high 128-bit lanes.\n\n   VEX.256 encoded version: The source operand is YMM register. The\n   destination operand is an YMM register. Bits (MAXVL-1:256) of the\n   corresponding ZMM register are zeroed. The count operand applies to both\n   the low and high 128-bit lanes.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register or a\n   512/256/128-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register. The count operand applies to each 128-bit lanes.\n\n   Note: VEX.vvvv/EVEX.vvvv encodes the destination register.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtusi2sh", "       VCVTUSI2SH \u2014 Convert Unsigned Doubleword Integer to an FP16 Value\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En Bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Convert an unsigned \n                                                          doubleword integer  \n                                                          from r32/m32 to an  \n   EVEX.LLIG.F3.MAP5.W0 7B /r                             FP16 value, and     \n   VCVTUSI2SH xmm1, xmm2, r32/m32   A V/V^1   AVX512-FP16 store the result in \n   {er}                                                   xmm1. Bits 127:16   \n                                                          from xmm2 are       \n                                                          copied to           \n                                                          xmm1[127:16].       \n                                                          Convert an unsigned \n                                                          quadword integer    \n                                                          from r64/m64 to an  \n   EVEX.LLIG.F3.MAP5.W1 7B /r                             FP16 value, and     \n   VCVTUSI2SH xmm1, xmm2, r64/m64   A V/N.E.  AVX512-FP16 store the result in \n   {er}                                                   xmm1. Bits 127:16   \n                                                          from xmm2 are       \n                                                          copied to           \n                                                          xmm1[127:16].       \n\n     1. Outside of 64b mode, the EVEX.W field is ignored. The instruction\n     behaves as if W=0 was used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction converts an unsigned doubleword integer (or unsigned\n   quadword integer if operand size is 64 bits) in the second source operand\n   to a FP16 value in the destination operand. The result is stored in the\n   low word of the destination operand. When conversion is inexact, the value\n   returned is rounded according to the rounding control bits in the MXCSR\n   register or embedded rounding controls.\n\n   The second source operand can be a general-purpose register or a 32/64-bit\n   memory location. The first source and destination operands are XMM\n   registers. Bits 127:16 of the XMM register destination are copied from\n   corresponding bits in the first source operand. Bits MAXVL-1:128 of the\n   destination register are zeroed.\n\n   If the result of the convert operation is overflow and MXCSR.OM=0 then a\n   SIMD exception will be raised with OE=1, PE=1.\n"],
	["psubq", "                   PSUBQ \u2014 Subtract Packed Quadword Integers\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F FB /r^1 PSUBQ     A     V/V       SSE2     Subtract quadword integer \n   mm1, mm2/m64                                     in mm1 from mm2 /m64.     \n   66 0F FB /r PSUBQ xmm1,                          Subtract packed quadword  \n   xmm2/m128               A     V/V       SSE2     integers in xmm1 from     \n                                                    xmm2 /m128.               \n   VEX.128.66.0F.WIG FB/r                           Subtract packed quadword  \n   VPSUBQ xmm1, xmm2,      B     V/V       AVX      integers in xmm3/m128     \n   xmm3/m128                                        from xmm2.                \n   VEX.256.66.0F.WIG FB /r                          Subtract packed quadword  \n   VPSUBQ ymm1, ymm2,      B     V/V       AVX2     integers in ymm3/m256     \n   ymm3/m256                                        from ymm2.                \n                                                    Subtract packed quadword  \n   EVEX.128.66.0F.W1 FB /r                 AVX512VL integers in               \n   VPSUBQ xmm1 {k1}{z},    C     V/V       AVX512F  xmm3/m128/m64bcst from    \n   xmm2, xmm3/m128/m64bcst                          xmm2 and store in xmm1    \n                                                    using writemask k1.       \n                                                    Subtract packed quadword  \n   EVEX.256.66.0F.W1 FB /r                 AVX512VL integers in               \n   VPSUBQ ymm1 {k1}{z},    C     V/V       AVX512F  ymm3/m256/m64bcst from    \n   ymm2, ymm3/m256/m64bcst                          ymm2 and store in ymm1    \n                                                    using writemask k1.       \n                                                    Subtract packed quadword  \n   EVEX.512.66.0F.W1 FB/r                           integers in               \n   VPSUBQ zmm1 {k1}{z},    C     V/V       AVX512F  zmm3/m512/m64bcst from    \n   zmm2, zmm3/m512/m64bcst                          zmm2 and store in zmm1    \n                                                    using writemask k1.       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Subtracts the second operand (source operand) from the first operand\n   (destination operand) and stores the result in the destination operand.\n   When packed quadword operands are used, a SIMD subtract is performed. When\n   a quadword result is too large to be represented in 64 bits (overflow),\n   the result is wrapped around and the low 64 bits are written to the\n   destination element (that is, the carry is ignored).\n\n   Note that the (V)PSUBQ instruction can operate on either unsigned or\n   signed (two\u2019s complement notation) integers; however, it does not set bits\n   in the EFLAGS register to indicate overflow and/or a carry. To prevent\n   undetected overflow conditions, software must control the ranges of the\n   values upon which it operates.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The source operand can be a quadword\n   integer stored in an MMX technology register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The second source operand is an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand is an XMM register or a\n   128-bit memory location. The first source operand and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded versions: The second source operand is an YMM register or\n   an 256-bit memory location. The first source operand and destination\n   operands are YMM registers. Bits (MAXVL-1:256) of the corresponding ZMM\n   register are zeroed.\n\n   EVEX encoded VPSUBQ: The second source operand is a ZMM/YMM/XMM register,\n   a 512/256/128-bit memory location or a 512/256/128-bit vector broadcasted\n   from a 32/64-bit memory location. The first source operand and destination\n   operands are ZMM/YMM/XMM registers. The destination is conditionally\n   updated with writemask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpermilpd", " VPERMILPD \u2014 Permute In-Lane of Pairs of Double Precision Floating-Point Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Permute double precision  \n   VEX.128.66.0F38.W0 0D /r                         floating-point values in  \n   VPERMILPD xmm1, xmm2,    A    V/V       AVX      xmm2 using controls from  \n   xmm3/m128                                        xmm3/m128 and store       \n                                                    result in xmm1.           \n                                                    Permute double precision  \n   VEX.256.66.0F38.W0 0D /r                         floating-point values in  \n   VPERMILPD ymm1, ymm2,    A    V/V       AVX      ymm2 using controls from  \n   ymm3/m256                                        ymm3/m256 and store       \n                                                    result in ymm1.           \n                                                    Permute double precision  \n   EVEX.128.66.0F38.W1 0D                           floating-point values in  \n   /r VPERMILPD xmm1        C    V/V       AVX512VL xmm2 using control from   \n   {k1}{z}, xmm2,                          AVX512F  xmm3/m128/m64bcst and     \n   xmm3/m128/m64bcst                                store the result in xmm1  \n                                                    using writemask k1.       \n                                                    Permute double precision  \n   EVEX.256.66.0F38.W1 0D                           floating-point values in  \n   /r VPERMILPD ymm1        C    V/V       AVX512VL ymm2 using control from   \n   {k1}{z}, ymm2,                          AVX512F  ymm3/m256/m64bcst and     \n   ymm3/m256/m64bcst                                store the result in ymm1  \n                                                    using writemask k1.       \n                                                    Permute double precision  \n   EVEX.512.66.0F38.W1 0D                           floating-point values in  \n   /r VPERMILPD zmm1        C    V/V       AVX512F  zmm2 using control from   \n   {k1}{z}, zmm2,                                   zmm3/m512/m64bcst and     \n   zmm3/m512/m64bcst                                store the result in zmm1  \n                                                    using writemask k1.       \n   VEX.128.66.0F3A.W0 05 /r                         Permute double precision  \n   ib VPERMILPD xmm1,       B    V/V       AVX      floating-point values in  \n   xmm2/m128, imm8                                  xmm2/m128 using controls  \n                                                    from imm8.                \n   VEX.256.66.0F3A.W0 05 /r                         Permute double precision  \n   ib VPERMILPD ymm1,       B    V/V       AVX      floating-point values in  \n   ymm2/m256, imm8                                  ymm2/m256 using controls  \n                                                    from imm8.                \n                                                    Permute double precision  \n   EVEX.128.66.0F3A.W1 05                           floating-point values in  \n   /r ib VPERMILPD xmm1     D    V/V       AVX512VL xmm2/m128/m64bcst using   \n   {k1}{z},                                AVX512F  controls from imm8 and    \n   xmm2/m128/m64bcst, imm8                          store the result in xmm1  \n                                                    using writemask k1.       \n                                                    Permute double precision  \n   EVEX.256.66.0F3A.W1 05                           floating-point values in  \n   /r ib VPERMILPD ymm1     D    V/V       AVX512VL ymm2/m256/m64bcst using   \n   {k1}{z},                                AVX512F  controls from imm8 and    \n   ymm2/m256/m64bcst, imm8                          store the result in ymm1  \n                                                    using writemask k1.       \n                                                    Permute double precision  \n   EVEX.512.66.0F3A.W1 05                           floating-point values in  \n   /r ib VPERMILPD zmm1     D    V/V       AVX512F  zmm2/m512/m64bcst using   \n   {k1}{z},                                         controls from imm8 and    \n   zmm2/m512/m64bcst, imm8                          store the result in zmm1  \n                                                    using writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     N/A        ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   C     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n\n  Description \u00b6\n\n   (variable control version)\n\n   Permute pairs of double precision floating-point values in the first\n   source operand (second operand), each using a 1-bit control field residing\n   in the corresponding quadword element of the second source operand (third\n   operand). Permuted results are stored in the destination operand (first\n   operand).\n\n   The control bits are located at bit 0 of each quadword element (see Figure\n   5-24). Each control determines which of the source element in an input\n   pair is selected for the destination element. Each pair of source elements\n   must lie in the same 128-bit region as the destination.\n\n   EVEX version: The second source operand (third operand) is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. Permuted results are written to\n   the destination under the writemask.\n\n   X3 X2 X1 X0 SRC1 DEST X2..X3 X2..X3 X0..X1 X0..X1 Figure 5-23. VPERMILPD\n   Operation\n\n   VEX.256 encoded version: Bits (MAXVL-1:256) of the corresponding ZMM\n   register are zeroed.\n\n   Bit 6665 1 255 194193 2 127 63 . . . ignored ignored sel sel sel Control\n   Field 4 Control Field 2 Control Field1 Figure 5-24. VPERMILPD Shuffle\n   Control\n\n   Immediate control version: Permute pairs of double precision\n   floating-point values in the first source operand (second operand), each\n   pair using a 1-bit control field in the imm8 byte. Each element in the\n   destination operand (first operand) use a separate control bit of the imm8\n   byte.\n\n   VEX version: The source operand is a YMM/XMM register or a 256/128-bit\n   memory location and the destination operand is a YMM/XMM register. Imm8\n   byte provides the lower 4/2 bit as permute control fields.\n\n   EVEX version: The source operand (second operand) is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. Permuted results are written to\n   the destination under the writemask. Imm8 byte provides the lower 8/4/2\n   bit as permute control fields.\n\n   Note: For the imm8 versions, VEX.vvvv and EVEX.vvvv are reserved and must\n   be 1111b otherwise instruction will #UD.\n"],
	["vpmaskmov", "          VPMASKMOV \u2014 Conditional SIMD Integer Packed Loads and Stores\n\n                                  64/32     CPUID                             \n   Opcode/Instruction       Op/En -bit Mode Feature Description\n                                            Flag    \n   VEX.128.66.0F38.W0 8C /r                         Conditionally load dword  \n   VPMASKMOVD xmm1, xmm2,   RVM   V/V       AVX2    values from m128 using    \n   m128                                             mask in xmm2 and store in \n                                                    xmm1.                     \n   VEX.256.66.0F38.W0 8C /r                         Conditionally load dword  \n   VPMASKMOVD ymm1, ymm2,   RVM   V/V       AVX2    values from m256 using    \n   m256                                             mask in ymm2 and store in \n                                                    ymm1.                     \n   VEX.128.66.0F38.W1 8C /r                         Conditionally load qword  \n   VPMASKMOVQ xmm1, xmm2,   RVM   V/V       AVX2    values from m128 using    \n   m128                                             mask in xmm2 and store in \n                                                    xmm1.                     \n   VEX.256.66.0F38.W1 8C /r                         Conditionally load qword  \n   VPMASKMOVQ ymm1, ymm2,   RVM   V/V       AVX2    values from m256 using    \n   m256                                             mask in ymm2 and store in \n                                                    ymm1.                     \n   VEX.128.66.0F38.W0 8E /r                         Conditionally store dword \n   VPMASKMOVD m128, xmm1,   MVR   V/V       AVX2    values from xmm2 using    \n   xmm2                                             mask in xmm1.             \n   VEX.256.66.0F38.W0 8E /r                         Conditionally store dword \n   VPMASKMOVD m256, ymm1,   MVR   V/V       AVX2    values from ymm2 using    \n   ymm2                                             mask in ymm1.             \n   VEX.128.66.0F38.W1 8E /r                         Conditionally store qword \n   VPMASKMOVQ m128, xmm1,   MVR   V/V       AVX2    values from xmm2 using    \n   xmm2                                             mask in xmm1.             \n   VEX.256.66.0F38.W1 8E /r                         Conditionally store qword \n   VPMASKMOVQ m256, ymm1,   MVR   V/V       AVX2    values from ymm2 using    \n   ymm2                                             mask in ymm1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVM   ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n   MVR   ModRM:r/m (w) VEX.vvvv (r) ModRM:reg (r) N/A       \n\nDescription \u00b6\n\n   Conditionally moves packed data elements from the second source operand\n   into the corresponding data element of the destination operand, depending\n   on the mask bits associated with each data element. The mask bits are\n   specified in the first source operand.\n\n   The mask bit for each data element is the most significant bit of that\n   element in the first source operand. If a mask is 1, the corresponding\n   data element is copied from the second source operand to the destination\n   operand. If the mask is 0, the corresponding data element is set to zero\n   in the load form of these instructions, and unmodified in the store form.\n\n   The second source operand is a memory address for the load form of these\n   instructions. The destination operand is a memory address for the store\n   form of these instructions. The other operands are either XMM registers\n   (for VEX.128 version) or YMM registers (for VEX.256 version).\n\n   Faults occur only due to mask-bit required memory accesses that caused the\n   faults. Faults will not occur due to referencing any memory location if\n   the corresponding mask bit for that memory location is 0. For example, no\n   faults will be detected if the mask bits are all zero.\n\n   Unlike previous MASKMOV instructions (MASKMOVQ and MASKMOVDQU), a\n   nontemporal hint is not applied to these instructions.\n\n   Instruction behavior on alignment check reporting with mask bits of less\n   than all 1s are the same as with mask bits of all 1s.\n\n   VMASKMOV should not be used to access memory mapped I/O as the ordering of\n   the individual loads or stores it does is implementation specific.\n\n   In cases where mask bits indicate data should not be loaded or stored\n   paging A and D bits will be set in an implementation dependent way.\n   However, A and D bits are always set for pages where data is actually\n   loaded/stored.\n\n   Note: for load forms, the first source (the mask) is encoded in VEX.vvvv;\n   the second source is encoded in rm_field, and the destination register is\n   encoded in reg_field.\n\n   Note: for store forms, the first source (the mask) is encoded in VEX.vvvv;\n   the second source register is encoded in reg_field, and the destination\n   memory location is encoded in rm_field.\n"],
	["pminub:pminuw", "              PMINUB/PMINUW \u2014 Minimum of Packed Unsigned Integers\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Compare unsigned byte     \n   NP 0F DA /r^1 PMINUB     A    V/V       SSE      integers in mm2/m64 and   \n   mm1, mm2/m64                                     mm1 and returns minimum   \n                                                    values.                   \n                                                    Compare packed unsigned   \n   66 0F DA /r PMINUB xmm1,                         byte integers in xmm1 and \n   xmm2/m128                A    V/V       SSE2     xmm2/m128 and store       \n                                                    packed minimum values in  \n                                                    xmm1.                     \n                                                    Compare packed unsigned   \n   66 0F 38 3A/r PMINUW                             word integers in          \n   xmm1, xmm2/m128          A    V/V       SSE4_1   xmm2/m128 and xmm1 and    \n                                                    store packed minimum      \n                                                    values in xmm1.           \n                                                    Compare packed unsigned   \n   VEX.128.66.0F DA /r                              byte integers in xmm2 and \n   VPMINUB xmm1, xmm2,      B    V/V       AVX      xmm3/m128 and store       \n   xmm3/m128                                        packed minimum values in  \n                                                    xmm1.                     \n                                                    Compare packed unsigned   \n   VEX.128.66.0F38 3A/r                             word integers in          \n   VPMINUW xmm1, xmm2,      B    V/V       AVX      xmm3/m128 and xmm2 and    \n   xmm3/m128                                        return packed minimum     \n                                                    values in xmm1.           \n                                                    Compare packed unsigned   \n   VEX.256.66.0F DA /r                              byte integers in ymm2 and \n   VPMINUB ymm1, ymm2,      B    V/V       AVX2     ymm3/m256 and store       \n   ymm3/m256                                        packed minimum values in  \n                                                    ymm1.                     \n                                                    Compare packed unsigned   \n   VEX.256.66.0F38 3A/r                             word integers in          \n   VPMINUW ymm1, ymm2,      B    V/V       AVX2     ymm3/m256 and ymm2 and    \n   ymm3/m256                                        return packed minimum     \n                                                    values in ymm1.           \n                                                    Compare packed unsigned   \n   EVEX.128.66.0F DA /r                    AVX512VL byte integers in xmm2 and \n   VPMINUB xmm1 {k1}{z},    C    V/V       AVX512BW xmm3/m128 and store       \n   xmm2, xmm3/m128                                  packed minimum values in  \n                                                    xmm1 under writemask k1.  \n                                                    Compare packed unsigned   \n   EVEX.256.66.0F DA /r                    AVX512VL byte integers in ymm2 and \n   VPMINUB ymm1 {k1}{z},    C    V/V       AVX512BW ymm3/m256 and store       \n   ymm2, ymm3/m256                                  packed minimum values in  \n                                                    ymm1 under writemask k1.  \n                                                    Compare packed unsigned   \n   EVEX.512.66.0F DA /r                             byte integers in zmm2 and \n   VPMINUB zmm1 {k1}{z},    C    V/V       AVX512BW zmm3/m512 and store       \n   zmm2, zmm3/m512                                  packed minimum values in  \n                                                    zmm1 under writemask k1.  \n                                                    Compare packed unsigned   \n   EVEX.128.66.0F38 3A/r                            word integers in          \n   VPMINUW xmm1{k1}{z},     C    V/V       AVX512VL xmm3/m128 and xmm2 and    \n   xmm2, xmm3/m128                         AVX512BW return packed minimum     \n                                                    values in xmm1 under      \n                                                    writemask k1.             \n                                                    Compare packed unsigned   \n   EVEX.256.66.0F38 3A/r                            word integers in          \n   VPMINUW ymm1{k1}{z},     C    V/V       AVX512VL ymm3/m256 and ymm2 and    \n   ymm2, ymm3/m256                         AVX512BW return packed minimum     \n                                                    values in ymm1 under      \n                                                    writemask k1.             \n                                                    Compare packed unsigned   \n   EVEX.512.66.0F38 3A/r                            word integers in          \n   VPMINUW zmm1{k1}{z},     C    V/V       AVX512BW zmm3/m512 and zmm2 and    \n   zmm2, zmm3/m512                                  return packed minimum     \n                                                    values in zmm1 under      \n                                                    writemask k1.             \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed unsigned byte or word integers in\n   the second source operand and the first source operand and returns the\n   minimum value for each pair of integers to the destination operand.\n\n   Legacy SSE version PMINUB: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register;\n   The second source operand is a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n"],
	["xabort", "                          XABORT \u2014 Transactional Abort\n\n   Opcode/Instruction   Op/En 64/32bit Mode CPUID        Description          \n                              Support       Feature Flag \n   C6 F8 ib XABORT imm8 A     V/V           RTM          Causes an RTM abort  \n                                                         if in RTM execution. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand2 Operand3 Operand4 \n   A     imm8      N/A      N/A      N/A      \n\nDescription \u00b6\n\n   XABORT forces an RTM abort. Following an RTM abort, the logical processor\n   resumes execution at the fallback address computed through the outermost\n   XBEGIN instruction. The EAX register is updated to reflect an XABORT\n   instruction caused the abort, and the imm8 argument will be provided in\n   bits 31:24 of EAX.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["arpl", "                  ARPL \u2014 Adjust RPL Field of Segment Selector\n\n   Opcode Instruction     Op/En 64-bit Compat/Leg Mode Description            \n                                Mode   \n                                                       Adjust RPL of r/m16 to \n   63 /r  ARPL r/m16, r16 MR    N. E.  Valid           not less than RPL of   \n                                                       r16.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Compares the RPL fields of two segment selectors. The first operand (the\n   destination operand) contains one segment selector and the second operand\n   (source operand) contains the other. (The RPL field is located in bits 0\n   and 1 of each operand.) If the RPL field of the destination operand is\n   less than the RPL field of the source operand, the ZF flag is set and the\n   RPL field of the destination operand is increased to match that of the\n   source operand. Otherwise, the ZF flag is cleared and no change is made to\n   the destination operand. (The destination operand can be a word register\n   or a memory location; the source operand must be a word register.)\n\n   The ARPL instruction is provided for use by operating-system procedures\n   (however, it can also be used by applications). It is generally used to\n   adjust the RPL of a segment selector that has been passed to the operating\n   system by an application program to match the privilege level of the\n   application program. Here the segment selector passed to the operating\n   system is placed in the destination operand and segment selector for the\n   application program\u2019s code segment is placed in the source operand. (The\n   RPL field in the source operand represents the privilege level of the\n   application program.) Execution of the ARPL instruction then ensures that\n   the RPL of the segment selector received by the operating system is no\n   lower (does not have a higher privilege) than the privilege level of the\n   application program (the segment selector for the application program\u2019s\n   code segment can be read from the stack following a procedure call).\n\n   This instruction executes as described in compatibility mode and legacy\n   mode. It is not encodable in 64-bit mode.\n\n   See \u201cChecking Caller Access Privileges\u201d in Chapter 3, \u201cProtected-Mode\n   Memory Management,\u201d of the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3A, for more information about the use of this\n   instruction.\n\nFlags Affected \u00b6\n\n   The ZF flag is set to 1 if the RPL field of the destination operand is\n   less than that of the source operand; otherwise, it is set to 0.\n"],
	["ffree", "                      FFREE \u2014 Free Floating-Point Register\n\n   Opcode   Mode Leg Mode Description                  \n   DD C0+i                Sets tag for ST(i) to empty. \n\nDescription \u00b6\n\n   Sets the tag in the FPU tag register associated with register ST(i) to\n   empty (11B). The contents of ST(i) and the FPU stack-top pointer (TOP) are\n   not affected.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C0, C1, C2, C3 undefined. \n"],
	["eincvirtchild", "                 EINCVIRTCHILD \u2014 Increment VIRTCHILDCNT in SECS\n\n                              64/32 bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                              Support   Flag    \n   EAX = 01H            IR    V/V       EAX[5]  This leaf function increments \n   ENCLV[EINCVIRTCHILD]                         the SECS VIRTCHILDCNT field.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                             RBX                   RCX            \n   IR    EINCVIRTCHILD (In) Return error Address of an enclave Address of an  \n                            code (Out)   page (In)             SECS page (In) \n\n  Description \u00b6\n\n   This instruction increments the SECS VIRTCHILDCNT field. This instruction\n   can only be executed when the current privilege level is 0.\n\n   The content of RCX is an effective address of an EPC page. The DS segment\n   is used to create a linear address. Segment override is not supported.\n\nEINCVIRTCHILD Memory Parameter Semantics \u00b6\n\n   EPCPAGE                                   SECS                             \n   Read/Write access permitted by Non        Read access permitted by Enclave \n   Enclave                                   \n\n   The instruction faults if any of the following:\n\nEINCVIRTCHILD Faulting Conditions \u00b6\n\n   A memory operand effective address is     A page fault occurs in accessing \n   outside the DS segment limit (32b mode).  memory operands.                 \n   DS segment is unusable (32b mode).        RBX does not refer to an enclave \n                                             page (REG, TCS, TRIM, SECS).     \n   A memory address is in a non-canonical    RCX does not refer to an SECS    \n   form (64b mode).                          page.                            \n                                             RBX does not refer to an enclave \n   A memory operand is not properly aligned. page associated with SECS        \n                                             referenced in RCX.               \n\n  Concurrency Restrictions \u00b6\n\n                               Base Concurrency Restrictions\n   Leaf          Parameter     Access     On Conflict   SGX_CONFLICT VM Exit  \n                                                        Qualification         \n                 Target        Shared     SGX_EPC_PAGE_ \n   EINCVIRTCHILD [DS:RBX]                 CONFLICT      \n                 SECS [DS:RCX] Concurrent \n\n   Table 38-78. Base Concurrency Restrictions of EINCVIRTCHILD\n\n                        Additional Concurrency Restrictions\n                        vs. EACCEPT,                                       \n                        EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\nLeaf          Parameter EMODPE, EMODPR,     EINIT\n                        EMODT      \n                        Access     On       Access     On       Access     On       \n                                   Conflict            Conflict            Conflict \n              Target    Concurrent          Concurrent          Concurrent \nEINCVIRTCHILD [DS:RBX]  \n              SECS      Concurrent          Concurrent          Concurrent \n              [DS:RCX]  \n\n   Table 38-79. Additional Concurrency Restrictions of EINCVIRTCHILD\n\n  Flags Affected \u00b6\n\n   ZF is set if EINCVIRTCHILD fails due to concurrent operation with another\n   SGX instruction; otherwise cleared.\n"],
	["vcvtsd2usi", " VCVTSD2USI \u2014 Convert Scalar Double Precision Floating-Point Value to Unsigned\n                               DoublewordInteger\n\n                               64/32 Bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                               Support   Flag    \n   EVEX.LLIG.F2.0F.W0 79                         Convert one double precision \n   /r VCVTSD2USI r32,    A     V/V       AVX512F floating-point value from    \n   xmm1/m64{er}                                  xmm1/m64 to one unsigned     \n                                                 doubleword integer r32.      \n                                                 Convert one double precision \n   EVEX.LLIG.F2.0F.W1 79                         floating-point value from    \n   /r VCVTSD2USI r64,    A     V/N.E.^1  AVX512F xmm1/m64 to one unsigned     \n   xmm1/m64{er}                                  quadword integer             \n                                                 zero-extended into r64.      \n\n     1. EVEX.W1 in non-64 bit is ignored; the instruction behaves as if the\n     W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts a double precision floating-point value in the source operand\n   (the second operand) to an unsigned doubleword integer in the destination\n   operand (the first operand). The source operand can be an XMM register or\n   a 64-bit memory location. The destination operand is a general-purpose\n   register. When the source operand is an XMM register, the double precision\n   floating-point value is contained in the low quadword of the register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n"],
	["ewb", "           EWB \u2014 Invalidate an EPC Page and Write out to Main Memory\n\n   Opcode/Instruction   Op/En 64/32 bit    CPUID        Description           \n                              Mode Support Feature Flag \n                                                        This leaf function    \n   EAX = 0BH ENCLS[EWB] IR    V/V          SGX1         invalidates an EPC    \n                                                        page and writes it    \n                                                        out to main memory.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                 RBX           RCX                   RDX          \n   IR    EWB (In) Error code Address of an Address of the EPC    Address of a \n                  (Out)      PAGEINFO (In) page (In)             VA slot (In) \n\n  Description \u00b6\n\n   This leaf function copies a page from the EPC to regular main memory. As\n   part of the copying process, the page is cryptographically protected. This\n   instruction can only be executed when current privilege level is 0.\n\n   The table below provides additional information on the memory parameter of\n   EPA leaf function.\n\nEWB Memory Parameter Semantics \u00b6\n\n   PAGEINFO      PAGEINFO.SRCPGE    PAGEINFO.PCMD      EPCPAGE     VASLOT     \n   Non-EPC R/W   Non-EPC R/W access Non-EPC R/W access EPC R/W     EPC R/W    \n   access                                              access      access     \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EWB successful.                                \n   SGX_PAGE_NOT_BLOCKED        If page is not marked as blocked.              \n   SGX_NOT_TRACKED             If EWB is racing with ETRACK instruction.      \n   SGX_VA_SLOT_OCCUPIED        Version array slot contained valid entry.      \n   SGX_CHILD_PRESENT           Child page present while attempting to page    \n                               out enclave.                                   \n\n   Table 38-51. EWB Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                      Base Concurrency Restrictions\n   Leaf Parameter     Access    On Conflict SGX_CONFLICT VM Exit              \n                                            Qualification                     \n        Source        Exclusive #GP         EPC_PAGE_CONFLICT_EXCEPTION       \n   EWB  [DS:RCX]      \n        VA [DS:RDX]   Shared    #GP         \n\n   Table 38-52. Base Concurrency Restrictions of EWB\n\n                  Additional Concurrency Restrictions\n                  vs. EACCEPT,                                       \n                  EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\n   Leaf Parameter EMODPE, EMODPR,     EINIT\n                  EMODT      \n                  Access     On       Access     On       Access     On       \n                             Conflict            Conflict            Conflict \n        Source    Concurrent          Concurrent          Concurrent \n   EWB  [DS:RCX]  \n        VA        Concurrent          Concurrent          Exclusive  \n        [DS:RDX]  \n\n   Table 38-53. Additional Concurrency Restrictions of EWB\n\n  Flags Affected \u00b6\n\n   ZF is set if page is not blocked, not tracked, or a child is present.\n   Otherwise cleared.\n\n   CF is set if VA slot is previously occupied, Otherwise cleared.\n"],
	["btr", "                            BTR \u2014 Bit Test and Reset\n\n   Opcode     Instruction     Op/En 64-bit Compat/Leg Description             \n                                    Mode   Mode       \n   0F B3 /r   BTR r/m16, r16  MR    Valid  Valid      Store selected bit in   \n                                                      CF flag and clear.      \n   0F B3 /r   BTR r/m32, r32  MR    Valid  Valid      Store selected bit in   \n                                                      CF flag and clear.      \n   REX.W + 0F BTR r/m64, r64  MR    Valid  N.E.       Store selected bit in   \n   B3 /r                                              CF flag and clear.      \n   0F BA /6   BTR r/m16, imm8 MI    Valid  Valid      Store selected bit in   \n   ib                                                 CF flag and clear.      \n   0F BA /6   BTR r/m32, imm8 MI    Valid  Valid      Store selected bit in   \n   ib                                                 CF flag and clear.      \n   REX.W + 0F BTR r/m64, imm8 MI    Valid  N.E.       Store selected bit in   \n   BA /6 ib                                           CF flag and clear.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8          N/A       N/A       \n\nDescription \u00b6\n\n   Selects the bit in a bit string (specified with the first operand, called\n   the bit base) at the bit-position designated by the bit offset operand\n   (second operand), stores the value of the bit in the CF flag, and clears\n   the selected bit in the bit string to 0. The bit base operand can be a\n   register or a memory location; the bit offset operand can be a register or\n   an immediate value:\n\n     * If the bit base operand specifies a register, the instruction takes\n       the modulo 16, 32, or 64 of the bit offset operand (modulo size\n       depends on the mode and register size; 64-bit operands are available\n       only in 64-bit mode). This allows any bit position to be selected.\n     * If the bit base operand specifies a memory location, the operand\n       represents the address of the byte in memory that contains the bit\n       base (bit 0 of the specified byte) of the bit string. The range of the\n       bit position that can be referenced by the offset operand depends on\n       the operand size.\n\n   See also: Bit(BitBase, BitOffset) on page 3-11.\n\n   Some assemblers support immediate bit offsets larger than 31 by using the\n   immediate bit offset field in combination with the displacement field of\n   the memory operand. See \u201cBT\u2014Bit Test\u201d in this chapter for more information\n   on this addressing mechanism.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The CF flag contains the value of the selected bit before it is cleared.\n   The ZF flag is unaffected. The OF, SF, AF, and PF flags are undefined.\n"],
	["cmps:cmpsb:cmpsw:cmpsd:cmpsq", "             CMPS/CMPSB/CMPSW/CMPSD/CMPSQ \u2014 Compare String Operands\n\n   Opcode  Instruction   Op/En 64-Bit Compat/Leg Description                  \n                               Mode   Mode       \n                                                 For legacy mode, compare     \n                                                 byte at address DS:(E)SI     \n                                                 with byte at address         \n   A6      CMPS m8, m8   ZO    Valid  Valid      ES:(E)DI; For 64-bit mode    \n                                                 compare byte at address      \n                                                 (R|E)SI to byte at address   \n                                                 (R|E)DI. The status flags    \n                                                 are set accordingly.         \n                                                 For legacy mode, compare     \n                                                 word at address DS:(E)SI     \n                                                 with word at address         \n   A7      CMPS m16, m16 ZO    Valid  Valid      ES:(E)DI; For 64-bit mode    \n                                                 compare word at address      \n                                                 (R|E)SI with word at address \n                                                 (R|E)DI. The status flags    \n                                                 are set accordingly.         \n                                                 For legacy mode, compare     \n                                                 dword at address DS:(E)SI at \n                                                 dword at address ES:(E)DI;   \n   A7      CMPS m32, m32 ZO    Valid  Valid      For 64-bit mode compare      \n                                                 dword at address (R|E)SI at  \n                                                 dword at address (R|E)DI.    \n                                                 The status flags are set     \n                                                 accordingly.                 \n                                                 Compares quadword at address \n   REX.W + CMPS m64, m64 ZO    Valid  N.E.       (R|E)SI with quadword at     \n   A7                                            address (R|E)DI and sets the \n                                                 status flags accordingly.    \n                                                 For legacy mode, compare     \n                                                 byte at address DS:(E)SI     \n                                                 with byte at address         \n   A6      CMPSB         ZO    Valid  Valid      ES:(E)DI; For 64-bit mode    \n                                                 compare byte at address      \n                                                 (R|E)SI with byte at address \n                                                 (R|E)DI. The status flags    \n                                                 are set accordingly.         \n                                                 For legacy mode, compare     \n                                                 word at address DS:(E)SI     \n                                                 with word at address         \n   A7      CMPSW         ZO    Valid  Valid      ES:(E)DI; For 64-bit mode    \n                                                 compare word at address      \n                                                 (R|E)SI with word at address \n                                                 (R|E)DI. The status flags    \n                                                 are set accordingly.         \n                                                 For legacy mode, compare     \n                                                 dword at address DS:(E)SI    \n                                                 with dword at address        \n   A7      CMPSD         ZO    Valid  Valid      ES:(E)DI; For 64-bit mode    \n                                                 compare dword at address     \n                                                 (R|E)SI with dword at        \n                                                 address (R|E)DI. The status  \n                                                 flags are set accordingly.   \n                                                 Compares quadword at address \n   REX.W + CMPSQ         ZO    Valid  N.E.       (R|E)SI with quadword at     \n   A7                                            address (R|E)DI and sets the \n                                                 status flags accordingly.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Compares the byte, word, doubleword, or quadword specified with the first\n   source operand with the byte, word, doubleword, or quadword specified with\n   the second source operand and sets the status flags in the EFLAGS register\n   according to the results.\n\n   Both source operands are located in memory. The address of the first\n   source operand is read from DS:SI, DS:ESI or RSI (depending on the\n   address-size attribute of the instruction is 16, 32, or 64, respectively).\n   The address of the second source operand is read from ES:DI, ES:EDI or RDI\n   (again depending on the address-size attribute of the instruction is 16,\n   32, or 64). The DS segment may be overridden with a segment override\n   prefix, but the ES segment cannot be overridden.\n\n   At the assembly-code level, two forms of this instruction are allowed: the\n   \u201cexplicit-operands\u201d form and the \u201cno-operands\u201d form. The explicit-operands\n   form (specified with the CMPS mnemonic) allows the two source operands to\n   be specified explicitly. Here, the source operands should be symbols that\n   indicate the size and location of the source values. This explicit-operand\n   form is provided to allow documentation. However, note that the\n   documentation provided by this form can be misleading. That is, the source\n   operand symbols must specify the correct type (size) of the operands\n   (bytes, words, or doublewords, quadwords), but they do not have to specify\n   the correct loca-\n\n   tion. Locations of the source operands are always specified by the\n   DS:(E)SI (or RSI) and ES:(E)DI (or RDI) registers, which must be loaded\n   correctly before the compare string instruction is executed.\n\n   The no-operands form provides \u201cshort forms\u201d of the byte, word, and\n   doubleword versions of the CMPS instructions. Here also the DS:(E)SI (or\n   RSI) and ES:(E)DI (or RDI) registers are assumed by the processor to\n   specify the location of the source operands. The size of the source\n   operands is selected with the mnemonic: CMPSB (byte comparison), CMPSW\n   (word comparison), CMPSD (doubleword comparison), or CMPSQ (quadword\n   comparison using REX.W).\n\n   After the comparison, the (E/R)SI and (E/R)DI registers increment or\n   decrement automatically according to the setting of the DF flag in the\n   EFLAGS register. (If the DF flag is 0, the (E/R)SI and (E/R)DI register\n   increment; if the DF flag is 1, the registers decrement.) The registers\n   increment or decrement by 1 for byte operations, by 2 for word operations,\n   4 for doubleword operations. If operand size is 64, RSI and RDI registers\n   increment by 8 for quadword operations.\n\n   The CMPS, CMPSB, CMPSW, CMPSD, and CMPSQ instructions can be preceded by\n   the REP prefix for block comparisons. More often, however, these\n   instructions will be used in a LOOP construct that takes some action based\n   on the setting of the status flags before the next comparison is made. See\n   \u201cREP/REPE/REPZ /REPNE/REPNZ\u2014Repeat String Operation Prefix\u201d in Chapter 4\n   of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 2B, for a description of the REP prefix.\n\n   In 64-bit mode, the instruction\u2019s default address size is 64 bits, 32 bit\n   address size is supported using the prefix 67H. Use of the REX.W prefix\n   promotes doubleword operation to 64 bits (see CMPSQ). See the summary\n   chart at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   The CF, OF, SF, ZF, AF, and PF flags are set according to the temporary\n   result of the comparison.\n"],
	["xsusldtrk", "                  XSUSLDTRK \u2014 Suspend Tracking Load Addresses\n\n   Opcode/Instruction    Op/En 64/32 bit    CPUID        Description          \n                               Mode Support Feature Flag \n                                                         Specifies the start  \n   F2 0F 01 E8 XSUSLDTRK ZO    V/V          TSXLDTRK     of an Intel TSX      \n                                                         suspend read address \n                                                         tracking region.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\n  Description \u00b6\n\n   The instruction marks the start of an Intel TSX (RTM) suspend load address\n   tracking region. If the instruction is used inside a transactional region,\n   subsequent loads are not added to the read set of the transaction. If the\n   instruction is used inside a suspend load address tracking region it will\n   cause transaction abort.\n\n   If the instruction is used outside of a transactional region it behaves\n   like a NOP.\n\n   Chapter 16, \u201cProgramming with Intel\u00ae Transactional Synchronization\n   Extensions\u201a\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1 provides additional information on Intel^\u00ae\n   TSX Suspend Load Address Tracking.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["sha1msg2", "  SHA1MSG2 \u2014 Perform a Final Calculation for the Next Four SHA1 Message Dwords\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Performs the final         \n                                                   calculation for the next   \n                                                   four SHA1 message dwords   \n   NP 0F 38 CA /r SHA1MSG2 RM    V/V       SHA     using intermediate results \n   xmm1, xmm2/m128                                 from xmm1 and the previous \n                                                   message dwords from        \n                                                   xmm2/m128, storing the     \n                                                   result in xmm1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   The SHA1MSG2 instruction is one of two SHA1 message scheduling\n   instructions. The instruction performs the final calculation to derive the\n   next four SHA1 message dwords.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cvtpd2dq", "   CVTPD2DQ \u2014 Convert Packed Double Precision Floating-Point Values to Packed\n                               DoublewordIntegers\n\n                             Op / 64/32 bit CPUID                             \n   Opcode Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     double precision         \n   F2 0F E6 /r CVTPD2DQ      A    V/V       SSE2     floating-point values in \n   xmm1, xmm2/m128                                   xmm2/mem to two signed   \n                                                     doubleword integers in   \n                                                     xmm1.                    \n                                                     Convert two packed       \n                                                     double precision         \n   VEX.128.F2.0F.WIG E6 /r   A    V/V       AVX      floating-point values in \n   VCVTPD2DQ xmm1, xmm2/m128                         xmm2/mem to two signed   \n                                                     doubleword integers in   \n                                                     xmm1.                    \n                                                     Convert four packed      \n                                                     double precision         \n   VEX.256.F2.0F.WIG E6 /r   A    V/V       AVX      floating-point values in \n   VCVTPD2DQ xmm1, ymm2/m256                         ymm2/mem to four signed  \n                                                     doubleword integers in   \n                                                     xmm1.                    \n                                                     Convert two packed       \n                                                     double precision         \n   EVEX.128.F2.0F.W1 E6 /r                  AVX512VL floating-point values in \n   VCVTPD2DQ xmm1 {k1}{z},   B    V/V       AVX512F  xmm2/m128/m64bcst to two \n   xmm2/m128/m64bcst                                 signed doubleword        \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Convert four packed      \n                                                     double precision         \n   EVEX.256.F2.0F.W1 E6 /r                  AVX512VL floating-point values in \n   VCVTPD2DQ xmm1 {k1}{z},   B    V/V       AVX512F  ymm2/m256/m64bcst to     \n   ymm2/m256/m64bcst                                 four signed doubleword   \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Convert eight packed     \n                                                     double precision         \n   EVEX.512.F2.0F.W1 E6 /r                           floating-point values in \n   VCVTPD2DQ ymm1 {k1}{z},   B    V/V       AVX512F  zmm2/m512/m64bcst to     \n   zmm2/m512/m64bcst{er}                             eight signed doubleword  \n                                                     integers in ymm1 subject \n                                                     to writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts packed double precision floating-point values in the source\n   operand (second operand) to packed signed doubleword integers in the\n   destination operand (first operand).\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (2^w-1, where w\n   represents the number of bits in the destination format) is returned.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512-bit memory location, or a 512-bit vector broadcasted from a 64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1. The upper bits\n   (MAXVL-1:256/128/64) of the corresponding destination are zeroed.\n\n   VEX.256 encoded version: The source operand is a YMM register or 256- bit\n   memory location. The destination operand is an XMM register. The upper\n   bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   zeroed.\n\n   VEX.128 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a XMM register. The upper bits\n   (MAXVL-1:64) of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 128-\n   bit memory location. The destination operand is an XMM register.\n   Bits[127:64] of the destination XMM register are zeroed. However, the\n   upper bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   SR X3 X2 X1 X0 DEST 0 X3 X2 X1 X0 Figure 3-12. VCVTPD2DQ (VEX.256 encoded\n   version)\n"],
	["psraw:psrad:psraq", "             PSRAW/PSRAD/PSRAQ \u2014 Shift Packed Data Right Arithmetic\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F E1 /r^1 PSRAW mm,                          Shift words in mm right   \n   mm/m64                  A     V/V       MMX      by mm/m64 while shifting  \n                                                    in sign bits.             \n   66 0F E1 /r PSRAW xmm1,                          Shift words in xmm1 right \n   xmm2/m128               A     V/V       SSE2     by xmm2/m128 while        \n                                                    shifting in sign bits.    \n   NP 0F 71 /4 ib^1 PSRAW                           Shift words in mm right   \n   mm, imm8                B     V/V       MMX      by imm8 while shifting in \n                                                    sign bits                 \n   66 0F 71 /4 ib PSRAW                             Shift words in xmm1 right \n   xmm1, imm8              B     V/V       SSE2     by imm8 while shifting in \n                                                    sign bits                 \n   NP 0F E2 /r^1 PSRAD mm,                          Shift doublewords in mm   \n   mm/m64                  A     V/V       MMX      right by mm/m64 while     \n                                                    shifting in sign bits.    \n   66 0F E2 /r PSRAD xmm1,                          Shift doubleword in xmm1  \n   xmm2/m128               A     V/V       SSE2     right by xmm2 /m128 while \n                                                    shifting in sign bits.    \n   NP 0F 72 /4 ib^1 PSRAD                           Shift doublewords in mm   \n   mm, imm8                B     V/V       MMX      right by imm8 while       \n                                                    shifting in sign bits.    \n   66 0F 72 /4 ib PSRAD                             Shift doublewords in xmm1 \n   xmm1, imm8              B     V/V       SSE2     right by imm8 while       \n                                                    shifting in sign bits.    \n   VEX.128.66.0F.WIG E1 /r                          Shift words in xmm2 right \n   VPSRAW xmm1, xmm2,      C     V/V       AVX      by amount specified in    \n   xmm3/m128                                        xmm3/m128 while shifting  \n                                                    in sign bits.             \n   VEX.128.66.0F.WIG 71 /4                          Shift words in xmm2 right \n   ib VPSRAW xmm1, xmm2,   D     V/V       AVX      by imm8 while shifting in \n   imm8                                             sign bits.                \n   VEX.128.66.0F.WIG E2 /r                          Shift doublewords in xmm2 \n   VPSRAD xmm1, xmm2,      C     V/V       AVX      right by amount specified \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in sign bits.    \n   VEX.128.66.0F.WIG 72 /4                          Shift doublewords in xmm2 \n   ib VPSRAD xmm1, xmm2,   D     V/V       AVX      right by imm8 while       \n   imm8                                             shifting in sign bits.    \n   VEX.256.66.0F.WIG E1 /r                          Shift words in ymm2 right \n   VPSRAW ymm1, ymm2,      C     V/V       AVX2     by amount specified in    \n   xmm3/m128                                        xmm3/m128 while shifting  \n                                                    in sign bits.             \n   VEX.256.66.0F.WIG 71 /4                          Shift words in ymm2 right \n   ib VPSRAW ymm1, ymm2,   D     V/V       AVX2     by imm8 while shifting in \n   imm8                                             sign bits.                \n   VEX.256.66.0F.WIG E2 /r                          Shift doublewords in ymm2 \n   VPSRAD ymm1, ymm2,      C     V/V       AVX2     right by amount specified \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in sign bits.    \n   VEX.256.66.0F.WIG 72 /4                          Shift doublewords in ymm2 \n   ib VPSRAD ymm1, ymm2,   D     V/V       AVX2     right by imm8 while       \n   imm8                                             shifting in sign bits.    \n                                                    Shift words in xmm2 right \n   EVEX.128.66.0F.WIG E1                   AVX512VL by amount specified in    \n   /r VPSRAW xmm1 {k1}{z}, G     V/V       AVX512BW xmm3/m128 while shifting  \n   xmm2, xmm3/m128                                  in sign bits using        \n                                                    writemask k1.             \n                                                    Shift words in ymm2 right \n   EVEX.256.66.0F.WIG E1                   AVX512VL by amount specified in    \n   /r VPSRAW ymm1 {k1}{z}, G     V/V       AVX512BW xmm3/m128 while shifting  \n   ymm2, xmm3/m128                                  in sign bits using        \n                                                    writemask k1.             \n                                                    Shift words in zmm2 right \n   EVEX.512.66.0F.WIG E1                            by amount specified in    \n   /r VPSRAW zmm1 {k1}{z}, G     V/V       AVX512BW xmm3/m128 while shifting  \n   zmm2, xmm3/m128                                  in sign bits using        \n                                                    writemask k1.             \n   EVEX.128.66.0F.WIG 71                            Shift words in xmm2/m128  \n   /4 ib VPSRAW xmm1       E     V/V       AVX512VL right by imm8 while       \n   {k1}{z}, xmm2/m128,                     AVX512BW shifting in sign bits     \n   imm8                                             using writemask k1.       \n   EVEX.256.66.0F.WIG 71                            Shift words in ymm2/m256  \n   /4 ib VPSRAW ymm1       E     V/V       AVX512VL right by imm8 while       \n   {k1}{z}, ymm2/m256,                     AVX512BW shifting in sign bits     \n   imm8                                             using writemask k1.       \n   EVEX.512.66.0F.WIG 71                            Shift words in zmm2/m512  \n   /4 ib VPSRAW zmm1       E     V/V       AVX512BW right by imm8 while       \n   {k1}{z}, zmm2/m512,                              shifting in sign bits     \n   imm8                                             using writemask k1.       \n                                                    Shift doublewords in xmm2 \n   EVEX.128.66.0F.W0 E2 /r                 AVX512VL right by amount specified \n   VPSRAD xmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   xmm2, xmm3/m128                                  shifting in sign bits     \n                                                    using writemask k1.       \n                                                    Shift doublewords in ymm2 \n   EVEX.256.66.0F.W0 E2 /r                 AVX512VL right by amount specified \n   VPSRAD ymm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   ymm2, xmm3/m128                                  shifting in sign bits     \n                                                    using writemask k1.       \n                                                    Shift doublewords in zmm2 \n   EVEX.512.66.0F.W0 E2 /r                          right by amount specified \n   VPSRAD zmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   zmm2, xmm3/m128                                  shifting in sign bits     \n                                                    using writemask k1.       \n                                                    Shift doublewords in      \n   EVEX.128.66.0F.W0 72 /4                 AVX512VL xmm2/m128/m32bcst right   \n   ib VPSRAD xmm1 {k1}{z}, F     V/V       AVX512F  by imm8 while shifting in \n   xmm2/m128/m32bcst, imm8                          sign bits using writemask \n                                                    k1.                       \n                                                    Shift doublewords in      \n   EVEX.256.66.0F.W0 72 /4                 AVX512VL ymm2/m256/m32bcst right   \n   ib VPSRAD ymm1 {k1}{z}, F     V/V       AVX512F  by imm8 while shifting in \n   ymm2/m256/m32bcst, imm8                          sign bits using writemask \n                                                    k1.                       \n                                                    Shift doublewords in      \n   EVEX.512.66.0F.W0 72 /4                          zmm2/m512/m32bcst right   \n   ib VPSRAD zmm1 {k1}{z}, F     V/V       AVX512F  by imm8 while shifting in \n   zmm2/m512/m32bcst, imm8                          sign bits using writemask \n                                                    k1.                       \n                                                    Shift quadwords in xmm2   \n   EVEX.128.66.0F.W1 E2 /r                 AVX512VL right by amount specified \n   VPSRAQ xmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   xmm2, xmm3/m128                                  shifting in sign bits     \n                                                    using writemask k1.       \n                                                    Shift quadwords in ymm2   \n   EVEX.256.66.0F.W1 E2 /r                 AVX512VL right by amount specified \n   VPSRAQ ymm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   ymm2, xmm3/m128                                  shifting in sign bits     \n                                                    using writemask k1.       \n                                                    Shift quadwords in zmm2   \n   EVEX.512.66.0F.W1 E2 /r                          right by amount specified \n   VPSRAQ zmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   zmm2, xmm3/m128                                  shifting in sign bits     \n                                                    using writemask k1.       \n                                                    Shift quadwords in        \n   EVEX.128.66.0F.W1 72 /4                 AVX512VL xmm2/m128/m64bcst right   \n   ib VPSRAQ xmm1 {k1}{z}, F     V/V       AVX512F  by imm8 while shifting in \n   xmm2/m128/m64bcst, imm8                          sign bits using writemask \n                                                    k1.                       \n                                                    Shift quadwords in        \n   EVEX.256.66.0F.W1 72 /4                 AVX512VL ymm2/m256/m64bcst right   \n   ib VPSRAQ ymm1 {k1}{z}, F     V/V       AVX512F  by imm8 while shifting in \n   ymm2/m256/m64bcst, imm8                          sign bits using writemask \n                                                    k1.                       \n                                                    Shift quadwords in        \n   EVEX.512.66.0F.W1 72 /4                          zmm2/m512/m64bcst right   \n   ib VPSRAQ zmm1 {k1}{z}, F     V/V       AVX512F  by imm8 while shifting in \n   zmm2/m512/m64bcst, imm8                          sign bits using writemask \n                                                    k1.                       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:r/m (r, w) imm8          N/A           N/A       \n   C     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   D     N/A        VEX.vvvv (w)     ModRM:r/m (r) imm8          N/A       \n   E     Full Mem   EVEX.vvvv (w)    ModRM:r/m (r) imm8          N/A       \n   F     Full       EVEX.vvvv (w)    ModRM:r/m (r) imm8          N/A       \n   G     Mem128     ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Shifts the bits in the individual data elements (words, doublewords or\n   quadwords) in the destination operand (first operand) to the right by the\n   number of bits specified in the count operand (second operand). As the\n   bits in the data elements are shifted right, the empty high-order bits are\n   filled with the initial value of the sign bit of the data element. If the\n   value specified by the count operand is greater than 15 (for words), 31\n   (for doublewords), or 63 (for quadwords), each destination data element is\n   filled with the initial value of the sign bit of the element. (Figure 4-18\n   gives an example of shifting words in a 64-bit operand.)\n\n   Pre-Shift X3 X2 X1 X0 DEST Shift Right with Sign Extension Post-Shift X0\n   >> COUNT X3 >> COUNT X2 >> COUNT X1 >> COUNT DEST Figure 4-18. PSRAW and\n   PSRAD Instruction Operation Using a 64-bit Operand\n\n   Note that only the first 64-bits of a 128-bit count operand are checked to\n   compute the count. If the second source operand is a memory address, 128\n   bits are loaded.\n\n   The (V)PSRAW instruction shifts each of the words in the destination\n   operand to the right by the number of bits specified in the count operand,\n   and the (V)PSRAD instruction shifts each of the doublewords in the\n   destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions 64-bit operand: The destination operand is an MMX\n   technology register; the count operand can be either an MMX technology\n   register or an 64-bit memory location.\n\n   128-bit Legacy SSE version: The destination and first source operands are\n   XMM registers. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged. The count operand can be either an XMM register\n   or a 128-bit memory location or an 8-bit immediate. If the count operand\n   is a memory address, 128 bits are loaded but the upper 64 bits are\n   ignored.\n\n   VEX.128 encoded version: The destination and first source operands are XMM\n   registers. Bits (MAXVL-1:128) of the destination YMM register are zeroed.\n   The count operand can be either an XMM register or a 128-bit memory\n   location or an 8-bit immediate. If the count operand is a memory address,\n   128 bits are loaded but the upper 64 bits are ignored.\n\n   VEX.256 encoded version: The destination operand is a YMM register. The\n   source operand is a YMM register or a memory location. The count operand\n   can come either from an XMM register or a memory location or an 8-bit\n   immediate. Bits (MAXVL-1:256) of the corresponding ZMM register are\n   zeroed.\n\n   EVEX encoded versions: The destination operand is a ZMM register updated\n   according to the writemask. The count operand is either an 8-bit immediate\n   (the immediate count version) or an 8-bit value from an XMM register or a\n   memory location (the variable count version). For the immediate count\n   version, the source operand (the second operand) can be a ZMM register, a\n   512-bit memory location or a 512-bit vector broadcasted from a 32/64-bit\n   memory location. For the variable count version, the first source operand\n   (the second operand) is a ZMM register, the second source operand (the\n   third operand, 8-bit variable count) can be an XMM register or a memory\n   location.\n\n   Note: In VEX/EVEX encoded versions of shifts with an immediate count, vvvv\n   of VEX/EVEX encode the destination register, and VEX.B/EVEX.B + ModRM.r/m\n   encodes the source register.\n\n   Note: For shifts with an immediate count (VEX.128.66.0F 71-73 /4,\n   EVEX.128.66.0F 71-73 /4), VEX.vvvv/EVEX.vvvv encodes the destination\n   register.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["sgdt", "                 SGDT \u2014 Store Global Descriptor Table Register\n\n   Opcode^1\n\n            Instruction Op/En 64-Bit Mode Compat/Leg Mode Description      \n   0F 01 /0                   Valid       Valid           Store GDTR to m. \n\n   1. See the IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Stores the content of the global descriptor table register (GDTR) in the\n   destination operand. The destination operand specifies a memory location.\n\n   In legacy or compatibility mode, the destination operand is a 6-byte\n   memory location. If the operand-size attribute is 16 or 32 bits, the\n   16-bit limit field of the register is stored in the low 2 bytes of the\n   memory location and the 32-bit base address is stored in the high 4 bytes.\n\n   In 64-bit mode, the operand size is fixed at 8+2 bytes. The instruction\n   stores an 8-byte base and a 2-byte limit.\n\n   SGDT is useful only by operating-system software. However, it can be used\n   in application programs without causing an exception to be generated if\n   CR4.UMIP = 0. See \u201cLGDT/LIDT\u2014Load Global/Interrupt Descriptor Table\n   Register\u201d in Chapter 3, Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 2A, for information on loading the GDTR and\n   IDTR.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The 16-bit form of the SGDT is compatible with the Intel 286 processor if\n   the upper 8 bits are not referenced. The Intel 286 processor fills these\n   bits with 1s; processor generations later than the Intel 286 processor\n   fill these bits with 0s.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["lddqu", "                    LDDQU \u2014 Load Unaligned Integer 128 Bits\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n   F2 0F F0 /r LDDQU xmm1,                         Load unaligned data from   \n   mem                     RM    V/V       SSE3    mem and return double      \n                                                   quadword in xmm1.          \n   VEX.128.F2.0F.WIG F0 /r                         Load unaligned packed      \n   VLDDQU xmm1, m128       RM    V/V       AVX     integer values from mem to \n                                                   xmm1.                      \n   VEX.256.F2.0F.WIG F0 /r                         Load unaligned packed      \n   VLDDQU ymm1, m256       RM    V/V       AVX     integer values from mem to \n                                                   ymm1.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   The instruction is functionally similar to (V)MOVDQU ymm/xmm, m256/m128\n   for loading from memory. That is: 32/16 bytes of data starting at an\n   address specified by the source memory operand (second operand) are\n   fetched from memory and placed in a destination register (first operand).\n   The source operand need not be aligned on a 32/16-byte boundary. Up to\n   64/32 bytes may be loaded from memory; this is implementation dependent.\n\n   This instruction may improve performance relative to (V)MOVDQU if the\n   source operand crosses a cache line boundary. In situations that require\n   the data loaded by (V)LDDQU be modified and stored to the same location,\n   use (V)MOVDQU or (V)MOVDQA instead of (V)LDDQU. To move a double quadword\n   to or from memory locations that are known to be aligned on 16-byte\n   boundaries, use the (V)MOVDQA instruction.\n\nImplementation Notes \u00b6\n\n     * If the source is aligned to a 32/16-byte boundary, based on the\n       implementation, the 32/16 bytes may be loaded more than once. For that\n       reason, the usage of (V)LDDQU should be avoided when using uncached or\n       write-combining (WC) memory regions. For uncached or WC memory\n       regions, keep using (V)MOVDQU.\n     * This instruction is a replacement for (V)MOVDQU (load) in situations\n       where cache line splits significantly affect performance. It should\n       not be used in situations where store-load forwarding is performance\n       critical. If performance of store-load forwarding is critical to the\n       application, use (V)MOVDQA store-load pairs when data is 256/128-bit\n       aligned or (V)MOVDQU store-load pairs when data is 256/128-bit\n       unaligned.\n     * If the memory address is not aligned on 32/16-byte boundary, some\n       implementations may load up to 64/32 bytes and return 32/16 bytes in\n       the destination. Some processor implementations may issue multiple\n       loads to access the appropriate 32/16 bytes. Developers of\n       multi-threaded or multi-processor software should be aware that on\n       these processors the loads will be performed in a non-atomic way.\n     * If alignment checking is enabled (CR0.AM = 1, RFLAGS.AC = 1, and CPL =\n       3), an alignment-check exception (#AC) may or may not be generated\n       (depending on processor implementation) when the memory address is not\n       aligned on an 8-byte boundary.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b\n   otherwise instructions will #UD.\n"],
	["vcvtps2uqq", "  VCVTPS2UQQ \u2014 Convert Packed Single Precision Floating-Point Values to Packed\n                        UnsignedQuadword Integer Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     single precision         \n   EVEX.128.66.0F.W0 79 /r                  AVX512VL floating-point values    \n   VCVTPS2UQQ xmm1 {k1}{z}, A     V/V       AVX512DQ from zmm2/m64/m32bcst to \n   xmm2/m64/m32bcst                                  two packed unsigned      \n                                                     quadword values in zmm1  \n                                                     subject to writemask k1. \n                                                     Convert four packed      \n                                                     single precision         \n   EVEX.256.66.0F.W0 79 /r                  AVX512VL floating-point values    \n   VCVTPS2UQQ ymm1 {k1}{z}, A     V/V       AVX512DQ from xmm2/m128/m32bcst   \n   xmm2/m128/m32bcst                                 to four packed unsigned  \n                                                     quadword values in ymm1  \n                                                     subject to writemask k1. \n                                                     Convert eight packed     \n                                                     single precision         \n   EVEX.512.66.0F.W0 79 /r                           floating-point values    \n   VCVTPS2UQQ zmm1 {k1}{z}, A     V/V       AVX512DQ from ymm2/m256/m32bcst   \n   ymm2/m256/m32bcst{er}                             to eight packed unsigned \n                                                     quadword values in zmm1  \n                                                     subject to writemask k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts up to eight packed single precision floating-point values in the\n   source operand to unsigned quadword integers in the destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   The source operand is a YMM/XMM/XMM (low 64- bits) register or a\n   256/128/64-bit memory location. The destination operation is a ZMM/YMM/XMM\n   register conditionally updated with writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["invpcid", "                INVPCID \u2014 Invalidate Process-Context Identifier\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                          Flag    \n                                                  Invalidates entries in the  \n   66 0F 38 82 /r INVPCID                         TLBs and paging-structure   \n   r32, m128              RM    N.E./V    INVPCID caches based on             \n                                                  invalidation type in r32    \n                                                  and descriptor in m128.     \n                                                  Invalidates entries in the  \n   66 0F 38 82 /r INVPCID                         TLBs and paging-structure   \n   r64, m128              RM    V/N.E.    INVPCID caches based on             \n                                                  invalidation type in r64    \n                                                  and descriptor in m128.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Invalidates mappings in the translation lookaside buffers (TLBs) and\n   paging-structure caches based on process-context identifier (PCID). (See\n   Section 4.10, \u201cCaching Translation Information,\u201d in the Intel 64 and IA-32\n   Architecture Software Developer\u2019s Manual, Volume 3A.) Invalidation is\n   based on the INVPCID type specified in the register operand and the\n   INVPCID descriptor specified in the memory operand.\n\n   Outside 64-bit mode, the register operand is always 32 bits, regardless of\n   the value of CS.D. In 64-bit mode the register operand has 64 bits.\n\n   There are four INVPCID types currently defined:\n\n     * Individual-address invalidation: If the INVPCID type is 0, the logical\n       processor invalidates mappings\u2014except global translations\u2014for the\n       linear address and PCID specified in the INVPCID descriptor.^1 In some\n       cases, the instruction may invalidate global translations or mappings\n       for other linear addresses (or other PCIDs) as well.\n     * Single-context invalidation: If the INVPCID type is 1, the logical\n       processor invalidates all mappings\u2014except global\n       translations\u2014associated with the PCID specified in the INVPCID\n       descriptor. In some cases, the instruction may invalidate global\n       translations or mappings for other PCIDs as well.\n     * All-context invalidation, including global translations: If the\n       INVPCID type is 2, the logical processor invalidates all\n       mappings\u2014including global translations\u2014associated with any PCID.\n     * All-context invalidation: If the INVPCID type is 3, the logical\n       processor invalidates all mappings\u2014except global\n       translations\u2014associated with any PCID. In some case, the instruction\n       may invalidate global translations as well.\n\n   The INVPCID descriptor comprises 128 bits and consists of a PCID and a\n   linear address as shown in Figure 3-25. For INVPCID type 0, the processor\n   uses the full 64 bits of the linear address even outside 64-bit mode; the\n   linear address is not used for other INVPCID types.\n\n   127 6463 1211 0 Linear Address Reserved (must be zero) PCID Figure 3-25.\n   INVPCID Descriptor\n\n     1. If the paging structures map the linear address using a page larger\n     than 4 KBytes and there are multiple TLB entries for that page (see\n     Section 4.10.2.3, \u201cDetails of TLB Use,\u201d in the Intel^\u00ae 64 and IA-32\n     Architectures Software Developer\u2019s Manual, Volume 3A), the instruction\n     invalidates all of them.\n\n   If CR4.PCIDE = 0, a logical processor does not cache information for any\n   PCID other than 000H. In this case, executions with INVPCID types 0 and 1\n   are allowed only if the PCID specified in the INVPCID descriptor is 000H;\n   executions with INVPCID types 2 and 3 invalidate mappings only for PCID\n   000H. Note that CR4.PCIDE must be 0 outside IA-32e mode (see Section\n   4.10.1, \u201cProcess-Context Identifiers (PCIDs),\u201d of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3A).\n"],
	["prefetchh", "                     PREFETCHh \u2014 Prefetch Data Into Caches\n\n   Opcode   Instruction    Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n                                                   Move data from m8 closer   \n   0F 18 /1 PREFETCHT0 m8  M     Valid  Valid      to the processor using T0  \n                                                   hint.                      \n                                                   Move data from m8 closer   \n   0F 18 /2 PREFETCHT1 m8  M     Valid  Valid      to the processor using T1  \n                                                   hint.                      \n                                                   Move data from m8 closer   \n   0F 18 /3 PREFETCHT2 m8  M     Valid  Valid      to the processor using T2  \n                                                   hint.                      \n                                                   Move data from m8 closer   \n   0F 18 /0 PREFETCHNTA m8 M     Valid  Valid      to the processor using NTA \n                                                   hint.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Fetches the line of data from memory that contains the byte specified with\n   the source operand to a location in the cache hierarchy specified by a\n   locality hint:\n\n     * T0 (temporal data)\u2014prefetch data into all levels of the cache\n       hierarchy.\n     * T1 (temporal data with respect to first level cache misses)\u2014prefetch\n       data into level 2 cache and higher.\n     * T2 (temporal data with respect to second level cache misses)\u2014prefetch\n       data into level 3 cache and higher, or an implementation-specific\n       choice.\n     * NTA (non-temporal data with respect to all cache levels)\u2014prefetch data\n       into non-temporal cache structure and into a location close to the\n       processor, minimizing cache pollution.\n\n   The source operand is a byte memory location. (The locality hints are\n   encoded into the machine level instruction using bits 3 through 5 of the\n   ModR/M byte.)\n\n   If the line selected is already present in the cache hierarchy at a level\n   closer to the processor, no data movement occurs. Prefetches from\n   uncacheable or WC memory are ignored.\n\n   The PREFETCHh instruction is merely a hint and does not affect program\n   behavior. If executed, this instruction moves data closer to the processor\n   in anticipation of future use.\n\n   The implementation of prefetch locality hints is implementation-dependent,\n   and can be overloaded or ignored by a processor implementation. The amount\n   of data prefetched is also processor implementation-dependent. It will,\n   however, be a minimum of 32 bytes. Additional details of the\n   implementation-dependent locality hints are described in Section 7.4 of\n   Intel\u00ae 64 and IA-32 Architectures Optimization Reference Manual.\n\n   It should be noted that processors are free to speculatively fetch and\n   cache data from system memory regions that are assigned a memory-type that\n   permits speculative reads (that is, the WB, WC, and WT memory types). A\n   PREFETCHh instruction is considered a hint to this speculative behavior.\n   Because this speculative fetching can occur at any time and is not tied to\n   instruction execution, a PREFETCHh instruction is not ordered with respect\n   to the fence instructions (MFENCE, SFENCE, and LFENCE) or locked memory\n   references. A PREFETCHh instruction is also unordered with respect to\n   CLFLUSH and CLFLUSHOPT instructions, other PREFETCHh instructions, or any\n   other general instruction. It is ordered with respect to serializing\n   instructions such as CPUID, WRMSR, OUT, and MOV CR.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n"],
	["phsubw:phsubd", "                   PHSUBW/PHSUBD \u2014 Packed Horizontal Subtract\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n   NP 0F 38 05 /r^1 PHSUBW                           Subtract 16-bit signed   \n   mm1, mm2/m64              RM    V/V       SSSE3   integers horizontally,   \n                                                     pack to mm1.             \n   66 0F 38 05 /r PHSUBW                             Subtract 16-bit signed   \n   xmm1, xmm2/m128           RM    V/V       SSSE3   integers horizontally,   \n                                                     pack to xmm1.            \n   NP 0F 38 06 /r PHSUBD                             Subtract 32-bit signed   \n   mm1, mm2/m64              RM    V/V       SSSE3   integers horizontally,   \n                                                     pack to mm1.             \n   66 0F 38 06 /r PHSUBD                             Subtract 32-bit signed   \n   xmm1, xmm2/m128           RM    V/V       SSSE3   integers horizontally,   \n                                                     pack to xmm1.            \n   VEX.128.66.0F38.WIG 05 /r                         Subtract 16-bit signed   \n   VPHSUBW xmm1, xmm2,       RVM   V/V       AVX     integers horizontally,   \n   xmm3/m128                                         pack to xmm1.            \n   VEX.128.66.0F38.WIG 06 /r                         Subtract 32-bit signed   \n   VPHSUBD xmm1, xmm2,       RVM   V/V       AVX     integers horizontally,   \n   xmm3/m128                                         pack to xmm1.            \n   VEX.256.66.0F38.WIG 05 /r                         Subtract 16-bit signed   \n   VPHSUBW ymm1, ymm2,       RVM   V/V       AVX2    integers horizontally,   \n   ymm3/m256                                         pack to ymm1.            \n   VEX.256.66.0F38.WIG 06 /r                         Subtract 32-bit signed   \n   VPHSUBD ymm1, ymm2,       RVM   V/V       AVX2    integers horizontally,   \n   ymm3/m256                                         pack to ymm1.            \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   (V)PHSUBW performs horizontal subtraction on each adjacent pair of 16-bit\n   signed integers by subtracting the most significant word from the least\n   significant word of each pair in the source and destination operands, and\n   packs the signed 16-bit results to the destination operand (first\n   operand). (V)PHSUBD performs horizontal subtraction on each adjacent pair\n   of 32-bit signed integers by subtracting the most significant doubleword\n   from the least significant doubleword of each pair, and packs the signed\n   32-bit result to the destination operand. When the source operand is a\n   128-bit memory operand, the operand must be aligned on a 16-byte boundary\n   or a general-protection exception (#GP) will be generated.\n\n   Legacy SSE version: Both operands can be MMX registers. The second source\n   operand can be an MMX register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   In 64-bit mode, use the REX prefix to access additional registers.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: The first source and destination operands are YMM\n   registers. The second source operand can be an YMM register or a 256-bit\n   memory location.\n"],
	["vpternlogd:vpternlogq", "                 VPTERNLOGD/VPTERNLOGQ \u2014 Bitwise Ternary Logic\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Bitwise ternary logic     \n                                                    taking xmm1, xmm2, and    \n                                                    xmm3/m128/m32bcst as      \n   EVEX.128.66.0F3A.W0 25                           source operands and       \n   /r ib VPTERNLOGD xmm1                   AVX512VL writing the result to     \n   {k1}{z}, xmm2,          A     V/V       AVX512F  xmm1 under writemask k1   \n   xmm3/m128/m32bcst, imm8                          with dword granularity.   \n                                                    The immediate value       \n                                                    determines the specific   \n                                                    binary function being     \n                                                    implemented.              \n                                                    Bitwise ternary logic     \n                                                    taking ymm1, ymm2, and    \n                                                    ymm3/m256/m32bcst as      \n   EVEX.256.66.0F3A.W0 25                           source operands and       \n   /r ib VPTERNLOGD ymm1                   AVX512VL writing the result to     \n   {k1}{z}, ymm2,          A     V/V       AVX512F  ymm1 under writemask k1   \n   ymm3/m256/m32bcst, imm8                          with dword granularity.   \n                                                    The immediate value       \n                                                    determines the specific   \n                                                    binary function being     \n                                                    implemented.              \n                                                    Bitwise ternary logic     \n                                                    taking zmm1, zmm2, and    \n                                                    zmm3/m512/m32bcst as      \n   EVEX.512.66.0F3A.W0 25                           source operands and       \n   /r ib VPTERNLOGD zmm1                            writing the result to     \n   {k1}{z}, zmm2,          A     V/V       AVX512F  zmm1 under writemask k1   \n   zmm3/m512/m32bcst, imm8                          with dword granularity.   \n                                                    The immediate value       \n                                                    determines the specific   \n                                                    binary function being     \n                                                    implemented.              \n                                                    Bitwise ternary logic     \n                                                    taking xmm1, xmm2, and    \n                                                    xmm3/m128/m64bcst as      \n   EVEX.128.66.0F3A.W1 25                           source operands and       \n   /r ib VPTERNLOGQ xmm1                   AVX512VL writing the result to     \n   {k1}{z}, xmm2,          A     V/V       AVX512F  xmm1 under writemask k1   \n   xmm3/m128/m64bcst, imm8                          with qword granularity.   \n                                                    The immediate value       \n                                                    determines the specific   \n                                                    binary function being     \n                                                    implemented.              \n                                                    Bitwise ternary logic     \n                                                    taking ymm1, ymm2, and    \n                                                    ymm3/m256/m64bcst as      \n   EVEX.256.66.0F3A.W1 25                           source operands and       \n   /r ib VPTERNLOGQ ymm1                   AVX512VL writing the result to     \n   {k1}{z}, ymm2,          A     V/V       AVX512F  ymm1 under writemask k1   \n   ymm3/m256/m64bcst, imm8                          with qword granularity.   \n                                                    The immediate value       \n                                                    determines the specific   \n                                                    binary function being     \n                                                    implemented.              \n                                                    Bitwise ternary logic     \n                                                    taking zmm1, zmm2, and    \n                                                    zmm3/m512/m64bcst as      \n   EVEX.512.66.0F3A.W1 25                           source operands and       \n   /r ib VPTERNLOGQ zmm1                            writing the result to     \n   {k1}{z}, zmm2,          A     V/V       AVX512F  zmm1 under writemask k1   \n   zmm3/m512/m64bcst, imm8                          with qword granularity.   \n                                                    The immediate value       \n                                                    determines the specific   \n                                                    binary function being     \n                                                    implemented.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   VPTERNLOGD/Q takes three bit vectors of 512-bit length (in the first,\n   second, and third operand) as input data to form a set of 512 indices,\n   each index is comprised of one bit from each input vector. The imm8 byte\n   specifies a boolean logic table producing a binary value for each 3-bit\n   index value. The final 512-bit boolean result is written to the\n   destination operand (the first operand) using the writemask k1 with the\n   granularity of doubleword element or quadword element into the\n   destination.\n\n   The destination operand is a ZMM (EVEX.512)/YMM (EVEX.256)/XMM (EVEX.128)\n   register. The first source operand is a ZMM/YMM/XMM register. The second\n   source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location or a 512/256/128-bit vector broadcasted from a 32/64-bit memory\n   location The destination operand is a ZMM register conditionally updated\n   with writemask k1.\n\n   Table 5-22 shows two examples of Boolean functions specified by immediate\n   values 0xE2 and 0xE4, with the look up result listed in the fourth column\n   following the three columns containing all possible values of the 3-bit\n   index.\n\n VPTERNLOGD reg1, reg2, src3,  Bit       VPTERNLOGD reg1, reg2, src3,  Bit       \n 0xE2                          Result    0xE4                          Result    \n                               with                                    with      \n Bit(reg1) Bit(reg2) Bit(src3) Imm8=0xE2 Bit(reg1) Bit(reg2) Bit(src3) Imm8=0xE4 \n 0         0         0         0         0         0         0         0         \n 0         0         1         1         0         0         1         0         \n 0         1         0         0         0         1         0         1         \n 0         1         1         0         0         1         1         0         \n 1         0         0         0         1         0         0         0         \n 1         0         1         1         1         0         1         1         \n 1         1         0         1         1         1         0         1         \n 1         1         1         1         1         1         1         1         \n\n   Table 5-22. Examples of VPTERNLOGD/Q Imm8 Boolean Function and Input Index\n   Values\n\n   Specifying different values in imm8 will allow any arbitrary three-input\n   Boolean functions to be implemented in software using VPTERNLOGD/Q. Table\n   5-11 and Table 5-12 provide a mapping of all 256 possible imm8 values to\n   various Boolean expressions.\n"],
	["phsubsw", "               PHSUBSW \u2014 Packed Horizontal Subtract and Saturate\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n                                                     Subtract 16-bit signed   \n   NP 0F 38 07 /r^1 PHSUBSW  RM    V/V       SSSE3   integer horizontally,    \n   mm1, mm2/m64                                      pack saturated integers  \n                                                     to mm1.                  \n                                                     Subtract 16-bit signed   \n   66 0F 38 07 /r PHSUBSW    RM    V/V       SSSE3   integer horizontally,    \n   xmm1, xmm2/m128                                   pack saturated integers  \n                                                     to xmm1.                 \n   VEX.128.66.0F38.WIG 07 /r                         Subtract 16-bit signed   \n   VPHSUBSW xmm1, xmm2,      RVM   V/V       AVX     integer horizontally,    \n   xmm3/m128                                         pack saturated integers  \n                                                     to xmm1.                 \n   VEX.256.66.0F38.WIG 07 /r                         Subtract 16-bit signed   \n   VPHSUBSW ymm1, ymm2,      RVM   V/V       AVX2    integer horizontally,    \n   ymm3/m256                                         pack saturated integers  \n                                                     to ymm1.                 \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   (V)PHSUBSW performs horizontal subtraction on each adjacent pair of 16-bit\n   signed integers by subtracting the most significant word from the least\n   significant word of each pair in the source and destination operands. The\n   signed, saturated 16-bit results are packed to the destination operand\n   (first operand). When the source operand is a 128-bit memory operand, the\n   operand must be aligned on a 16-byte boundary or a general-protection\n   exception (#GP) will be generated.\n\n   Legacy SSE version: Both operands can be MMX registers. The second source\n   operand can be an MMX register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   In 64-bit mode, use the REX prefix to access additional registers.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: The first source and destination operands are YMM\n   registers. The second source operand can be an YMM register or a 256-bit\n   memory location.\n"],
	["vfmadd132ss:vfmadd213ss:vfmadd231ss", "   VFMADD132SS/VFMADD213SS/VFMADD231SS \u2014 Fused Multiply-Add of Scalar Single\n                         PrecisionFloating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Multiply scalar single    \n   VEX.LIG.66.0F38.W0 99 /r                         precision floating-point  \n   VFMADD132SS xmm1, xmm2,  A     V/V       FMA     value from xmm1 and       \n   xmm3/m32                                         xmm3/m32, add to xmm2 and \n                                                    put result in xmm1.       \n                                                    Multiply scalar single    \n   VEX.LIG.66.0F38.W0 A9 /r                         precision floating-point  \n   VFMADD213SS xmm1, xmm2,  A     V/V       FMA     value from xmm1 and xmm2, \n   xmm3/m32                                         add to xmm3/m32 and put   \n                                                    result in xmm1.           \n                                                    Multiply scalar single    \n   VEX.LIG.66.0F38.W0 B9 /r                         precision floating-point  \n   VFMADD231SS xmm1, xmm2,  A     V/V       FMA     value from xmm2 and       \n   xmm3/m32                                         xmm3/m32, add to xmm1 and \n                                                    put result in xmm1.       \n   EVEX.LLIG.66.0F38.W0 99                          Multiply scalar single    \n   /r VFMADD132SS xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm1 and       \n   xmm3/m32{er}                                     xmm3/m32, add to xmm2 and \n                                                    put result in xmm1.       \n   EVEX.LLIG.66.0F38.W0 A9                          Multiply scalar single    \n   /r VFMADD213SS xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm1 and xmm2, \n   xmm3/m32{er}                                     add to xmm3/m32 and put   \n                                                    result in xmm1.           \n   EVEX.LLIG.66.0F38.W0 B9                          Multiply scalar single    \n   /r VFMADD231SS xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm2 and       \n   xmm3/m32{er}                                     xmm3/m32, add to xmm1 and \n                                                    put result in xmm1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a SIMD multiply-add computation on single precision\n   floating-point values using three source operands and writes the\n   multiply-add results in the destination operand. The destination operand\n   is also the first source operand. The first and second operands are XMM\n   registers. The third source operand can be a XMM register or a 32-bit\n   memory location.\n\n   VFMADD132SS: Multiplies the low single precision floating-point value from\n   the first source operand to the low single precision floating-point value\n   in the third source operand, adds the infinite precision intermediate\n   result to the low single precision floating-point value in the second\n   source operand, performs rounding and stores the resulting single\n   precision floating-point value to the destination operand (first source\n   operand).\n\n   VFMADD213SS: Multiplies the low single precision floating-point value from\n   the second source operand to the low single precision floating-point value\n   in the first source operand, adds the infinite precision intermediate\n   result to the low single precision floating-point value in the third\n   source operand, performs rounding and stores the resulting single\n   precision floating-point value to the destination operand (first source\n   operand).\n\n   VFMADD231SS: Multiplies the low single precision floating-point value from\n   the second source operand to the low single precision floating-point value\n   in the third source operand, adds the infinite precision intermediate\n   result to the low single precision floating-point value in the first\n   source operand, performs rounding and stores the resulting single\n   precision floating-point value to the destination operand (first source\n   operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:32 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination is\n   updated according to the writemask.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["fstcw:fnstcw", "                   FSTCW/FNSTCW \u2014 Store x87 FPU Control Word\n\n   Opcode   Instruction     64-Bit Compat/Leg Description                     \n                            Mode   Mode       \n                                              Store FPU control word to       \n   9B D9 /7 FSTCW m2byte    Valid  Valid      m2byte after checking for       \n                                              pending unmasked floating-point \n                                              exceptions.                     \n                                              Store FPU control word to       \n   D9 /7    FNSTCW^1 m2byte Valid  Valid      m2byte without checking for     \n                                              pending unmasked floating-point \n                                              exceptions.                     \n\n     1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Stores the current value of the FPU control word at the specified\n   destination in memory. The FSTCW instruction checks for and handles\n   pending unmasked floating-point exceptions before storing the control\n   word; the FNSTCW instruction does not.\n\n   The assembler issues two instructions for the FSTCW instruction (an FWAIT\n   instruction followed by an FNSTCW instruction), and the processor executes\n   each of these instructions in separately. If an exception is generated for\n   either of these instructions, the save EIP points to the instruction that\n   caused the exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   When operating a Pentium or Intel486 processor in MS-DOS compatibility\n   mode, it is possible (under unusual circumstances) for an FNSTCW\n   instruction to be interrupted prior to being executed to handle a pending\n   FPU exception. See the section titled \u201cNo-Wait FPU Instructions Can Get\n   FPU Interrupt in Window\u201d in Appendix D of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a description of\n   these circumstances. An FNSTCW instruction cannot be interrupted in this\n   way on later Intel processors, except for the Intel Quark^TM X1000\n   processor.\n\nFPU Flags Affected \u00b6\n\n   The C0, C1, C2, and C3 flags are undefined.\n"],
	["vmxon", "                          VMXON \u2014 Enter VMX Operation\n\n   Opcode/Instruction    Op/En Description               \n   F3 0F C7 /6 VMXON m64 M     Enter VMX root operation. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) NA        NA        NA        \n\nDescription \u00b6\n\n   Puts the logical processor in VMX operation with no current VMCS, blocks\n   INIT signals, disables A20M, and clears any address-range monitoring\n   established by the MONITOR instruction.^1\n\n   The operand of this instruction is a 4KB-aligned physical address (the\n   VMXON pointer) that references the VMXON region, which the logical\n   processor may use to support VMX operation. This operand is always 64 bits\n   and is always in memory.\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["ftst", "                                  FTST \u2014 TEST\n\n   Opcode  Mode Leg Mode Description             \n   D9 E4                 Compare ST(0) with 0.0. \n\nDescription \u00b6\n\n   Compares the value in the ST(0) register with 0.0 and sets the condition\n   code flags C0, C2, and C3 in the FPU status word according to the results\n   (see table below).\n\n   Condition   C3 C2 C0 \n   ST(0) > 0.0 0  0  0  \n   ST(0) < 0.0 0  0  1  \n   ST(0) = 0.0 1  0  0  \n   Unordered   1  1  1  \n\n   Table 3-40. FTST Results\n\n   This instruction performs an \u201cunordered comparison.\u201d An unordered\n   comparison also checks the class of the numbers being compared (see\n   \u201cFXAM\u2014Examine Floating-Point\u201d in this chapter). If the value in register\n   ST(0) is a NaN or is in an undefined format, the condition flags are set\n   to \u201cunordered\u201d and the invalid operation exception is generated.\n\n   The sign of zero is ignored, so that (\u2013 0.0 := +0.0).\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0.       \n   C0, C2, C3 See Table 3-40. \n"],
	["vrangess", " VRANGESS \u2014 Range Restriction Calculation From a Pair of Scalar Float32 Values\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Calculate a RANGE         \n                                                    operation output value    \n   EVEX.LLIG.66.0F3A.W0 51                          from 2 single-precision   \n   /r VRANGESS xmm1                                 floating-point values in  \n   {k1}{z}, xmm2,          A     V/V       AVX512DQ xmm2 and xmm3/m32, store  \n   xmm3/m32{sae}, imm8                              the output to xmm1 under  \n                                                    writemask. Imm8 specifies \n                                                    the comparison and sign   \n                                                    of the range operation.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction calculates a range operation output from two input\n   single-precision floating-point values in the low dword element of the\n   first source operand (the second operand) and second source operand (the\n   third operand). The range output is written to the low dword element of\n   the destination operand (the first operand) under the writemask k1.\n\n   Bits7:4 of imm8 byte must be zero. The range operation output is performed\n   in two parts, each configured by a two-bit control field within imm8[3:0]:\n\n     * Imm8[1:0] specifies the initial comparison operation to be one of max,\n       min, max absolute value or min absolute value of the input value pair.\n       Each comparison of two input values produces an intermediate result\n       that combines with the sign selection control (imm8[3:2]) to determine\n       the final range operation output.\n     * Imm8[3:2] specifies the sign of the range operation output to be one\n       of the following: from the first input value, from the comparison\n       result, set or clear.\n\n   The encodings of imm8[1:0] and imm8[3:2] are shown in Figure 5-27.\n\n   Bits 128:31 of the destination operand are copied from the respective\n   elements of the first source operand.\n\n   When one or more of the input value is a NAN, the comparison operation may\n   signal invalid exception (IE). Details with one of more input value is NAN\n   is listed in Table 5-23. If the comparison raises an IE, the sign select\n   control (imm8[3:2]) has no effect to the range operation output; this is\n   indicated also in Table 5-23.\n\n   When both input values are zeros of opposite signs, the comparison\n   operation of MIN/MAX in the range compare operation is slightly different\n   from the conceptually similar floating-point MIN/MAX operation that are\n   found in the instructions VMAXPD/VMINPD. The details of\n   MIN/MAX/MIN_ABS/MAX_ABS operation for VRANGEPD/PS/SD/SS for magnitude-0,\n   opposite-signed input cases are listed in Table 5-24.\n\n   Additionally, non-zero, equal-magnitude with opposite-sign input values\n   perform MIN_ABS or MAX_ABS comparison operation with result listed in\n   Table 5-25.\n"],
	["vrsqrtph", "      VRSQRTPH \u2014 Compute Reciprocals of Square Roots of Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En bit     \n   Mode Flag CPUID Feature        \n   Instruction En bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En bit Mode Flag   \n   CPUID Feature Instruction En   \n   bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Compute the           \n                                                        approximate           \n                                                        reciprocals of the    \n   EVEX.128.66.MAP6.W0 4E /r                AVX512-FP16 square roots of       \n   VRSQRTPH xmm1{k1}{z},          A V/V     AVX512VL    packed FP16 values in \n   xmm2/m128/m16bcst                                    xmm2/m128/m16bcst and \n                                                        store the result in   \n                                                        xmm1 subject to       \n                                                        writemask k1.         \n                                                        Compute the           \n                                                        approximate           \n                                                        reciprocals of the    \n   EVEX.256.66.MAP6.W0 4E /r                AVX512-FP16 square roots of       \n   VRSQRTPH ymm1{k1}{z},          A V/V     AVX512VL    packed FP16 values in \n   ymm2/m256/m16bcst                                    ymm2/m256/m16bcst and \n                                                        store the result in   \n                                                        ymm1 subject to       \n                                                        writemask k1.         \n                                                        Compute the           \n                                                        approximate           \n                                                        reciprocals of the    \n   EVEX.512.66.MAP6.W0 4E /r                            square roots of       \n   VRSQRTPH zmm1{k1}{z},          A V/V     AVX512-FP16 packed FP16 values in \n   zmm2/m512/m16bcst                                    zmm2/m512/m16bcst and \n                                                        store the result in   \n                                                        zmm1 subject to       \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate\n   reciprocals square-root of 8/16/32 packed FP16 floating-point values in\n   the source operand (the second operand) and stores the packed FP16\n   floating-point results in the destination operand.\n\n   The maximum relative error for this approximation is less than 2^\u221211 +\n   2^\u221214. For special cases, see Table 5-38.\n\n   The destination elements are updated according to the writemask.\n\n   Input value  Reset Value     Comments                 \n   Any denormal Normal          Cannot generate overflow \n   X = 2^\u22122n    _2^n            \n   X<0          QNaN_Indefinite Including \u2212\u221e             \n   X = \u22120       \u2212\u221e              \n   X = +0       +\u221e              \n   X = +\u221e       +0              \n\n   Table 5-38. VRSQRTPH/VRSQRTSH Special Cases\n"],
	["haddpd", "         HADDPD \u2014 Packed Double Precision Floating-Point Horizontal Add\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Horizontal add packed      \n   66 0F 7C /r HADDPD      RM    V/V       SSE3    double precision           \n   xmm1, xmm2/m128                                 floating-point values from \n                                                   xmm2/m128 to xmm1.         \n   VEX.128.66.0F.WIG 7C /r                         Horizontal add packed      \n   VHADDPD xmm1,xmm2,      RVM   V/V       AVX     double precision           \n   xmm3/m128                                       floating-point values from \n                                                   xmm2 and xmm3/mem.         \n   VEX.256.66.0F.WIG 7C /r                         Horizontal add packed      \n   VHADDPD ymm1, ymm2,     RVM   V/V       AVX     double precision           \n   ymm3/m256                                       floating-point values from \n                                                   ymm2 and ymm3/mem.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds the double precision floating-point values in the high and low\n   quadwords of the destination operand and stores the result in the low\n   quadword of the destination operand.\n\n   Adds the double precision floating-point values in the high and low\n   quadwords of the source operand and stores the result in the high quadword\n   of the destination operand.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n\n   See Figure 3-17 for HADDPD; see Figure 3-18 for VHADDPD.\n\n   HADDPD xmm1, xmm2/m128 xmm2 [127:64] [63:0] /m128 xmm1 [127:64] [63:0]\n   Result: xmm2/m128[63:0] + xmm1[63:0] + xmm1[127:64] xmm1 xmm2/m128[127:64]\n   [127:64] [63:0] Figure 3-17. HADDPD\u2014Packed Double Precision Floating-Point\n   Horizontal Add X3 X2 X1 X0 SRC1 Y3 Y2 Y1 Y0 SRC2 DEST Y2 + Y3 X2 + X3 Y0 +\n   Y1 X0 + X1 Figure 3-18. VHADDPD Operation\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n"],
	["lsl", "                            LSL \u2014 Load Segment Limit\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   0F 03 /r   LSL r16,    RM    Valid  Valid      Load: r16 := segment limit, \n              r16/m16                             selector r16/m16.           \n   0F 03 /r   LSL r32,    RM    Valid  Valid      Load: r32 := segment limit, \n              r32/m16^1                           selector r32/m16.           \n   REX.W + 0F LSL r64,    RM    Valid  Valid      Load: r64 := segment limit, \n   03 /r      r32/m16^1                           selector r32/m16            \n\n     1. For all loads (regardless of destination sizing), only bits 16-0 are\n     used. Other bits are ignored.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Loads the unscrambled segment limit from the segment descriptor specified\n   with the second operand (source operand) into the first operand\n   (destination operand) and sets the ZF flag in the EFLAGS register. The\n   source operand (which can be a register or a memory location) contains the\n   segment selector for the segment descriptor being accessed. The\n   destination operand is a general-purpose register.\n\n   The processor performs access checks as part of the loading process. Once\n   loaded in the destination register, software can compare the segment limit\n   with the offset of a pointer.\n\n   The segment limit is a 20-bit value contained in bytes 0 and 1 and in the\n   first 4 bits of byte 6 of the segment descriptor. If the descriptor has a\n   byte granular segment limit (the granularity flag is set to 0), the\n   destination operand is loaded with a byte granular value (byte limit). If\n   the descriptor has a page granular segment limit (the granularity flag is\n   set to 1), the LSL instruction will translate the page granular limit\n   (page limit) into a byte limit before loading it into the destination\n   operand. The translation is performed by shifting the 20-bit \u201craw\u201d limit\n   left 12 bits and filling the low-order 12 bits with 1s.\n\n   When the operand size is 32 bits, the 32-bit byte limit is stored in the\n   destination operand. When the operand size is 16 bits, a valid 32-bit\n   limit is computed; however, the upper 16 bits are truncated and only the\n   low-order 16 bits are loaded into the destination operand.\n\n   This instruction performs the following checks before it loads the segment\n   limit into the destination register:\n\n     * Checks that the segment selector is not NULL.\n     * Checks that the segment selector points to a descriptor that is within\n       the limits of the GDT or LDT being accessed\n     * Checks that the descriptor type is valid for this instruction. All\n       code and data segment descriptors are valid for (can be accessed with)\n       the LSL instruction. The valid special segment and gate descriptor\n       types are given in the following table.\n     * If the segment is not a conforming code segment, the instruction\n       checks that the specified segment descriptor is visible at the CPL\n       (that is, if the CPL and the RPL of the segment selector are less than\n       or equal to the DPL of the segment selector).\n\n   If the segment descriptor cannot be accessed or is an invalid type for the\n   instruction, the ZF flag is cleared and no value is loaded in the\n   destination operand.\n\n   Type      Protected Mode                      IA-32e Mode       \n             Name                     Valid      Name              Valid      \n             Reserved Available                  Reserved Reserved            \n             16-bit TSS LDT Busy                 LDT^1 Reserved               \n             16-bit TSS 16-bit call              Reserved Reserved            \n             gate 16-bit/32-bit task  No Yes Yes Reserved Reserved No No Yes  \n   0 1 2 3 4 gate 16-bit interrupt    Yes No No  Reserved 64-bit   No No No   \n   5 6 7 8 9 gate 16-bit trap gate    No No No   TSS^1 Reserved    No No No   \n   A B C D E Reserved Available       Yes No Yes Busy 64-bit TSS^1 Yes No Yes\n   F         32-bit TSS Reserved Busy No No No   64-bit call gate  No No No\n             32-bit TSS 32-bit call   No         Reserved 64-bit   No\n             gate Reserved 32-bit                interrupt gate    \n             interrupt gate 32-bit               64-bit trap gate  \n             trap gate                \n\n   Table 3-56. Segment and Gate Descriptor Types\n\n     1. In this case, the descriptor comprises 16 bytes; bits 12:8 of the\n     upper 4 bytes must be 0.\n\nFlags Affected \u00b6\n\n   The ZF flag is set to 1 if the segment limit is loaded successfully;\n   otherwise, it is set to 0.\n"],
	["adox", "      ADOX \u2014 Unsigned Integer Addition of Two Operands With Overflow Flag\n\n                                  64/32bit     CPUID                          \n   Opcode/Instruction       Op/En Mode Support Feature Description\n                                               Flag    \n   F3 0F 38 F6 /r ADOX r32,                            Unsigned addition of   \n   r/m32                    RM    V/V          ADX     r32 with OF, r/m32 to  \n                                                       r32, writes OF.        \n   F3 REX.w 0F 38 F6 /r                                Unsigned addition of   \n   ADOX r64, r/m64          RM    V/N.E.       ADX     r64 with OF, r/m64 to  \n                                                       r64, writes OF.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs an unsigned addition of the destination operand (first operand),\n   the source operand (second operand) and the overflow-flag (OF) and stores\n   the result in the destination operand. The destination operand is a\n   general-purpose register, whereas the source operand can be a\n   general-purpose register or memory location. The state of OF represents a\n   carry from a previous addition. The instruction sets the OF flag with the\n   carry generated by the unsigned addition of the operands.\n\n   The ADOX instruction is executed in the context of multi-precision\n   addition, where we add a series of operands with a carry-chain. At the\n   beginning of a chain of additions, we execute an instruction to zero the\n   OF (e.g. XOR).\n\n   This instruction is supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode.\n\n   In 64-bit mode, the default operation size is 32 bits. Using a REX Prefix\n   in the form of REX.R permits access to additional registers (R8-15). Using\n   REX Prefix in the form of REX.W promotes operation to 64-bits.\n\n   ADOX executes normally either inside or outside a transaction region.\n\n   Note: ADOX defines the CF and OF flags differently than the ADD/ADC\n   instructions as defined in Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 2A.\n\nFlags Affected \u00b6\n\n   OF is updated based on result. CF, SF, ZF, AF, and PF flags are\n   unmodified.\n"],
	["mpsadbw", "         MPSADBW \u2014 Compute Multiple Packed Sums of Absolute Difference\n\n                                  64/32-bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                            Flag    \n                                                    Sums absolute 8-bit       \n                                                    integer difference of     \n                                                    adjacent groups of 4 byte \n   66 0F 3A 42 /r ib                                integers in xmm1 and      \n   MPSADBW xmm1, xmm2/m128, RMI   V/V       SSE4_1  xmm2/m128 and writes the  \n   imm8                                             results in xmm1. Starting \n                                                    offsets within xmm1 and   \n                                                    xmm2/m128 are determined  \n                                                    by imm8.                  \n                                                    Sums absolute 8-bit       \n                                                    integer difference of     \n                                                    adjacent groups of 4 byte \n   VEX.128.66.0F3A.WIG 42                           integers in xmm2 and      \n   /r ib VMPSADBW xmm1,     RVMI  V/V       AVX     xmm3/m128 and writes the  \n   xmm2, xmm3/m128, imm8                            results in xmm1. Starting \n                                                    offsets within xmm2 and   \n                                                    xmm3/m128 are determined  \n                                                    by imm8.                  \n                                                    Sums absolute 8-bit       \n                                                    integer difference of     \n                                                    adjacent groups of 4 byte \n   VEX.256.66.0F3A.WIG 42                           integers in xmm2 and      \n   /r ib VMPSADBW ymm1,     RVMI  V/V       AVX2    ymm3/m128 and writes the  \n   ymm2, ymm3/m256, imm8                            results in ymm1. Starting \n                                                    offsets within ymm2 and   \n                                                    xmm3/m128 are determined  \n                                                    by imm8.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   (V)MPSADBW calculates packed word results of sum-absolute-difference (SAD)\n   of unsigned bytes from two blocks of 32-bit dword elements, using two\n   select fields in the immediate byte to select the offsets of the two\n   blocks within the first source operand and the second operand. Packed SAD\n   word results are calculated within each 128-bit lane. Each SAD word result\n   is calculated between a stationary block_2 (whose offset within the second\n   source operand is selected by a two bit select control, multiplied by 32\n   bits) and a sliding block_1 at consecutive byte-granular position within\n   the first source operand. The offset of the first 32-bit block of block_1\n   is selectable using a one bit select control, multiplied by 32 bits.\n\n   128-bit Legacy SSE version: Imm8[1:0]*32 specifies the bit offset of\n   block_2 within the second source operand. Imm[2]*32 specifies the initial\n   bit offset of the block_1 within the first source operand. The first\n   source operand and destination operand are the same. The first source and\n   destination operands are XMM registers. The second source operand is\n   either an XMM register or a 128-bit memory location. Bits (MAXVL-1:128) of\n   the corresponding YMM destination register remain unchanged. Bits 7:3 of\n   the immediate byte are ignored.\n\n   VEX.128 encoded version: Imm8[1:0]*32 specifies the bit offset of block_2\n   within the second source operand. Imm[2]*32 specifies the initial bit\n   offset of the block_1 within the first source operand. The first source\n   and destination operands are XMM registers. The second source operand is\n   either an XMM register or a 128-bit memory location. Bits (127:128) of the\n   corresponding YMM register are zeroed. Bits 7:3 of the immediate byte are\n   ignored.\n\n   VEX.256 encoded version: The sum-absolute-difference (SAD) operation is\n   repeated 8 times for MPSADW between the same block_2 (fixed offset within\n   the second source operand) and a variable block_1 (offset is shifted by 8\n   bits for each SAD operation) in the first source operand. Each 16-bit\n   result of eight SAD operations between block_2 and block_1 is written to\n   the respective word in the lower 128 bits of the destination operand.\n\n   Additionally, VMPSADBW performs another eight SAD operations on block_4 of\n   the second source operand and block_3 of the first source operand.\n   (Imm8[4:3]*32 + 128) specifies the bit offset of block_4 within the second\n   source operand. (Imm[5]*32+128) specifies the initial bit offset of the\n   block_3 within the first source operand. Each 16-bit result of eight SAD\n   operations between block_4 and block_3 is written to the respective word\n   in the upper 128 bits of the destination operand.\n\n   The first source operand is a YMM register. The second source register can\n   be a YMM register or a 256-bit memory location. The destination operand is\n   a YMM register. Bits 7:6 of the immediate byte are ignored.\n\n   Note: If VMPSADBW is encoded with VEX.L= 1, an attempt to execute the\n   instruction encoded with VEX.L= 1 will cause an #UD exception.\n\n   Imm[4:3]*32+128 128 255 224 192 Src2 Abs. Diff. Imm[5]*32+128 Src1 Sum 144\n   128 255 Destination Imm[1:0]*32 0 127 96 64 Src2 Abs. Diff. Imm[2]*32 Src1\n   Sum 16 0 127 Destination Figure 4-5. 256-bit VMPSADBW Operation\n\nFlags Affected \u00b6\n\n   None.\n"],
	["ins:insb:insw:insd", "                 INS/INSB/INSW/INSD \u2014 Input from Port to String\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Description                \n                                        Mode       \n                                                   Input byte from I/O port   \n   6C     INS m8, DX  ZO    Valid       Valid      specified in DX into       \n                                                   memory location specified  \n                                                   in ES:(E)DI or RDI.^1      \n                                                   Input word from I/O port   \n   6D     INS m16, DX ZO    Valid       Valid      specified in DX into       \n                                                   memory location specified  \n                                                   in ES:(E)DI or RDI.^1      \n                                                   Input doubleword from I/O  \n   6D     INS m32, DX ZO    Valid       Valid      port specified in DX into  \n                                                   memory location specified  \n                                                   in ES:(E)DI or RDI.^1      \n                                                   Input byte from I/O port   \n   6C     INSB        ZO    Valid       Valid      specified in DX into       \n                                                   memory location specified  \n                                                   with ES:(E)DI or RDI.^1    \n                                                   Input word from I/O port   \n   6D     INSW        ZO    Valid       Valid      specified in DX into       \n                                                   memory location specified  \n                                                   in ES:(E)DI or RDI.^1      \n                                                   Input doubleword from I/O  \n   6D     INSD        ZO    Valid       Valid      port specified in DX into  \n                                                   memory location specified  \n                                                   in ES:(E)DI or RDI.^1      \n\n     1. In 64-bit mode, only 64-bit (RDI) and 32-bit (EDI) address sizes are\n     supported. In non-64-bit mode, only 32-bit (EDI) and 16-bit (DI) address\n     sizes are supported.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Copies the data from the I/O port specified with the source operand\n   (second operand) to the destination operand (first operand). The source\n   operand is an I/O port address (from 0 to 65,535) that is read from the DX\n   register. The destination operand is a memory location, the address of\n   which is read from either the ES:DI, ES:EDI or the RDI registers\n   (depending on the address-size attribute of the instruction, 16, 32 or 64,\n   respectively). (The ES segment cannot be overridden with a segment\n   override prefix.) The size of the I/O port being accessed (that is, the\n   size of the source and destination operands) is determined by the opcode\n   for an 8-bit I/O port or by the operand-size attribute of the instruction\n   for a 16- or 32-bit I/O port.\n\n   At the assembly-code level, two forms of this instruction are allowed: the\n   \u201cexplicit-operands\u201d form and the \u201cno-operands\u201d form. The explicit-operands\n   form (specified with the INS mnemonic) allows the source and destination\n   operands to be specified explicitly. Here, the source operand must be\n   \u201cDX,\u201d and the destination operand should be a symbol that indicates the\n   size of the I/O port and the destination address. This explicit-operands\n   form is provided to allow documentation; however, note that the\n   documentation provided by this form can be misleading. That is, the\n   destination operand symbol must specify the correct type (size) of the\n   operand (byte, word, or doubleword), but it does not have to specify the\n   correct location. The location is always specified by the ES:(E)DI\n   registers, which must be loaded correctly before the INS instruction is\n   executed.\n\n   The no-operands form provides \u201cshort forms\u201d of the byte, word, and\n   doubleword versions of the INS instructions. Here also DX is assumed by\n   the processor to be the source operand and ES:(E)DI is assumed to be the\n   destination operand. The size of the I/O port is specified with the choice\n   of mnemonic: INSB (byte), INSW (word), or INSD (doubleword).\n\n   After the byte, word, or doubleword is transfer from the I/O port to the\n   memory location, the DI/EDI/RDI register is incremented or decremented\n   automatically according to the setting of the DF flag in the EFLAGS\n   register. (If the DF flag is 0, the (E)DI register is incremented; if the\n   DF flag is 1, the (E)DI register is decremented.) The (E)DI register is\n   incremented or decremented by 1 for byte operations, by 2 for word\n   operations, or by 4 for doubleword operations.\n\n   The INS, INSB, INSW, and INSD instructions can be preceded by the REP\n   prefix for block input of ECX bytes, words, or doublewords. See\n   \u201cREP/REPE/REPZ /REPNE/REPNZ\u2014Repeat String Operation Prefix\u201d in Chapter 4\n   of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 2B, for a description of the REP prefix.\n\n   These instructions are only useful for accessing I/O ports located in the\n   processor\u2019s I/O address space. See Chapter 19, \u201cInput/Output,\u201d in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1,\n   for more information on accessing I/O ports in the I/O address space.\n\n   In 64-bit mode, default address size is 64 bits, 32 bit address size is\n   supported using the prefix 67H. The address of the memory destination is\n   specified by RDI or EDI. 16-bit address size is not supported in 64-bit\n   mode. The operand size is not promoted.\n\n   These instructions may read from the I/O port without writing to the\n   memory location if an exception or VM exit occurs due to the write (e.g.\n   #PF). If this would be problematic, for example because the I/O port read\n   has side-effects, software should ensure the write to the memory location\n   does not cause an exception or VM exit.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vgetexpph", "       VGETEXPPH \u2014 Convert Exponents of Packed FP16 Values to FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode   \n   Flag Support 64/32 CPUID Feature  \n   Instruction En Bit Mode Flag      \n   CPUID Feature Instruction En Bit  \n   Mode Flag Op/ 64/32 CPUID Feature   Support             Description\n   Instruction En Bit Mode Flag      \n   64/32 CPUID Feature Instruction   \n   En Bit Mode Flag CPUID Feature    \n   Instruction En Bit Mode Flag Op/  \n   64/32 CPUID Feature               \n                                                           Convert the        \n                                                           exponent of FP16   \n                                                           values in the      \n                                                           source operand to  \n   EVEX.128.66.MAP6.W0 42 /r                               FP16 results       \n   VGETEXPPH xmm1{k1}{z},            A V/V     AVX512-FP16 representing       \n   xmm2/m128/m16bcst                           AVX512VL    unbiased integer   \n                                                           exponents and      \n                                                           stores the results \n                                                           in the destination \n                                                           register subject   \n                                                           to writemask k1.   \n                                                           Convert the        \n                                                           exponent of FP16   \n                                                           values in the      \n                                                           source operand to  \n   EVEX.256.66.MAP6.W0 42 /r                               FP16 results       \n   VGETEXPPH ymm1{k1}{z},            A V/V     AVX512-FP16 representing       \n   ymm2/m256/m16bcst                           AVX512VL    unbiased integer   \n                                                           exponents and      \n                                                           stores the results \n                                                           in the destination \n                                                           register subject   \n                                                           to writemask k1.   \n                                                           Convert the        \n                                                           exponent of FP16   \n                                                           values in the      \n                                                           source operand to  \n   EVEX.512.66.MAP6.W0 42 /r                               FP16 results       \n   VGETEXPPH zmm1{k1}{z},            A V/V     AVX512-FP16 representing       \n   zmm2/m512/m16bcst {sae}                                 unbiased integer   \n                                                           exponents and      \n                                                           stores the results \n                                                           in the destination \n                                                           register subject   \n                                                           to writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction extracts the biased exponents from the normalized FP16\n   representation of each word element of the source operand (the second\n   operand) as unbiased signed integer value, or convert the denormal\n   representation of input data to unbiased negative integer values. Each\n   integer value of the unbiased exponent is converted to an FP16 value and\n   written to the corresponding word elements of the destination operand (the\n   first operand) as FP16 numbers.\n\n   The destination elements are updated according to the writemask.\n\n   Each GETEXP operation converts the exponent value into a floating-point\n   number (permitting input value in denormal representation). Special cases\n   of input values are listed in Table 5-6.\n\n   The formula is:\n\n   GETEXP(x) = floor(log_2(|x|))\n\n   Notation floor(x) stands for maximal integer not exceeding real number x.\n\n   Software usage of VGETEXPxx and VGETMANTxx instructions generally involve\n   a combination of GETEXP operation and GETMANT operation (see VGETMANTPH).\n   Thus, the VGETEXPPH instruction does not require software to handle SIMD\n   floating-point exceptions.\n\n   Input Operand    Result               Comments                             \n   src1 = NaN       QNaN(src1)                                                \n   0 < |src1| < INF floor(log_2(|src1|)) If (SRC = SNaN), then #IE. If (SRC = \n   | src1| = +INF   +INF                 denormal), then #DE.\n   | src1| = 0      -INF                 \n\n   Table 5-16. VGETEXPPH/VGETEXPSH Special Cases\n"],
	["vpcmpw:vpcmpuw", "             VPCMPW/VPCMPUW \u2014 Compare Packed Word Values Into Mask\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Compare packed signed word \n                                                   integers in xmm3/m128 and  \n   EVEX.128.66.0F3A.W1 3F                 AVX512VL xmm2 using bits 2:0 of     \n   /r ib VPCMPW k1 {k2},  A     V/V       AVX512BW imm8 as a comparison       \n   xmm2, xmm3/m128, imm8                           predicate with writemask   \n                                                   k2 and leave the result in \n                                                   mask register k1.          \n                                                   Compare packed signed word \n                                                   integers in ymm3/m256 and  \n   EVEX.256.66.0F3A.W1 3F                 AVX512VL ymm2 using bits 2:0 of     \n   /r ib VPCMPW k1 {k2},  A     V/V       AVX512BW imm8 as a comparison       \n   ymm2, ymm3/m256, imm8                           predicate with writemask   \n                                                   k2 and leave the result in \n                                                   mask register k1.          \n                                                   Compare packed signed word \n                                                   integers in zmm3/m512 and  \n   EVEX.512.66.0F3A.W1 3F                          zmm2 using bits 2:0 of     \n   /r ib VPCMPW k1 {k2},  A     V/V       AVX512BW imm8 as a comparison       \n   zmm2, zmm3/m512, imm8                           predicate with writemask   \n                                                   k2 and leave the result in \n                                                   mask register k1.          \n                                                   Compare packed unsigned    \n                                                   word integers in xmm3/m128 \n   EVEX.128.66.0F3A.W1 3E                 AVX512VL and xmm2 using bits 2:0 of \n   /r ib VPCMPUW k1 {k2}, A     V/V       AVX512BW imm8 as a comparison       \n   xmm2, xmm3/m128, imm8                           predicate with writemask   \n                                                   k2 and leave the result in \n                                                   mask register k1.          \n                                                   Compare packed unsigned    \n                                                   word integers in ymm3/m256 \n   EVEX.256.66.0F3A.W1 3E                 AVX512VL and ymm2 using bits 2:0 of \n   /r ib VPCMPUW k1 {k2}, A     V/V       AVX512BW imm8 as a comparison       \n   ymm2, ymm3/m256, imm8                           predicate with writemask   \n                                                   k2 and leave the result in \n                                                   mask register k1.          \n                                                   Compare packed unsigned    \n                                                   word integers in zmm3/m512 \n   EVEX.512.66.0F3A.W1 3E                          and zmm2 using bits 2:0 of \n   /r ib VPCMPUW k1 {k2}, A     V/V       AVX512BW imm8 as a comparison       \n   zmm2, zmm3/m512, imm8                           predicate with writemask   \n                                                   k2 and leave the result in \n                                                   mask register k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a SIMD compare of the packed integer word in the second source\n   operand and the first source operand and returns the results of the\n   comparison to the mask destination operand. The comparison predicate\n   operand (immediate byte) specifies the type of comparison performed on\n   each pair of packed values in the two source operands. The result of each\n   comparison is a single mask bit result of 1 (comparison true) or 0\n   (comparison false).\n\n   VPCMPW performs a comparison between pairs of signed word values.\n\n   VPCMPUW performs a comparison between pairs of unsigned word values.\n\n   The first source operand (second operand) is a ZMM/YMM/XMM register. The\n   second source operand can be a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location. The destination operand (first operand) is a mask\n   register k1. Up to 32/16/8 comparisons are performed with results written\n   to the destination operand under the writemask k2.\n\n   The comparison predicate operand is an 8-bit immediate: bits 2:0 define\n   the type of comparison to be performed. Bits 3 through 7 of the immediate\n   are reserved. Compiler can implement the pseudo-op mnemonic listed in\n   Table 5-21.\n"],
	["xbegin", "                          XBEGIN \u2014 Transactional Begin\n\n                            64/32bit Mode CPUID                               \n   Opcode/Instruction Op/En Support       Feature Description\n                                          Flag    \n                                                  Specifies the start of an   \n                                                  RTM region. Provides a      \n                                                  16-bit relative offset to   \n   C7 F8 XBEGIN rel16 A     V/V           RTM     compute the address of the  \n                                                  fallback instruction        \n                                                  address at which execution  \n                                                  resumes following an RTM    \n                                                  abort.                      \n                                                  Specifies the start of an   \n                                                  RTM region. Provides a      \n                                                  32-bit relative offset to   \n   C7 F8 XBEGIN rel32 A     V/V           RTM     compute the address of the  \n                                                  fallback instruction        \n                                                  address at which execution  \n                                                  resumes following an RTM    \n                                                  abort.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand2 Operand3 Operand4 \n   A     Offset    N/A      N/A      N/A      \n\nDescription \u00b6\n\n   The XBEGIN instruction specifies the start of an RTM code region. If the\n   logical processor was not already in transactional execution, then the\n   XBEGIN instruction causes the logical processor to transition into\n   transactional execution. The XBEGIN instruction that transitions the\n   logical processor into transactional execution is referred to as the\n   outermost XBEGIN instruction. The instruction also specifies a relative\n   offset to compute the address of the fallback code path following a\n   transactional abort. (Use of the 16-bit operand size does not cause this\n   address to be truncated to 16 bits, unlike a near jump to a relative\n   offset.)\n\n   On an RTM abort, the logical processor discards all architectural register\n   and memory updates performed during the RTM execution and restores\n   architectural state to that corresponding to the outermost XBEGIN\n   instruction. The fallback address following an abort is computed from the\n   outermost XBEGIN instruction.\n\n   Execution of XBEGIN while in a suspend read address tracking region causes\n   a transactional abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpsllvw:vpsllvd:vpsllvq", "           VPSLLVW/VPSLLVD/VPSLLVQ \u2014 Variable Bit Shift Left Logical\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Shift doublewords in xmm2 \n   VEX.128.66.0F38.W0 47 /r                         left by amount specified  \n   VPSLLVD xmm1, xmm2,      A    V/V       AVX2     in the corresponding      \n   xmm3/m128                                        element of xmm3/m128      \n                                                    while shifting in 0s.     \n                                                    Shift quadwords in xmm2   \n   VEX.128.66.0F38.W1 47 /r                         left by amount specified  \n   VPSLLVQ xmm1, xmm2,      A    V/V       AVX2     in the corresponding      \n   xmm3/m128                                        element of xmm3/m128      \n                                                    while shifting in 0s.     \n                                                    Shift doublewords in ymm2 \n   VEX.256.66.0F38.W0 47 /r                         left by amount specified  \n   VPSLLVD ymm1, ymm2,      A    V/V       AVX2     in the corresponding      \n   ymm3/m256                                        element of ymm3/m256      \n                                                    while shifting in 0s.     \n                                                    Shift quadwords in ymm2   \n   VEX.256.66.0F38.W1 47 /r                         left by amount specified  \n   VPSLLVQ ymm1, ymm2,      A    V/V       AVX2     in the corresponding      \n   ymm3/m256                                        element of ymm3/m256      \n                                                    while shifting in 0s.     \n                                                    Shift words in xmm2 left  \n   EVEX.128.66.0F38.W1 12                           by amount specified in    \n   /r VPSLLVW xmm1 {k1}{z}, B    V/V       AVX512VL the corresponding element \n   xmm2, xmm3/m128                         AVX512BW of xmm3/m128 while        \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift words in ymm2 left  \n   EVEX.256.66.0F38.W1 12                           by amount specified in    \n   /r VPSLLVW ymm1 {k1}{z}, B    V/V       AVX512VL the corresponding element \n   ymm2, ymm3/m256                         AVX512BW of ymm3/m256 while        \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift words in zmm2 left  \n   EVEX.512.66.0F38.W1 12                           by amount specified in    \n   /r VPSLLVW zmm1 {k1}{z}, B    V/V       AVX512BW the corresponding element \n   zmm2, zmm3/m512                                  of zmm3/m512 while        \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift doublewords in xmm2 \n                                                    left by amount specified  \n   EVEX.128.66.0F38.W0 47                  AVX512VL in the corresponding      \n   /r VPSLLVD xmm1 {k1}{z}, C    V/V       AVX512F  element of                \n   xmm2, xmm3/m128/m32bcst                          xmm3/m128/m32bcst while   \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift doublewords in ymm2 \n                                                    left by amount specified  \n   EVEX.256.66.0F38.W0 47                  AVX512VL in the corresponding      \n   /r VPSLLVD ymm1 {k1}{z}, C    V/V       AVX512F  element of                \n   ymm2, ymm3/m256/m32bcst                          ymm3/m256/m32bcst while   \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift doublewords in zmm2 \n                                                    left by amount specified  \n   EVEX.512.66.0F38.W0 47                           in the corresponding      \n   /r VPSLLVD zmm1 {k1}{z}, C    V/V       AVX512F  element of                \n   zmm2, zmm3/m512/m32bcst                          zmm3/m512/m32bcst while   \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift quadwords in xmm2   \n                                                    left by amount specified  \n   EVEX.128.66.0F38.W1 47                  AVX512VL in the corresponding      \n   /r VPSLLVQ xmm1 {k1}{z}, C    V/V       AVX512F  element of                \n   xmm2, xmm3/m128/m64bcst                          xmm3/m128/m64bcst while   \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift quadwords in ymm2   \n                                                    left by amount specified  \n   EVEX.256.66.0F38.W1 47                  AVX512VL in the corresponding      \n   /r VPSLLVQ ymm1 {k1}{z}, C    V/V       AVX512F  element of                \n   ymm2, ymm3/m256/m64bcst                          ymm3/m256/m64bcst while   \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift quadwords in zmm2   \n                                                    left by amount specified  \n   EVEX.512.66.0F38.W1 47                           in the corresponding      \n   /r VPSLLVQ zmm1 {k1}{z}, C    V/V       AVX512F  element of                \n   zmm2, zmm3/m512/m64bcst                          zmm3/m512/m64bcst while   \n                                                    shifting in 0s using      \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Shifts the bits in the individual data elements (words, doublewords or\n   quadword) in the first source operand to the left by the count value of\n   respective data elements in the second source operand. As the bits in the\n   data elements are shifted left, the empty low-order bits are cleared (set\n   to 0).\n\n   The count values are specified individually in each data element of the\n   second source operand. If the unsigned integer value specified in the\n   respective data element of the second source operand is greater than 15\n   (for word), 31 (for doublewords), or 63 (for a quadword), then the\n   destination data element are written with 0.\n\n   VEX.128 encoded version: The destination and first source operands are XMM\n   registers. The count operand can be either an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The destination and first source operands are YMM\n   registers. The count operand can be either an YMM register or a 256-bit\n   memory. Bits (MAXVL-1:256) of the corresponding ZMM register are zeroed.\n\n   EVEX encoded VPSLLVD/Q: The destination and first source operands are\n   ZMM/YMM/XMM registers. The count operand can be either a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512-bit vector\n   broadcasted from a 32/64-bit memory location. The destination is\n   conditionally updated with writemask k1.\n\n   EVEX encoded VPSLLVW: The destination and first source operands are\n   ZMM/YMM/XMM registers. The count operand can be either a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location. The destination is\n   conditionally updated with writemask k1.\n"],
	["lfence", "                              LFENCE \u2014 Load Fence\n\n   Opcode /           Op/En 64/32 bit Mode CPUID Feature Description          \n   Instruction              Support        Flag          \n   NP 0F AE E8 LFENCE ZO    V/V            SSE2          Serializes load      \n                                                         operations.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a serializing operation on all load-from-memory instructions that\n   were issued prior the LFENCE instruction. Specifically, LFENCE does not\n   execute until all prior instructions have completed locally, and no later\n   instruction begins execution until LFENCE completes. In particular, an\n   instruction that loads from memory and that precedes an LFENCE receives\n   data from memory prior to completion of the LFENCE. (An LFENCE that\n   follows an instruction that stores to memory might complete before the\n   data being stored have become globally visible.) Instructions following an\n   LFENCE may be fetched from memory before the LFENCE, but they will not\n   execute (even speculatively) until the LFENCE completes.\n\n   Weakly ordered memory types can be used to achieve higher processor\n   performance through such techniques as out-of-order issue and speculative\n   reads. The degree to which a consumer of data recognizes or knows that the\n   data is weakly ordered varies among applications and may be unknown to the\n   producer of this data. The LFENCE instruction provides a\n   performance-efficient way of ensuring load ordering between routines that\n   produce weakly-ordered results and routines that consume that data.\n\n   Processors are free to fetch and cache data speculatively from regions of\n   system memory that use the WB, WC, and WT memory types. This speculative\n   fetching can occur at any time and is not tied to instruction execution.\n   Thus, it is not ordered with respect to executions of the LFENCE\n   instruction; data can be brought into the caches speculatively just\n   before, during, or after the execution of an LFENCE instruction.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\n   Specification of the instruction's opcode above indicates a ModR/M byte of\n   E8. For this instruction, the processor ignores the r/m field of the\n   ModR/M byte. Thus, LFENCE is encoded by any opcode of the form 0F AE Ex,\n   where x is in the range 8-F.\n\nExceptions (All Modes of Operation) \u00b6\n\n   #UD If CPUID.01H:EDX.SSE2[bit 26] = 0.\n\n   If the LOCK prefix is used.\n"],
	["vrcp28pd", "     VRCP28PD \u2014 Approximation to the Reciprocal of Packed Double Precision\n            Floating-Point ValuesWith Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes the approximate  \n                                                    reciprocals ( < 2^-28     \n   EVEX.512.66.0F38.W1 CA                           relative error) of the    \n   /r VRCP28PD zmm1        A     V/V       AVX512ER packed double precision   \n   {k1}{z},                                         floating-point values in  \n   zmm2/m512/m64bcst {sae}                          zmm2/m512/m64bcst and     \n                                                    stores the results in     \n                                                    zmm1. Under writemask.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4 \n   A Full ModRM:reg (w) ModRM:r/m (r) N/A N/A               \n\n  Description \u00b6\n\n   Computes the reciprocal approximation of the float64 values in the source\n   operand (the second operand) and store the results to the destination\n   operand (the first operand). The approximate reciprocal is evaluated with\n   less than 2^-28 of maximum relative error.\n\n   Denormal input values are treated as zeros and do not signal #DE,\n   irrespective of MXCSR.DAZ. Denormal results are flushed to zeros and do\n   not signal #UE, irrespective of MXCSR.FTZ.\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. If any source element is \u00b1\u221e, \u00b10.0 is returned for that\n   element. Also, if any source element is \u00b10.0, \u00b1\u221e is returned for that\n   element.\n\n   The source operand is a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n  A numerically exact implementation of VRCP28xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["sysret", "                     SYSRET \u2014 Return From Fast System Call\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   0F 07      SYSRET      ZO    Valid  Invalid    Return to compatibility     \n                                                  mode from fast system call. \n   REX.W + 0F SYSRET      ZO    Valid  Invalid    Return to 64-bit mode from  \n   07                                             fast system call.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   SYSRET is a companion instruction to the SYSCALL instruction. It returns\n   from an OS system-call handler to user code at privilege level 3. It does\n   so by loading RIP from RCX and loading RFLAGS from R11.^1 With a 64-bit\n   operand size, SYSRET remains in 64-bit mode; otherwise, it enters\n   compatibility mode and only the low 32 bits of the registers are loaded.\n\n   SYSRET loads the CS and SS selectors with values derived from bits 63:48\n   of the IA32_STAR MSR. However, the CS and SS descriptor caches are not\n   loaded from the descriptors (in GDT or LDT) referenced by those selectors.\n   Instead, the descriptor caches are loaded with fixed values. See the\n   Operation section for details. It is the responsibility of OS software to\n   ensure that the descriptors (in GDT or LDT) referenced by those selector\n   values correspond to the fixed values loaded into the descriptor caches;\n   the SYSRET instruction does not ensure this correspondence.\n\n   The SYSRET instruction does not modify the stack pointer (ESP or RSP). For\n   that reason, it is necessary for software to switch to the user stack. The\n   OS may load the user stack pointer (if it was saved after SYSCALL) before\n   executing SYSRET; alternatively, user code may load the stack pointer (if\n   it was saved before SYSCALL) after receiving control from SYSRET.\n\n   If the OS loads the stack pointer before executing SYSRET, it must ensure\n   that the handler of any interrupt or exception delivered between restoring\n   the stack pointer and successful execution of SYSRET is not invoked with\n   the user stack. It can do so using approaches such as the following:\n\n     * External interrupts. The OS can prevent an external interrupt from\n       being delivered by clearing EFLAGS.IF before loading the user stack\n       pointer.\n     * Nonmaskable interrupts (NMIs). The OS can ensure that the NMI handler\n       is invoked with the correct stack by using the interrupt stack table\n       (IST) mechanism for gate 2 (NMI) in the IDT (see Section 6.14.5,\n       \u201cInterrupt Stack Table,\u201d in Intel^\u00ae 64 and IA-32 Architectures\n       Software Developer\u2019s Manual, Volume 3A).\n     * General-protection exceptions (#GP). The SYSRET instruction generates\n       #GP(0) if the value of RCX is not canonical. The OS can address this\n       possibility using one or more of the following approaches:\n          * Confirming that the value of RCX is canonical before executing\n            SYSRET.\n          * Confirming that the value of RCX is canonical before executing\n            SYSRET.\n          * Using paging to ensure that the SYSCALL instruction will never\n            save a non-canonical value into RCX.\n          * Using paging to ensure that the SYSCALL instruction will never\n            save a non-canonical value into RCX.\n          * Using the IST mechanism for gate 13 (#GP) in the IDT.\n          * Using the IST mechanism for gate 13 (#GP) in the IDT.\n\n   When shadow stacks are enabled at privilege level 3 the instruction loads\n   SSP with value from IA32_PL3_SSP MSR. Refer to Chapter 6, \u201cProcedure\n   Calls, Interrupts, and Exceptions\u201a\u201d and Chapter 17, \u201cControl-flow\n   Enforcement Technology (CET)\u201a\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, for additional CET details.\n\n     1. Regardless of the value of R11, the RF and VM flags are always 0 in\n     RFLAGS after execution of SYSRET. In addition, all reserved bits in\n     RFLAGS retain the fixed values.\n\n   Instruction ordering. Instructions following a SYSRET may be fetched from\n   memory before earlier instructions complete execution, but they will not\n   execute (even speculatively) until all instructions prior to the SYSRET\n   have completed execution (the later instructions may execute before data\n   stored by the earlier instructions have become globally visible).\n\nFlags Affected \u00b6\n\n   All.\n"],
	["xtest", "                   XTEST \u2014 Test if in Transactional Execution\n\n   Opcode/Instruction Op/En 64/32bit Mode CPUID        Description            \n                            Support       Feature Flag \n   NP 0F 01 D6 XTEST  ZO    V/V           HLE or RTM   Test if executing in a \n                                                       transactional region.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand2 Operand3 Operand4 \n   ZO    N/A       N/A      N/A      N/A      \n\nDescription \u00b6\n\n   The XTEST instruction queries the transactional execution status. If the\n   instruction executes inside a transactionally executing RTM region or a\n   transactionally executing HLE region, then the ZF flag is cleared, else it\n   is set.\n\nFlags Affected \u00b6\n\n   The ZF flag is cleared if the instruction is executed transactionally;\n   otherwise it is set to 1. The CF, OF, SF, PF, and AF, flags are cleared.\n"],
	["vpscatterdd:vpscatterdq:vpscatterqd:vpscatterqq", "    VPSCATTERDD/VPSCATTERDQ/VPSCATTERQD/VPSCATTERQQ \u2014 Scatter Packed Dword,\n              PackedQword with Signed Dword, Signed Qword Indices\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   EVEX.128.66.0F38.W0 A0                           Using signed dword        \n   /vsib VPSCATTERDD vm32x A     V/V       AVX512VL indices, scatter dword    \n   {k1}, xmm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.256.66.0F38.W0 A0                           Using signed dword        \n   /vsib VPSCATTERDD vm32y A     V/V       AVX512VL indices, scatter dword    \n   {k1}, ymm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.512.66.0F38.W0 A0                           Using signed dword        \n   /vsib VPSCATTERDD vm32z A     V/V       AVX512F  indices, scatter dword    \n   {k1}, zmm1                                       values to memory using    \n                                                    writemask k1.             \n   EVEX.128.66.0F38.W1 A0                           Using signed dword        \n   /vsib VPSCATTERDQ vm32x A     V/V       AVX512VL indices, scatter qword    \n   {k1}, xmm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.256.66.0F38.W1 A0                           Using signed dword        \n   /vsib VPSCATTERDQ vm32x A     V/V       AVX512VL indices, scatter qword    \n   {k1}, ymm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.512.66.0F38.W1 A0                           Using signed dword        \n   /vsib VPSCATTERDQ vm32y A     V/V       AVX512F  indices, scatter qword    \n   {k1}, zmm1                                       values to memory using    \n                                                    writemask k1.             \n   EVEX.128.66.0F38.W0 A1                           Using signed qword        \n   /vsib VPSCATTERQD vm64x A     V/V       AVX512VL indices, scatter dword    \n   {k1}, xmm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.256.66.0F38.W0 A1                           Using signed qword        \n   /vsib VPSCATTERQD vm64y A     V/V       AVX512VL indices, scatter dword    \n   {k1}, xmm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.512.66.0F38.W0 A1                           Using signed qword        \n   /vsib VPSCATTERQD vm64z A     V/V       AVX512F  indices, scatter dword    \n   {k1}, ymm1                                       values to memory using    \n                                                    writemask k1.             \n   EVEX.128.66.0F38.W1 A1                           Using signed qword        \n   /vsib VPSCATTERQQ vm64x A     V/V       AVX512VL indices, scatter qword    \n   {k1}, xmm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.256.66.0F38.W1 A1                           Using signed qword        \n   /vsib VPSCATTERQQ vm64y A     V/V       AVX512VL indices, scatter qword    \n   {k1}, ymm1                              AVX512F  values to memory using    \n                                                    writemask k1.             \n   EVEX.512.66.0F38.W1 A1                           Using signed qword        \n   /vsib VPSCATTERQQ vm64z A     V/V       AVX512F  indices, scatter qword    \n   {k1}, zmm1                                       values to memory using    \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1               Operand 2     Operand 3 Operand 4 \n         Tuple1     BaseReg (R): VSIB:base,                                   \n   A     Scalar     VectorReg(R):           ModRM:reg (r) N/A       N/A\n                    VSIB:index              \n\n  Description \u00b6\n\n   Stores up to 16 elements (8 elements for qword indices) in doubleword\n   vector or 8 elements in quadword vector to the memory locations pointed by\n   base address BASE_ADDR and index vector VINDEX, with scale SCALE. The\n   elements are specified via the VSIB (i.e., the index register is a vector\n   register, holding packed indices). Elements will only be stored if their\n   corresponding mask bit is one. The entire mask register will be set to\n   zero by this instruction unless it triggers an exception.\n\n   This instruction can be suspended by an exception if at least one element\n   is already scattered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask register are partially updated. If\n   any traps or interrupts are pending from already scattered elements, they\n   will be delivered in lieu of the exception; in this case, EFLAG.RF is set\n   to one so an instruction breakpoint is not re-triggered when the\n   instruction is continued.\n\n   Note that:\n\n     * Only writes to overlapping vector indices are guaranteed to be ordered\n       with respect to each other (from LSB to MSB of the source registers).\n       Note that this also include partially overlapping vector indices.\n       Writes that are not overlapped may happen in any order. Memory\n       ordering with other instructions follows the Intel-64 memory ordering\n       model. Note that this does not account for non-overlapping indices\n       that map into the same physical address locations.\n     * If two or more destination indices completely overlap, the \u201cearlier\u201d\n       write(s) may be skipped.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination ZMM will be completed (and non-faulting).\n       Individual elements closer to the MSB may or may not be completed. If\n       a given element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be scattered in any order, but faults must be delivered\n       in a right-to left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n     * If this instruction overwrites itself and then takes a fault, only a\n       subset of elements may be completed before the fault is delivered (as\n       described above). If the fault handler completes and attempts to\n       re-execute this instruction, the new instruction will be executed, and\n       the scatter will not complete.\n\n   Note that the presence of VSIB byte is enforced in this instruction.\n   Hence, the instruction will #UD fault if ModRM.rm is different than 100b.\n\n   This instruction has special disp8*N and alignment rules. N is considered\n   to be the size of a single vector element.\n\n   The scaled index may require more bits to represent than the address bits\n   used by the processor (e.g., in 32-bit mode, if the scale is greater than\n   one). In this case, the most significant bits beyond the number of address\n   bits are ignored.\n\n   The instruction will #UD fault if the k0 mask register is specified.\n\n   The instruction will #UD fault if EVEX.Z = 1.\n"],
	["lods:lodsb:lodsw:lodsd:lodsq", "                   LODS/LODSB/LODSW/LODSD/LODSQ \u2014 Load String\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n                                                  For legacy mode, Load byte  \n                                                  at address DS:(E)SI into    \n   AC         LODS m8     ZO    Valid  Valid      AL. For 64-bit mode load    \n                                                  byte at address (R)SI into  \n                                                  AL.                         \n                                                  For legacy mode, Load word  \n                                                  at address DS:(E)SI into    \n   AD         LODS m16    ZO    Valid  Valid      AX. For 64-bit mode load    \n                                                  word at address (R)SI into  \n                                                  AX.                         \n                                                  For legacy mode, Load dword \n                                                  at address DS:(E)SI into    \n   AD         LODS m32    ZO    Valid  Valid      EAX. For 64-bit mode load   \n                                                  dword at address (R)SI into \n                                                  EAX.                        \n   REX.W + AD LODS m64    ZO    Valid  N.E.       Load qword at address (R)SI \n                                                  into RAX.                   \n                                                  For legacy mode, Load byte  \n                                                  at address DS:(E)SI into    \n   AC         LODSB       ZO    Valid  Valid      AL. For 64-bit mode load    \n                                                  byte at address (R)SI into  \n                                                  AL.                         \n                                                  For legacy mode, Load word  \n                                                  at address DS:(E)SI into    \n   AD         LODSW       ZO    Valid  Valid      AX. For 64-bit mode load    \n                                                  word at address (R)SI into  \n                                                  AX.                         \n                                                  For legacy mode, Load dword \n                                                  at address DS:(E)SI into    \n   AD         LODSD       ZO    Valid  Valid      EAX. For 64-bit mode load   \n                                                  dword at address (R)SI into \n                                                  EAX.                        \n   REX.W + AD LODSQ       ZO    Valid  N.E.       Load qword at address (R)SI \n                                                  into RAX.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads a byte, word, or doubleword from the source operand into the AL, AX,\n   or EAX register, respectively. The source operand is a memory location,\n   the address of which is read from the DS:ESI or the DS:SI registers\n   (depending on the address-size attribute of the instruction, 32 or 16,\n   respectively). The DS segment may be overridden with a segment override\n   prefix.\n\n   At the assembly-code level, two forms of this instruction are allowed: the\n   \u201cexplicit-operands\u201d form and the \u201cno-operands\u201d form. The explicit-operands\n   form (specified with the LODS mnemonic) allows the source operand to be\n   specified explicitly. Here, the source operand should be a symbol that\n   indicates the size and location of the source value. The destination\n   operand is then automatically selected to match the size of the source\n   operand (the AL register for byte operands, AX for word operands, and EAX\n   for doubleword operands). This explicit-operands form is provided to allow\n   documentation; however, note that the documentation provided by this form\n   can be misleading. That is, the source operand symbol must specify the\n   correct type (size) of the operand (byte, word, or doubleword), but it\n   does not have to specify the correct location. The location is always\n   specified by the DS:(E)SI registers, which must be loaded correctly before\n   the load string instruction is executed.\n\n   The no-operands form provides \u201cshort forms\u201d of the byte, word, and\n   doubleword versions of the LODS instructions. Here also DS:(E)SI is\n   assumed to be the source operand and the AL, AX, or EAX register is\n   assumed to be the destination operand. The size of the source and\n   destination operands is selected with the mnemonic: LODSB (byte loaded\n   into register AL), LODSW (word loaded into AX), or LODSD (doubleword\n   loaded into EAX).\n\n   After the byte, word, or doubleword is transferred from the memory\n   location into the AL, AX, or EAX register, the (E)SI register is\n   incremented or decremented automatically according to the setting of the\n   DF flag in the EFLAGS register. (If the DF flag is 0, the (E)SI register\n   is incremented; if the DF flag is 1, the ESI register is decremented.) The\n   (E)SI register is incremented or decremented by 1 for byte operations, by\n   2 for word operations, or by 4 for doubleword operations.\n\n   In 64-bit mode, use of the REX.W prefix promotes operation to 64 bits.\n   LODS/LODSQ load the quadword at address (R)SI into RAX. The (R)SI register\n   is then incremented or decremented automatically according to the setting\n   of the DF flag in the EFLAGS register.\n\n   The LODS, LODSB, LODSW, and LODSD instructions can be preceded by the REP\n   prefix for block loads of ECX bytes, words, or doublewords. More often,\n   however, these instructions are used within a LOOP construct because\n   further processing of the data moved into the register is usually\n   necessary before the next transfer can be made. See \u201cREP/REPE/REPZ\n   /REPNE/REPNZ\u2014Repeat String Operation Prefix\u201d in Chapter 4 of the Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 2B, for a\n   description of the REP prefix.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["stc", "                              STC \u2014 Set Carry Flag\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description  \n   F9     STC         ZO    Valid       Valid           Set CF flag. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Sets the CF flag in the EFLAGS register. Operation is the same in all\n   modes.\n\nFlags Affected \u00b6\n\n   The CF flag is set. The OF, ZF, SF, AF, and PF flags are unaffected.\n"],
	["rdsspd:rdsspq", "                   RDSSPD/RDSSPQ \u2014 Read Shadow Stack Pointer\n\n                              64/32 bit    CPUID                              \n   Opcode/Instruction   Op/En Mode Support Feature Description\n                                           Flag    \n   F3 0F 1E /1 (mod=11)                            Copy low 32 bits of shadow \n   RDSSPD r32           R     V/V          CET_SS  stack pointer (SSP) to     \n                                                   r32.                       \n   F3 REX.W 0F 1E /1    R     V/N.E.       CET_SS  Copies shadow stack        \n   (mod=11) RDSSPQ r64                             pointer (SSP) to r64.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   R     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Copies the current shadow stack pointer (SSP) register to the register\n   destination. This opcode is a NOP when CET shadow stacks are not enabled\n   and on processors that do not support CET.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pmulhw", "         PMULHW \u2014 Multiply Packed Signed Integers and Store High Result\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply the packed      \n                                                     signed word integers in  \n   NP 0F E5 /r^1 PMULHW mm, A     V/V       MMX      mm1 register and         \n   mm/m64                                            mm2/m64, and store the   \n                                                     high 16 bits of the      \n                                                     results in mm1.          \n                                                     Multiply the packed      \n   66 0F E5 /r PMULHW xmm1,                          signed word integers in  \n   xmm2/m128                A     V/V       SSE2     xmm1 and xmm2/m128, and  \n                                                     store the high 16 bits   \n                                                     of the results in xmm1.  \n                                                     Multiply the packed      \n   VEX.128.66.0F.WIG E5 /r                           signed word integers in  \n   VPMULHW xmm1, xmm2,      B     V/V       AVX      xmm2 and xmm3/m128, and  \n   xmm3/m128                                         store the high 16 bits   \n                                                     of the results in xmm1.  \n                                                     Multiply the packed      \n   VEX.256.66.0F.WIG E5 /r                           signed word integers in  \n   VPMULHW ymm1, ymm2,      B     V/V       AVX2     ymm2 and ymm3/m256, and  \n   ymm3/m256                                         store the high 16 bits   \n                                                     of the results in ymm1.  \n                                                     Multiply the packed      \n   EVEX.128.66.0F.WIG E5 /r                          signed word integers in  \n   VPMULHW xmm1 {k1}{z},    C     V/V       AVX512VL xmm2 and xmm3/m128, and  \n   xmm2, xmm3/m128                          AVX512BW store the high 16 bits   \n                                                     of the results in xmm1   \n                                                     under writemask k1.      \n                                                     Multiply the packed      \n   EVEX.256.66.0F.WIG E5 /r                          signed word integers in  \n   VPMULHW ymm1 {k1}{z},    C     V/V       AVX512VL ymm2 and ymm3/m256, and  \n   ymm2, ymm3/m256                          AVX512BW store the high 16 bits   \n                                                     of the results in ymm1   \n                                                     under writemask k1.      \n                                                     Multiply the packed      \n   EVEX.512.66.0F.WIG E5 /r                          signed word integers in  \n   VPMULHW zmm1 {k1}{z},    C     V/V       AVX512BW zmm2 and zmm3/m512, and  \n   zmm2, zmm3/m512                                   store the high 16 bits   \n                                                     of the results in zmm1   \n                                                     under writemask k1.      \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD signed multiply of the packed signed word integers in the\n   destination operand (first operand) and the source operand (second\n   operand), and stores the high 16 bits of each intermediate 32-bit result\n   in the destination operand. (Figure 4-12 shows this operation when using\n   64-bit operands.)\n\n   n 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The source operand can be an MMX\n   technology register or a 64-bit memory location. The destination operand\n   is an MMX technology register.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed. VEX.L must be 0, otherwise the instruction will #UD.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pextrb:pextrd:pextrq", "                PEXTRB/PEXTRD/PEXTRQ \u2014 Extract Byte/Dword/Qword\n\n                             Op/ 64/32 bit CPUID                              \n   Opcode/Instruction        En  Mode      Feature  Description\n                                 Support   Flag     \n                                                    Extract a byte integer    \n                                                    value from xmm2 at the    \n   66 0F 3A 14 /r ib PEXTRB  A   V/V       SSE4_1   source byte offset        \n   reg/m8, xmm2, imm8                               specified by imm8 into    \n                                                    reg or m8. The upper bits \n                                                    of r32 or r64 are zeroed. \n                                                    Extract a dword integer   \n   66 0F 3A 16 /r ib PEXTRD                         value from xmm2 at the    \n   r/m32, xmm2, imm8         A   V/V       SSE4_1   source dword offset       \n                                                    specified by imm8 into    \n                                                    r/m32.                    \n                                                    Extract a qword integer   \n   66 REX.W 0F 3A 16 /r ib                          value from xmm2 at the    \n   PEXTRQ r/m64, xmm2, imm8  A   V/N.E.    SSE4_1   source qword offset       \n                                                    specified by imm8 into    \n                                                    r/m64.                    \n                                                    Extract a byte integer    \n                                                    value from xmm2 at the    \n   VEX.128.66.0F3A.W0 14 /r                         source byte offset        \n   ib VPEXTRB reg/m8, xmm2,  A   V^1/V     AVX      specified by imm8 into    \n   imm8                                             reg or m8. The upper bits \n                                                    of r64/r32 is filled with \n                                                    zeros.                    \n                                                    Extract a dword integer   \n   VEX.128.66.0F3A.W0 16 /r                         value from xmm2 at the    \n   ib VPEXTRD r32/m32, xmm2, A   V/V       AVX      source dword offset       \n   imm8                                             specified by imm8 into    \n                                                    r32/m32.                  \n                                                    Extract a qword integer   \n   VEX.128.66.0F3A.W1 16 /r                         value from xmm2 at the    \n   ib VPEXTRQ r64/m64, xmm2, A   V/I^2     AVX      source dword offset       \n   imm8                                             specified by imm8 into    \n                                                    r64/m64.                  \n                                                    Extract a byte integer    \n                                                    value from xmm2 at the    \n   EVEX.128.66.0F3A.WIG 14                          source byte offset        \n   /r ib VPEXTRB reg/m8,     B   V/V       AVX512BW specified by imm8 into    \n   xmm2, imm8                                       reg or m8. The upper bits \n                                                    of r64/r32 is filled with \n                                                    zeros.                    \n                                                    Extract a dword integer   \n   EVEX.128.66.0F3A.W0 16 /r                        value from xmm2 at the    \n   ib VPEXTRD r32/m32, xmm2, B   V/V       AVX512DQ source dword offset       \n   imm8                                             specified by imm8 into    \n                                                    r32/m32.                  \n                                                    Extract a qword integer   \n   EVEX.128.66.0F3A.W1 16 /r                        value from xmm2 at the    \n   ib VPEXTRQ r64/m64, xmm2, B   V/N.E.^2  AVX512DQ source dword offset       \n   imm8                                             specified by imm8 into    \n                                                    r64/m64.                  \n\n     1. In 64-bit mode, VEX.W1 is ignored for VPEXTRB (similar to legacy\n     REX.W=1 prefix in PEXTRB).\n\n     2. VEX.W/EVEX.W in non-64 bit is ignored; the instructions behaves as if\n     the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   B     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n\nDescription \u00b6\n\n   Extract a byte/dword/qword integer value from the source XMM register at a\n   byte/dword/qword offset determined from imm8[3:0]. The destination can be\n   a register or byte/dword/qword memory location. If the destination is a\n   register, the upper bits of the register are zero extended.\n\n   In legacy non-VEX encoded version and if the destination operand is a\n   register, the default operand size in 64-bit mode for PEXTRB/PEXTRD is 64\n   bits, the bits above the least significant byte/dword data are filled with\n   zeros. PEXTRQ is not encodable in non-64-bit modes and requires REX.W in\n   64-bit mode.\n\n   Note: In VEX.128 encoded versions, VEX.vvvv is reserved and must be 1111b,\n   VEX.L must be 0, otherwise the instruction will #UD. In EVEX.128 encoded\n   versions, EVEX.vvvv is reserved and must be 1111b, EVEX.L\u201dL must be 0,\n   otherwise the instruction will #UD. If the destination operand is a\n   register, the default operand size in 64-bit mode for VPEXTRB/VPEXTRD is\n   64 bits, the bits above the least significant byte/word/dword data are\n   filled with zeros.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvttss2usi", "  VCVTTSS2USI \u2014 Convert With Truncation Scalar Single Precision Floating-Point\n                            Value toUnsigned Integer\n\n                               64/32 Bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                               Support   Flag    \n                                                 Convert one single precision \n   EVEX.LLIG.F3.0F.W0 78                         floating-point value from    \n   /r VCVTTSS2USI r32,   A     V/V       AVX512F xmm1/m32 to one unsigned     \n   xmm1/m32{sae}                                 doubleword integer in r32    \n                                                 using truncation.            \n                                                 Convert one single precision \n   EVEX.LLIG.F3.0F.W1 78                         floating-point value from    \n   /r VCVTTSS2USI r64,   A     V/N.E.^1  AVX512F xmm1/m32 to one unsigned     \n   xmm1/m32{sae}                                 quadword integer in r64      \n                                                 using truncation.            \n\n     1. For this specific instruction, EVEX.W in non-64 bit is ignored; the\n     instruction behaves as if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation a single precision floating-point value in the\n   source operand (the second operand) to an unsigned doubleword integer (or\n   unsigned quadword integer if operand size is 64 bits) in the destination\n   operand (the first operand). The source operand can be an XMM register or\n   a memory location. The destination operand is a general-purpose register.\n   When the source operand is an XMM register, the single precision\n   floating-point value is contained in the low doubleword of the register.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   EVEX.W1 version: promotes the instruction to produce 64-bit data in 64-bit\n   mode.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["vfpclassps", "               VFPCLASSPS \u2014 Tests Types of Packed Float32 Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Tests the input for the  \n                                                     following categories:    \n                                                     NaN, +0, -0, +Infinity,  \n   EVEX.128.66.0F3A.W0 66                            -Infinity, denormal,     \n   /r ib VFPCLASSPS k2                      AVX512VL finite negative. The     \n   {k1}, xmm2/m128/m32bcst, A     V/V       AVX512DQ immediate field provides \n   imm8                                              a mask bit for each of   \n                                                     these category tests.    \n                                                     The masked test results  \n                                                     are OR-ed together to    \n                                                     form a mask result.      \n                                                     Tests the input for the  \n                                                     following categories:    \n                                                     NaN, +0, -0, +Infinity,  \n   EVEX.256.66.0F3A.W0 66                            -Infinity, denormal,     \n   /r ib VFPCLASSPS k2                      AVX512VL finite negative. The     \n   {k1}, ymm2/m256/m32bcst, A     V/V       AVX512DQ immediate field provides \n   imm8                                              a mask bit for each of   \n                                                     these category tests.    \n                                                     The masked test results  \n                                                     are OR-ed together to    \n                                                     form a mask result.      \n                                                     Tests the input for the  \n                                                     following categories:    \n                                                     NaN, +0, -0, +Infinity,  \n   EVEX.512.66.0F3A.W0 66                            -Infinity, denormal,     \n   /r ib VFPCLASSPS k2                               finite negative. The     \n   {k1}, zmm2/m512/m32bcst, A     V/V       AVX512DQ immediate field provides \n   imm8                                              a mask bit for each of   \n                                                     these category tests.    \n                                                     The masked test results  \n                                                     are OR-ed together to    \n                                                     form a mask result.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   The FPCLASSPS instruction checks the packed single-precision\n   floating-point values for special categories, specified by the set bits in\n   the imm8 byte. Each set bit in imm8 specifies a category of floating-point\n   values that the input data element is classified against. The classified\n   results of all specified categories of an input value are ORed together to\n   form the final boolean result for the input element. The result of each\n   element is written to the corresponding bit in a mask register k2\n   according to the writemask k1. Bits [MAX_KL-1:16/8/4] of the destination\n   are cleared.\n\n   The classification categories specified by imm8 are shown in Figure 5-13.\n   The classification test for each category is listed in Table 5-14.\n\n   The source operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location, or a 512/256/128-bit vector broadcasted from a 32-bit memory\n   location.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["vpmovm2b:vpmovm2w:vpmovm2d:vpmovm2q", "       VPMOVM2B/VPMOVM2W/VPMOVM2D/VPMOVM2Q \u2014 Convert a Mask Register to a\n                                 VectorRegister\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Sets each byte in XMM1 to  \n   EVEX.128.F3.0F38.W0 28 RM    V/V       AVX512VL all 1\u2019s or all 0\u2019s based   \n   /r VPMOVM2B xmm1, k1                   AVX512BW on the value of the        \n                                                   corresponding bit in k1.   \n                                                   Sets each byte in YMM1 to  \n   EVEX.256.F3.0F38.W0 28 RM    V/V       AVX512VL all 1\u2019s or all 0\u2019s based   \n   /r VPMOVM2B ymm1, k1                   AVX512BW on the value of the        \n                                                   corresponding bit in k1.   \n                                                   Sets each byte in ZMM1 to  \n   EVEX.512.F3.0F38.W0 28 RM    V/V       AVX512BW all 1\u2019s or all 0\u2019s based   \n   /r VPMOVM2B zmm1, k1                            on the value of the        \n                                                   corresponding bit in k1.   \n                                                   Sets each word in XMM1 to  \n   EVEX.128.F3.0F38.W1 28 RM    V/V       AVX512VL all 1\u2019s or all 0\u2019s based   \n   /r VPMOVM2W xmm1, k1                   AVX512BW on the value of the        \n                                                   corresponding bit in k1.   \n                                                   Sets each word in YMM1 to  \n   EVEX.256.F3.0F38.W1 28 RM    V/V       AVX512VL all 1\u2019s or all 0\u2019s based   \n   /r VPMOVM2W ymm1, k1                   AVX512BW on the value of the        \n                                                   corresponding bit in k1.   \n                                                   Sets each word in ZMM1 to  \n   EVEX.512.F3.0F38.W1 28 RM    V/V       AVX512BW all 1\u2019s or all 0\u2019s based   \n   /r VPMOVM2W zmm1, k1                            on the value of the        \n                                                   corresponding bit in k1.   \n                                                   Sets each doubleword in    \n   EVEX.128.F3.0F38.W0 38 RM    V/V       AVX512VL XMM1 to all 1\u2019s or all 0\u2019s \n   /r VPMOVM2D xmm1, k1                   AVX512DQ based on the value of the  \n                                                   corresponding bit in k1.   \n                                                   Sets each doubleword in    \n   EVEX.256.F3.0F38.W0 38 RM    V/V       AVX512VL YMM1 to all 1\u2019s or all 0\u2019s \n   /r VPMOVM2D ymm1, k1                   AVX512DQ based on the value of the  \n                                                   corresponding bit in k1.   \n                                                   Sets each doubleword in    \n   EVEX.512.F3.0F38.W0 38 RM    V/V       AVX512DQ ZMM1 to all 1\u2019s or all 0\u2019s \n   /r VPMOVM2D zmm1, k1                            based on the value of the  \n                                                   corresponding bit in k1.   \n                                                   Sets each quadword in XMM1 \n   EVEX.128.F3.0F38.W1 38 RM    V/V       AVX512VL to all 1\u2019s or all 0\u2019s      \n   /r VPMOVM2Q xmm1, k1                   AVX512DQ based on the value of the  \n                                                   corresponding bit in k1.   \n                                                   Sets each quadword in YMM1 \n   EVEX.256.F3.0F38.W1 38 RM    V/V       AVX512VL to all 1\u2019s or all 0\u2019s      \n   /r VPMOVM2Q ymm1, k1                   AVX512DQ based on the value of the  \n                                                   corresponding bit in k1.   \n                                                   Sets each quadword in ZMM1 \n   EVEX.512.F3.0F38.W1 38 RM    V/V       AVX512DQ to all 1\u2019s or all 0\u2019s      \n   /r VPMOVM2Q zmm1, k1                            based on the value of the  \n                                                   corresponding bit in k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts a mask register to a vector register. Each element in the\n   destination register is set to all 1\u2019s or all 0\u2019s depending on the value\n   of the corresponding bit in the source mask register.\n\n   The source operand is a mask register. The destination operand is a\n   ZMM/YMM/XMM register.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["wbnoinvd", "               WBNOINVD \u2014 Write Back and Do Not Invalidate Cache\n\n   Opcode /    Op/En 64/32 bit    CPUID Feature Description                   \n   Instruction       Mode Support Flag          \n                                                Write back and do not flush   \n   F3 0F 09    ZO    V/V          WBNOINVD      internal caches; initiate     \n   WBNOINVD                                     writing-back without flushing \n                                                of external caches.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The WBNOINVD instruction writes back all modified cache lines in the\n   processor\u2019s internal cache to main memory but does not invalidate (flush)\n   the internal caches.\n\n   After executing this instruction, the processor does not wait for the\n   external caches to complete their write-back operation before proceeding\n   with instruction execution. It is the responsibility of hardware to\n   respond to the cache write-back signal. The amount of time or cycles for\n   WBNOINVD to complete will vary due to size and other factors of different\n   cache hierarchies. As a consequence, the use of the WBNOINVD instruction\n   can have an impact on logical processor interrupt/event response time.\n\n   The WBNOINVD instruction is a privileged instruction. When the processor\n   is running in protected mode, the CPL of a program or procedure must be 0\n   to execute this instruction. This instruction is also a serializing\n   instruction (see \u201cSerializing Instructions\u201d in Chapter 9 of the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A).\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["shufps", "     SHUFPS \u2014 Packed Interleave Shuffle of Quadruplets of Single Precision\n                             Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Select from quadruplet of  \n                                                   single precision           \n   NP 0F C6 /r ib SHUFPS   A    V/V       SSE      floating-point values in   \n   xmm1, xmm3/m128, imm8                           xmm1 and xmm2/m128 using   \n                                                   imm8, interleaved result   \n                                                   pairs are stored in xmm1.  \n                                                   Select from quadruplet of  \n   VEX.128.0F.WIG C6 /r ib                         single precision           \n   VSHUFPS xmm1, xmm2,     B    V/V       AVX      floating-point values in   \n   xmm3/m128, imm8                                 xmm1 and xmm2/m128 using   \n                                                   imm8, interleaved result   \n                                                   pairs are stored in xmm1.  \n                                                   Select from quadruplet of  \n   VEX.256.0F.WIG C6 /r ib                         single precision           \n   VSHUFPS ymm1, ymm2,     B    V/V       AVX      floating-point values in   \n   ymm3/m256, imm8                                 ymm2 and ymm3/m256 using   \n                                                   imm8, interleaved result   \n                                                   pairs are stored in ymm1.  \n                                                   Select from quadruplet of  \n   EVEX.128.0F.W0 C6 /r ib                         single precision           \n   VSHUFPS xmm1{k1}{z},                   AVX512VL floating-point values in   \n   xmm2,                   C    V/V       AVX512F  xmm1 and xmm2/m128 using   \n   xmm3/m128/m32bcst, imm8                         imm8, interleaved result   \n                                                   pairs are stored in xmm1,  \n                                                   subject to writemask k1.   \n                                                   Select from quadruplet of  \n   EVEX.256.0F.W0 C6 /r ib                         single precision           \n   VSHUFPS ymm1{k1}{z},                   AVX512VL floating-point values in   \n   ymm2,                   C    V/V       AVX512F  ymm2 and ymm3/m256 using   \n   ymm3/m256/m32bcst, imm8                         imm8, interleaved result   \n                                                   pairs are stored in ymm1,  \n                                                   subject to writemask k1.   \n                                                   Select from quadruplet of  \n   EVEX.512.0F.W0 C6 /r ib                         single precision           \n   VSHUFPS zmm1{k1}{z},                            floating-point values in   \n   zmm2,                   C    V/V       AVX512F  zmm2 and zmm3/m512 using   \n   zmm3/m512/m32bcst, imm8                         imm8, interleaved result   \n                                                   pairs are stored in zmm1,  \n                                                   subject to writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Selects a single precision floating-point value of an input quadruplet\n   using a two-bit control and move to a designated element of the\n   destination operand. Each 64-bit element-pair of a 128-bit lane of the\n   destination operand is interleaved between the corresponding lane of the\n   first source operand and the second source operand at the granularity 128\n   bits. Each two bits in the imm8 byte, starting from bit 0, is the select\n   control of the corresponding element of a 128-bit lane of the destination\n   to received the shuffled result of an input quadruplet. The two lower\n   elements of a 128-bit lane in the destination receives shuffle results\n   from the quadruple of the first source operand. The next two elements of\n   the destination receives shuffle results from the quadruple of the second\n   source operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register updated\n   according to the writemask. imm8[7:0] provides 4 select controls for each\n   applicable 128-bit lane of the destination.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. Imm8[7:0] provides 4 select\n   controls for the high and low 128-bit of the destination.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed. Imm8[7:0] provides\n   4 select controls for each element of the destination.\n\n   128-bit Legacy SSE version: The source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified. Imm8[7:0] provides 4 select\n   controls for each element of the destination.\n\n   X7 X6 X5 X4 X3 X2 X1 X0 SRC1 Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 SRC2 Y7..Y4 Y7..Y4\n   X7..X4 X7..X4 Y3..Y0 Y3..Y0 DEST X3..X0 X3..X0 Figure 4-26. 256-bit\n   VSHUFPS Operation of Selection from Input Quadruplet and Pair-wise\n   Interleaved Result\n"],
	["pmuldq", "                  PMULDQ \u2014 Multiply Packed Doubleword Integers\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature  Description\n                               Support   Flag     \n                                                  Multiply packed signed      \n                                                  doubleword integers in xmm1 \n   66 0F 38 28 /r PMULDQ  A    V/V       SSE4_1   by packed signed doubleword \n   xmm1, xmm2/m128                                integers in xmm2/m128, and  \n                                                  store the quadword results  \n                                                  in xmm1.                    \n                                                  Multiply packed signed      \n   VEX.128.66.0F38.WIG 28                         doubleword integers in xmm2 \n   /r VPMULDQ xmm1, xmm2, B    V/V       AVX      by packed signed doubleword \n   xmm3/m128                                      integers in xmm3/m128, and  \n                                                  store the quadword results  \n                                                  in xmm1.                    \n                                                  Multiply packed signed      \n   VEX.256.66.0F38.WIG 28                         doubleword integers in ymm2 \n   /r VPMULDQ ymm1, ymm2, B    V/V       AVX2     by packed signed doubleword \n   ymm3/m256                                      integers in ymm3/m256, and  \n                                                  store the quadword results  \n                                                  in ymm1.                    \n                                                  Multiply packed signed      \n   EVEX.128.66.0F38.W1 28                         doubleword integers in xmm2 \n   /r VPMULDQ xmm1                       AVX512VL by packed signed doubleword \n   {k1}{z}, xmm2,         C    V/V       AVX512F  integers in                 \n   xmm3/m128/m64bcst                              xmm3/m128/m64bcst, and      \n                                                  store the quadword results  \n                                                  in xmm1 using writemask k1. \n                                                  Multiply packed signed      \n   EVEX.256.66.0F38.W1 28                         doubleword integers in ymm2 \n   /r VPMULDQ ymm1                       AVX512VL by packed signed doubleword \n   {k1}{z}, ymm2,         C    V/V       AVX512F  integers in                 \n   ymm3/m256/m64bcst                              ymm3/m256/m64bcst, and      \n                                                  store the quadword results  \n                                                  in ymm1 using writemask k1. \n                                                  Multiply packed signed      \n   EVEX.512.66.0F38.W1 28                         doubleword integers in zmm2 \n   /r VPMULDQ zmm1                                by packed signed doubleword \n   {k1}{z}, zmm2,         C    V/V       AVX512F  integers in                 \n   zmm3/m512/m64bcst                              zmm3/m512/m64bcst, and      \n                                                  store the quadword results  \n                                                  in zmm1 using writemask k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Multiplies packed signed doubleword integers in the even-numbered\n   (zero-based reference) elements of the first source operand with the\n   packed signed doubleword integers in the corresponding elements of the\n   second source operand and stores packed signed quadword results in the\n   destination operand.\n\n   128-bit Legacy SSE version: The input signed doubleword integers are taken\n   from the even-numbered elements of the source operands, i.e., the first\n   (low) and third doubleword element. For 128-bit memory operands, 128 bits\n   are fetched from memory, but only the first and third doublewords are used\n   in the computation. The first source operand and the destination XMM\n   operand is the same. The second source operand can be an XMM register or\n   128-bit memory location. Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The input signed doubleword integers are taken\n   from the even-numbered elements of the source operands, i.e., the first\n   (low) and third doubleword element. For 128-bit memory operands, 128 bits\n   are fetched from memory, but only the first and third doublewords are used\n   in the computation.The first source operand and the destination operand\n   are XMM registers. The second source operand can be an XMM register or\n   128-bit memory location. Bits (MAXVL-1:128) of the corresponding\n   destination register are zeroed.\n\n   VEX.256 encoded version: The input signed doubleword integers are taken\n   from the even-numbered elements of the source operands, i.e., the first,\n   3rd, 5th, 7th doubleword element. For 256-bit memory operands, 256 bits\n   are fetched from memory, but only the four even-numbered doublewords are\n   used in the computation. The first source operand and the destination\n   operand are YMM registers. The second source operand can be a YMM register\n   or 256-bit memory location. Bits (MAXVL-1:256) of the corresponding\n   destination ZMM register are zeroed.\n\n   EVEX encoded version: The input signed doubleword integers are taken from\n   the even-numbered elements of the source operands. The first source\n   operand is a ZMM/YMM/XMM registers. The second source operand can be an\n   ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination is a ZMM/YMM/XMM register, and updated according to the\n   writemask at 64-bit granularity.\n"],
	["divsd", "          DIVSD \u2014 Divide Scalar Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Divide low double          \n                                                   precision floating-point   \n   F2 0F 5E /r DIVSD xmm1,  A    V/V       SSE2    value in xmm1 by low       \n   xmm2/m64                                        double precision           \n                                                   floating-point value in    \n                                                   xmm2/m64.                  \n                                                   Divide low double          \n   VEX.LIG.F2.0F.WIG 5E /r                         precision floating-point   \n   VDIVSD xmm1, xmm2,       B    V/V       AVX     value in xmm2 by low       \n   xmm3/m64                                        double precision           \n                                                   floating-point value in    \n                                                   xmm3/m64.                  \n                                                   Divide low double          \n   EVEX.LLIG.F2.0F.W1 5E /r                        precision floating-point   \n   VDIVSD xmm1 {k1}{z},     C    V/V       AVX512F value in xmm2 by low       \n   xmm2, xmm3/m64{er}                              double precision           \n                                                   floating-point value in    \n                                                   xmm3/m64.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Divides the low double precision floating-point value in the first source\n   operand by the low double precision floating-point value in the second\n   source operand, and stores the double precision floating-point result in\n   the destination operand. The second source operand can be an XMM register\n   or a 64-bit memory location. The first source and destination are XMM\n   registers.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:64) of the corresponding ZMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The first source operand is an xmm register\n   encoded by VEX.vvvv. The quadword at bits 127:64 of the destination\n   operand is copied from the corresponding quadword of the first source\n   operand. Bits (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX.128 encoded version: The first source operand is an xmm register\n   encoded by EVEX.vvvv. The quadword element of the destination operand at\n   bits 127:64 are copied from the first source operand. Bits (MAXVL-1:128)\n   of the destination register are zeroed.\n\n   EVEX version: The low quadword element of the destination is updated\n   according to the writemask.\n\n   Software should ensure VDIVSD is encoded with VEX.L=0. Encoding VDIVSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["cpuid", "                           CPUID \u2014 CPU Identification\n\n   Opcode Instruction Op/En 64-Bit Compat/Leg Description                     \n                            Mode   Mode       \n                                              Returns processor               \n                                              identification and feature      \n                                              information to the EAX, EBX,    \n   0F A2  CPUID       ZO    Valid  Valid      ECX, and EDX registers, as      \n                                              determined by input entered in  \n                                              EAX (in some cases, ECX as      \n                                              well).                          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The ID flag (bit 21) in the EFLAGS register indicates support for the\n   CPUID instruction. If a software procedure can set and clear this flag,\n   the processor executing the procedure supports the CPUID instruction. This\n   instruction operates the same in non-64-bit modes and 64-bit mode.\n\n   CPUID returns processor identification and feature information in the EAX,\n   EBX, ECX, and EDX registers.^1 The instruction\u2019s output is dependent on\n   the contents of the EAX register upon execution (in some cases, ECX as\n   well). For example, the following pseudocode loads EAX with 00H and causes\n   CPUID to return a Maximum Return Value and the Vendor Identification\n   String in the appropriate registers:\n\n   MOV EAX, 00H\n\n   CPUID\n\n   Table 3-8 shows information returned, depending on the initial value\n   loaded into the EAX register.\n\n   Two types of information are returned: basic and extended function\n   information. If a value entered for CPUID.EAX is higher than the maximum\n   input value for basic or extended function for that processor then the\n   data for the highest basic information leaf is returned. For example,\n   using some Intel processors, the following is true:\n\n   CPUID.EAX = 05H (* Returns MONITOR/MWAIT leaf. *)\n\n   CPUID.EAX = 0AH (* Returns Architectural Performance Monitoring leaf. *)\n   CPUID.EAX = 0BH (* Returns Extended Topology Enumeration leaf. *)^2\n   CPUID.EAX =1FH (* Returns V2 Extended Topology Enumeration leaf. *)^2\n\n   CPUID.EAX = 80000008H (* Returns linear/physical address size data. *)\n\n   CPUID.EAX = 8000000AH (* INVALID: Returns same information as CPUID.EAX =\n   0BH. *)\n\n   If a value entered for CPUID.EAX is less than or equal to the maximum\n   input value and the leaf is not supported on that processor then 0 is\n   returned in all the registers.\n\n   When CPUID returns the highest basic leaf information as a result of an\n   invalid input EAX value, any dependence on input ECX value in the basic\n   leaf is honored.\n\n   CPUID can be executed at any privilege level to serialize instruction\n   execution. Serializing instruction execution guarantees that any\n   modifications to flags, registers, and memory for previous instructions\n   are completed before the next instruction is fetched and executed.\n\n   See also:\n\n   \u201cSerializing Instructions\u201d in Chapter 9, \u201cMultiple-Processor Management,\u201d\n   in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3A.\n\n   \u201cCaching Translation Information\u201d in Chapter 4, \u201cPaging,\u201d in the Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A.\n\n     1. On Intel 64 processors, CPUID clears the high 32 bits of the\n     RAX/RBX/RCX/RDX registers in all modes.\n\n     2. CPUID leaf 1FH is a preferred superset to leaf 0BH. Intel recommends\n     first checking for the existence of CPUID leaf 1FH before using leaf\n     0BH.\n\nInitial \nEAX     \nValue   \nAX      \nBasic CPUID Information\n0H      EAX Maximum Input Value for Basic CPUID Information. EBX \u201cGenu\u201d ECX \u201cntel\u201d EDX \u201cineI\u201d   \n        EAX Version Information: Type, Family, Model, and Stepping ID (see Figure 3-6). EBX     \n        Bits 07-00: Brand Index. Bits 15-08: CLFLUSH line size (Value \u2217 8 = cache line size in  \n        bytes; used also by CLFLUSHOPT). Bits 23-16: Maximum number of addressable IDs for      \n        logical processors in this physical package*. Bits 31-24: Initial APIC ID**. ECX        \n01H     Feature Information (see Figure 3-7 and Table 3-10). EDX Feature Information (see       \n        Figure 3-8 and Table 3-11). NOTES: *                                                    \n        Thenearestpower-of-2integerthatisnotsmallerthanEBX[23:16]isthenumberofuniqueinitialAPIC \n        IDs reserved for addressing different logical processors in a physical package. This    \n        field is only valid if CPUID.1.EDX.HTT[bit 28]= 1. ** The 8-bit initial APIC ID in      \n        EBX[31:24] is replaced by the 32-bit x2APIC ID, available in Leaf 0BH and Leaf 1FH.     \n02H     EAX Cache and TLB Information (see Table 3-12). EBX Cache and TLB Information. ECX      \n        Cache and TLB Information. EDX Cache and TLB Information.                               \n        EAX Reserved. EBX Reserved. ECX Bits 00-31 of 96-bit processor serial number.           \n        (Available in Pentium III processor only; otherwise, the value in this register is      \n        reserved.) EDX Bits 32-63 of 96-bit processor serial number. (Available in Pentium III  \n03H     processor only; otherwise, the value in this register is reserved.) NOTES: Processor    \n        serial number (PSN) is not supported in the Pentium 4 processor or later. On all        \n        models, use the PSN flag (returned using CPUID) to check for PSN support before         \n        accessing the feature.                                                                  \nCPUID leaves above 2 and below 80000000H are visible only when IA32_MISC_ENABLE[bit 22] has its\ndefault value of 0.\nDeterministic Cache Parameters Leaf (Initial EAX Value = 04H)\n        NOTES: Leaf 04H output depends on the initial value in ECX.* See also: \u201cINPUT EAX =     \n04H     04H: Returns Deterministic Cache Parameters for Each Level\u201d on page 251. EAX Bits       \n        04-00: Cache Type Field. 0 = Null - No more caches. 1 = Data Cache. 2 = Instruction     \n        Cache. 3 = Unified Cache. 4-31 = Reserved.                                              \n\n   Table 3-8. Information Returned by CPUID Instruction\n\n   Initial EAX Value Information Provided about the Processor                 \n                     Bits 07-05: Cache Level (starts at 1). Bit 08: Self      \n                     Initializing cache level (does not need SW               \n                     initialization). Bit 09: Fully Associative cache. Bits   \n                     13-10: Reserved. Bits 25-14: Maximum number of           \n                     addressable IDs for logical processors sharing this      \n                     cache**, ***. Bits 31-26: Maximum number of addressable  \n                     IDs for processor cores in the physical package**, ****, \n                     *****. EBX Bits 11-00: L = System Coherency Line Size**. \n                     Bits 21-12: P = Physical Line partitions**. Bits 31-22:  \n                     W = Ways of associativity**. ECX Bits 31-00: S = Number  \n                     of Sets**. EDX Bit 00: Write-Back Invalidate/Invalidate. \n                     0 = WBINVD/INVD from threads sharing this cache acts     \n                     upon lower level caches for threads sharing this cache.  \n                     1 = WBINVD/INVD is not guaranteed to act upon lower      \n                     level caches of non-originating threads sharing this     \n                     cache. Bit 01: Cache Inclusiveness. 0 = Cache is not     \n                     inclusive of lower cache levels. 1 = Cache is inclusive  \n                     of lower cache levels. Bit 02: Complex Cache Indexing. 0 \n                     = Direct mapped cache. 1 = A complex function is used to \n                     index the cache, potentially using all address bits.     \n                     Bits 31-03: Reserved = 0. NOTES: * If ECX contains an    \n                     invalid sub leaf index, EAX/EBX/ECX/EDX return 0.        \n                     Sub-leaf index n+1 is invalid if sub-leaf n returns      \n                     EAX[4:0] as 0. ** Add one to the return value to get the \n                     result. ***The nearest power-of-2 integer that is not    \n                     smaller than (1 + EAX[25:14]) is the number of unique    \n                     initial APIC IDs reserved for addressing different       \n                     logical processors sharing this cache. **** The nearest  \n                     power-of-2 integer that is not smaller than (1 +         \n                     EAX[31:26]) is the number of unique Core_IDs reserved    \n                     for addressing different processor cores in a physical   \n                     package. Core ID is a subset of bits of the initial APIC \n                     ID. ***** The returned value is constant for valid       \n                     initial values in ECX. Valid ECX values start from 0.    \n   MONITOR/MWAIT Leaf (Initial EAX Value = 05H)\n                     EAX Bits 15-00: Smallest monitor-line size in bytes      \n                     (default is processor's monitor granularity). Bits       \n                     31-16: Reserved = 0. EBX Bits 15-00: Largest             \n                     monitor-line size in bytes (default is processor's       \n                     monitor granularity). Bits 31-16: Reserved = 0. ECX Bit  \n                     00: Enumeration of Monitor-Mwait extensions (beyond EAX  \n                     and EBX registers) supported. Bit 01: Supports treating  \n                     interrupts as break-event for MWAIT, even when           \n   05H               interrupts disabled. Bits 31-02: Reserved. EDX Bits      \n                     03-00: Number of C0* sub C-states supported using MWAIT. \n                     Bits 07-04: Number of C1* sub C-states supported using   \n                     MWAIT. Bits 11-08: Number of C2* sub C-states supported  \n                     using MWAIT. Bits 15-12: Number of C3* sub C-states      \n                     supported using MWAIT. Bits 19-16: Number of C4* sub     \n                     C-states supported using MWAIT. Bits 23-20: Number of    \n                     C5* sub C-states supported using MWAIT. Bits 27-24:      \n                     Number of C6* sub C-states supported using MWAIT. Bits   \n                     31-28: Number of C7* sub C-states supported using MWAIT. \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\nInitial \nEAX     \nValue   \nAX      \n        NOTE: *                                                                                         \n        ThedefinitionofC0throughC7statesforMWAITextensionareprocessor-specificC-states,notACPIC-states. \nThermal and Power Management Leaf (Initial EAX Value = 06H)\n        EAX Bit 00: Digital temperature sensor is supported if set. Bit 01: Intel Turbo Boost           \n        Technology available (see description of IA32_MISC_ENABLE[38]). Bit 02: ARAT.                   \n        APIC-Timer-always-running feature is supported if set. Bit 03: Reserved. Bit 04: PLN. Power     \n        limit notification controls are supported if set. Bit 05: ECMD. Clock modulation duty cycle     \n        extension is supported if set. Bit 06: PTM. Package thermal management is supported if set. Bit \n        07: HWP. HWP base registers (IA32_PM_ENABLE[bit 0], IA32_HWP_CAPABILITIES, IA32_HWP_RE-QUEST,   \n        IA32_HWP_STATUS) are supported if set. Bit 08: HWP_Notification. IA32_HWP_INTERRUPT MSR is      \n        supported if set. Bit 09: HWP_Activity_Window. IA32_HWP_REQUEST[bits 41:32] is supported if     \n        set. Bit 10: HWP_Energy_Performance_Preference. IA32_HWP_REQUEST[bits 31:24] is supported if    \n        set. Bit 11: HWP_Package_Level_Request. IA32_HWP_REQUEST_PKG MSR is supported if set. Bit 12:   \n        Reserved. Bit 13: HDC. HDC base registers IA32_PKG_HDC_CTL, IA32_PM_CTL1, IA32_THREAD_STALL     \n        MSRs are supported if set. Bit 14: Intel\u00ae Turbo Boost Max Technology 3.0 available. Bit 15: HWP \n        Capabilities. Highest Performance change is supported if set. Bit 16: HWP PECI override is      \n        supported if set. Bit 17: Flexible HWP is supported if set. Bit 18: Fast access mode for the    \n06H     IA32_HWP_REQUEST MSR is supported if set. Bit 19: HW_FEEDBACK. IA32_HW_FEEDBACK_PTR MSR,        \n        IA32_HW_FEEDBACK_CONFIG MSR, IA32_PACK-AGE_THERM_STATUS MSR bit 26, and                         \n        IA32_PACKAGE_THERM_INTERRUPT MSR bit 25 are supported if set. Bit 20: Ignoring Idle Logical     \n        Processor HWP request is supported if set. Bits 22-21: Reserved. Bit 23: Intel\u00ae Thread Director \n        supported if set. IA32_HW_FEEDBACK_CHAR and IA32_HW_FEEDBACK_-THREAD_CONFIG MSRs are supported  \n        if set. Bit 24: IA32_THERM_INTERRUPT MSR bit 25 is supported if set. Bits 31-25: Reserved. EBX  \n        Bits 03-00: Number of Interrupt Thresholds in Digital Thermal Sensor. Bits 31-04: Reserved. ECX \n        Bit 00: Hardware Coordination Feedback Capability (Presence of IA32_MPERF and IA32_APERF). The  \n        capability to provide a measure of delivered processor performance (since last reset of the     \n        counters), as a percentage of the expected processor performance when running at the TSC        \n        frequency. Bits 02-01: Reserved = 0. Bit 03: The processor supports performance-energy bias     \n        preference if CPUID.06H:ECX.SETBH[bit 3] is set and it also implies the presence of a new       \n        architectural MSR called IA32_ENERGY_PERF_BIAS (1B0H). Bits 07-04: Reserved = 0. Bits 15-08:    \n        Number of Intel\u00ae Thread Director classes supported by the processor. Information for that many  \n        classes is written into the Intel Thread Director Table by the hardware. Bits 31-16: Reserved = \n        0.                                                                                              \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX  \n   Value AX     \n                EDX Bits 07-00: Bitmap of supported hardware feedback         \n                interface capabilities. 0 = When set to 1, indicates support  \n                for performance capability reporting. 1 = When set to 1,      \n                indicates support for energy efficiency capability reporting. \n                2-7 = Reserved Bits 11-08: Enumerates the size of the         \n                hardware feedback interface structure in number of 4 KB       \n                pages; add one to the return value to get the result. Bits    \n                31-16: Index (starting at 0) of this logical processor's row  \n                in the hardware feedback interface structure. Note that on    \n                some parts the index may be same for multiple logical         \n                processors. On some parts the indices may not be contiguous,  \n                i.e., there may be unused rows in the hardware feedback       \n                interface structure. NOTE: Bits 0 and 1 will always be set    \n                together.                                                     \n   Structured Extended Feature Flags Enumeration Leaf (Initial EAX Value =\n   07H, ECX = 0)\n                EAX Bits 31-00: Reports the maximum input value for supported \n                leaf 7 sub-leaves. EBX Bit 00: FSGSBASE. Supports             \n                RDFSBASE/RDGSBASE/WRFSBASE/WRGSBASE if 1. Bit 01:             \n                IA32_TSC_ADJUST MSR is supported if 1. Bit 02: SGX. Supports  \n                Intel\u00ae Software Guard Extensions (Intel\u00ae SGX Extensions) if   \n                1. Bit 03: BMI1. Bit 04: HLE. Bit 05: AVX2. Supports Intel\u00ae   \n                Advanced Vector Extensions 2 (Intel\u00ae AVX2) if 1. Bit 06:      \n                FDP_EXCPTN_ONLY. x87 FPU Data Pointer updated only on x87     \n                exceptions if 1. Bit 07: SMEP. Supports Supervisor-Mode       \n                Execution Prevention if 1. Bit 08: BMI2. Bit 09: Supports     \n                Enhanced REP MOVSB/STOSB if 1. Bit 10: INVPCID. If 1,         \n                supports INVPCID instruction for system software that manages \n                process-context identifiers. Bit 11: RTM. Bit 12: RDT-M.      \n   07H          Supports Intel\u00ae Resource Director Technology (Intel\u00ae RDT)     \n                Monitoring capability if 1. Bit 13: Deprecates FPU CS and FPU \n                DS values if 1. Bit 14: MPX. Supports Intel\u00ae Memory           \n                Protection Extensions if 1. Bit 15: RDT-A. Supports Intel\u00ae    \n                Resource Director Technology (Intel\u00ae RDT) Allocation          \n                capability if 1. Bit 16: AVX512F. Bit 17: AVX512DQ. Bit 18:   \n                RDSEED. Bit 19: ADX. Bit 20: SMAP. Supports Supervisor-Mode   \n                Access Prevention (and the CLAC/STAC instructions) if 1. Bit  \n                21: AVX512_IFMA. Bit 22: Reserved. Bit 23: CLFLUSHOPT. Bit    \n                24: CLWB. Bit 25: Intel Processor Trace. Bit 26: AVX512PF.    \n                (Intel\u00ae Xeon PhiTM only.) Bit 27: AVX512ER. (Intel\u00ae Xeon      \n                PhiTM only.) Bit 28: AVX512CD. Bit 29: SHA. supports Intel\u00ae   \n                Secure Hash Algorithm Extensions (Intel\u00ae SHA Extensions) if   \n                1. Bit 30: AVX512BW. Bit 31: AVX512VL.                        \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Information Provided about the Processor                       \n   Value       \n               ECX Bit 00: PREFETCHWT1. (Intel\u00ae Xeon PhiTM only.) Bit 01:     \n               AVX512_VBMI. Bit 02: UMIP. Supports user-mode instruction      \n               prevention if 1. Bit 03: PKU. Supports protection keys for     \n               user-mode pages if 1. Bit 04: OSPKE. If 1, OS has set CR4.PKE  \n               to enable protection keys (and the RDPKRU/WRPKRU               \n               instructions). Bit 05: WAITPKG. Bit 06: AVX512_VBMI2. Bit 07:  \n               CET_SS. Supports CET shadow stack features if 1. Processors    \n               that set this bit define bits 1:0 of the IA32_U_CET and        \n               IA32_S_CET MSRs. Enumerates support for the following MSRs:    \n               IA32_INTERRUPT_SPP_TABLE_ADDR, IA32_PL3_SSP, IA32_PL2_SSP,     \n               IA32_PL1_SSP, and IA32_PL0_SSP. Bit 08: GFNI. Bit 09: VAES.    \n               Bit 10: VPCLMULQDQ. Bit 11: AVX512_VNNI. Bit 12:               \n               AVX512_BITALG. Bits 13: TME_EN. If 1, the following MSRs are   \n               supported: IA32_TME_CAPABILITY, IA32_TME_ACTIVATE,             \n               IA32_TME_EXCLUDE_MASK, and IA32_TME_EXCLUDE_BASE. Bit 14:      \n               AVX512_VPOPCNTDQ. Bit 15: Reserved. Bit 16: LA57. Supports     \n               57-bit linear addresses and five-level paging if 1. Bits       \n               21-17: The value of MAWAU used by the BNDLDX and BNDSTX        \n               instructions in 64-bit mode. Bit 22: RDPID and IA32_TSC_AUX    \n               are available if 1. Bit 23: KL. Supports Key Locker if 1. Bit  \n               24: BUS_LOCK_DETECT. If 1, indicates support for OS bus-lock   \n               detection. Bit 25: CLDEMOTE. Supports cache line demote if 1.  \n               Bit 26: Reserved. Bit 27: MOVDIRI. Supports MOVDIRI if 1. Bit  \n               28: MOVDIR64B. Supports MOVDIR64B if 1. Bit 29: ENQCMD.        \n               Supports Enqueue Stores if 1. Bit 30: SGX_LC. Supports SGX     \n               Launch Configuration if 1. Bit 31: PKS. Supports protection    \n               keys for supervisor-mode pages if 1. EDX Bit 00: Reserved. Bit \n               01: SGX-KEYS. If 1, Attestation Services for Intel\u00ae SGX is     \n               supported. Bit 02: AVX512_4VNNIW. (Intel\u00ae Xeon PhiTM only.)    \n               Bit 03: AVX512_4FMAPS. (Intel\u00ae Xeon PhiTM only.) Bit 04: Fast  \n               Short REP MOV. Bit 05: UINTR. If 1, the processor supports     \n               user interrupts. Bits 07-06: Reserved. Bit 08:                 \n               AVX512_VP2INTERSECT. Bit 09: SRBDS_CTRL. If 1, enumerates      \n               support for the IA32_MCU_OPT_CTRL MSR and indicates its bit 0  \n               (RNGDS_MITG_DIS) is also supported. Bit 10: MD_CLEAR           \n               supported. Bit 11: RTM_ALWAYS_ABORT. If set, any execution of  \n               XBEGIN immediately aborts and transitions to the specified     \n               fallback address. Bit 12: Reserved. Bit 13: If 1,              \n               RTM_FORCE_ABORT supported. Processors that set this bit        \n               support the IA32_TSX_FORCE_ABORT MSR. They allow software to   \n               set IA32_TSX_FORCE_ABORT[0] (RTM_FORCE_ABORT). Bit 14:         \n               SERIALIZE. Bit 15: Hybrid. If 1, the processor is identified   \n               as a hybrid part. If CPUID.0.MAXLEAF \u2265 1AH and CPUID.1A.EAX =\u0338 \n               0, then the Native Model ID Enumeration Leaf 1AH exists. Bit   \n               16: TSXLDTRK. If 1, the processor supports Intel TSX           \n               suspend/resume of load address tracking.                       \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value Information Provided about the Processor                 \n                     Bit 17: Reserved. Bit 18: PCONFIG. Supports PCONFIG if   \n                     1. Bit 19: Architectural LBRs. If 1, indicates support   \n                     for architectural LBRs. Bit 20: CET_IBT. Supports CET    \n                     indirect branch tracking features if 1. Processors that  \n                     set this bit define bits 5:2 and bits 63:10 of the       \n                     IA32_U_CET and IA32_S_CET MSRs. Bit 21: Reserved. Bit    \n                     22: AMX-BF16. If 1, the processor supports tile          \n                     computational operations on bfloat16 numbers. Bit 23:    \n                     AVX512_FP16. Bit 24: AMX-TILE. If 1, the processor       \n                     supports tile architecture. Bits 25: AMX-INT8. If 1, the \n                     processor supports tile computational operations on      \n                     8-bit integers. Bit 26: Enumerates support for indirect  \n                     branch restricted speculation (IBRS) and the indirect    \n                     branch predictor barrier (IBPB). Processors that set     \n                     this bit support the IA32_SPEC_CTRL MSR and the          \n                     IA32_PRED_CMD MSR. They allow software to set            \n                     IA32_SPEC_CTRL[0] (IBRS) and IA32_PRED_CMD[0] (IBPB).    \n                     Bit 27: Enumerates support for single thread indirect    \n                     branch predictors (STIBP). Processors that set this bit  \n                     support the IA32_SPEC_CTRL MSR. They allow software to   \n                     set IA32_SPEC_CTRL[1] (STIBP). Bit 28: Enumerates        \n                     support for L1D_FLUSH. Processors that set this bit      \n                     support the IA32_FLUSH_CMD MSR. They allow software to   \n                     set IA32_FLUSH_CMD[0] (L1D_FLUSH). Bit 29: Enumerates    \n                     support for the IA32_ARCH_CAPABILITIES MSR. Bit 30:      \n                     Enumerates support for the IA32_CORE_CAPABILITIES MSR.   \n                     IA32_CORE_CAPABILITIES is an architectural MSR that      \n                     enumerates model-specific features. A bit being set in   \n                     this MSR indicates that a model specific feature is      \n                     supported; software must still consult CPUID             \n                     family/model/stepping to determine the behavior of the   \n                     enumerated feature as features enumerated in             \n                     IA32_CORE_CAPABILITIES may have different behavior on    \n                     different processor models. Some of these features may   \n                     have behavior that is consistent across processor models \n                     (and for which consultation of CPUID                     \n                     family/model/stepping is not necessary); such features   \n                     are identified explicitly where they are documented in   \n                     this manual. Bit 31: Enumerates support for Speculative  \n                     Store Bypass Disable (SSBD). Processors that set this    \n                     bit support the IA32_SPEC_CTRL MSR. They allow software  \n                     to set IA32_SPEC_CTRL[2] (SSBD). NOTE: * If ECX contains \n                     an invalid sub-leaf index, EAX/EBX/ECX/EDX return 0.     \n                     Sub-leaf index n is invalid if n exceeds the value that  \n                     sub-leaf 0 returns in EAX.                               \n   Structured Extended Feature Enumeration Sub-leaf (Initial EAX Value = 07H,\n   ECX = 1)          \n                     NOTES: Leaf 07H output depends on the initial value in   \n                     ECX. If ECX contains an invalid sub leaf index,          \n                     EAX/EBX/ECX/EDX return 0. EAX This field reports 0 if    \n                     the sub-leaf index, 1, is invalid. Bits 03-00: Reserved. \n                     Bit 04: AVX-VNNI. AVX (VEX-encoded) versions of the      \n                     Vector Neural Network Instructions. Bit 05: AVX512_BF16. \n                     Vector Neural Network Instructions supporting BFLOAT16   \n   07H               inputs and conversion instructions from IEEE single      \n                     precision. Bits 09-06: Reserved. Bit 10: If 1, supports  \n                     fast zero-length REP MOVSB. Bit 11: If 1, supports fast  \n                     short REP STOSB. Bit 12: If 1, supports fast short REP   \n                     CMPSB, REP SCASB. Bits 21-13: Reserved. Bit 22: HRESET.  \n                     If 1, supports history reset via the HRESET instruction  \n                     and the IA32_HRESET_ENABLE MSR. When set, indicates that \n                     the Processor History Reset Leaf (EAX = 20H) is valid.   \n                     Bits 29-23: Reserved.                                    \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value Information Provided about the Processor                 \n                     Bit 30: INVD_DISABLE_POST_BIOS_DONE. If 1, supports INVD \n                     execution prevention after BIOS Done. Bit 31: Reserved.  \n                     EBX This field reports 0 if the sub-leaf index, 1, is    \n                     invalid. Bit 00: Enumerates the presence of the          \n                     IA32_PPIN and IA32_PPIN_CTL MSRs. If 1, these MSRs are   \n                     supported. Bits 31-01: Reserved. ECX This field reports  \n                     0 if the sub-leaf index, 1, is invalid; otherwise it is  \n                     reserved. EDX This field reports 0 if the sub-leaf       \n                     index, 1, is invalid. Bits 17-00: Reserved. Bit 18:      \n                     CET_SSS. If 1, indicates that an operating system can    \n                     enable supervisor shadow stacks as long as it ensures    \n                     that a supervisor shadow stack cannot become prematurely \n                     busy due to page faults (see Section 17.2.3 of the       \n                     Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s  \n                     Manual, Volume 1). When emulating the CPUID instruction, \n                     a virtual-machine monitor (VMM) should return this bit   \n                     as 1 only if it ensures that VM exits cannot cause a     \n                     guest supervisor shadow stack to appear to be            \n                     prematurely busy. Such a VMM could set the \u201cprematurely  \n                     busy shadow stack\u201d VM-exit control and use the           \n                     additional information that it provides. Bits 31-19:     \n                     Reserved.                                                \n   Structured Extended Feature Enumeration Sub-leaf (Initial EAX Value = 07H,\n   ECX = 2)          \n                     NOTES: Leaf 07H output depends on the initial value in   \n                     ECX. If ECX contains an invalid sub leaf index,          \n                     EAX/EBX/ECX/EDX return 0. EAX This field reports 0 if    \n                     the sub-leaf index, 2, is invalid; otherwise it is       \n                     reserved. EBX This field reports 0 if the sub-leaf       \n                     index, 2, is invalid; otherwise it is reserved. ECX This \n                     field reports 0 if the sub-leaf index, 2, is invalid;    \n                     otherwise it is reserved. EDX This field reports 0 if    \n                     the sub-leaf index, 2, is invalid. Bit 00: PSFD. If 1,   \n                     indicates bit 7 of the IA32_SPEC_CTRL MSR is supported.  \n                     Bit 7 of this MSR disables Fast Store Forwarding         \n                     Predictor without disabling Speculative Store Bypass.    \n                     Bit 01: IPRED_CTRL. If 1, indicates bits 3 and 4 of the  \n                     IA32_SPEC_CTRL MSR are supported. Bit 3 of this MSR      \n   07H               enables IPRED_DIS control for CPL3. Bit 4 of this MSR    \n                     enables IPRED_DIS control for CPL0/1/2. Bit 02:          \n                     RRSBA_CTRL. If 1, indicates bits 5 and 6 of the          \n                     IA32_SPEC_CTRL MSR are supported. Bit 5 of this MSR      \n                     disables RRSBA behavior for CPL3. Bit 6 of this MSR      \n                     disables RRSBA behavior for CPL0/1/2. Bit 03: DDPD_U. If \n                     1, indicates bit 8 of the IA32_SPEC_CTRL MSR is          \n                     supported. Bit 8 of this MSR disables Data Dependent     \n                     Prefetcher. Bit 04: BHI_CTRL. If 1, indicates bit 10 of  \n                     the IA32_SPEC_CTRL MSR is supported. Bit 10 of this MSR  \n                     enables BHI_DIS_S behavior. Bit 05: MCDT_NO. Processors  \n                     that enumerate this bit as 1 do not exhibit MXCSR        \n                     Configuration Dependent Timing (MCDT) behavior and do    \n                     not need to be mitigated to avoid data-dependent         \n                     behavior for certain instructions. Bits 31-06: Reserved. \n   Direct Cache Access Information Leaf (Initial EAX Value = 09H)\n                     EAX Value of bits [31:0] of IA32_PLATFORM_DCA_CAP MSR    \n   09H               (address 1F8H). EBX Reserved. ECX Reserved. EDX          \n                     Reserved.                                                \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value \n   AX                \n   Architectural Performance Monitoring Leaf (Initial EAX Value = 0AH)\n                     EAX Bits 07-00: Version ID of architectural performance  \n                     monitoring. Bits 15-08: Number of general-purpose        \n                     performance monitoring counter per logical processor.    \n                     Bits 23-16: Bit width of general-purpose, performance    \n                     monitoring counter. Bits 31-24: Length of EBX bit vector \n                     to enumerate architectural performance monitoring        \n                     events. Architectural event x is supported if EBX[x]=0   \n                     && EAX[31:24]>x. EBX Bit 00: Core cycle event not        \n                     available if 1 or if EAX[31:24]<1. Bit 01: Instruction   \n                     retired event not available if 1 or if EAX[31:24]<2. Bit \n                     02: Reference cycles event not available if 1 or if      \n                     EAX[31:24]<3. Bit 03: Last-level cache reference event   \n                     not available if 1 or if EAX[31:24]<4. Bit 04:           \n                     Last-level cache misses event not available if 1 or if   \n   0AH               EAX[31:24]<5. Bit 05: Branch instruction retired event   \n                     not available if 1 or if EAX[31:24]<6. Bit 06: Branch    \n                     mispredict retired event not available if 1 or if        \n                     EAX[31:24]<7. Bit 07: Top-down slots event not available \n                     if 1 or if EAX[31:24]<8. Bits 31-08: Reserved = 0. ECX   \n                     Bits 31-00: Supported fixed counters bit mask.           \n                     Fixed-function performance counter 'i' is supported if   \n                     bit \u2018i\u2019 is 1 (first counter index starts at zero). It is \n                     recommended to use the following logic to determine if a \n                     Fixed Counter is supported: FxCtr[i]_is_supported :=     \n                     ECX[i] || (EDX[4:0] > i); EDX Bits 04-00: Number of      \n                     contiguous fixed-function performance counters starting  \n                     from 0 (if Version ID > 1). Bits 12-05: Bit width of     \n                     fixed-function performance counters (if Version ID > 1). \n                     Bits 14-13: Reserved = 0. Bit 15: AnyThread deprecation. \n                     Bits 31-16: Reserved = 0.                                \n   Extended Topology Enumeration Leaf (Initial EAX Value = 0BH)\n                     NOTES: CPUID leaf 1FH is a preferred superset to leaf    \n                     0BH. Intel recommends first checking for the existence   \n                     of Leaf 1FH before using leaf 0BH. The sub-leaves of     \n                     CPUID leaf 0BH describe an ordered hierarchy of logical  \n                     processors starting from the smallest-scoped domain of a \n                     Logical Processor (sub-leaf index 0) to the Core domain  \n                     (sub-leaf index 1) to the largest-scoped domain (the     \n                     last valid sub-leaf index) that is implicitly            \n                     subordinate to the unenumerated highest-scoped domain of \n                     the processor package (socket). The details of each      \n                     valid domain is enumerated by a corresponding sub-leaf.  \n                     Details for a domain include its type and how all        \n                     instances of that domain determine the number of logical \n                     processors and x2 APIC ID partitioning at the next       \n                     higher-scoped domain. The ordering of domains within the \n                     hierarchy is fixed architecturally as shown below. For a \n   0BH               given processor, not all domains may be relevant or      \n                     enumerated; however, the logical processor and core      \n                     domains are always enumerated. For two valid sub-leaves  \n                     N and N+1, sub-leaf N+1 represents the next immediate    \n                     higher-scoped domain with respect to the domain of       \n                     sub-leaf N for the given processor. If sub-leaf index    \n                     \u201cN\u201d returns an invalid domain type in ECX[15:08] (00H),  \n                     then all sub-leaves with an index greater than \u201cN\u201d shall \n                     also return an invalid domain type. A sub-leaf returning \n                     an invalid domain always returns 0 in EAX and EBX. EAX   \n                     Bits 04-00: The number of bits that the x2APIC ID must   \n                     be shifted to the right to address instances of the next \n                     higher-scoped domain. When logical processor is not      \n                     supported by the processor, the value of this field at   \n                     the Logical Processor domain sub-leaf may be returned as \n                     either 0 (no allocated bits in the x2APIC ID) or 1 (one  \n                     allocated bit in the x2APIC ID); software should plan    \n                     accordingly. Bits 31-05: Reserved.                       \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX \n   Value AX    \n               EBX Bits 15-00: The number of logical     \n               processors across all instances of this   \n               domain within the next higher-scoped      \n               domain. (For example, in a processor      \n               socket/package comprising \u201cM\u201d dies of \u201cN\u201d \n               cores each, where each core has \u201cL\u201d       \n               logical processors, the \u201cdie\u201d domain      \n               sub-leaf value of this field would be     \n               M*N*L.) This number reflects              \n               configuration as shipped by Intel. Note,  \n               software must not use this field to       \n               enumerate processor topology*. Bits       \n               31-16: Reserved. ECX Bits 07-00: The      \n               input ECX sub-leaf index. Bits 15-08:     \n               Domain Type. This field provides an       \n               identification value which indicates the  \n               domain as shown below. Although domains              \n               are ordered, their assigned                          \n               identification values are not and                    \n               software should not depend on it. Domain             \n               Domain Type Identification Value                     \n               Hierarchy Lowest Logical Processor 1      \n               Highest Core 2 (Note that enumeration     \n               values of 0 and 3-255 are reserved.) Bits Processor Extended\n               31-16: Reserved. EDX Bits 31-00: x2APIC   State Enumeration\n               ID of the current logical processor.      Main Leaf (Initial\n               NOTES: * Software must not use the value  EAX Value = 0DH, ECX\n               of EBX[15:0] to enumerate processor       = 0)\n               topology of the system. The value is only \n               intended for display and diagnostic       \n               purposes. The actual number of logical    \n               processors available to                   \n               BIOS/OS/Applications may be different     \n               from the value of EBX[15:0], depending on \n               software and platform hardware            \n               configurations.                           \n               NOTES: Leaf 0DH main leaf (ECX = 0). EAX  \n               Bits 31-00: Reports the supported bits of \n               the lower 32 bits of XCR0. XCR0[n] can be \n               set to 1 only if EAX[n] is 1. Bit 00: x87 \n               state. Bit 01: SSE state. Bit 02: AVX     \n               state. Bits 04-03: MPX state. Bits 07-05: \n               AVX-512 state. Bit 08: Used for IA32_XSS. \n               Bit 09: PKRU state. Bits 16-10: Used for  \n               IA32_XSS. Bit 17: TILECFG state. Bit 18:  \n               TILEDATA state. Bits 31-19: Reserved. EBX \n               Bits 31-00: Maximum size (bytes, from the \n               beginning of the XSAVE/XRSTOR save area)  \n   0DH         required by enabled features in XCR0. May \n               be different than ECX if some features at \n               the end of the XSAVE save area are not    \n               enabled. ECX Bit 31-00: Maximum size      \n               (bytes, from the beginning of the         \n               XSAVE/XRSTOR save area) of the            \n               XSAVE/XRSTOR save area required by all    \n               supported features in the processor,      \n               i.e., all the valid bit fields in XCR0.   \n               EDX Bit 31-00: Reports the supported bits \n               of the upper 32 bits of XCR0. XCR0[n+32]  \n               can be set to 1 only if EDX[n] is 1. Bits \n               31-00: Reserved.                          \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value AX \n   Processor Extended State Enumeration Sub-leaf (Initial EAX Value = 0DH,\n   ECX = 1)             \n                        EAX Bit 00: XSAVEOPT is available. Bit 01: Supports   \n                        XSAVEC and the compacted form of XRSTOR if set. Bit   \n                        02: Supports XGETBV with ECX = 1 if set. Bit 03:      \n                        Supports XSAVES/XRSTORS and IA32_XSS if set. Bit 04:  \n                        Supports extended feature disable (XFD) if set. Bits  \n                        31-05: Reserved. EBX Bits 31-00: The size in bytes of \n                        the XSAVE area containing all states enabled by XCRO  \n                        | IA32_XSS. NOTES: If EAX[3] is enumerated as 0 and   \n                        EAX[1] is enumerated as 1, EBX enumerates the size of \n                        the XSAVE area containing all states enabled by XCRO. \n                        If EAX[1] and EAX[3] are both enumerated as 0, EBX    \n   0DH                  enumerates zero. ECX Bits 31-00: Reports the          \n                        supported bits of the lower 32 bits of the IA32_XSS   \n                        MSR. IA32_XSS[n] can be set to 1 only if ECX[n] is 1. \n                        Bits 07-00: Used for XCR0. Bit 08: PT state. Bit 09:  \n                        Used for XCR0. Bit 10: PASID state. Bit 11: CET user  \n                        state. Bit 12: CET supervisor state. Bit 13: HDC      \n                        state. Bit 14: UINTR state. Bit 15: LBR state (only   \n                        for the architectural LBR feature). Bit 16: HWP       \n                        state. Bits 18-17: Used for XCR0. Bits 31-19:         \n                        Reserved. EDX Bits 31-00: Reports the supported bits  \n                        of the upper 32 bits of the IA32_XSS MSR.             \n                        IA32_XSS[n+32] can be set to 1 only if EDX[n] is 1.   \n                        Bits 31-00: Reserved.                                 \n   Processor Extended State Enumeration Sub-leaves (Initial EAX Value = 0DH,\n   ECX = n, n > 1)      \n                        NOTES: Leaf 0DH output depends on the initial value   \n                        in ECX. Each sub-leaf index (starting at position 2)  \n                        is supported if it corresponds to a supported bit in  \n                        either the XCR0 register or the IA32_XSS MSR. * If    \n                        ECX contains an invalid sub-leaf index,               \n                        EAX/EBX/ECX/EDX return 0. Sub-leaf n (0 \u2264 n \u2264 31) is  \n                        invalid if sub-leaf 0 returns 0 in EAX[n] and         \n                        sub-leaf 1 returns 0 in ECX[n]. Sub-leaf n (32 \u2264 n \u2264  \n                        63) is invalid if sub-leaf 0 returns 0 in EDX[n-32]   \n                        and sub-leaf 1 returns 0 in EDX[n-32]. EAX Bits       \n                        31-00: The size in bytes (from the offset specified   \n                        in EBX) of the save area for an extended state        \n                        feature associated with a valid sub-leaf index, n.    \n   0DH                  EBX Bits 31-00: The offset in bytes of this extended  \n                        state component\u2019s save area from the beginning of the \n                        XSAVE/XRSTOR area. This field reports 0 if the        \n                        sub-leaf index, n, does not map to a valid bit in the \n                        XCR0 register*. ECX Bit 00 is set if the bit n        \n                        (corresponding to the sub-leaf index) is supported in \n                        the IA32_XSS MSR; it is clear if bit n is instead     \n                        supported in XCR0. Bit 01 is set if, when the         \n                        compacted format of an XSAVE area is used, this       \n                        extended state component located on the next 64-byte  \n                        boundary following the preceding state component      \n                        (otherwise, it is located immediately following the   \n                        preceding state component). Bits 31-02 are reserved.  \n                        This field reports 0 if the sub-leaf index, n, is     \n                        invalid*.                                             \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value AX \n                        EDX This field reports 0 if the sub-leaf index, n, is \n                        invalid*; otherwise it is reserved.                   \n   Intel\u00ae Resource Director Technology (Intel\u00ae RDT) Monitoring Enumeration\n   Sub-leaf (Initial EAX Value = 0FH, ECX = 0)\n                        NOTES: Leaf 0FH output depends on the initial value   \n                        in ECX. Sub-leaf index 0 reports valid resource type  \n                        starting at bit position 1 of EDX. EAX Reserved. EBX  \n   0FH                  Bits 31-00: Maximum range (zero-based) of RMID within \n                        this physical processor of all types. ECX Reserved.   \n                        EDX Bit 00: Reserved. Bit 01: Supports L3 Cache Intel \n                        RDT Monitoring if 1. Bits 31-02: Reserved.            \n   L3 Cache Intel\u00ae RDT Monitoring Capability Enumeration Sub-leaf (Initial\n   EAX Value = 0FH, ECX = 1)\n                        NOTES: Leaf 0FH output depends on the initial value   \n                        in ECX. EAX Bits 07-00:The counter width is encoded   \n                        as an offset from 24b. A value of zero in this field  \n                        indicates that 24-bit counters are supported. A value \n                        of 8 in this field indicates that 32-bit counters are \n                        supported. Bit 08: If 1, indicates the presence of an \n                        overflow bit in the IA32_QM_CTR MSR (bit 61). Bit 09: \n                        If 1, indicates the presence of non-CPU agent Intel   \n   0FH                  RDT CMT support. Bit 10: If 1, indicates the presence \n                        of non-CPU agent Intel RDT MBM support. Bits 31-11:   \n                        Reserved. EBX Bits 31-00: Conversion factor from      \n                        reported IA32_QM_CTR value to occupancy metric        \n                        (bytes) and Memory Bandwidth Monitoring (MBM)         \n                        metrics. ECX Maximum range (zero-based) of RMID of    \n                        this resource type. EDX Bit 00: Supports L3 occupancy \n                        monitoring if 1. Bit 01: Supports L3 Total Bandwidth  \n                        monitoring if 1. Bit 02: Supports L3 Local Bandwidth  \n                        monitoring if 1. Bits 31-03: Reserved.                \n   Intel\u00ae Resource Director Technology (Intel\u00ae RDT) Allocation Enumeration\n   Sub-leaf (Initial EAX Value = 10H, ECX = 0)\n                        NOTES: Leaf 10H output depends on the initial value   \n                        in ECX. Sub-leaf index 0 reports valid resource       \n                        identification (ResID) starting at bit position 1 of  \n   10H                  EBX. EAX Reserved. EBX Bit 00: Reserved. Bit 01:      \n                        Supports L3 Cache Allocation Technology if 1. Bit 02: \n                        Supports L2 Cache Allocation Technology if 1. Bit 03: \n                        Supports Memory Bandwidth Allocation if 1. Bits       \n                        31-04: Reserved. ECX Reserved. EDX Reserved.          \n   L3 Cache Allocation Technology Enumeration Sub-leaf (Initial EAX Value =\n   10H, ECX = ResID =1) \n   10H                  NOTES: Leaf 10H output depends on the initial value   \n                        in ECX.                                               \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value  \n   AX                 \n                      EAX Bits 04-00: Length of the capacity bit mask for the \n                      corresponding ResID. Add one to the return value to get \n                      the result. Bits 31-05: Reserved. EBX Bits 31-00:       \n                      Bit-granular map of isolation/contention of allocation  \n                      units. ECX Bit 00: Reserved. Bit 01: If 1, indicates L3 \n                      CAT for non-CPU agents is supported. Bit 02: If 1,      \n                      indicates L3 Code and Data Prioritization Technology is \n                      supported. Bit 03: If 1, indicates non-contiguous       \n                      capacity bitmask is supported. The bits that are set in \n                      the various IA32_L3_MASK_n registers do not have to be  \n                      contiguous. Bits 31-04: Reserved. EDX Bits 15-00:       \n                      Highest Class of Service (COS) number supported for     \n                      this ResID. Bits 31-16: Reserved.                       \n   L2 Cache Allocation Technology Enumeration Sub-leaf (Initial EAX Value =\n   10H, ECX = ResID =2)\n                      NOTES: Leaf 10H output depends on the initial value in  \n                      ECX. EAX Bits 04-00: Length of the capacity bit mask    \n                      for the corresponding ResID. Add one to the return      \n                      value to get the result. Bits 31-05: Reserved. EBX Bits \n                      31-00: Bit-granular map of isolation/contention of      \n                      allocation units. ECX Bits 01-00: Reserved. Bit 02:     \n   10H                CDP. If 1, indicates L2 Code and Data Prioritization    \n                      Technology is supported. Bit 03: If 1, indicates        \n                      non-contiguous capacity bitmask is supported. The bits  \n                      that are set in the various IA32_L2_MASK_n registers do \n                      not have to be contiguous. Bits 31-04: Reserved. EDX    \n                      Bits 15-00: Highest COS number supported for this       \n                      ResID. Bits 31-16: Reserved.                            \n   Memory Bandwidth Allocation Enumeration Sub-leaf (Initial EAX Value = 10H,\n   ECX = ResID =3)    \n                      NOTES: Leaf 10H output depends on the initial value in  \n                      ECX. EAX Bits 11-00: Reports the maximum MBA throttling \n                      value supported for the corresponding ResID. Add one to \n                      the return value to get the result. Bits 31-12:         \n   10H                Reserved. EBX Bits 31-00: Reserved. ECX Bits 01-00:     \n                      Reserved. Bit 02: Reports whether the response of the   \n                      delay values is linear. Bits 31-03: Reserved. EDX Bits  \n                      15-00: Highest COS number supported for this ResID.     \n                      Bits 31-16: Reserved.                                   \n   Intel\u00ae SGX Capability Enumeration Leaf, Sub-leaf 0 (Initial EAX Value =\n   12H, ECX = 0)      \n   12H                NOTES: Leaf 12H sub-leaf 0 (ECX = 0) is supported if    \n                      CPUID.(EAX=07H, ECX=0H):EBX[SGX] = 1.                   \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value Information Provided about the Processor                 \n                     EAX Bit 00: SGX1. If 1, Indicates Intel SGX supports the \n                     collection of SGX1 leaf functions. Bit 01: SGX2. If 1,   \n                     Indicates Intel SGX supports the collection of SGX2 leaf \n                     functions. Bits 04-02: Reserved. Bit 05: If 1, indicates \n                     Intel SGX supports ENCLV instruction leaves              \n                     EINCVIRTCHILD, EDECVIRTCHILD, and ESETCONTEXT. Bit 06:   \n                     If 1, indicates Intel SGX supports ENCLS instruction     \n                     leaves ETRACKC, ERDINFO, ELDBC, and ELDUC. Bit 07: If 1, \n                     indicates Intel SGX supports ENCLU instruction leaf      \n                     EVERIFYREPORT2. Bits 09-08: Reserved. Bit 10: If 1,      \n                     indicates Intel SGX supports ENCLS instruction leaf      \n                     EUPDATESVN. Bit 11: If 1, indicates Intel SGX supports   \n                     ENCLU instruction leaf EDECCSSA. Bits 31-12: Reserved.   \n                     EBX Bits 31-00: MISCSELECT. Bit vector of supported      \n                     extended SGX features. ECX Bits 31-00: Reserved. EDX     \n                     Bits 07-00: MaxEnclaveSize_Not64. The maximum supported  \n                     enclave size in non-64-bit mode is 2^(EDX[7:0]). Bits    \n                     15-08: MaxEnclaveSize_64. The maximum supported enclave  \n                     size in 64-bit mode is 2^(EDX[15:8]). Bits 31-16:        \n                     Reserved.                                                \n   Intel SGX Attributes Enumeration Leaf, Sub-leaf 1 (Initial EAX Value =\n   12H, ECX = 1)     \n                     NOTES: Leaf 12H sub-leaf 1 (ECX = 1) is supported if     \n                     CPUID.(EAX=07H, ECX=0H):EBX[SGX] = 1. EAX Bit 31-00:     \n                     Reports the valid bits of SECS.ATTRIBUTES[31:0] that     \n                     software can set with ECREATE. EBX Bit 31-00: Reports    \n   12H               the valid bits of SECS.ATTRIBUTES[63:32] that software   \n                     can set with ECREATE. ECX Bit 31-00: Reports the valid   \n                     bits of SECS.ATTRIBUTES[95:64] that software can set     \n                     with ECREATE. EDX Bit 31-00: Reports the valid bits of   \n                     SECS.ATTRIBUTES[127:96] that software can set with       \n                     ECREATE.                                                 \n   Intel\u00ae SGX EPC Enumeration Leaf, Sub-leaves (Initial EAX Value = 12H, ECX\n   = 2 or higher)    \n                     NOTES: Leaf 12H sub-leaf 2 or higher (ECX >= 2) is       \n                     supported if CPUID.(EAX=07H, ECX=0H):EBX[SGX] = 1. For   \n                     sub-leaves (ECX = 2 or higher), definition of            \n                     EDX,ECX,EBX,EAX[31:4] depends on the sub-leaf type       \n   12H               listed below. EAX Bit 03-00: Sub-leaf Type 0000b:        \n                     Indicates this sub-leaf is invalid. 0001b: This sub-leaf \n                     enumerates an EPC section. EBX:EAX and EDX:ECX provide   \n                     information on the Enclave Page Cache (EPC) section. All \n                     other type encodings are reserved. Type 0000b. This      \n                     sub-leaf is invalid. EDX:ECX:EBX:EAX return 0.           \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value Information Provided about the Processor                 \n                     Type 0001b. This sub-leaf enumerates an EPC sections     \n                     with EDX:ECX, EBX:EAX defined as follows. EAX[11:04]:    \n                     Reserved (enumerate 0). EAX[31:12]: Bits 31:12 of the    \n                     physical address of the base of the EPC section.         \n                     EBX[19:00]: Bits 51:32 of the physical address of the    \n                     base of the EPC section. EBX[31:20]: Reserved.           \n                     ECX[03:00]: EPC section property encoding defined as     \n                     follows: If ECX[3:0] = 0000b, then all bits of the       \n                     EDX:ECX pair are enumerated as 0. If ECX[3:0] = 0001b,   \n                     then this section has confidentiality and integrity      \n                     protection. If ECX[3:0] = 0010b, then this section has   \n                     confidentiality protection only. All other encodings are \n                     reserved. ECX[11:04]: Reserved (enumerate 0).            \n                     ECX[31:12]: Bits 31:12 of the size of the corresponding  \n                     EPC section within the Processor Reserved Memory.        \n                     EDX[19:00]: Bits 51:32 of the size of the corresponding  \n                     EPC section within the Processor Reserved Memory.        \n                     EDX[31:20]: Reserved.                                    \n   Intel\u00ae Processor Trace Enumeration Main Leaf (Initial EAX Value = 14H, ECX\n   = 0)              \n                     NOTES: Leaf 14H main leaf (ECX = 0). EAX Bits 31-00:     \n                     Reports the maximum sub-leaf supported in leaf 14H. EBX  \n                     Bit 00: If 1, indicates that IA32_RTIT_CTL.CR3Filter can \n                     be set to 1, and that IA32_RTIT_CR3_MATCH MSR can be     \n                     accessed. Bit 01: If 1, indicates support of             \n                     Configurable PSB and Cycle-Accurate Mode. Bit 02: If 1,  \n                     indicates support of IP Filtering, TraceStop filtering,  \n                     and preservation of Intel PT MSRs across warm reset. Bit \n                     03: If 1, indicates support of MTC timing packet and     \n                     suppression of COFI-based packets. Bit 04: If 1,         \n                     indicates support of PTWRITE. Writes can set             \n                     IA32_RTIT_CTL[12] (PTWEn) and IA32_RTIT_CTL[5]           \n                     (FUPonPTW), and PTWRITE can generate packets. Bit 05: If \n                     1, indicates support of Power Event Trace. Writes can    \n                     set IA32_RTIT_CTL[4] (PwrEvtEn), enabling Power Event    \n                     Trace packet generation. Bit 06: If 1, indicates support \n                     for PSB and PMI preservation. Writes can set             \n                     IA32_RTIT_CTL[56] (InjectPsbPmiOnEnable), enabling the   \n   14H               processor to set IA32_RTIT_STATUS[7] (PendTopaPMI)       \n                     and/or IA32_R-TIT_STATUS[6] (PendPSB) in order to        \n                     preserve ToPA PMIs and/or PSBs otherwise lost due to     \n                     Intel PT disable. Writes can also set PendToPAPMI and    \n                     PendPSB. Bit 07: If 1, writes can set IA32_RTIT_CTL[31]  \n                     (EventEn), enabling Event Trace packet generation. Bit   \n                     08: If 1, writes can set IA32_RTIT_CTL[55] (DisTNT),     \n                     disabling TNT packet generation. Bit 31-09: Reserved.    \n                     ECX Bit 00: If 1, Tracing can be enabled with            \n                     IA32_RTIT_CTL.ToPA = 1, hence utilizing the ToPA output  \n                     scheme; IA32_RTIT_OUTPUT_BASE and                        \n                     IA32_RTIT_OUTPUT_MASK_PTRS MSRs can be accessed. Bit 01: \n                     If 1, ToPA tables can hold any number of output entries, \n                     up to the maximum allowed by the MaskOrTableOffset field \n                     of IA32_RTIT_OUTPUT_MASK_PTRS. Bit 02: If 1, indicates   \n                     support of Single-Range Output scheme. Bit 03: If 1,     \n                     indicates support of output to Trace Transport           \n                     subsystem. Bit 30-04: Reserved. Bit 31: If 1, generated  \n                     packets which contain IP payloads have LIP values, which \n                     include the CS base component. EDX Bits 31-00: Reserved. \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value   \n   AX                  \n   Intel\u00ae Processor Trace Enumeration Sub-leaf (Initial EAX Value = 14H, ECX\n   = 1)                \n                       EAX Bits 02-00: Number of configurable Address Ranges  \n                       for filtering. Bits 15-03: Reserved. Bits 31-16:       \n                       Bitmap of supported MTC period encodings. EBX Bits     \n   14H                 15-00: Bitmap of supported Cycle Threshold value       \n                       encodings. Bit 31-16: Bitmap of supported Configurable \n                       PSB frequency encodings. ECX Bits 31-00: Reserved. EDX \n                       Bits 31-00: Reserved.                                  \n   Time Stamp Counter and Nominal Core Crystal Clock Information Leaf\n   (Initial EAX Value = 15H)\n                       NOTES: If EBX[31:0] is 0, the TSC/\u201dcore crystal clock\u201d \n                       ratio is not enumerated. EBX[31:0]/EAX[31:0] indicates \n                       the ratio of the TSC frequency and the core crystal    \n                       clock frequency. If ECX is 0, the nominal core crystal \n                       clock frequency is not enumerated. \u201cTSC frequency\u201d =   \n                       \u201ccore crystal clock frequency\u201d * EBX/EAX. The core     \n                       crystal clock may differ from the reference clock, bus \n   15H                 clock, or core clock frequencies. EAX Bits 31-00: An   \n                       unsigned integer which is the denominator of the       \n                       TSC/\u201dcore crystal clock\u201d ratio. EBX Bits 31-00: An     \n                       unsigned integer which is the numerator of the         \n                       TSC/\u201dcore crystal clock\u201d ratio. ECX Bits 31-00: An     \n                       unsigned integer which is the nominal frequency of the \n                       core crystal clock in Hz. EDX Bits 31-00: Reserved =   \n                       0.                                                     \n   Processor Frequency Information Leaf (Initial EAX Value = 16H)\n                       EAX Bits 15-00: Processor Base Frequency (in MHz).     \n                       Bits 31-16: Reserved =0. EBX Bits 15-00: Maximum       \n                       Frequency (in MHz). Bits 31-16: Reserved = 0. ECX Bits \n                       15-00: Bus (Reference) Frequency (in MHz). Bits 31-16: \n                       Reserved = 0. EDX Reserved. NOTES: * Data is returned  \n                       from this interface in accordance with the processor's \n                       specification and does not reflect actual values.      \n                       Suitable use of this data includes the display of      \n   16H                 processor information in like manner to the processor  \n                       brand string and for determining the appropriate range \n                       to use when displaying processor information e.g.      \n                       frequency history graphs. The returned information     \n                       should not be used for any other purpose as the        \n                       returned information does not accurately correlate to  \n                       information / counters returned by other processor     \n                       interfaces. While a processor may support the          \n                       Processor Frequency Information leaf, fields that      \n                       return a value of zero are not supported.              \n   System-On-Chip Vendor Attribute Enumeration Main Leaf (Initial EAX Value =\n   17H, ECX = 0)       \n                       NOTES: Leaf 17H main leaf (ECX = 0). Leaf 17H output   \n                       depends on the initial value in ECX. Leaf 17H          \n   17H                 sub-leaves 1 through 3 reports SOC Vendor Brand        \n                       String. Leaf 17H is valid if MaxSOCID_Index >= 3. Leaf \n                       17H sub-leaves 4 and above are reserved.               \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value AX \n                        EAX Bits 31-00: MaxSOCID_Index. Reports the maximum   \n                        input value of supported sub-leaf in leaf 17H. EBX    \n                        Bits 15-00: SOC Vendor ID. Bit 16: IsVendorScheme. If \n                        1, the SOC Vendor ID field is assigned via an         \n                        industry standard enumeration scheme. Otherwise, the  \n                        SOC Vendor ID field is assigned by Intel. Bits 31-17: \n                        Reserved = 0. ECX Bits 31-00: Project ID. A unique    \n                        number an SOC vendor assigns to its SOC projects. EDX \n                        Bits 31-00: Stepping ID. A unique number within an    \n                        SOC project that an SOC vendor assigns.               \n   System-On-Chip Vendor Attribute Enumeration Sub-leaf (Initial EAX Value =\n   17H, ECX = 1..3)     \n                        EAX Bit 31-00: SOC Vendor Brand String. UTF-8 encoded \n                        string. EBX Bit 31-00: SOC Vendor Brand String. UTF-8 \n                        encoded string. ECX Bit 31-00: SOC Vendor Brand       \n                        String. UTF-8 encoded string. EDX Bit 31-00: SOC      \n                        Vendor Brand String. UTF-8 encoded string. NOTES:     \n   17H                  Leaf 17H output depends on the initial value in ECX.  \n                        SOC Vendor Brand String is a UTF-8 encoded string     \n                        padded with trailing bytes of 00H. The complete SOC   \n                        Vendor Brand String is constructed by concatenating   \n                        in ascending order of EAX:EBX:ECX:EDX and from the    \n                        sub-leaf 1 fragment towards sub-leaf 3.               \n   System-On-Chip Vendor Attribute Enumeration Sub-leaves (Initial EAX Value\n   = 17H, ECX > MaxSOCID_Index)\n                        NOTES: Leaf 17H output depends on the initial value   \n   17H                  in ECX. EAX Bits 31-00: Reserved = 0. EBX Bits 31-00: \n                        Reserved = 0. ECX Bits 31-00: Reserved = 0. EDX Bits  \n                        31-00: Reserved = 0.                                  \n   Deterministic Address Translation Parameters Main Leaf (Initial EAX Value\n   = 18H, ECX = 0)      \n                        NOTES: Each sub-leaf enumerates a different address   \n                        translation structure. If ECX contains an invalid     \n                        sub-leaf index, EAX/EBX/ECX/EDX return 0. Sub-leaf    \n                        index n is invalid if n exceeds the value that        \n                        sub-leaf 0 returns in EAX. A sub-leaf index is also   \n                        invalid if EDX[4:0] returns 0. Valid sub-leaves do    \n                        not need to be contiguous or in any particular order. \n                        A valid sub-leaf may be in a higher input ECX value   \n                        than an invalid sub-leaf or than a valid sub-leaf of  \n   18H                  a higher or lower-level structure. * Some unified     \n                        TLBs will allow a single TLB entry to satisfy data    \n                        read/write and instruction fetches. Others will       \n                        require separate entries (e.g., one loaded on data    \n                        read/write and another loaded on an instruction       \n                        fetch). See the Intel\u00ae 64 and IA-32 Architectures     \n                        Optimization Reference Manual for details of a        \n                        particular product. ** Add one to the return value to \n                        get the result. EAX Bits 31-00: Reports the maximum   \n                        input value of supported sub-leaf in leaf 18H.        \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value AX \n                        EBX Bit 00: 4K page size entries supported by this    \n                        structure. Bit 01: 2MB page size entries supported by \n                        this structure. Bit 02: 4MB page size entries         \n                        supported by this structure. Bit 03: 1 GB page size   \n                        entries supported by this structure. Bits 07-04:      \n                        Reserved. Bits 10-08: Partitioning (0: Soft           \n                        partitioning between the logical processors sharing   \n                        this structure). Bits 15-11: Reserved. Bits 31-16: W  \n                        = Ways of associativity. ECX Bits 31-00: S = Number   \n                        of Sets. EDX Bits 04-00: Translation cache type       \n                        field. 00000b: Null (indicates this sub-leaf is not   \n                        valid). 00001b: Data TLB. 00010b: Instruction TLB.    \n                        00011b: Unified TLB*. 00100b: Load Only TLB. Hit on   \n                        loads; fills on both loads and stores. 00101b: Store  \n                        Only TLB. Hit on stores; fill on stores. All other    \n                        encodings are reserved. Bits 07-05: Translation cache \n                        level (starts at 1). Bit 08: Fully associative        \n                        structure. Bits 13-09: Reserved. Bits 25-14: Maximum  \n                        number of addressable IDs for logical processors      \n                        sharing this translation cache.** Bits 31-26:         \n                        Reserved.                                             \n   Deterministic Address Translation Parameters Sub-leaf (Initial EAX Value =\n   18H, ECX \u2265 1)        \n                        NOTES: Each sub-leaf enumerates a different address   \n                        translation structure. If ECX contains an invalid     \n                        sub-leaf index, EAX/EBX/ECX/EDX return 0. Sub-leaf    \n                        index n is invalid if n exceeds the value that        \n                        sub-leaf 0 returns in EAX. A sub-leaf index is also   \n                        invalid if EDX[4:0] returns 0. Valid sub-leaves do    \n                        not need to be contiguous or in any particular order. \n                        A valid sub-leaf may be in a higher input ECX value   \n                        than an invalid sub-leaf or than a valid sub-leaf of  \n                        a higher or lower-level structure. * Some unified     \n                        TLBs will allow a single TLB entry to satisfy data    \n                        read/write and instruction fetches. Others will       \n                        require separate entries (e.g., one loaded on data    \n   18H                  read/write and another loaded on an instruction       \n                        fetch. See the Intel\u00ae 64 and IA-32 Architectures      \n                        Optimization Reference Manual for details of a        \n                        particular product. ** Add one to the return value to \n                        get the result. EAX Bits 31-00: Reserved. EBX Bit 00: \n                        4K page size entries supported by this structure. Bit \n                        01: 2MB page size entries supported by this           \n                        structure. Bit 02: 4MB page size entries supported by \n                        this structure. Bit 03: 1 GB page size entries        \n                        supported by this structure. Bits 07-04: Reserved.    \n                        Bits 10-08: Partitioning (0: Soft partitioning        \n                        between the logical processors sharing this           \n                        structure). Bits 15-11: Reserved. Bits 31-16: W =     \n                        Ways of associativity. ECX Bits 31-00: S = Number of  \n                        Sets.                                                 \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value \n   AX                \n                     EDX Bits 04-00: Translation cache type field. 0000b:     \n                     Null (indicates this sub-leaf is not valid). 0001b: Data \n                     TLB. 0010b: Instruction TLB. 0011b: Unified TLB*. All    \n                     other encodings are reserved. Bits 07-05: Translation    \n                     cache level (starts at 1). Bit 08: Fully associative     \n                     structure. Bits 13-09: Reserved. Bits 25-14: Maximum     \n                     number of addressable IDs for logical processors sharing \n                     this translation cache** Bits 31-26: Reserved.           \n   Key Locker Leaf (Initial EAX Value = 19H)\n                     EAX Bit 00: Key Locker restriction of CPL0-only          \n                     supported. Bit 01: Key Locker restriction of no-encrypt  \n                     supported. Bit 02: Key Locker restriction of no-decrypt  \n                     supported. Bits 31-03: Reserved. EBX Bit 00: AESKLE. If  \n                     1, the AES Key Locker instructions are fully enabled.    \n                     Bit 01: Reserved. Bit 02: If 1, the AES wide Key Locker  \n                     instructions are supported. Bit 03: Reserved. Bit 04: If \n   19H               1, the platform supports the Key Locker MSRs             \n                     (IA32_COPY_LOCAL_TO_PLATFORM,                            \n                     IA23_COPY_PLATFORM_TO_LOCAL, IA32_COPY_STATUS, and       \n                     IA32_IWKEYBACKUP_STATUS) and backing up the internal     \n                     wrapping key. Bits 31-05: Reserved. ECX Bit 00: If 1,    \n                     the NoBackup parameter to LOADIWKEY is supported. Bit    \n                     01: If 1, KeySource encoding of 1 (randomization of the  \n                     internal wrapping key) is supported. Bits 31-02:         \n                     Reserved. EDX Reserved.                                  \n   Native Model ID Enumeration Leaf (Initial EAX Value = 1AH, ECX = 0)\n                     NOTES: This leaf exists on all hybrid parts, however     \n                     this leaf is not only available on hybrid parts. The     \n                     following algorithm is used for detection of this leaf:  \n                     If CPUID.0.MAXLEAF \u2265 1AH and CPUID.1A.EAX =\u0338 0, then the \n                     leaf exists. EAX Enumerates the native model ID and core \n                     type. Bits 31-24: Core type* 10H: Reserved 20H: Intel    \n                     Atom\u00ae 30H: Reserved 40H: Intel\u00ae CoreTM Bits 23-00:       \n                     Native model ID of the core. The core-type and native    \n                     model ID can be used to uniquely identify the            \n   1AH               microarchitecture of the core. This native model ID is   \n                     not unique across core types, and not related to the     \n                     model ID reported in CPUID leaf 01H, and does not        \n                     identify the SOC. * The core type may only be used as an \n                     identification of the microarchitecture for this logical \n                     processor and its numeric value has no significance,     \n                     neither large nor small. This field neither implies nor  \n                     expresses any other attribute to this logical processor  \n                     and software should not assume any. EBX Reserved. ECX    \n                     Reserved. EDX Reserved.                                  \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value \n   AX                \n   PCONFIG Information Sub-leaf (Initial EAX Value = 1BH, ECX \u2265 0)\n                     For details on this sub-leaf, see \u201cINPUT EAX = 1BH:      \n   1BH               Returns PCONFIG Information\u201d on page 3-253. NOTE: Leaf   \n                     1BH is supported if CPUID.(EAX=07H, ECX=0H):EDX[18] = 1. \n   Last Branch Records Information Leaf (Initial EAX Value = 1CH)\n                     NOTE: This leaf pertains to the architectural feature.   \n                     EAX Bits 07-00: Supported LBR Depth Values. For each bit \n                     n set in this field, the IA32_LBR_DEPTH.DEPTH value      \n                     8*(n+1) is supported. Bits 29-08: Reserved. Bit 30: Deep \n                     C-state Reset. If set, indicates that LBRs may be        \n                     cleared on an MWAIT that requests a C-state numerically  \n                     greater than C1. Bit 31: IP Values Contain LIP. If set,  \n                     LBR IP values contain LIP. If clear, IP values contain   \n                     Effective IP. EBX Bit 00: CPL Filtering Supported. If    \n                     set, the processor supports setting IA32_LBR_CTL[2:1] to \n                     non-zero value. Bit 01: Branch Filtering Supported. If   \n   1CH               set, the processor supports setting IA32_LBR_CTL[22:16]  \n                     to nonzero value. Bit 02: Call-stack Mode Supported. If  \n                     set, the processor supports setting IA32_LBR_CTL[3] to   \n                     1. Bits 31-03: Reserved. ECX Bit 00: Mispredict Bit      \n                     Supported. IA32_LBR_x_INFO[63] holds indication of       \n                     branch misprediction (MISPRED). Bit 01: Timed LBRs       \n                     Supported. IA32_LBR_x_INFO[15:0] holds CPU cycles since  \n                     last LBR entry (CYC_CNT), and IA32_LBR_x_INFO[60] holds  \n                     an indication of whether the value held there is valid   \n                     (CYC_CNT_VALID). Bit 02: Branch Type Field Supported.    \n                     IA32_LBR_INFO_x[59:56] holds indication of the recorded  \n                     operation's branch type (BR_TYPE). Bits 31-03: Reserved. \n                     EDX Bits 31-00: Reserved.                                \n   Tile Information Main Leaf (Initial EAX Value = 1DH, ECX = 0)\n                     NOTES: For sub-leaves of 1DH, they are indexed by the    \n                     palette id. Leaf 1DH sub-leaves 2 and above are          \n   1DH               reserved. EAX Bits 31-00: max_palette. Highest numbered  \n                     palette sub-leaf. Value = 1. EBX Bits 31-00: Reserved =  \n                     0. ECX Bits 31-00: Reserved = 0. EDX Bits 31-00:         \n                     Reserved = 0.                                            \n   Tile Palette 1 Sub-leaf (Initial EAX Value = 1DH, ECX = 1)\n                     EAX Bits 15-00: Palette 1 total_tile_bytes. Value =      \n                     8192. Bits 31-16: Palette 1 bytes_per_tile. Value =      \n                     1024. EBX Bits 15-00: Palette 1 bytes_per_row. Value =   \n   1DH               64. Bits 31-16: Palette 1 max_names (number of tile      \n                     registers). Value = 8. ECX Bits 15-00: Palette 1         \n                     max_rows. Value = 16. Bits 31-16: Reserved = 0. EDX Bits \n                     31-00: Reserved = 0.                                     \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX Value AX \n   TMUL Information Main Leaf (Initial EAX Value = 1EH, ECX = 0)\n                        NOTE: Leaf 1EH sub-leaves 1 and above are reserved.   \n                        EAX Bits 31-00: Reserved = 0. EBX Bits 07-00:         \n   1EH                  tmul_maxk (rows or columns). Value = 16. Bits 23-08:  \n                        tmul_maxn (column bytes). Value = 64. Bits 31-24:     \n                        Reserved = 0. ECX Bits 31-00: Reserved = 0. EDX Bits  \n                        31-00: Reserved = 0.                                  \n   V2 Extended Topology Enumeration Leaf (Initial EAX Value = 1FH)\n                        NOTES: CPUID leaf 1FH is a preferred superset to leaf \n                        0BH. Intel recommends using leaf 1FH when available   \n                        rather than leaf 0BH and ensuring that any leaf 0BH   \n                        algorithms are updated to support leaf 1FH. The       \n                        sub-leaves of CPUID leaf 1FH describe an ordered      \n                        hierarchy of logical processors starting from the     \n                        smallest-scoped domain of a Logical Processor         \n                        (sub-leaf index 0) to the Core domain (sub-leaf index \n                        1) to the largest-scoped domain (the last valid       \n                        sub-leaf index) that is implicitly subordinate to the \n                        unenumerated highest-scoped domain of the processor   \n                        package (socket). The details of each valid domain is \n                        enumerated by a corresponding sub-leaf. Details for a \n                        domain include its type and how all instances of that \n                        domain determine the number of logical processors and \n                        x2 APIC ID partitioning at the next higher-scoped     \n                        domain. The ordering of domains within the hierarchy  \n                        is fixed architecturally as shown below. For a given  \n                        processor, not all domains may be relevant or         \n                        enumerated; however, the logical processor and core   \n                        domains are always enumerated. As an example, a       \n                        processor may report an ordered hierarchy consisting  \n                        only of \u201cLogical Processor,\u201d \u201cCore,\u201d and \u201cDie.\u201d For   \n                        two valid sub-leaves N and N+1, sub-leaf N+1          \n                        represents the next immediate higher-scoped domain    \n                        with respect to the domain of sub-leaf N for the      \n   1FH                  given processor. If sub-leaf index \u201cN\u201d returns an     \n                        invalid domain type in ECX[15:08] (00H), then all     \n                        sub-leaves with an index greater than \u201cN\u201d shall also  \n                        return an invalid domain type. A sub-leaf returning   \n                        an invalid domain always returns 0 in EAX and EBX.    \n                        EAX Bits 04-00: The number of bits that the x2APIC ID \n                        must be shifted to the right to address instances of  \n                        the next higher-scoped domain. When logical processor \n                        is not supported by the processor, the value of this  \n                        field at the Logical Processor domain sub-leaf may be \n                        returned as either 0 (no allocated bits in the x2APIC \n                        ID) or 1 (one allocated bit in the x2APIC ID);        \n                        software should plan accordingly. Bits 31-05:         \n                        Reserved. EBX Bits 15-00: The number of logical       \n                        processors across all instances of this domain within \n                        the next higher-scoped domain relative to this        \n                        current logical processor. (For example, in a         \n                        processor socket/package comprising \u201cM\u201d dies of \u201cN\u201d   \n                        cores each, where each core has \u201cL\u201d logical           \n                        processors, the \u201cdie\u201d domain sub-leaf value of this   \n                        field would be M*N*L. In an asymmetric topology this  \n                        would be the summation of the value across the lower  \n                        domain level instances to create each upper domain    \n                        level instance.) This number reflects configuration   \n                        as shipped by Intel. Note, software must not use this \n                        field to enumerate processor topology*. Bits 31-16:   \n                        Reserved.                                             \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\n   Initial EAX \n   Value AX    \n               ECX Bits 07-00: The input ECX sub-leaf      \n               index. Bits 15-08: Domain Type. This field  \n               provides an identification value which      \n               indicates the domain as shown below.        \n               Although domains are ordered, as also shown \n               below, their assigned identification values \n               are not and software should not depend on   \n               it. (For example, if a new domain between   \n               core and module is specified, it will have  \n               an identification value higher than 5.)     \n               Hierarchy Domain Domain Type Identification \n               Value Lowest Logical Processor 1 ... Core 2 \n               ... Module 3 ... Tile 4 ... Die 5 ...       \n               DieGrp 6 Highest Package/Socket (implied)             \n               (Note that enumeration values of 0 and                \n               7-255 are reserved.) Bits 31-16: Reserved.            \n               EDX Bits 31-00: x2APIC ID of the current              \n               logical processor. It is always valid and   \n               does not vary with the sub-leaf index in    \n               ECX. NOTES: * Software must not use the     Processor History\n               value of EBX[15:0] to enumerate processor   Reset Sub-leaf\n               topology of the system. The value is only   (Initial EAX Value\n               intended for display and diagnostic         = 20H, ECX = 0)\n               purposes. The actual number of logical      \n               processors available to                     \n               BIOS/OS/Applications may be different from  \n               the value of EBX[15:0], depending on        \n               software and platform hardware              \n               configurations.                             \n               EAX Reports the maximum number of           \n               sub-leaves that are supported in leaf 20H.  \n               EBX Indicates which bits may be set in the  \n               IA32_HRESET_ENABLE MSR to enable reset of   \n               different components of hardware-maintained \n   20H         history. Bit 00: Indicates support for both \n               HRESET\u2019s EAX[0] parameter, and              \n               IA32_HRESET_ENABLE[0] set by the OS to      \n               enable reset of Intel\u00ae Thread Director      \n               history. Bits 31-01: Reserved = 0. ECX      \n               Reserved. EDX Reserved.                     \n   Unimplemented CPUID Leaf Functions\n               Invalid. No existing or future CPU will     \n               return processor identification or feature  \n               information if the initial EAX value is     \n               21H. If the value returned by CPUID.0:EAX   \n   21H         (the maximum input value for basic CPUID    \n               information) is at least 21H, 0 is returned \n               in the registers EAX, EBX, ECX, and EDX.    \n               Otherwise, the data for the highest basic   \n               information leaf is returned.               \n               Invalid. No existing or future CPU will     \n   40000000H \u2212 return processor identification or feature  \n   4FFFFFFFH   information if the initial EAX value is in  \n               the range 40000000H to 4FFFFFFFH.           \n   Extended Function CPUID Information\n               EAX Maximum Input Value for Extended        \n   80000000H   Function CPUID Information. EBX Reserved.   \n               ECX Reserved. EDX Reserved.                 \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\nInitial   Information Provided about the Processor                                               \nEAX Value \n          EAX Extended Processor Signature and Feature Bits. EBX Reserved. ECX Bit 00: LAHF/SAHF \n          available in 64-bit mode.* Bits 04-01: Reserved. Bit 05: LZCNT. Bits 07-06: Reserved.  \n          Bit 08: PREFETCHW. Bits 31-09: Reserved. EDX Bits 10-00: Reserved. Bit 11:             \n          SYSCALL/SYSRET.** Bits 19-12: Reserved = 0. Bit 20: Execute Disable Bit available.     \n80000001H Bits 25-21: Reserved = 0. Bit 26: 1-GByte pages are available if 1. Bit 27: RDTSCP and \n          IA32_TSC_AUX are available if 1. Bit 28: Reserved = 0. Bit 29: Intel^\u00ae 64 Architecture \n          available if 1. Bits 31-30: Reserved = 0. NOTES: *                                     \n          LAHFandSAHFarealwaysavailableinothermodes,regardlessoftheenumerationofthisfeatureflag. \n          ** Intel processors support SYSCALL and SYSRET only in 64-bit mode. This feature flag  \n          is always enumerated as 0 outside 64-bit mode.                                         \n80000002H EAX Processor Brand String. EBX Processor Brand String Continued. ECX Processor Brand  \n          String Continued. EDX Processor Brand String Continued.                                \n80000003H EAX Processor Brand String Continued. EBX Processor Brand String Continued. ECX        \n          Processor Brand String Continued. EDX Processor Brand String Continued.                \n80000004H EAX Processor Brand String Continued. EBX Processor Brand String Continued. ECX        \n          Processor Brand String Continued. EDX Processor Brand String Continued.                \n80000005H EAX Reserved = 0. EBX Reserved = 0. ECX Reserved = 0. EDX Reserved = 0.                \n          EAX Reserved = 0. EBX Reserved = 0. ECX Bits 07-00: Cache Line size in bytes. Bits     \n80000006H 11-08: Reserved. Bits 15-12: L2 Associativity field *. Bits 31-16: Cache size in 1K    \n          units. EDX Reserved = 0.                                                               \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\nInitial   Information Provided about the Processor                                             \nEAX Value \n          NOTES: * L2 associativity field encodings: 00H - Disabled 08H - 16 ways 01H - 1 way  \n          (direct mapped) 09H - Reserved 02H - 2 ways 0AH - 32 ways 03H - Reserved 0BH - 48    \n          ways 04H - 4 ways 0CH - 64 ways 05H - Reserved 0DH - 96 ways 06H - 8 ways 0EH - 128  \n          ways 07H - See CPUID leaf 04H, sub-leaf 2** 0FH - Fully associative ** CPUID leaf    \n          04H provides details of deterministic cache parameters, including the L2 cache in    \n          sub-leaf 2                                                                           \n80000007H EAX Reserved = 0. EBX Reserved = 0. ECX Reserved = 0. EDX Bits 07-00: Reserved = 0.  \n          Bit 08: Invariant TSC available if 1. Bits 31-09: Reserved = 0.                      \n          EAX Linear/Physical Address size. Bits 07-00: #Physical Address Bits*. Bits 15-08:   \n          #Linear Address Bits. Bits 31-16: Reserved = 0. EBX Bits 08-00: Reserved = 0. Bit    \n          09: WBNOINVD is available if 1. Bits 31-10: Reserved = 0. ECX Reserved = 0. EDX      \n80000008H Reserved = 0. NOTES: *                                                               \n          IfCPUID.80000008H:EAX[7:0]issupported,themaximumphysicaladdressnumbersupportedshould \n          come from this field. If TME-MK is enabled, the number of bits that can be used to   \n          address physical memory is CPUID.80000008H:EAX[7:0] - IA32_TME_ACTIVATE[35:32].      \n\n   Table 3-8. Information Returned by CPUID Instruction (Contd.)\n\nINPUT EAX = 0: Returns CPUID\u2019s Highest Value for Basic Processor Information and\nthe Vendor Identification String \u00b6\n\n   When CPUID executes with EAX set to 0, the processor returns the highest\n   value the CPUID recognizes for returning basic processor information. The\n   value is returned in the EAX register and is processor specific.\n\n   A vendor identification string is also returned in EBX, EDX, and ECX. For\n   Intel processors, the string is \u201cGenuineIntel\u201d and is expressed:\n\n   EBX := 756e6547h (* \u201cGenu\u201d, with G in the low eight bits of BL *)\n\n   EDX := 49656e69h (* \u201cineI\u201d, with i in the low eight bits of DL *)\n\n   ECX := 6c65746eh (* \u201cntel\u201d, with n in the low eight bits of CL *)\n\nINPUT EAX = 80000000H: Returns CPUID\u2019s Highest Value for Extended Processor\nInformation \u00b6\n\n   When CPUID executes with EAX set to 80000000H, the processor returns the\n   highest value the processor recognizes for returning extended processor\n   information. The value is returned in the EAX register and is processor\n   specific.\n\nIA32_BIOS_SIGN_ID Returns Microcode Update Signature \u00b6\n\n   For processors that support the microcode update facility, the\n   IA32_BIOS_SIGN_ID MSR is loaded with the update signature whenever CPUID\n   executes. The signature is returned in the upper DWORD. For details, see\n   Chapter 10 in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 3A.\n\nINPUT EAX = 01H: Returns Model, Family, Stepping Information \u00b6\n\n   When CPUID executes with EAX set to 01H, version information is returned\n   in EAX (see Figure 3-6). For example: model, family, and processor type\n   for the Intel Xeon processor 5100 series is as follows:\n\n     * Model \u2014 1111B\n     * Family \u2014 0101B\n     * Processor Type \u2014 00B\n\n   See Table 3-9 for available processor type values. Stepping IDs are\n   provided as needed.\n\n   31 2827 2019 161514131211 8 7 4 3 0 Stepping Extended Extended Family\n   Model EAX ID Family ID Model ID ID Extended Family ID (0) Extended Model\n   ID (0) Processor Type Family (0FH for the Pentium 4 Processor Family)\n   Model Reserved Figure 3-6. Version Information Returned by CPUID in EAX\n\n   Type                                                   Encoding \n   Original OEM Processor                                 00B      \n   Intel OverDrive^\u00ae Processor                            01B      \n   Dual processor (not applicable to Intel486 processors) 10B      \n   Intel reserved                                         11B      \n\n   Table 3-9. Processor Type Field\n\n     See Chapter 20 in the Intel^\u00ae 64 and IA-32 Architectures Software\n     Developer\u2019s Manual, Volume 1, for information on identifying earlier\n     IA-32 processors.\n\n   The Extended Family ID needs to be examined only when the Family ID is\n   0FH. Integrate the fields into a display using the following rule:\n\n   IF Family_ID =\u0338 0FH\n\n   THEN DisplayFamily = Family_ID;\n\n   ELSE DisplayFamily = Extended_Family_ID + Family_ID;\n\n   FI;\n\n   (* Show DisplayFamily as HEX field. *)\n\n   The Extended Model ID needs to be examined only when the Family ID is 06H\n   or 0FH. Integrate the field into a display using the following rule:\n\n   IF (Family_ID = 06H or Family_ID = 0FH)\n\n   THEN DisplayModel = (Extended_Model_ID \u00ab 4) + Model_ID;\n\n   (* Right justify and zero-extend 4-bit field; display Model_ID as HEX\n   field.*)\n\n   ELSE DisplayModel = Model_ID;\n\n   FI;\n\n   (* Show DisplayModel as HEX field. *)\n\nINPUT EAX = 01H: Returns Additional Information in EBX \u00b6\n\n   When CPUID executes with EAX set to 01H, additional information is\n   returned to the EBX register:\n\n     * Brand index (low byte of EBX) \u2014 this number provides an entry into a\n       brand string table that contains brand strings for IA-32 processors.\n       More information about this field is provided later in this section.\n     * CLFLUSH instruction cache line size (second byte of EBX) \u2014 this number\n       indicates the size of the cache line flushed by the CLFLUSH and\n       CLFLUSHOPT instructions in 8-byte increments. This field was\n       introduced in the Pentium 4 processor.\n     * Local APIC ID (high byte of EBX) \u2014 this number is the 8-bit ID that is\n       assigned to the local APIC on the processor during power up. This\n       field was introduced in the Pentium 4 processor.\n\nINPUT EAX = 01H: Returns Feature Information in ECX and EDX \u00b6\n\n   When CPUID executes with EAX set to 01H, feature information is returned\n   in ECX and EDX.\n\n     * Figure 3-7 and Table 3-10 show encodings for ECX.\n     * Figure 3-8 and Table 3-11 show encodings for EDX.\n\n   For all feature flags, a 1 indicates that the feature is supported. Use\n   Intel to properly interpret feature flags.\n\n     Software must confirm that a processor feature is present using feature\n     flags returned by CPUID prior to using the feature. Software should not\n     depend on future offerings retaining all features.\n\n   31302928272625242322212019181716151413121110 9 8 7 6 5 4 3 2 1 0 ECX       \n   RDRAND F16C AVX OSXSAVE XSAVE AES TSC-Deadline POPCNT MOVBE x2APIC SSE4_2  \n   \u2014 SSE4.2 SSE4_1 \u2014 SSE4.1 DCA \u2014 Direct Cache Access PCID \u2014 Process-context  \n   Identifiers PDCM \u2014 Perf/Debug Capability MSR xTPR Update Control           \n   CMPXCHG16B FMA \u2014 Fused Multiply Add SDBG CNXT-ID \u2014 L1 Context ID SSSE3 \u2014   \n   SSSE3 Extensions TM2 \u2014 Thermal Monitor 2 EIST \u2014 Enhanced Intel SpeedStep\u00ae  \n   Technology SMX \u2014 Safer Mode Extensions VMX \u2014 Virtual Machine Extensions    \n   DS-CPL \u2014 CPL Qualified Debug Store MONITOR \u2014 MONITOR/MWAIT DTES64 \u2014 64-bit \n   DS Area PCLMULQDQ \u2014 Carryless Multiplication SSE3 \u2014 SSE3 Extensions        \n   OM16524b Reserved                                                          \n\n   Figure 3-7. Feature Information Returned in the ECX Register\n\n   Bit # Mnemonic            Description                                      \n                             Streaming SIMD Extensions 3 (SSE3). A value of 1 \n   0     SSE3                indicates the processor supports this            \n                             technology.                                      \n   1     PCLMULQDQ           PCLMULQDQ. A value of 1 indicates the processor  \n                             supports the PCLMULQDQ instruction.              \n   2     DTES64              64-bit DS Area. A value of 1 indicates the       \n                             processor supports DS area using 64-bit layout.  \n   3     MONITOR             MONITOR/MWAIT. A value of 1 indicates the        \n                             processor supports this feature.                 \n                             CPL Qualified Debug Store. A value of 1          \n   4     DS-CPL              indicates the processor supports the extensions  \n                             to the Debug Store feature to allow for branch   \n                             message storage qualified by CPL.                \n                             Virtual Machine Extensions. A value of 1         \n   5     VMX                 indicates that the processor supports this       \n                             technology.                                      \n                             Safer Mode Extensions. A value of 1 indicates    \n   6     SMX                 that the processor supports this technology. See \n                             Chapter 7, \u201cSafer Mode Extensions Reference.\u201d    \n                             Enhanced Intel SpeedStep\u00ae technology. A value of \n   7     EIST                1 indicates that the processor supports this     \n                             technology.                                      \n   8     TM2                 Thermal Monitor 2. A value of 1 indicates        \n                             whether the processor supports this technology.  \n                             A value of 1 indicates the presence of the       \n   9     SSSE3               Supplemental Streaming SIMD Extensions 3         \n                             (SSSE3). A value of 0 indicates the instruction  \n                             extensions are not present in the processor.     \n                             L1 Context ID. A value of 1 indicates the L1     \n                             data cache mode can be set to either adaptive    \n   10    CNXT-ID             mode or shared mode. A value of 0 indicates this \n                             feature is not supported. See definition of the  \n                             IA32_MISC_ENABLE MSR Bit 24 (L1 Data Cache       \n                             Context Mode) for details.                       \n   11    SDBG                A value of 1 indicates the processor supports    \n                             IA32_DEBUG_INTERFACE MSR for silicon debug.      \n   12    FMA                 A value of 1 indicates the processor supports    \n                             FMA extensions using YMM state.                  \n                             CMPXCHG16B Available. A value of 1 indicates     \n                             that the feature is available. See the           \n   13    CMPXCHG16B          \u201cCMPXCHG8B/CMPXCHG16B\u2014Compare and Exchange       \n                             Bytes\u201d section in this chapter for a             \n                             description.                                     \n                             xTPR Update Control. A value of 1 indicates that \n   14    xTPR Update Control the processor supports changing                  \n                             IA32_MISC_ENABLE[bit 23].                        \n                             Perfmon and Debug Capability: A value of 1       \n   15    PDCM                indicates the processor supports the performance \n                             and debug feature indication MSR                 \n                             IA32_PERF_CAPABILITIES.                          \n   16    Reserved            Reserved                                         \n                             Process-context identifiers. A value of 1        \n   17    PCID                indicates that the processor supports PCIDs and  \n                             that software may set CR4.PCIDE to 1.            \n                             A value of 1 indicates the processor supports    \n   18    DCA                 the ability to prefetch data from a memory       \n                             mapped device.                                   \n   19    SSE4_1              A value of 1 indicates that the processor        \n                             supports SSE4.1.                                 \n   20    SSE4_2              A value of 1 indicates that the processor        \n                             supports SSE4.2.                                 \n   21    x2APIC              A value of 1 indicates that the processor        \n                             supports x2APIC feature.                         \n   22    MOVBE               A value of 1 indicates that the processor        \n                             supports MOVBE instruction.                      \n   23    POPCNT              A value of 1 indicates that the processor        \n                             supports the POPCNT instruction.                 \n                             A value of 1 indicates that the processor\u2019s      \n   24    TSC-Deadline        local APIC timer supports one-shot operation     \n                             using a TSC deadline value.                      \n   25    AESNI               A value of 1 indicates that the processor        \n                             supports the AESNI instruction extensions.       \n                             A value of 1 indicates that the processor        \n   26    XSAVE               supports the XSAVE/XRSTOR processor extended     \n                             states feature, the XSETBV/XGETBV instructions,  \n                             and XCR0.                                        \n                             A value of 1 indicates that the OS has set       \n                             CR4.OSXSAVE[bit 18] to enable XSETBV/XGETBV      \n   27    OSXSAVE             instructions to access XCR0 and to support       \n                             processor extended state management using        \n                             XSAVE/XRSTOR.                                    \n   28    AVX                 A value of 1 indicates the processor supports    \n                             the AVX instruction extensions.                  \n   29    F16C                A value of 1 indicates that processor supports   \n                             16-bit floating-point conversion instructions.   \n   30    RDRAND              A value of 1 indicates that processor supports   \n                             RDRAND instruction.                              \n   31    Not Used            Always returns 0.                                \n\n   Table 3-10. Feature Information Returned in the ECX Register\n   31302928272625242322212019181716151413121110 9 8 7 6 5 4 3 2 1 0 EDX\n   PBE\u2013Pend. Brk. EN. TM\u2013Therm. Monitor HTT\u2013Multi-threading SS\u2013Self Snoop\n   SSE2\u2013SSE2 Extensions SSE\u2013SSE Extensions FXSR\u2013FXSAVE/FXRSTOR MMX\u2013MMX\n   Technology ACPI\u2013Thermal Monitor and Clock Ctrl DS\u2013Debug Store\n   CLFSH\u2013CLFLUSH instruction PSN\u2013Processor Serial Number PSE-36 \u2013 Page Size\n   Extension PAT\u2013Page Attribute Table CMOV\u2013Conditional Move/Compare\n   Instruction MCA\u2013Machine Check Architecture PGE\u2013PTE Global Bit MTRR\u2013Memory\n   Type Range Registers SEP\u2013SYSENTER and SYSEXIT APIC\u2013APIC on Chip\n   CX8\u2013CMPXCHG8B Inst. MCE\u2013Machine Check Exception PAE\u2013Physical Address\n   Extensions MSR\u2013RDMSR and WRMSR Support TSC\u2013Time Stamp Counter PSE\u2013Page\n   Size Extensions DE\u2013Debugging Extensions VME\u2013Virtual-8086 Mode Enhancement\n   FPU\u2013x87 FPU on Chip Reserved Figure 3-8. Feature Information Returned in\n   the EDX Register\n\n   Bit # Mnemonic Description                                                 \n   0     FPU      Floating-Point Unit On-Chip. The processor contains an x87  \n                  FPU.                                                        \n                  Virtual 8086 Mode Enhancements. Virtual 8086 mode           \n                  enhancements, including CR4.VME for controlling the         \n   1     VME      feature, CR4.PVI for protected mode virtual interrupts,     \n                  software interrupt indirection, expansion of the TSS with   \n                  the software indirection bitmap, and EFLAGS.VIF and         \n                  EFLAGS.VIP flags.                                           \n                  Debugging Extensions. Support for I/O breakpoints,          \n   2     DE       including CR4.DE for controlling the feature, and optional  \n                  trapping of accesses to DR4 and DR5.                        \n                  Page Size Extension. Large pages of size 4 MByte are        \n   3     PSE      supported, including CR4.PSE for controlling the feature,   \n                  the defined dirty bit in PDE (Page Directory Entries),      \n                  optional reserved bit trapping in CR3, PDEs, and PTEs.      \n   4     TSC      Time Stamp Counter. The RDTSC instruction is supported,     \n                  including CR4.TSD for controlling privilege.                \n                  Model Specific Registers RDMSR and WRMSR Instructions. The  \n   5     MSR      RDMSR and WRMSR instructions are supported. Some of the     \n                  MSRs are implementation dependent.                          \n                  Physical Address Extension. Physical addresses greater than \n                  32 bits are supported: extended page table entry formats,   \n   6     PAE      an extra level in the page translation tables is defined,   \n                  2-MByte pages are supported instead of 4 Mbyte pages if PAE \n                  bit is 1.                                                   \n                  Machine Check Exception. Exception 18 is defined for        \n                  Machine Checks, including CR4.MCE for controlling the       \n                  feature. This feature does not define the model-specific    \n   7     MCE      implementations of machine-check error logging, reporting,  \n                  and processor shutdowns. Machine Check exception handlers   \n                  may have to depend on processor version to do model         \n                  specific processing of the exception, or test for the       \n                  presence of the Machine Check feature.                      \n                  CMPXCHG8B Instruction. The compare-and-exchange 8 bytes (64 \n   8     CX8      bits) instruction is supported (implicitly locked and       \n                  atomic).                                                    \n                  APIC On-Chip. The processor contains an Advanced            \n                  Programmable Interrupt Controller (APIC), responding to     \n   9     APIC     memory mapped commands in the physical address range        \n                  FFFE0000H to FFFE0FFFH (by default - some processors permit \n                  the APIC to be relocated).                                  \n   10    Reserved Reserved                                                    \n   11    SEP      SYSENTER and SYSEXIT Instructions. The SYSENTER and SYSEXIT \n                  and associated MSRs are supported.                          \n                  Memory Type Range Registers. MTRRs are supported. The       \n   12    MTRR     MTRRcap MSR contains feature bits that describe what memory \n                  types are supported, how many variable MTRRs are supported, \n                  and whether fixed MTRRs are supported.                      \n                  Page Global Bit. The global bit is supported in             \n   13    PGE      paging-structure entries that map a page, indicating TLB    \n                  entries that are common to different processes and need not \n                  be flushed. The CR4.PGE bit controls this feature.          \n                  Machine Check Architecture. A value of 1 indicates the      \n   14    MCA      Machine Check Architecture of reporting machine errors is   \n                  supported. The MCG_CAP MSR contains feature bits describing \n                  how many banks of error reporting MSRs are supported.       \n                  Conditional Move Instructions. The conditional move         \n   15    CMOV     instruction CMOV is supported. In addition, if x87 FPU is   \n                  present as indicated by the CPUID.FPU feature bit, then the \n                  FCOMI and FCMOV instructions are supported                  \n                  Page Attribute Table. Page Attribute Table is supported.    \n                  This feature augments the Memory Type Range Registers       \n   16    PAT      (MTRRs), allowing an operating system to specify attributes \n                  of memory accessed through a linear address on a 4KB        \n                  granularity.                                                \n                  36-Bit Page Size Extension. 4-MByte pages addressing        \n                  physical memory beyond 4 GBytes are supported with 32-bit   \n   17    PSE-36   paging. This feature indicates that upper bits of the       \n                  physical address of a 4-MByte page are encoded in bits      \n                  20:13 of the page-directory entry. Such physical addresses  \n                  are limited by MAXPHYADDR and may be up to 40 bits in size. \n                  Processor Serial Number. The processor supports the 96-bit  \n   18    PSN      processor identification number feature and the feature is  \n                  enabled.                                                    \n   19    CLFSH    CLFLUSH Instruction. CLFLUSH Instruction is supported.      \n   20    Reserved Reserved                                                    \n                  Debug Store. The processor supports the ability to write    \n                  debug information into a memory resident buffer. This       \n                  feature is used by the branch trace store (BTS) and         \n   21    DS       processor event-based sampling (PEBS) facilities (see       \n                  Chapter 24, \u201cIntroduction to Virtual Machine Extensions,\u201d   \n                  in the Intel^\u00ae 64 and IA-32 Architectures Software          \n                  Developer\u2019s Manual, Volume 3C).                             \n                  Thermal Monitor and Software Controlled Clock Facilities.   \n   22    ACPI     The processor implements internal MSRs that allow processor \n                  temperature to be monitored and processor performance to be \n                  modulated in predefined duty cycles under software control. \n   23    MMX      Intel MMX Technology. The processor supports the Intel MMX  \n                  technology.                                                 \n                  FXSAVE and FXRSTOR Instructions. The FXSAVE and FXRSTOR     \n                  instructions are supported for fast save and restore of the \n   24    FXSR     floating-point context. Presence of this bit also indicates \n                  that CR4.OSFXSR is available for an operating system to     \n                  indicate that it supports the FXSAVE and FXRSTOR            \n                  instructions.                                               \n   25    SSE      SSE. The processor supports the SSE extensions.             \n   26    SSE2     SSE2. The processor supports the SSE2 extensions.           \n                  Self Snoop. The processor supports the management of        \n   27    SS       conflicting memory types by performing a snoop of its own   \n                  cache structure for transactions issued to the bus.         \n                  Max APIC IDs reserved field is Valid. A value of 0 for HTT  \n                  indicates there is only a single logical processor in the   \n                  package and software should assume only a single APIC ID is \n   28    HTT      reserved. A value of 1 for HTT indicates the value in       \n                  CPUID.1.EBX[23:16] (the Maximum number of addressable IDs   \n                  for logical processors in this package) is valid for the    \n                  package.                                                    \n   29    TM       Thermal Monitor. The processor implements the thermal       \n                  monitor automatic thermal control circuitry (TCC).          \n   30    Reserved Reserved                                                    \n                  Pending Break Enable. The processor supports the use of the \n                  FERR#/PBE# pin when the processor is in the stop-clock      \n   31    PBE      state (STPCLK# is asserted) to signal the processor that an \n                  interrupt is pending and that the processor should return   \n                  to normal operation to handle the interrupt.                \n\n   Table 3-11. More on Feature Information Returned in the EDX Register\n\nINPUT EAX = 02H: TLB/Cache/Prefetch Information Returned in EAX, EBX, ECX, EDX \u00b6\n\n   When CPUID executes with EAX set to 02H, the processor returns information\n   about the processor\u2019s internal TLBs, cache, and prefetch hardware in the\n   EAX, EBX, ECX, and EDX registers. The information is reported in encoded\n   form and fall into the following categories:\n\n     * The least-significant byte in register EAX (register AL) will always\n       return 01H. Software should ignore this value and not interpret it as\n       an informational descriptor.\n     * The most significant bit (bit 31) of each register indicates whether\n       the register contains valid information (set to 0) or is reserved (set\n       to 1).\n     * If a register contains valid information, the information is contained\n       in 1 byte descriptors. There are four types of encoding values for the\n       byte descriptor, the encoding type is noted in the second column of\n       Table 3-12. Table 3-12 lists the encoding of these descriptors. Note\n       that the order of descriptors in the EAX, EBX, ECX, and EDX registers\n       is not defined; that is, specific bytes are not designated to contain\n       descriptors for specific cache, prefetch, or TLB types. The\n       descriptors may appear in any order. Note also a processor may report\n       a general descriptor type (FFH) and not report any byte descriptor of\n       \u201ccache type\u201d via CPUID leaf 2.\n\n   Descriptor Value Type    Cache or TLB Description                          \n   00H              General Null descriptor, this byte contains no            \n                            information.                                      \n   01H              TLB     Instruction TLB: 4 KByte pages, 4-way set         \n                            associative, 32 entries.                          \n   02H              TLB     Instruction TLB: 4 MByte pages, fully             \n                            associative, 2 entries.                           \n   03H              TLB     Data TLB: 4 KByte pages, 4-way set associative,   \n                            64 entries.                                       \n   04H              TLB     Data TLB: 4 MByte pages, 4-way set associative, 8 \n                            entries.                                          \n   05H              TLB     Data TLB1: 4 MByte pages, 4-way set associative,  \n                            32 entries.                                       \n   06H              Cache   1st-level instruction cache: 8 KBytes, 4-way set  \n                            associative, 32 byte line size.                   \n   08H              Cache   1st-level instruction cache: 16 KBytes, 4-way set \n                            associative, 32 byte line size.                   \n   09H              Cache   1st-level instruction cache: 32KBytes, 4-way set  \n                            associative, 64 byte line size.                   \n   0AH              Cache   1st-level data cache: 8 KBytes, 2-way set         \n                            associative, 32 byte line size.                   \n   0BH              TLB     Instruction TLB: 4 MByte pages, 4-way set         \n                            associative, 4 entries.                           \n   0CH              Cache   1st-level data cache: 16 KBytes, 4-way set        \n                            associative, 32 byte line size.                   \n   0DH              Cache   1st-level data cache: 16 KBytes, 4-way set        \n                            associative, 64 byte line size.                   \n   0EH              Cache   1st-level data cache: 24 KBytes, 6-way set        \n                            associative, 64 byte line size.                   \n   1DH              Cache   2nd-level cache: 128 KBytes, 2-way set            \n                            associative, 64 byte line size.                   \n   21H              Cache   2nd-level cache: 256 KBytes, 8-way set            \n                            associative, 64 byte line size.                   \n                            3rd-level cache: 512 KBytes, 4-way set            \n   22H              Cache   associative, 64 byte line size, 2 lines per       \n                            sector.                                           \n   23H              Cache   3rd-level cache: 1 MBytes, 8-way set associative, \n                            64 byte line size, 2 lines per sector.            \n   24H              Cache   2nd-level cache: 1 MBytes, 16-way set             \n                            associative, 64 byte line size.                   \n   25H              Cache   3rd-level cache: 2 MBytes, 8-way set associative, \n                            64 byte line size, 2 lines per sector.            \n   29H              Cache   3rd-level cache: 4 MBytes, 8-way set associative, \n                            64 byte line size, 2 lines per sector.            \n   2CH              Cache   1st-level data cache: 32 KBytes, 8-way set        \n                            associative, 64 byte line size.                   \n   30H              Cache   1st-level instruction cache: 32 KBytes, 8-way set \n                            associative, 64 byte line size.                   \n   40H              Cache   No 2nd-level cache or, if processor contains a    \n                            valid 2nd-level cache, no 3rd-level cache.        \n   41H              Cache   2nd-level cache: 128 KBytes, 4-way set            \n                            associative, 32 byte line size.                   \n   42H              Cache   2nd-level cache: 256 KBytes, 4-way set            \n                            associative, 32 byte line size.                   \n   43H              Cache   2nd-level cache: 512 KBytes, 4-way set            \n                            associative, 32 byte line size.                   \n   44H              Cache   2nd-level cache: 1 MByte, 4-way set associative,  \n                            32 byte line size.                                \n   45H              Cache   2nd-level cache: 2 MByte, 4-way set associative,  \n                            32 byte line size.                                \n   46H              Cache   3rd-level cache: 4 MByte, 4-way set associative,  \n                            64 byte line size.                                \n   47H              Cache   3rd-level cache: 8 MByte, 8-way set associative,  \n                            64 byte line size.                                \n   48H              Cache   2nd-level cache: 3MByte, 12-way set associative,  \n                            64 byte line size.                                \n                            3rd-level cache: 4MB, 16-way set associative,     \n   49H              Cache   64-byte line size (Intel Xeon processor MP,       \n                            Family 0FH, Model 06H); 2nd-level cache: 4 MByte, \n                            16-way set associative, 64 byte line size.        \n   4AH              Cache   3rd-level cache: 6MByte, 12-way set associative,  \n                            64 byte line size.                                \n   4BH              Cache   3rd-level cache: 8MByte, 16-way set associative,  \n                            64 byte line size.                                \n   4CH              Cache   3rd-level cache: 12MByte, 12-way set associative, \n                            64 byte line size.                                \n   4DH              Cache   3rd-level cache: 16MByte, 16-way set associative, \n                            64 byte line size.                                \n   4EH              Cache   2nd-level cache: 6MByte, 24-way set associative,  \n                            64 byte line size.                                \n   4FH              TLB     Instruction TLB: 4 KByte pages, 32 entries.       \n   50H              TLB     Instruction TLB: 4 KByte and 2-MByte or 4-MByte   \n                            pages, 64 entries.                                \n   51H              TLB     Instruction TLB: 4 KByte and 2-MByte or 4-MByte   \n                            pages, 128 entries.                               \n   52H              TLB     Instruction TLB: 4 KByte and 2-MByte or 4-MByte   \n                            pages, 256 entries.                               \n   55H              TLB     Instruction TLB: 2-MByte or 4-MByte pages, fully  \n                            associative, 7 entries.                           \n   56H              TLB     Data TLB0: 4 MByte pages, 4-way set associative,  \n                            16 entries.                                       \n   57H              TLB     Data TLB0: 4 KByte pages, 4-way associative, 16   \n                            entries.                                          \n   59H              TLB     Data TLB0: 4 KByte pages, fully associative, 16   \n                            entries.                                          \n   5AH              TLB     Data TLB0: 2 MByte or 4 MByte pages, 4-way set    \n                            associative, 32 entries.                          \n   5BH              TLB     Data TLB: 4 KByte and 4 MByte pages, 64 entries.  \n   5CH              TLB     Data TLB: 4 KByte and 4 MByte pages,128 entries.  \n   5DH              TLB     Data TLB: 4 KByte and 4 MByte pages,256 entries.  \n   60H              Cache   1st-level data cache: 16 KByte, 8-way set         \n                            associative, 64 byte line size.                   \n   61H              TLB     Instruction TLB: 4 KByte pages, fully             \n                            associative, 48 entries.                          \n                            Data TLB: 2 MByte or 4 MByte pages, 4-way set     \n   63H              TLB     associative, 32 entries and a separate array with \n                            1 GByte pages, 4-way set associative, 4 entries.  \n   64H              TLB     Data TLB: 4 KByte pages, 4-way set associative,   \n                            512 entries.                                      \n   66H              Cache   1st-level data cache: 8 KByte, 4-way set          \n                            associative, 64 byte line size.                   \n   67H              Cache   1st-level data cache: 16 KByte, 4-way set         \n                            associative, 64 byte line size.                   \n   68H              Cache   1st-level data cache: 32 KByte, 4-way set         \n                            associative, 64 byte line size.                   \n   6AH              Cache   uTLB: 4 KByte pages, 8-way set associative, 64    \n                            entries.                                          \n   6BH              Cache   DTLB: 4 KByte pages, 8-way set associative, 256   \n                            entries.                                          \n   6CH              Cache   DTLB: 2M/4M pages, 8-way set associative, 128     \n                            entries.                                          \n   6DH              Cache   DTLB: 1 GByte pages, fully associative, 16        \n                            entries.                                          \n   70H              Cache   Trace cache: 12 K-\u03bcop, 8-way set associative.     \n   71H              Cache   Trace cache: 16 K-\u03bcop, 8-way set associative.     \n   72H              Cache   Trace cache: 32 K-\u03bcop, 8-way set associative.     \n   76H              TLB     Instruction TLB: 2M/4M pages, fully associative,  \n                            8 entries.                                        \n   78H              Cache   2nd-level cache: 1 MByte, 4-way set associative,  \n                            64byte line size.                                 \n                            2nd-level cache: 128 KByte, 8-way set             \n   79H              Cache   associative, 64 byte line size, 2 lines per       \n                            sector.                                           \n                            2nd-level cache: 256 KByte, 8-way set             \n   7AH              Cache   associative, 64 byte line size, 2 lines per       \n                            sector.                                           \n                            2nd-level cache: 512 KByte, 8-way set             \n   7BH              Cache   associative, 64 byte line size, 2 lines per       \n                            sector.                                           \n   7CH              Cache   2nd-level cache: 1 MByte, 8-way set associative,  \n                            64 byte line size, 2 lines per sector.            \n   7DH              Cache   2nd-level cache: 2 MByte, 8-way set associative,  \n                            64byte line size.                                 \n   7FH              Cache   2nd-level cache: 512 KByte, 2-way set             \n                            associative, 64-byte line size.                   \n   80H              Cache   2nd-level cache: 512 KByte, 8-way set             \n                            associative, 64-byte line size.                   \n   82H              Cache   2nd-level cache: 256 KByte, 8-way set             \n                            associative, 32 byte line size.                   \n   83H              Cache   2nd-level cache: 512 KByte, 8-way set             \n                            associative, 32 byte line size.                   \n   84H              Cache   2nd-level cache: 1 MByte, 8-way set associative,  \n                            32 byte line size.                                \n   85H              Cache   2nd-level cache: 2 MByte, 8-way set associative,  \n                            32 byte line size.                                \n   86H              Cache   2nd-level cache: 512 KByte, 4-way set             \n                            associative, 64 byte line size.                   \n   87H              Cache   2nd-level cache: 1 MByte, 8-way set associative,  \n                            64 byte line size.                                \n\n   Table 3-12. Encoding of CPUID Leaf 2 Descriptors\n\n   Descriptor Value Type     Cache or TLB Description                         \n   A0H              DTLB     DTLB: 4k pages, fully associative, 32 entries.   \n   B0H              TLB      Instruction TLB: 4 KByte pages, 4-way set        \n                             associative, 128 entries.                        \n   B1H              TLB      Instruction TLB: 2M pages, 4-way, 8 entries or   \n                             4M pages, 4-way, 4 entries.                      \n   B2H              TLB      Instruction TLB: 4KByte pages, 4-way set         \n                             associative, 64 entries.                         \n   B3H              TLB      Data TLB: 4 KByte pages, 4-way set associative,  \n                             128 entries.                                     \n   B4H              TLB      Data TLB1: 4 KByte pages, 4-way associative, 256 \n                             entries.                                         \n   B5H              TLB      Instruction TLB: 4KByte pages, 8-way set         \n                             associative, 64 entries.                         \n   B6H              TLB      Instruction TLB: 4KByte pages, 8-way set         \n                             associative, 128 entries.                        \n   BAH              TLB      Data TLB1: 4 KByte pages, 4-way associative, 64  \n                             entries.                                         \n   C0H              TLB      Data TLB: 4 KByte and 4 MByte pages, 4-way       \n                             associative, 8 entries.                          \n   C1H              STLB     Shared 2nd-Level TLB: 4 KByte/2MByte pages,      \n                             8-way associative, 1024 entries.                 \n   C2H              DTLB     DTLB: 4 KByte/2 MByte pages, 4-way associative,  \n                             16 entries.                                      \n                             Shared 2nd-Level TLB: 4 KByte /2 MByte pages,    \n   C3H              STLB     6-way associative, 1536 entries. Also 1GBbyte    \n                             pages, 4-way, 16 entries.                        \n   C4H              DTLB     DTLB: 2M/4M Byte pages, 4-way associative, 32    \n                             entries.                                         \n   CAH              STLB     Shared 2nd-Level TLB: 4 KByte pages, 4-way       \n                             associative, 512 entries.                        \n   D0H              Cache    3rd-level cache: 512 KByte, 4-way set            \n                             associative, 64 byte line size.                  \n   D1H              Cache    3rd-level cache: 1 MByte, 4-way set associative, \n                             64 byte line size.                               \n   D2H              Cache    3rd-level cache: 2 MByte, 4-way set associative, \n                             64 byte line size.                               \n   D6H              Cache    3rd-level cache: 1 MByte, 8-way set associative, \n                             64 byte line size.                               \n   D7H              Cache    3rd-level cache: 2 MByte, 8-way set associative, \n                             64 byte line size.                               \n   D8H              Cache    3rd-level cache: 4 MByte, 8-way set associative, \n                             64 byte line size.                               \n   DCH              Cache    3rd-level cache: 1.5 MByte, 12-way set           \n                             associative, 64 byte line size.                  \n   DDH              Cache    3rd-level cache: 3 MByte, 12-way set             \n                             associative, 64 byte line size.                  \n   DEH              Cache    3rd-level cache: 6 MByte, 12-way set             \n                             associative, 64 byte line size.                  \n   E2H              Cache    3rd-level cache: 2 MByte, 16-way set             \n                             associative, 64 byte line size.                  \n   E3H              Cache    3rd-level cache: 4 MByte, 16-way set             \n                             associative, 64 byte line size.                  \n   E4H              Cache    3rd-level cache: 8 MByte, 16-way set             \n                             associative, 64 byte line size.                  \n   EAH              Cache    3rd-level cache: 12MByte, 24-way set             \n                             associative, 64 byte line size.                  \n   EBH              Cache    3rd-level cache: 18MByte, 24-way set             \n                             associative, 64 byte line size.                  \n   ECH              Cache    3rd-level cache: 24MByte, 24-way set             \n                             associative, 64 byte line size.                  \n   F0H              Prefetch 64-Byte prefetching.                             \n   F1H              Prefetch 128-Byte prefetching.                            \n                             CPUID leaf 2 does not report TLB descriptor      \n   FEH              General  information; use CPUID leaf 18H to query TLB and \n                             other address translation parameters.            \n                             CPUID leaf 2 does not report cache descriptor    \n   FFH              General  information, use CPUID leaf 4 to query cache     \n                             parameters.                                      \n\n   Table 3-12. Encoding of CPUID Leaf 2 Descriptors (Contd.)\n\nExample 3-1. Example of Cache and TLB Interpretation \u00b6\n\n   The first member of the family of Pentium 4 processors returns the\n   following information about caches and TLBs when the CPUID executes with\n   an input value of 2:\n\n   EAX 66 5B 50 01H EBX 0H ECX 0H EDX 00 7A 70 00H\n\n   Which means:\n\n     * The least-significant byte (byte 0) of register EAX is set to 01H.\n       This value should be ignored.\n     * The most-significant bit of all four registers (EAX, EBX, ECX, and\n       EDX) is set to 0, indicating that each register contains valid 1-byte\n       descriptors.\n     * Bytes 1, 2, and 3 of register EAX indicate that the processor has:\n          * 50H - a 64-entry instruction TLB, for mapping 4-KByte and 2-MByte\n            or 4-MByte pages.\n          * 50H - a 64-entry instruction TLB, for mapping 4-KByte and 2-MByte\n            or 4-MByte pages.\n          * 5BH - a 64-entry data TLB, for mapping 4-KByte and 4-MByte pages.\n          * 5BH - a 64-entry data TLB, for mapping 4-KByte and 4-MByte pages.\n          * 66H - an 8-KByte 1st level data cache, 4-way set associative,\n            with a 64-Byte cache line size.\n          * 66H - an 8-KByte 1st level data cache, 4-way set associative,\n            with a 64-Byte cache line size.\n     * The descriptors in registers EBX and ECX are valid, but contain NULL\n       descriptors.\n     * Bytes 0, 1, 2, and 3 of register EDX indicate that the processor has:\n          * 00H - NULL descriptor.\n          * 00H - NULL descriptor.\n          * 70H - Trace cache: 12 K-\u03bcop, 8-way set associative.\n          * 70H - Trace cache: 12 K-\u03bcop, 8-way set associative.\n          * 7AH - a 256-KByte 2nd level cache, 8-way set associative, with a\n            sectored, 64-byte cache line size.\n          * 7AH - a 256-KByte 2nd level cache, 8-way set associative, with a\n            sectored, 64-byte cache line size.\n          * 00H - NULL descriptor.\n          * 00H - NULL descriptor.\n\nINPUT EAX = 04H: Returns Deterministic Cache Parameters for Each Level \u00b6\n\n   When CPUID executes with EAX set to 04H and ECX contains an index value,\n   the processor returns encoded data that describe a set of deterministic\n   cache parameters (for the cache level associated with the input in ECX).\n   Valid index values start from 0.\n\n   Software can enumerate the deterministic cache parameters for each level\n   of the cache hierarchy starting with an index value of 0, until the\n   parameters report the value associated with the cache type field is 0. The\n   architecturally defined fields reported by deterministic cache parameters\n   are documented in Table 3-8.\n\n   This Cache Size in Bytes\n\n   = (Ways + 1) * (Partitions + 1) * (Line_Size + 1) * (Sets + 1)\n\n   = (EBX[31:22] + 1) * (EBX[21:12] + 1) * (EBX[11:0] + 1) * (ECX + 1)\n\n   The CPUID leaf 04H also reports data that can be used to derive the\n   topology of processor cores in a physical package. This information is\n   constant for all valid index values. Software can query the raw data\n   reported by executing CPUID with EAX=04H and ECX=0 and use it as part of\n   the topology enumeration algorithm described in Chapter 9,\n   \u201cMultiple-Processor Management,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3A.\n\nINPUT EAX = 05H: Returns MONITOR and MWAIT Features \u00b6\n\n   When CPUID executes with EAX set to 05H, the processor returns information\n   about features available to MONITOR/MWAIT instructions. The MONITOR\n   instruction is used for address-range monitoring in conjunction with MWAIT\n   instruction. The MWAIT instruction optionally provides additional\n   extensions for advanced power management. See Table 3-8.\n\nINPUT EAX = 06H: Returns Thermal and Power Management Features \u00b6\n\n   When CPUID executes with EAX set to 06H, the processor returns information\n   about thermal and power management features. See Table 3-8.\n\nINPUT EAX = 07H: Returns Structured Extended Feature Enumeration Information \u00b6\n\n   When CPUID executes with EAX set to 07H and ECX = 0, the processor returns\n   information about the maximum input value for sub-leaves that contain\n   extended feature flags. See Table 3-8.\n\n   When CPUID executes with EAX set to 07H and the input value of ECX is\n   invalid (see leaf 07H entry in Table 3-8), the processor returns 0 in\n   EAX/EBX/ECX/EDX. In subleaf 0, EAX returns the maximum input value of the\n   highest leaf 7 sub-leaf, and EBX, ECX & EDX contain information of\n   extended feature flags.\n\nINPUT EAX = 09H: Returns Direct Cache Access Information \u00b6\n\n   When CPUID executes with EAX set to 09H, the processor returns information\n   about Direct Cache Access capabilities. See Table 3-8.\n\nINPUT EAX = 0AH: Returns Architectural Performance Monitoring Features \u00b6\n\n   When CPUID executes with EAX set to 0AH, the processor returns information\n   about support for architectural performance monitoring capabilities.\n   Architectural performance monitoring is supported if the version ID (see\n   Table 3-8) is greater than Pn 0. See Table 3-8.\n\n   For each version of architectural performance monitoring capability,\n   software must enumerate this leaf to discover the programming facilities\n   and the architectural performance events available in the processor. The\n   details are described in Chapter 24, \u201cIntroduction to Virtual Machine\n   Extensions,\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3C.\n\nINPUT EAX = 0BH: Returns Extended Topology Information \u00b6\n\n   CPUID leaf 1FH is a preferred superset to leaf 0BH. Intel recommends first\n   checking for the existence of Leaf 1FH before using leaf 0BH.\n\n   When CPUID executes with EAX set to 0BH, the processor returns information\n   about extended topology enumeration data. Software must detect the\n   presence of CPUID leaf 0BH by verifying (a) the highest leaf index\n   supported by CPUID is >= 0BH, and (b) CPUID.0BH:EBX[15:0] reports a\n   non-zero value. See Table 3-8.\n\nINPUT EAX = 0DH: Returns Processor Extended States Enumeration Information \u00b6\n\n   When CPUID executes with EAX set to 0DH and ECX = 0, the processor returns\n   information about the bit-vector representation of all processor state\n   extensions that are supported in the processor and storage size\n   requirements of the XSAVE/XRSTOR area. See Table 3-8.\n\n   When CPUID executes with EAX set to 0DH and ECX = n (n > 1, and is a valid\n   sub-leaf index), the processor returns information about the size and\n   offset of each processor extended state save area within the XSAVE/XRSTOR\n   area. See Table 3-8. Software can use the forward-extendable technique\n   depicted below to query the valid sub-leaves and obtain size and offset\n   information for each processor extended state save area:\n\n   For i = 2 to 62 // sub-leaf 1 is reserved IF (CPUID.(EAX=0DH,\n   ECX=0H):VECTOR[i] = 1 ) // VECTOR is the 64-bit value of EDX:EAX Execute\n   CPUID.(EAX=0DH, ECX = i) to examine size and offset for sub-leaf i; FI;\n\nINPUT EAX = 0FH: Returns Intel Resource Director Technology (Intel RDT)\nMonitoring Enumeration Information \u00b6\n\n   When CPUID executes with EAX set to 0FH and ECX = 0, the processor returns\n   information about the bit-vector representation of QoS monitoring resource\n   types that are supported in the processor and maximum range of RMID values\n   the processor can use to monitor of any supported resource types. Each\n   bit, starting from bit 1, corresponds to a specific resource type if the\n   bit is set. The bit position corresponds to the sub-leaf index (or ResID)\n   that software must use to query QoS monitoring capability available for\n   that type. See Table 3-8.\n\n   When CPUID executes with EAX set to 0FH and ECX = n (n >= 1, and is a\n   valid ResID), the processor returns information software can use to\n   program IA32_PQR_ASSOC, IA32_QM_EVTSEL MSRs before reading QoS data from\n   the IA32_QM_CTR MSR.\n\nINPUT EAX = 10H: Returns Intel Resource Director Technology (Intel RDT)\nAllocation Enumeration Information \u00b6\n\n   When CPUID executes with EAX set to 10H and ECX = 0, the processor returns\n   information about the bit-vector representation of QoS Enforcement\n   resource types that are supported in the processor. Each bit, starting\n   from bit 1, corresponds to a specific resource type if the bit is set. The\n   bit position corresponds to the sub-leaf index (or ResID) that software\n   must use to query QoS enforcement capability available for that type. See\n   Table 3-8.\n\n   When CPUID executes with EAX set to 10H and ECX = n (n >= 1, and is a\n   valid ResID), the processor returns information about available classes of\n   service and range of QoS mask MSRs that software can use to configure each\n   class of services using capability bit masks in the QoS Mask registers,\n   IA32_resourceType_Mask_n.\n\nINPUT EAX = 12H: Returns Intel SGX Enumeration Information \u00b6\n\n   When CPUID executes with EAX set to 12H and ECX = 0H, the processor\n   returns information about Intel SGX capabilities. See Table 3-8.\n\n   When CPUID executes with EAX set to 12H and ECX = 1H, the processor\n   returns information about Intel SGX attributes. See Table 3-8.\n\n   When CPUID executes with EAX set to 12H and ECX = n (n > 1), the processor\n   returns information about Intel SGX Enclave Page Cache. See Table 3-8.\n\nINPUT EAX = 14H: Returns Intel Processor Trace Enumeration Information \u00b6\n\n   When CPUID executes with EAX set to 14H and ECX = 0H, the processor\n   returns information about Intel Processor Trace extensions. See Table 3-8.\n\n   When CPUID executes with EAX set to 14H and ECX = n (n > 0 and less than\n   the number of non-zero bits in CPUID.(EAX=14H, ECX= 0H).EAX), the\n   processor returns information about packet generation in Intel Processor\n   Trace. See Table 3-8.\n\nINPUT EAX = 15H: Returns Time Stamp Counter and Nominal Core Crystal Clock\nInformation \u00b6\n\n   When CPUID executes with EAX set to 15H and ECX = 0H, the processor\n   returns information about Time Stamp Counter and Core Crystal Clock. See\n   Table 3-8.\n\nINPUT EAX = 16H: Returns Processor Frequency Information \u00b6\n\n   When CPUID executes with EAX set to 16H, the processor returns information\n   about Processor Frequency Information. See Table 3-8.\n\nINPUT EAX = 17H: Returns System-On-Chip Information \u00b6\n\n   When CPUID executes with EAX set to 17H, the processor returns information\n   about the System-On-Chip Vendor Attribute Enumeration. See Table 3-8.\n\nINPUT EAX = 18H: Returns Deterministic Address Translation Parameters\nInformation \u00b6\n\n   When CPUID executes with EAX set to 18H, the processor returns information\n   about the Deterministic Address Translation Parameters. See Table 3-8.\n\nINPUT EAX = 19H: Returns Key Locker Information \u00b6\n\n   When CPUID executes with EAX set to 19H, the processor returns information\n   about Key Locker. See Table 3-8.\n\nINPUT EAX = 1AH: Returns Native Model ID Information \u00b6\n\n   When CPUID executes with EAX set to 1AH, the processor returns information\n   about Native Model Identification. See Table 3-8.\n\nINPUT EAX = 1BH: Returns PCONFIG Information \u00b6\n\n   When CPUID executes with EAX set to 1BH, the processor returns information\n   about PCONFIG capabilities. This information is enumerated in sub-leaves\n   selected by the value of ECX (starting with 0).\n\n   Each sub-leaf of CPUID function 1BH enumerates its sub-leaf type in EAX.\n   If a sub-leaf type is 0, the sub-leaf is invalid and zero is returned in\n   EBX, ECX, and EDX. In this case, all subsequent sub-leaves (selected by\n   larger input values of ECX) are also invalid.\n\n   The only valid sub-leaf type currently defined is 1, indicating that the\n   sub-leaf enumerates target identifiers for the PCONFIG instruction. Any\n   non-zero value returned in EBX, ECX, or EDX indicates a valid target\n   identifier of the PCONFIG instruction (any value of zero should be\n   ignored). The only target identifier currently defined is 1, indicating\n   TME-MK. See the \u201cPCONFIG\u2014Platform Configuration\u201d instruction in Chapter 4\n   of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 2B, for more information.\n\nINPUT EAX = 1CH: Returns Last Branch Record Information \u00b6\n\n   When CPUID executes with EAX set to 1CH, the processor returns information\n   about LBRs (the architectural feature). See Table 3-8.\n\nINPUT EAX = 1DH: Returns Tile Information \u00b6\n\n   When CPUID executes with EAX set to 1DH and ECX = 0H, the processor\n   returns information about tile architecture. See Table 3-8.\n\n   When CPUID executes with EAX set to 1DH and ECX = 1H, the processor\n   returns information about tile palette 1. See Table 3-8.\n\nINPUT EAX = 1EH: Returns TMUL Information \u00b6\n\n   When CPUID executes with EAX set to 1EH and ECX = 0H, the processor\n   returns information about TMUL capabilities. See Table 3-8.\n\nINPUT EAX = 1FH: Returns V2 Extended Topology Information \u00b6\n\n   When CPUID executes with EAX set to 1FH, the processor returns information\n   about extended topology enumeration data. Software must detect the\n   presence of CPUID leaf 1FH by verifying (a) the highest leaf index\n   supported by CPUID is >= 1FH, and (b) CPUID.1FH:EBX[15:0] reports a\n   non-zero value. See Table 3-8.\n\nINPUT EAX = 20H: Returns History Reset Information \u00b6\n\n   When CPUID executes with EAX set to 20H, the processor returns information\n   about History Reset. See Table 3-8.\n\nMETHODS FOR RETURNING BRANDING INFORMATION \u00b6\n\n   Use the following techniques to access branding information:\n\n   1. Processor brand string method.\n\n   2. Processor brand index; this method uses a software supplied brand\n   string table.\n\n   These two methods are discussed in the following sections. For methods\n   that are available in early processors, see Section: \u201cIdentification of\n   Earlier IA-32 Processors\u201d in Chapter 20 of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1.\n\nThe Processor Brand String Method \u00b6\n\n   Figure 3-9 describes the algorithm used for detection of the brand string.\n   Processor brand identification software should execute this algorithm on\n   all Intel 64 and IA-32 processors.\n\n   This method (introduced with Pentium 4 processors) returns an ASCII brand\n   identification string and the Processor Base frequency of the processor to\n   the EAX, EBX, ECX, and EDX registers.\n\n   Input: EAX= 0x80000000 CPUID Processor Brand False IF (EAX & 0x80000000)\n   String Not Supported CPUID True\u2265 Function Extended Supported EAX Return\n   Value = Max. Extended CPUID Function Index True Processor Brand IF (EAX\n   Return Value String Supported \u2265 0x80000004) Figure 3-9. Determination of\n   Support for the Processor Brand String\n\nHow Brand Strings Work \u00b6\n\n   To use the brand string method, execute CPUID with EAX input of 8000002H\n   through 80000004H. For each input value, CPUID returns 16 ASCII characters\n   using EAX, EBX, ECX, and EDX. The returned string will be NULL-terminated.\n\n   Table 3-13 shows the brand string that is returned by the first processor\n   in the Pentium 4 processor family.\n\n   EAX Input Value Return Values                         ASCII Equivalent     \n   80000002H       EAX = 20202020H EBX = 20202020H ECX = \u201c\u201d \u201c\u201d \u201c\u201d \u201cnI \u201d       \n                   20202020H EDX = 6E492020H             \n   80000003H       EAX = 286C6574H EBX = 50202952H ECX = \u201c(let\u201d \u201cP )R\u201d \u201citne\u201d \n                   69746E65H EDX = 52286D75H             \u201cR(mu\u201d               \n   80000004H       EAX = 20342029H EBX = 20555043H ECX = \u201c 4 )\u201d \u201c UPC\u201d \u201c0051\u201d \n                   30303531H EDX = 007A484DH             \u201c\\0zHM\u201d              \n\n   Table 3-13. Processor Brand String Returned with Pentium 4 Processor\n\nExtracting the Processor Frequency from Brand Strings \u00b6\n\n   Figure 3-10 provides an algorithm which software can use to extract the\n   Processor Base frequency from the processor brand string.\n\n   Scan \"Brand String\" in Reverse Byte Order \"zHM\", or Match \"zHG\", or\n   Substring \"zHT\" False IF Substring Matched Report Error Determine \"Freq\"\n   True If \"zHM\" Multiplier = 1 x 106 and \"Multiplier\" If \"zHG\" Multiplier =\n   1 x 109 Determine \"Multiplier\" If \"zHT\" Multiplier = 1 x 1012 Scan Digits\n   Until Blank Reverse Digits Determine \"Freq\" To Decimal Value In Reverse\n   Order Processor Base Frequency = \"Freq\" = X.YZ if \"Freq\" x \"Multiplier\"\n   Digits = \"ZY.X\" Figure 3-10. Algorithm for Extracting Processor Frequency\n\nThe Processor Brand Index Method \u00b6\n\n   The brand index method (introduced with Pentium^\u00ae III Xeon^\u00ae processors)\n   provides an entry point into a brand identification table that is\n   maintained in memory by system software and is accessible from system- and\n   user-level code. In this table, each brand index is associate with an\n   ASCII brand identification string that identifies the official Intel\n   family and model number of a processor.\n\n   When CPUID executes with EAX set to 1, the processor returns a brand index\n   to the low byte in EBX. Software can then use this index to locate the\n   brand identification string for the processor in the brand identification\n   table. The first entry (brand index 0) in this table is reserved, allowing\n   for backward compatibility with processors that do not support the brand\n   identification feature. Starting with processor signature family ID = 0FH,\n   model = 03H, brand index method is no longer supported. Use brand string\n   method instead.\n\n   Table 3-14 shows brand indices that have identification strings associated\n   with them.\n\n   Brand Index Brand String                                                   \n   00H         This processor does not support the brand identification       \n               feature                                                        \n   01H         Intel(R) Celeron(R) processor^1                                \n   02H         Intel(R) Pentium(R) III processor^1                            \n   03H         Intel(R) Pentium(R) III Xeon(R) processor; If processor        \n               signature = 000006B1h, then Intel(R) Celeron(R) processor      \n   04H         Intel(R) Pentium(R) III processor                              \n   06H         Mobile Intel(R) Pentium(R) III processor-M                     \n   07H         Mobile Intel(R) Celeron(R) processor^1                         \n   08H         Intel(R) Pentium(R) 4 processor                                \n   09H         Intel(R) Pentium(R) 4 processor                                \n   0AH         Intel(R) Celeron(R) processor^1                                \n   0BH         Intel(R) Xeon(R) processor; If processor signature =           \n               00000F13h, then Intel(R) Xeon(R) processor MP                  \n   0CH         Intel(R) Xeon(R) processor MP                                  \n   0EH         Mobile Intel(R) Pentium(R) 4 processor-M; If processor         \n               signature = 00000F13h, then Intel(R) Xeon(R) processor         \n   0FH         Mobile Intel(R) Celeron(R) processor^1                         \n   11H         Mobile Genuine Intel(R) processor                              \n   12H         Intel(R) Celeron(R) M processor                                \n   13H         Mobile Intel(R) Celeron(R) processor^1                         \n   14H         Intel(R) Celeron(R) processor                                  \n   15H         Mobile Genuine Intel(R) processor                              \n   16H         Intel(R) Pentium(R) M processor                                \n   17H         Mobile Intel(R) Celeron(R) processor^1                         \n   18H \u2013 0FFH  RESERVED                                                       \n\n   Table 3-14. Mapping of Brand Indices; and Intel 64 and IA-32 Processor\n   Brand Strings\n\n   NOTES:\n\n   1. Indicates versions of these processors that were introduced after the\n   Pentium III\n\nIA-32 Architecture Compatibility \u00b6\n\n   CPUID is not supported in early models of the Intel486 processor or in any\n   IA-32 processor earlier than the Intel486 processor.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pmovzx", "                     PMOVZX \u2014 Packed Move With Zero Extend\n\n                             Op / 64/32 bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Zero extend 8 packed     \n   66 0f 38 30 /r PMOVZXBW                           8-bit integers in the    \n   xmm1, xmm2/m64            A    V/V       SSE4_1   low 8 bytes of xmm2/m64  \n                                                     to 8 packed 16-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 4 packed     \n   66 0f 38 31 /r PMOVZXBD                           8-bit integers in the    \n   xmm1, xmm2/m32            A    V/V       SSE4_1   low 4 bytes of xmm2/m32  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 2 packed     \n   66 0f 38 32 /r PMOVZXBQ                           8-bit integers in the    \n   xmm1, xmm2/m16            A    V/V       SSE4_1   low 2 bytes of xmm2/m16  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 4 packed     \n   66 0f 38 33 /r PMOVZXWD                           16-bit integers in the   \n   xmm1, xmm2/m64            A    V/V       SSE4_1   low 8 bytes of xmm2/m64  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 2 packed     \n   66 0f 38 34 /r PMOVZXWQ                           16-bit integers in the   \n   xmm1, xmm2/m32            A    V/V       SSE4_1   low 4 bytes of xmm2/m32  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 2 packed     \n   66 0f 38 35 /r PMOVZXDQ                           32-bit integers in the   \n   xmm1, xmm2/m64            A    V/V       SSE4_1   low 8 bytes of xmm2/m64  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 8 packed     \n   VEX.128.66.0F38.WIG 30 /r                         8-bit integers in the    \n   VPMOVZXBW xmm1, xmm2/m64  A    V/V       AVX      low 8 bytes of xmm2/m64  \n                                                     to 8 packed 16-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 4 packed     \n   VEX.128.66.0F38.WIG 31 /r                         8-bit integers in the    \n   VPMOVZXBD xmm1, xmm2/m32  A    V/V       AVX      low 4 bytes of xmm2/m32  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 2 packed     \n   VEX.128.66.0F38.WIG 32 /r                         8-bit integers in the    \n   VPMOVZXBQ xmm1, xmm2/m16  A    V/V       AVX      low 2 bytes of xmm2/m16  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 4 packed     \n   VEX.128.66.0F38.WIG 33 /r                         16-bit integers in the   \n   VPMOVZXWD xmm1, xmm2/m64  A    V/V       AVX      low 8 bytes of xmm2/m64  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 2 packed     \n   VEX.128.66.0F38.WIG 34 /r                         16-bit integers in the   \n   VPMOVZXWQ xmm1, xmm2/m32  A    V/V       AVX      low 4 bytes of xmm2/m32  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 2 packed     \n   VEX.128.66.0F 38.WIG 35                           32-bit integers in the   \n   /r VPMOVZXDQ xmm1,        A    V/V       AVX      low 8 bytes of xmm2/m64  \n   xmm2/m64                                          to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 16 packed    \n   VEX.256.66.0F38.WIG 30 /r A    V/V       AVX2     8-bit integers in        \n   VPMOVZXBW ymm1, xmm2/m128                         xmm2/m128 to 16 packed   \n                                                     16-bit integers in ymm1. \n                                                     Zero extend 8 packed     \n   VEX.256.66.0F38.WIG 31 /r                         8-bit integers in the    \n   VPMOVZXBD ymm1, xmm2/m64  A    V/V       AVX2     low 8 bytes of xmm2/m64  \n                                                     to 8 packed 32-bit       \n                                                     integers in ymm1.        \n                                                     Zero extend 4 packed     \n   VEX.256.66.0F38.WIG 32 /r                         8-bit integers in the    \n   VPMOVZXBQ ymm1, xmm2/m32  A    V/V       AVX2     low 4 bytes of xmm2/m32  \n                                                     to 4 packed 64-bit       \n                                                     integers in ymm1.        \n                                                     Zero extend 8 packed     \n   VEX.256.66.0F38.WIG 33 /r A    V/V       AVX2     16-bit integers          \n   VPMOVZXWD ymm1, xmm2/m128                         xmm2/m128 to 8 packed    \n                                                     32-bit integers in ymm1. \n                                                     Zero extend 4 packed     \n   VEX.256.66.0F38.WIG 34 /r                         16-bit integers in the   \n   VPMOVZXWQ ymm1, xmm2/m64  A    V/V       AVX2     low 8 bytes of xmm2/m64  \n                                                     to 4 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Zero extend 4 packed     \n   VEX.256.66.0F38.WIG 35 /r A    V/V       AVX2     32-bit integers in       \n   VPMOVZXDQ ymm1, xmm2/m128                         xmm2/m128 to 4 packed    \n                                                     64-bit integers in ymm1. \n                                                     Zero extend 8 packed     \n   EVEX.128.66.0F38 30.WIG                  AVX512VL 8-bit integers in the    \n   /r VPMOVZXBW xmm1         B    V/V       AVX512BW low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                                 to 8 packed 16-bit       \n                                                     integers in xmm1.        \n   EVEX.256.66.0F38.WIG 30                           Zero extend 16 packed    \n   /r VPMOVZXBW ymm1         B    V/V       AVX512VL 8-bit integers in        \n   {k1}{z}, xmm2/m128                       AVX512BW xmm2/m128 to 16 packed   \n                                                     16-bit integers in ymm1. \n   EVEX.512.66.0F38.WIG 30                           Zero extend 32 packed    \n   /r VPMOVZXBW zmm1         B    V/V       AVX512BW 8-bit integers in        \n   {k1}{z}, ymm2/m256                                ymm2/m256 to 32 packed   \n                                                     16-bit integers in zmm1. \n                                                     Zero extend 4 packed     \n   EVEX.128.66.0F38.WIG 31                           8-bit integers in the    \n   /r VPMOVZXBD xmm1         C    V/V       AVX512VL low 4 bytes of xmm2/m32  \n   {k1}{z}, xmm2/m32                        AVX512F  to 4 packed 32-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 8 packed     \n   EVEX.256.66.0F38.WIG 31                           8-bit integers in the    \n   /r VPMOVZXBD ymm1         C    V/V       AVX512VL low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                        AVX512F  to 8 packed 32-bit       \n                                                     integers in ymm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 16 packed    \n   EVEX.512.66.0F38.WIG 31                           8-bit integers in        \n   /r VPMOVZXBD zmm1         C    V/V       AVX512F  xmm2/m128 to 16 packed   \n   {k1}{z}, xmm2/m128                                32-bit integers in zmm1  \n                                                     subject to writemask k1. \n                                                     Zero extend 2 packed     \n   EVEX.128.66.0F38.WIG 32                           8-bit integers in the    \n   /r VPMOVZXBQ xmm1         D    V/V       AVX512VL low 2 bytes of xmm2/m16  \n   {k1}{z}, xmm2/m16                        AVX512F  to 2 packed 64-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 4 packed     \n   EVEX.256.66.0F38.WIG 32                           8-bit integers in the    \n   /r VPMOVZXBQ ymm1         D    V/V       AVX512VL low 4 bytes of xmm2/m32  \n   {k1}{z}, xmm2/m32                        AVX512F  to 4 packed 64-bit       \n                                                     integers in ymm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 8 packed     \n   EVEX.512.66.0F38.WIG 32                           8-bit integers in the    \n   /r VPMOVZXBQ zmm1         D    V/V       AVX512F  low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                                 to 8 packed 64-bit       \n                                                     integers in zmm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 4 packed     \n   EVEX.128.66.0F38.WIG 33                           16-bit integers in the   \n   /r VPMOVZXWD xmm1         B    V/V       AVX512VL low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                        AVX512F  to 4 packed 32-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 8 packed     \n   EVEX.256.66.0F38.WIG 33                  AVX512VL 16-bit integers in       \n   /r VPMOVZXWD ymm1         B    V/V       AVX512F  xmm2/m128 to 8 packed    \n   {k1}{z}, xmm2/m128                                32-bit integers in zmm1  \n                                                     subject to writemask k1. \n                                                     Zero extend 16 packed    \n   EVEX.512.66.0F38.WIG 33                           16-bit integers in       \n   /r VPMOVZXWD zmm1         B    V/V       AVX512F  ymm2/m256 to 16 packed   \n   {k1}{z}, ymm2/m256                                32-bit integers in zmm1  \n                                                     subject to writemask k1. \n                                                     Zero extend 2 packed     \n   EVEX.128.66.0F38.WIG 34                           16-bit integers in the   \n   /r VPMOVZXWQ xmm1         C    V/V       AVX512VL low 4 bytes of xmm2/m32  \n   {k1}{z}, xmm2/m32                        AVX512F  to 2 packed 64-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 4 packed     \n   EVEX.256.66.0F38.WIG 34                           16-bit integers in the   \n   /r VPMOVZXWQ ymm1         C    V/V       AVX512VL low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                        AVX512F  to 4 packed 64-bit       \n                                                     integers in ymm1 subject \n                                                     to writemask k1.         \n                                                     Zero extend 8 packed     \n   EVEX.512.66.0F38.WIG 34                           16-bit integers in       \n   /r VPMOVZXWQ zmm1         C    V/V       AVX512F  xmm2/m128 to 8 packed    \n   {k1}{z}, xmm2/m128                                64-bit integers in zmm1  \n                                                     subject to writemask k1. \n                                                     Zero extend 2 packed     \n   EVEX.128.66.0F38.W0 35 /r                         32-bit integers in the   \n   VPMOVZXDQ xmm1 {k1}{z},   B    V/V       AVX512VL low 8 bytes of xmm2/m64  \n   xmm2/m64                                 AVX512F  to 2 packed 64-bit       \n                                                     integers in zmm1 using   \n                                                     writemask k1.            \n                                                     Zero extend 4 packed     \n   EVEX.256.66.0F38.W0 35 /r                AVX512VL 32-bit integers in       \n   VPMOVZXDQ ymm1 {k1}{z},   B    V/V       AVX512F  xmm2/m128 to 4 packed    \n   xmm2/m128                                         64-bit integers in zmm1  \n                                                     using writemask k1.      \n                                                     Zero extend 8 packed     \n   EVEX.512.66.0F38.W0 35 /r                         32-bit integers in       \n   VPMOVZXDQ zmm1 {k1}{z},   B    V/V       AVX512F  ymm2/m256 to 8 packed    \n   ymm2/m256                                         64-bit integers in zmm1  \n                                                     using writemask k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A         ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Half Mem    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   C     Quarter Mem ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Eighth Mem  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Legacy, VEX, and EVEX encoded versions: Packed byte, word, or dword\n   integers starting from the low bytes of the source operand (second\n   operand) are zero extended to word, dword, or quadword integers and stored\n   in packed signed bytes the destination operand.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the corresponding\n   destination register are zeroed.\n\n   VEX.256 encoded version: Bits (MAXVL-1:256) of the corresponding\n   destination register are zeroed.\n\n   EVEX encoded versions: Packed dword integers starting from the low bytes\n   of the source operand (second operand) are zero extended to quadword\n   integers and stored to the destination operand under the writemask.The\n   destination register is XMM, YMM or ZMM Register.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["vcvtps2phx", "  VCVTPS2PHX \u2014 Convert Packed Single Precision Floating-Point Values to Packed\n                                  FP16 Values\n\n                          Op 64/32 Bit CPUID Feature                          \n   Opcode/Instruction     /  Mode      Flag          Description\n                          En Support   \n                                                     Convert four packed      \n   EVEX.128.66.MAP5.W0 1D                            single precision         \n   /r VCVTPS2PHX                       AVX512-FP16   floating-point values in \n   xmm1{k1}{z},           A  V/V       AVX512VL      xmm2/m128/m32bcst to     \n   xmm2/m128/m32bcst                                 packed FP16 values, and  \n                                                     store the result in xmm1 \n                                                     subject to writemask k1. \n                                                     Convert eight packed     \n   EVEX.256.66.MAP5.W0 1D                            single precision         \n   /r VCVTPS2PHX                       AVX512-FP16   floating-point values in \n   xmm1{k1}{z},           A  V/V       AVX512VL      ymm2/m256/m32bcst to     \n   ymm2/m256/m32bcst                                 packed FP16 values, and  \n                                                     store the result in xmm1 \n                                                     subject to writemask k1. \n                                                     Convert sixteen packed   \n   EVEX.512.66.MAP5.W0 1D                            single precision         \n   /r VCVTPS2PHX                                     floating-point values in \n   ymm1{k1}{z},           A  V/V       AVX512-FP16   zmm2 /m512/m32bcst to    \n   zmm2/m512/m32bcst {er}                            packed FP16 values, and  \n                                                     store the result in ymm1 \n                                                     subject to writemask k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed single precision floating values in the\n   source operand to FP16 values and stores to the destination operand.\n\n   The VCVTPS2PHX instruction supports broadcasting.\n\n   This instruction uses MXCSR.DAZ for handling FP32 inputs. FP16 outputs can\n   be normal or denormal numbers, and are not conditionally flushed based on\n   MXCSR settings.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["hlt", "                                   HLT \u2014 Halt\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description \n   F4     HLT         ZO    Valid       Valid           Halt        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Stops instruction execution and places the processor in a HALT state. An\n   enabled interrupt (including NMI and SMI), a debug exception, the BINIT#\n   signal, the INIT# signal, or the RESET# signal will resume execution. If\n   an interrupt (including NMI) is used to resume execution after a HLT\n   instruction, the saved instruction pointer (CS:EIP) points to the\n   instruction following the HLT instruction.\n\n   When a HLT instruction is executed on an Intel 64 or IA-32 processor\n   supporting Intel Hyper-Threading Technology, only the logical processor\n   that executes the instruction is halted. The other logical processors in\n   the physical processor remain active, unless they are each individually\n   halted by executing a HLT instruction.\n\n   The HLT instruction is a privileged instruction. When the processor is\n   running in protected or virtual-8086 mode, the privilege level of a\n   program or procedure must be 0 to execute the HLT instruction.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vdbpsadbw", "VDBPSADBW \u2014 Double Block Packed Sum-Absolute-Differences (SAD) on Unsigned Bytes\n\n                                64/32 Bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Compute packed SAD word    \n                                                   results of unsigned bytes  \n                                                   in dword block from xmm2   \n   EVEX.128.66.0F3A.W0 42                          with unsigned bytes of     \n   /r ib VDBPSADBW xmm1   A     V/V       AVX512VL dword blocks transformed   \n   {k1}{z}, xmm2,                         AVX512BW from xmm3/m128 using the   \n   xmm3/m128, imm8                                 shuffle controls in imm8.  \n                                                   Results are written to     \n                                                   xmm1 under the writemask   \n                                                   k1.                        \n                                                   Compute packed SAD word    \n                                                   results of unsigned bytes  \n                                                   in dword block from ymm2   \n   EVEX.256.66.0F3A.W0 42                          with unsigned bytes of     \n   /r ib VDBPSADBW ymm1   A     V/V       AVX512VL dword blocks transformed   \n   {k1}{z}, ymm2,                         AVX512BW from ymm3/m256 using the   \n   ymm3/m256, imm8                                 shuffle controls in imm8.  \n                                                   Results are written to     \n                                                   ymm1 under the writemask   \n                                                   k1.                        \n                                                   Compute packed SAD word    \n                                                   results of unsigned bytes  \n                                                   in dword block from zmm2   \n   EVEX.512.66.0F3A.W0 42                          with unsigned bytes of     \n   /r ib VDBPSADBW zmm1   A     V/V       AVX512BW dword blocks transformed   \n   {k1}{z}, zmm2,                                  from zmm3/m512 using the   \n   zmm3/m512, imm8                                 shuffle controls in imm8.  \n                                                   Results are written to     \n                                                   zmm1 under the writemask   \n                                                   k1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Compute packed SAD (sum of absolute differences) word results of unsigned\n   bytes from two 32-bit dword elements. Packed SAD word results are\n   calculated in multiples of qword superblocks, producing 4 SAD word results\n   in each 64-bit superblock of the destination register.\n\n   Within each super block of packed word results, the SAD results from two\n   32-bit dword elements are calculated as follows:\n\n     * The lower two word results are calculated each from the SAD operation\n       between a sliding dword element within a qword superblock from an\n       intermediate vector with a stationary dword element in the\n       corresponding qword superblock of the first source operand. The\n       intermediate vector, see \u201cTmp1\u201d in Figure 5-8, is constructed from the\n       second source operand the imm8 byte as shuffle control to select dword\n       elements within a 128-bit lane of the second source operand. The two\n       sliding dword elements in a qword superblock of Tmp1 are located at\n       byte offset 0 and 1 within the superblock, respectively. The\n       stationary dword element in the qword superblock from the first source\n       operand is located at byte offset 0.\n     * The next two word results are calculated each from the SAD operation\n       between a sliding dword element within a qword superblock from the\n       intermediate vector Tmp1 with a second stationary dword element in the\n       corresponding qword superblock of the first source operand. The two\n       sliding dword elements in a qword superblock of Tmp1 are located at\n       byte offset 2and 3 within the superblock, respectively. The stationary\n       dword element in the qword superblock from the first source operand is\n       located at byte offset 4.\n     * The intermediate vector is constructed in 128-bits lanes. Within each\n       128-bit lane, each dword element of the intermediate vector is\n       selected by a two-bit field within the imm8 byte on the corresponding\n       128-bits of the second source operand. The imm8 byte serves as dword\n       shuffle control within each 128-bit lanes of the intermediate vector\n       and the second source operand, similarly to PSHUFD.\n\n   The first source operand is a ZMM/YMM/XMM register. The second source\n   operand is a ZMM/YMM/XMM register, or a 512/256/128-bit memory location.\n   The destination operand is conditionally updated based on writemask k1 at\n   16-bit word granularity.\n\n   127+128*n 95+128*n 63+128*n 31+128*n 128*n 128-bit Lane of Src2 DW1 DW0\n   DW3 DW2 00B: DW0 01B: DW1 10B: DW2 imm8 shuffle control 11B: DW3 75310\n   127+128*n 95+128*n 63+128*n 31+128*n 128*n 128-bit Lane of Tmp1 Tmp1 qword\n   superblock 39 31 23 15 8 55 47 39 31 24 Tmp1 sliding dword Tmp1 sliding\n   dword 31 23 15 7 0 63 55 47 39 32 Src1 stationary dword 0 Src1 stationary\n   dword 1 _ _ _ _ _ _ _ _ abs abs abs abs abs abs abs abs + + 47 39 31 23 16\n   31 23 15 7 0 Tmp1 sliding dword Tmp1 sliding dword 63 55 47 31 23 15 7 0\n   Src1 stationary dword 1 Src1 stationary dword 0 ____ ____ abs abs abs abs\n   abs abs abs abs + 63 47 31 15 0 Destination qword superblock Figure 5-8.\n   64-bit Super Block of SAD Operation in VDBPSADBW\n"],
	["scas:scasb:scasw:scasd", "                      SCAS/SCASB/SCASW/SCASD \u2014 Scan String\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n                                                  Compare AL with byte at     \n   AE         SCAS m8     ZO    Valid  Valid      ES:(E)DI or RDI, then set   \n                                                  status flags.^1             \n                                                  Compare AX with word at     \n   AF         SCAS m16    ZO    Valid  Valid      ES:(E)DI or RDI, then set   \n                                                  status flags.^1             \n                                                  Compare EAX with doubleword \n   AF         SCAS m32    ZO    Valid  Valid      at ES(E)DI or RDI then set  \n                                                  status flags.^1             \n                                                  Compare RAX with quadword   \n   REX.W + AF SCAS m64    ZO    Valid  N.E.       at RDI or EDI then set      \n                                                  status flags.               \n                                                  Compare AL with byte at     \n   AE         SCASB       ZO    Valid  Valid      ES:(E)DI or RDI then set    \n                                                  status flags.^1             \n                                                  Compare AX with word at     \n   AF         SCASW       ZO    Valid  Valid      ES:(E)DI or RDI then set    \n                                                  status flags.^1             \n                                                  Compare EAX with doubleword \n   AF         SCASD       ZO    Valid  Valid      at ES:(E)DI or RDI then set \n                                                  status flags.^1             \n                                                  Compare RAX with quadword   \n   REX.W + AF SCASQ       ZO    Valid  N.E.       at RDI or EDI then set      \n                                                  status flags.               \n\n     1. In 64-bit mode, only 64-bit (RDI) and 32-bit (EDI) address sizes are\n     supported. In non-64-bit mode, only 32-bit (EDI) and 16-bit (DI) address\n     sizes are supported.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   In non-64-bit modes and in default 64-bit mode: this instruction compares\n   a byte, word, doubleword or quadword specified using a memory operand with\n   the value in AL, AX, or EAX. It then sets status flags in EFLAGS recording\n   the results. The memory operand address is read from ES:(E)DI register\n   (depending on the address-size attribute of the instruction and the\n   current operational mode). Note that ES cannot be overridden with a\n   segment override prefix.\n\n   At the assembly-code level, two forms of this instruction are allowed. The\n   explicit-operand form and the no-operands form. The explicit-operand form\n   (specified using the SCAS mnemonic) allows a memory operand to be\n   specified explicitly. The memory operand must be a symbol that indicates\n   the size and location of the operand value. The register operand is then\n   automatically selected to match the size of the memory operand (AL\n   register for byte comparisons, AX for word comparisons, EAX for doubleword\n   comparisons). The explicit-operand form is provided to allow\n   documentation. Note that the documentation provided by this form can be\n   misleading. That is, the memory operand symbol must specify the correct\n   type (size) of the operand (byte, word, or doubleword) but it does not\n   have to specify the correct location. The location is always specified by\n   ES:(E)DI.\n\n   The no-operands form of the instruction uses a short form of SCAS. Again,\n   ES:(E)DI is assumed to be the memory operand and AL, AX, or EAX is assumed\n   to be the register operand. The size of operands is selected by the\n   mnemonic: SCASB (byte comparison), SCASW (word comparison), or SCASD\n   (doubleword comparison).\n\n   After the comparison, the (E)DI register is incremented or decremented\n   automatically according to the setting of the DF flag in the EFLAGS\n   register. If the DF flag is 0, the (E)DI register is incremented; if the\n   DF flag is 1, the (E)DI register is decremented. The register is\n   incremented or decremented by 1 for byte operations, by 2 for word\n   operations, and by 4 for doubleword operations.\n\n   SCAS, SCASB, SCASW, SCASD, and SCASQ can be preceded by the REP prefix for\n   block comparisons of ECX bytes, words, doublewords, or quadwords. Often,\n   however, these instructions will be used in a LOOP construct that takes\n   some action based on the setting of status flags. See \u201cREP/REPE/REPZ\n   /REPNE/REPNZ\u2014Repeat String Operation Prefix\u201d in this chapter for a\n   description of the REP prefix.\n\n   In 64-bit mode, the instruction\u2019s default address size is 64-bits, 32-bit\n   address size is supported using the prefix 67H. Using a REX prefix in the\n   form of REX.W promotes operation on doubleword operand to 64 bits. The\n   64-bit no-operand mnemonic is SCASQ. Address of the memory operand is\n   specified in either RDI or EDI, and AL/AX/EAX/RAX may be used as the\n   register operand. After a comparison, the destination register is\n   incremented or decremented by the current operand size (depending on the\n   value of the DF flag). See the summary chart at the beginning of this\n   section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   The OF, SF, ZF, AF, PF, and CF flags are set according to the temporary\n   result of the comparison.\n"],
	["vfnmsub132pd:vfnmsub213pd:vfnmsub231pd", "   VFNMSUB132PD/VFNMSUB213PD/VFNMSUB231PD \u2014 Fused Negative Multiply-Subtract\n                ofPacked Double Precision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.128.66.0F38.W1 9E /r                          values from xmm1 and     \n   VFNMSUB132PD xmm1, xmm2, A     V/V       FMA      xmm3/mem, negate the     \n   xmm3/m128                                         multiplication result    \n                                                     and subtract xmm2 and    \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.128.66.0F38.W1 AE /r                          values from xmm1 and     \n   VFNMSUB213PD xmm1, xmm2, A     V/V       FMA      xmm2, negate the         \n   xmm3/m128                                         multiplication result    \n                                                     and subtract xmm3/mem    \n                                                     and put result in xmm1.  \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.128.66.0F38.W1 BE /r                          values from xmm2 and     \n   VFNMSUB231PD xmm1, xmm2, A     V/V       FMA      xmm3/mem, negate the     \n   xmm3/m128                                         multiplication result    \n                                                     and subtract xmm1 and    \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.256.66.0F38.W1 9E /r                          values from ymm1 and     \n   VFNMSUB132PD ymm1, ymm2, A     V/V       FMA      ymm3/mem, negate the     \n   ymm3/m256                                         multiplication result    \n                                                     and subtract ymm2 and    \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.256.66.0F38.W1 AE /r                          values from ymm1 and     \n   VFNMSUB213PD ymm1, ymm2, A     V/V       FMA      ymm2, negate the         \n   ymm3/m256                                         multiplication result    \n                                                     and subtract ymm3/mem    \n                                                     and put result in ymm1.  \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.256.66.0F38.W1 BE /r                          values from ymm2 and     \n   VFNMSUB231PD ymm1, ymm2, A     V/V       FMA      ymm3/mem, negate the     \n   ymm3/m256                                         multiplication result    \n                                                     and subtract ymm1 and    \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 9E                            values from xmm1 and     \n   /r VFNMSUB132PD xmm1     B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm2,                           AVX512F  negate the               \n   xmm3/m128/m64bcst                                 multiplication result    \n                                                     and subtract xmm2 and    \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 AE                            values from xmm1 and     \n   /r VFNMSUB213PD xmm1     B     V/V       AVX512VL xmm2, negate the         \n   {k1}{z}, xmm2,                           AVX512F  multiplication result    \n   xmm3/m128/m64bcst                                 and subtract             \n                                                     xmm3/m128/m64bcst and    \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 BE                            values from xmm2 and     \n   /r VFNMSUB231PD xmm1     B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm2,                           AVX512F  negate the               \n   xmm3/m128/m64bcst                                 multiplication result    \n                                                     and subtract xmm1 and    \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 9E                            values from ymm1 and     \n   /r VFNMSUB132PD ymm1     B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  negate the               \n   ymm3/m256/m64bcst                                 multiplication result    \n                                                     and subtract ymm2 and    \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 AE                            values from ymm1 and     \n   /r VFNMSUB213PD ymm1     B     V/V       AVX512VL ymm2, negate the         \n   {k1}{z}, ymm2,                           AVX512F  multiplication result    \n   ymm3/m256/m64bcst                                 and subtract             \n                                                     ymm3/m256/m64bcst and    \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 BE                            values from ymm2 and     \n   /r VFNMSUB231PD ymm1     B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  negate the               \n   ymm3/m256/m64bcst                                 multiplication result    \n                                                     and subtract ymm1 and    \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 9E                            values from zmm1 and     \n   /r VFNMSUB132PD zmm1     B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    negate the               \n   zmm3/m512/m64bcst{er}                             multiplication result    \n                                                     and subtract zmm2 and    \n                                                     put result in zmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 AE                            values from zmm1 and     \n   /r VFNMSUB213PD zmm1     B     V/V       AVX512F  zmm2, negate the         \n   {k1}{z}, zmm2,                                    multiplication result    \n   zmm3/m512/m64bcst{er}                             and subtract             \n                                                     zmm3/m512/m64bcst and    \n                                                     put result in zmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 BE                            values from zmm2 and     \n   /r VFNMSUB231PD zmm1     B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    negate the               \n   zmm3/m512/m64bcst{er}                             multiplication result    \n                                                     and subtract zmm1 and    \n                                                     put result in zmm1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMSUB132PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the first source operand to the two, four or\n   eight packed double precision floating-point values in the third source\n   operand. From negated infinite precision intermediate results, subtracts\n   the two, four or eight packed double precision floating-point values in\n   the second source operand, performs rounding and stores the resulting two,\n   four or eight packed double precision floating-point values to the\n   destination operand (first source operand).\n\n   VFNMSUB213PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source operand to the two, four or\n   eight packed double precision floating-point values in the first source\n   operand. From negated infinite precision intermediate results, subtracts\n   the two, four or eight packed double precision floating-point values in\n   the third source operand, performs rounding and stores the resulting two,\n   four or eight packed double precision floating-point values to the\n   destination operand (first source operand).\n\n   VFNMSUB231PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source to the two, four or eight\n   packed double precision floating-point values in the third source operand.\n   From negated infinite precision intermediate results, subtracts the two,\n   four or eight packed double precision floating-point values in the first\n   source operand, performs rounding and stores the resulting two, four or\n   eight packed double precision floating-point values to the destination\n   operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["vcvtdq2ph", "  VCVTDQ2PH \u2014 Convert Packed Signed Doubleword Integers to Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert four packed   \n                                                        signed doubleword     \n                                                        integers from         \n   EVEX.128.NP.MAP5.W0 5B /r                AVX512-FP16 xmm2/m128/m32bcst to  \n   VCVTDQ2PH xmm1{k1}{z},         A V/V     AVX512VL    four packed FP16      \n   xmm2/m128/m32bcst                                    values, and store the \n                                                        result in xmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert eight packed  \n                                                        signed doubleword     \n                                                        integers from         \n   EVEX.256.NP.MAP5.W0 5B /r                AVX512-FP16 ymm2/m256/m32bcst to  \n   VCVTDQ2PH xmm1{k1}{z},         A V/V     AVX512VL    eight packed FP16     \n   ymm2/m256/m32bcst                                    values, and store the \n                                                        result in xmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert sixteen       \n                                                        packed signed         \n                                                        doubleword integers   \n   EVEX.512.NP.MAP5.W0 5B /r                            from                  \n   VCVTDQ2PH ymm1{k1}{z},         A V/V     AVX512-FP16 zmm2/m512/m32bcst to  \n   zmm2/m512/m32bcst {er}                               sixteen packed FP16   \n                                                        values, and store the \n                                                        result in ymm1        \n                                                        subject to writemask  \n                                                        k1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts four, eight, or sixteen packed signed doubleword\n   integers in the source operand to four, eight, or sixteen packed FP16\n   values in the destination operand.\n\n   EVEX encoded versions: The source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location or a 512/256/128-bit vector broadcast from\n   a 32-bit memory location. The destination operand is a YMM/XMM register\n   conditionally updated with writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b, otherwise instructions will #UD.\n\n   If the result of the convert operation is overflow and MXCSR.OM=0 then a\n   SIMD exception will be raised with OE=1, PE=1.\n"],
	["movq2dq", "          MOVQ2DQ \u2014 Move Quadword from MMX Technology to XMM Register\n\n   Opcode /        Op/En 64/32-bit Mode CPUID Feature Description             \n   Instruction                          Flag          \n   F3 0F D6 /r     RM    V/V            SSE2          Move quadword from mmx  \n   MOVQ2DQ xmm, mm                                    to low quadword of xmm. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the quadword from the source operand (second operand) to the low\n   quadword of the destination operand (first operand). The source operand is\n   an MMX technology register and the destination operand is an XMM register.\n\n   This instruction causes a transition from x87 FPU to MMX technology\n   operation (that is, the x87 FPU top-of-stack pointer is set to 0 and the\n   x87 FPU tag word is set to all 0s [valid]). If this instruction is\n   executed while an x87 FPU floating-point exception is pending, the\n   exception is handled before the MOVQ2DQ instruction is executed.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["vgetexpsd", "VGETEXPSD \u2014 Convert Exponents of Scalar Double Precision Floating-Point Value to\n                      DoublePrecision Floating-Point Value\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Convert the biased         \n                                                   exponent (bits 62:52) of   \n                                                   the low double precision   \n                                                   floating-point value in    \n   EVEX.LLIG.66.0F38.W1 43                         xmm3/m64 to a double       \n   /r VGETEXPSD xmm1                               precision floating-point   \n   {k1}{z}, xmm2,          A     V/V       AVX512F value representing         \n   xmm3/m64{sae}                                   unbiased integer exponent. \n                                                   Stores the result to the   \n                                                   low 64-bit of xmm1 under   \n                                                   the writemask k1 and merge \n                                                   with the other elements of \n                                                   xmm2.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Extracts the biased exponent from the normalized double precision\n   floating-point representation of the low qword data element of the source\n   operand (the third operand) as unbiased signed integer value, or convert\n   the denormal representation of input data to unbiased negative integer\n   values. The integer value of the unbiased exponent is converted to double\n   precision floating-point value and written to the destination operand (the\n   first operand) as double precision floating-point numbers. Bits (127:64)\n   of the XMM register destination are copied from corresponding bits in the\n   first source operand.\n\n   The destination must be a XMM register, the source operand can be a XMM\n   register or a float64 memory location.\n\n   If writemasking is used, the low quadword element of the destination\n   operand is conditionally updated depending on the value of writemask\n   register k1. If writemasking is not used, the low quadword element of the\n   destination operand is unconditionally updated.\n\n   Each GETEXP operation converts the exponent value into a floating-point\n   number (permitting input value in denormal representation). Special cases\n   of input values are listed in Table 5-15.\n\n   The formula is:\n\n   GETEXP(x) = floor(log_2(|x|))\n\n   Notation floor(x) stands for maximal integer not exceeding real number x.\n"],
	["vgetmantpd", "VGETMANTPD \u2014 Extract Float64 Vector of Normalized Mantissas From Float64 Vector\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Get Normalized Mantissa \n                                                      from float64 vector     \n   EVEX.128.66.0F3A.W1 26 /r                          xmm2/m128/m64bcst and   \n   ib VGETMANTPD xmm1                        AVX512VL store the result in     \n   {k1}{z},                  A     V/V       AVX512F  xmm1, using imm8 for    \n   xmm2/m128/m64bcst, imm8                            sign control and        \n                                                      mantissa interval       \n                                                      normalization, under    \n                                                      writemask.              \n                                                      Get Normalized Mantissa \n                                                      from float64 vector     \n   EVEX.256.66.0F3A.W1 26 /r                          ymm2/m256/m64bcst and   \n   ib VGETMANTPD ymm1                        AVX512VL store the result in     \n   {k1}{z},                  A     V/V       AVX512F  ymm1, using imm8 for    \n   ymm2/m256/m64bcst, imm8                            sign control and        \n                                                      mantissa interval       \n                                                      normalization, under    \n                                                      writemask.              \n                                                      Get Normalized Mantissa \n                                                      from float64 vector     \n   EVEX.512.66.0F3A.W1 26 /r                          zmm2/m512/m64bcst and   \n   ib VGETMANTPD zmm1                                 store the result in     \n   {k1}{z},                  A     V/V       AVX512F  zmm1, using imm8 for    \n   zmm2/m512/m64bcst{sae},                            sign control and        \n   imm8                                               mantissa interval       \n                                                      normalization, under    \n                                                      writemask.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\n  Description \u00b6\n\n   Convert double precision floating values in the source operand (the second\n   operand) to double precision floating-point values with the mantissa\n   normalization and sign control specified by the imm8 byte, see Figure\n   5-15. The converted results are written to the destination operand (the\n   first operand) using writemask k1. The normalized mantissa is specified by\n   interv (imm8[1:0]) and the sign control (sc) is specified by bits 3:2 of\n   the immediate byte.\n\n   The destination operand is a ZMM/YMM/XMM register updated under the\n   writemask. The source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 64-bit memory location.\n\n   0 imm8 Must Be Zero Sign Control (SC) Normaiization Interval Imm8[1:0] =\n   00b : Interval is [ 1, 2) Imm8[3:2] = 00b : sign(SRC) Imm8[1:0] = 01b :\n   Interval is [1/2, 2) Imm8[3:2] = 01b : 0 Imm8[1:0] = 10b : Interval is [\n   1/2, 1) Imm8[3] = 1b : qNan_Indefinite if sign(SRC) != 0, regardless of\n   imm8[2]. Imm8[1:0] = 11b : Interval is [3/4, 3/2) Figure 5-15. Imm8\n   Controls for VGETMANTPD/SD/PS/SS\n\n   For each input double precision floating-point value x, The conversion\n   operation is:\n\n   GetMant(x) = \u00b12^k|x.significand|\n\n   where:\n\n   1 <= |x.significand| < 2\n\n   Unbiased exponent k can be either 0 or -1, depending on the interval range\n   defined by interv, the range of the significand and whether the exponent\n   of the source is even or odd. The sign of the final result is determined\n   by sc\n\n   and the source sign. The encoded value of imm8[1:0] and sign control are\n   shown in Figure 5-15.\n\n   Each converted double precision floating-point result is encoded according\n   to the sign control, the unbiased exponent k (adding bias) and a mantissa\n   normalized to the range specified by interv.\n\n   The GetMant() function follows Table 5-18 when dealing with floating-point\n   special numbers.\n\n   This instruction is writemasked, so only those elements with the\n   corresponding bit set in vector mask register k1 are computed and stored\n   into the destination. Elements in zmm1 with the corresponding bit clear in\n   k1 retain their previous values.\n\n   Note: EVEX.vvvv is reserved and must be 1111b; otherwise instructions will\n   #UD.\n\n   Input    Result                                   Exceptions / Comments    \n   NaN      QNaN(SRC)                                Ignore interv If (SRC =  \n                                                     SNaN) then #IE           \n   +\u221e       1.0                                      Ignore interv            \n   +0       1.0                                      Ignore interv            \n   -0       IF (SC[0]) THEN +1.0 ELSE -1.0           Ignore interv            \n   -\u221e       IF (SC[1]) THEN {QNaN_Indefinite} ELSE { Ignore interv If (SC[1]) \n            IF (SC[0]) THEN +1.0 ELSE -1.0           then #IE                 \n   negative SC[1] ? QNaN_Indefinite : Getmant(SRC)^1 If (SC[1]) then #IE      \n\n   Table 5-18. GetMant() Special Float Values Behavior\n\n     1. In case SC[1]==0, the sign of Getmant(SRC) is declared according to\n     SC[0].\n"],
	["cvttsd2si", "CVTTSD2SI \u2014 Convert With Truncation Scalar Double Precision Floating-Point Value\n                                to SignedInteger\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Convert one double          \n   F2 0F 2C /r CVTTSD2SI                          precision floating-point    \n   r32, xmm1/m64           A    V/V       SSE2    value from xmm1/m64 to one  \n                                                  signed doubleword integer   \n                                                  in r32 using truncation.    \n                                                  Convert one double          \n   F2 REX.W 0F 2C /r                              precision floating-point    \n   CVTTSD2SI r64, xmm1/m64 A    V/N.E.    SSE2    value from xmm1/m64 to one  \n                                                  signed quadword integer in  \n                                                  r64 using truncation.       \n                                                  Convert one double          \n   VEX.LIG.F2.0F.W0 2C /r                         precision floating-point    \n   ^1 VCVTTSD2SI r32,      A    V/V       AVX     value from xmm1/m64 to one  \n   xmm1/m64                                       signed doubleword integer   \n                                                  in r32 using truncation.    \n                                                  Convert one double          \n   VEX.LIG.F2.0F.W1 2C /r                         precision floating-point    \n   ^1 VCVTTSD2SI r64,      B    V/N.E.^2  AVX     value from xmm1/m64 to one  \n   xmm1/m64                                       signed quadword integer in  \n                                                  r64 using truncation.       \n                                                  Convert one double          \n   EVEX.LLIG.F2.0F.W0 2C                          precision floating-point    \n   /r VCVTTSD2SI r32,      B    V/V       AVX512F value from xmm1/m64 to one  \n   xmm1/m64{sae}                                  signed doubleword integer   \n                                                  in r32 using truncation.    \n                                                  Convert one double          \n   EVEX.LLIG.F2.0F.W1 2C                          precision floating-point    \n   /r VCVTTSD2SI r64,      B    V/N.E.^2  AVX512F value from xmm1/m64 to one  \n   xmm1/m64{sae}                                  signed quadword integer in  \n                                                  r64 using truncation.       \n\n     1. Software should ensure VCVTTSD2SI is encoded with VEX.L=0. Encoding\n     VCVTTSD2SI with VEX.L=1 may encounter unpredictable behavior across\n     different processor generations.\n\n     2. For this specific instruction, VEX.W/EVEX.W in non-64 bit is ignored;\n     the instructions behaves as if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A          ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts a double precision floating-point value in the source operand\n   (the second operand) to a signed double-word integer (or signed quadword\n   integer if operand size is 64 bits) in the destination operand (the first\n   operand). The source operand can be an XMM register or a 64-bit memory\n   location. The destination operand is a general purpose register. When the\n   source operand is an XMM register, the double precision floating-point\n   value is contained in the low quadword of the register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register.\n\n   If a converted result exceeds the range limits of signed doubleword\n   integer (in non-64-bit modes or 64-bit mode with REX.W/VEX.W/EVEX.W=0),\n   the floating-point invalid exception is raised, and if this exception is\n   masked, the indefinite integer value (80000000H) is returned.\n\n   If a converted result exceeds the range limits of signed quadword integer\n   (in 64-bit mode and REX.W/VEX.W/EVEX.W = 1), the floating-point invalid\n   exception is raised, and if this exception is masked, the indefinite\n   integer value (80000000_00000000H) is returned.\n\n   Legacy SSE instructions: In 64-bit mode, Use of the REX.W prefix promotes\n   the instruction to 64-bit operation. See the summary chart at the\n   beginning of this section for encoding data and limits.\n\n   VEX.W1 and EVEX.W1 versions: promotes the instruction to produce 64-bit\n   data in 64-bit mode.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCVTTSD2SI is encoded with VEX.L=0. Encoding\n   VCVTTSD2SI with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["vsqrtph", "              VSQRTPH \u2014 Compute Square Root of Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En bit    \n   Mode Flag CPUID Feature       \n   Instruction En bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En bit Mode Flag  \n   CPUID Feature Instruction En  \n   bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Compute square roots   \n                                                       of the packed FP16     \n   EVEX.128.NP.MAP5.W0 51 /r               AVX512-FP16 values in              \n   VSQRTPH xmm1{k1}{z},          A V/V     AVX512VL    xmm2/m128/m16bcst, and \n   xmm2/m128/m16bcst                                   store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Compute square roots   \n                                                       of the packed FP16     \n   EVEX.256.NP.MAP5.W0 51 /r               AVX512-FP16 values in              \n   VSQRTPH ymm1{k1}{z},          A V/V     AVX512VL    ymm2/m256/m16bcst, and \n   ymm2/m256/m16bcst                                   store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Compute square roots   \n                                                       of the packed FP16     \n   EVEX.512.NP.MAP5.W0 51 /r                           values in              \n   VSQRTPH zmm1{k1}{z},          A V/V     AVX512-FP16 zmm2/m512/m16bcst, and \n   zmm2/m512/m16bcst {er}                              store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction performs a packed FP16 square-root computation on the\n   values from source operand and stores the packed FP16 result in the\n   destination operand. The destination elements are updated according to the\n   write-mask.\n"],
	["sha1msg1", " SHA1MSG1 \u2014 Perform an Intermediate Calculation for the Next Four SHA1 Message\n                                     Dwords\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Performs an intermediate   \n                                                   calculation for the next   \n   NP 0F 38 C9 /r SHA1MSG1                         four SHA1 message dwords   \n   xmm1, xmm2/m128         RM    V/V       SHA     using previous message     \n                                                   dwords from xmm1 and       \n                                                   xmm2/m128, storing the     \n                                                   result in xmm1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   The SHA1MSG1 instruction is one of two SHA1 message scheduling\n   instructions. The instruction performs an intermediate calculation for the\n   next four SHA1 message dwords.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pmulhuw", "       PMULHUW \u2014 Multiply Packed Unsigned Integers and Store High Result\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply the packed      \n                                                     unsigned word integers   \n   NP 0F E4 /r^1 PMULHUW    A     V/V       SSE      in mm1 register and      \n   mm1, mm2/m64                                      mm2/m64, and store the   \n                                                     high 16 bits of the      \n                                                     results in mm1.          \n                                                     Multiply the packed      \n                                                     unsigned word integers   \n   66 0F E4 /r PMULHUW      A     V/V       SSE2     in xmm1 and xmm2/m128,   \n   xmm1, xmm2/m128                                   and store the high 16    \n                                                     bits of the results in   \n                                                     xmm1.                    \n                                                     Multiply the packed      \n   VEX.128.66.0F.WIG E4 /r                           unsigned word integers   \n   VPMULHUW xmm1, xmm2,     B     V/V       AVX      in xmm2 and xmm3/m128,   \n   xmm3/m128                                         and store the high 16    \n                                                     bits of the results in   \n                                                     xmm1.                    \n                                                     Multiply the packed      \n   VEX.256.66.0F.WIG E4 /r                           unsigned word integers   \n   VPMULHUW ymm1, ymm2,     B     V/V       AVX2     in ymm2 and ymm3/m256,   \n   ymm3/m256                                         and store the high 16    \n                                                     bits of the results in   \n                                                     ymm1.                    \n                                                     Multiply the packed      \n   EVEX.128.66.0F.WIG E4 /r                          unsigned word integers   \n   VPMULHUW xmm1 {k1}{z},   C     V/V       AVX512VL in xmm2 and xmm3/m128,   \n   xmm2, xmm3/m128                          AVX512BW and store the high 16    \n                                                     bits of the results in   \n                                                     xmm1 under writemask k1. \n                                                     Multiply the packed      \n   EVEX.256.66.0F.WIG E4 /r                          unsigned word integers   \n   VPMULHUW ymm1 {k1}{z},   C     V/V       AVX512VL in ymm2 and ymm3/m256,   \n   ymm2, ymm3/m256                          AVX512BW and store the high 16    \n                                                     bits of the results in   \n                                                     ymm1 under writemask k1. \n                                                     Multiply the packed      \n   EVEX.512.66.0F.WIG E4 /r                          unsigned word integers   \n   VPMULHUW zmm1 {k1}{z},   C     V/V       AVX512BW in zmm2 and zmm3/m512,   \n   zmm2, zmm3/m512                                   and store the high 16    \n                                                     bits of the results in   \n                                                     zmm1 under writemask k1. \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD unsigned multiply of the packed unsigned word integers in\n   the destination operand (first operand) and the source operand (second\n   operand), and stores the high 16 bits of each 32-bit intermediate results\n   in the destination operand. (Figure 4-12 shows this operation when using\n   64-bit operands.)\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The source operand can be an MMX\n   technology register or a 64-bit memory location. The destination operand\n   is an MMX technology register.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed. VEX.L must be 0, otherwise the instruction will #UD.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   SRC X3 X2 X1 X0 DEST Y3 Y2 Y1 Y0 Z3 = X3 \u2217 Y3 Z2 = X2 \u2217 Y2 Z1 = X1 \u2217 Y1 Z0\n   = X0 \u2217 Y0 TEMP DEST Z3[31:16] Z2[31:16] Z1[31:16] Z0[31:16] Figure 4-12.\n   PMULHUW and PMULHW Instruction Operation Using 64-bit Operands\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fsub:fsubp:fisub", "                          FSUB/FSUBP/FISUB \u2014 Subtract\n\n   Opcode  Instruction  64-Bit Compat/Leg Mode Description                    \n                        Mode   \n   D8 /4   FSUB m32fp   Valid  Valid           Subtract m32fp from ST(0) and  \n                                               store result in ST(0).         \n   DC /4   FSUB m64fp   Valid  Valid           Subtract m64fp from ST(0) and  \n                                               store result in ST(0).         \n   D8 E0+i FSUB ST(0),  Valid  Valid           Subtract ST(i) from ST(0) and  \n           ST(i)                               store result in ST(0).         \n   DC E8+i FSUB ST(i),  Valid  Valid           Subtract ST(0) from ST(i) and  \n           ST(0)                               store result in ST(i).         \n           FSUBP ST(i),                        Subtract ST(0) from ST(i),     \n   DE E8+i ST(0)        Valid  Valid           store result in ST(i), and pop \n                                               register stack.                \n                                               Subtract ST(0) from ST(1),     \n   DE E9   FSUBP        Valid  Valid           store result in ST(1), and pop \n                                               register stack.                \n   DA /4   FISUB m32int Valid  Valid           Subtract m32int from ST(0) and \n                                               store result in ST(0).         \n   DE /4   FISUB m16int Valid  Valid           Subtract m16int from ST(0) and \n                                               store result in ST(0).         \n\nDescription \u00b6\n\n   Subtracts the source operand from the destination operand and stores the\n   difference in the destination location. The destination operand is always\n   an FPU data register; the source operand can be a register or a memory\n   location. Source operands in memory can be in single precision or double\n   precision floating-point format or in word or doubleword integer format.\n\n   The no-operand version of the instruction subtracts the contents of the\n   ST(0) register from the ST(1) register and stores the result in ST(1). The\n   one-operand version subtracts the contents of a memory location (either a\n   floating-point or an integer value) from the contents of the ST(0)\n   register and stores the result in ST(0). The two-operand version,\n   subtracts the contents of the ST(0) register from the ST(i) register or\n   vice versa.\n\n   The FSUBP instructions perform the additional operation of popping the FPU\n   register stack following the subtraction. To pop the register stack, the\n   processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1. The no-operand version of the floating-point subtract\n   instructions always results in the register stack being popped. In some\n   assemblers, the mnemonic for this instruction is FSUB rather than FSUBP.\n\n   The FISUB instructions convert an integer source operand to double\n   extended-precision floating-point format before performing the\n   subtraction.\n\n   Table 3-38 shows the results obtained when subtracting various classes of\n   numbers from one another, assuming that neither overflow nor underflow\n   occurs. Here, the SRC value is subtracted from the DEST value (DEST \u2212 SRC\n   = result).\n\n   When the difference between two operands of like sign is 0, the result is\n   +0, except for the round toward \u2212\u221e mode, in which case the result is \u22120.\n   This instruction also guarantees that +0 \u2212 (\u22120) = +0, and that \u22120 \u2212 (+0) =\n   \u22120. When the source operand is an integer 0, it is treated as a +0.\n\n   When one operand is \u221e, the result is \u221e of the expected sign. If both\n   operands are \u221e of the same sign, an invalidoperation exception is\n   generated.\n\n   SRC  \n            \u2212\u221e  \u2212 F or \u2212 I \u22120   +0   + F or + I +\u221e  NaN \n        \u2212\u221e  *   \u2212\u221e         \u2212\u221e   \u2212\u221e   \u2212\u221e         \u2212\u221e  NaN \n        \u2212F  +\u221e  \u00b1F or \u00b10   DEST DEST \u2212F         \u2212\u221e  NaN \n   DEST \u22120  +\u221e  \u2212SRC       \u00b10   \u22120   \u2212 SRC      \u2212\u221e  NaN \n        +0  +\u221e  \u2212SRC       +0   \u00b10   \u2212 SRC      \u2212\u221e  NaN \n        +F  +\u221e  +F         DEST DEST \u00b1F or \u00b10   \u2212\u221e  NaN \n        +\u221e  +\u221e  +\u221e         +\u221e   +\u221e   +\u221e         *   NaN \n        NaN NaN NaN        NaN  NaN  NaN        NaN NaN \n\n   Table 3-38. FSUB/FSUBP/FISUB Results\n\n     F Means finite floating-point value.\n\n     I Means integer.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["vfixupimmsd", "               VFIXUPIMMSD \u2014 Fix Up Special Scalar Float64 Value\n\n                                    64/32 Bit CPUID                           \n   Opcode/Instruction         Op/En Mode      Feature Description\n                                    Support   Flag    \n                                                      Fix up a float64 number \n   EVEX.LLIG.66.0F3A.W1 55 /r                         in the low quadword     \n   ib VFIXUPIMMSD xmm1        A     V/V       AVX512F element of xmm2 using   \n   {k1}{z}, xmm2,                                     scalar int32 table in   \n   xmm3/m64{sae}, imm8                                xmm3/m64 and store the  \n                                                      result in xmm1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Perform a fix-up of the low quadword element encoded in double precision\n   floating-point format in the first source operand (the second operand)\n   using a 32-bit, two-level look-up table specified in the low quadword\n   element of the second source operand (the third operand) with exception\n   reporting specifier imm8. The element that is fixed-up is selected by mask\n   bit of 1 specified in the opmask k1. Mask bit of 0 in the opmask k1 or\n   table response action of 0000b preserves the corresponding element of the\n   first operand. The fixed-up element from the first source operand or the\n   preserved element in the first operand becomes the low quadword element of\n   the destination operand (the first operand). Bits 127:64 of the\n   destination operand is copied from the corresponding bits of the first\n   source operand. The destination and first source operands are XMM\n   registers. The second source operand can be a XMM register or a 64- bit\n   memory location.\n\n   The two-level look-up table perform a fix-up of each double precision\n   floating-point input data in the first source operand by decoding the\n   input data encoding into 8 token types. A response table is defined for\n   each token type that converts the input encoding in the first source\n   operand with one of 16 response actions.\n\n   This instruction is specifically intended for use in fixing up the results\n   of arithmetic calculations involving one source so that they match the\n   spec, although it is generally useful for fixing up the results of\n   multiple-instruction sequences to reflect special-number inputs. For\n   example, consider rcp(0). Input 0 to rcp, and you should get INF according\n   to the DX10 spec. However, evaluating rcp via Newton-Raphson, where\n   x=approx(1/0), yields an incorrect result. To deal with this, VFIXUPIMMPD\n   can be used after the N-R reciprocal sequence to set the result to the\n   correct value (i.e., INF when the input is 0).\n\n   If MXCSR.DAZ is not set, denormal input elements in the first source\n   operand are considered as normal inputs and do not trigger any fixup nor\n   fault reporting.\n\n   Imm8 is used to set the required flags reporting. It supports #ZE and #IE\n   fault reporting (see details below).\n\n   MXCSR.DAZ is used and refer to zmm2 only (i.e., zmm1 is not considered as\n   zero in case MXCSR.DAZ is set).\n\n   MXCSR mask bits are ignored and are treated as if all mask bits are set to\n   masked response). If any of the imm8 bits is set and the condition met for\n   fault reporting, MXCSR.IE or MXCSR.ZE might be updated.\n"],
	["rdpid", "                           RDPID \u2014 Read Processor ID\n\n   Opcode/Instruction    Op/En 64/32-bit Mode CPUID        Description        \n                                              Feature Flag \n   F3 0F C7 /7 RDPID r32 R     N.E./V         RDPID        Read IA32_TSC_AUX  \n                                                           into r32.          \n   F3 0F C7 /7 RDPID r64 R     V/N.E.         RDPID        Read IA32_TSC_AUX  \n                                                           into r64.          \n\nInstruction Operand Encoding^1 \u00b6\n\n     1.ModRM.MOD = 011B required\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   R     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reads the value of the IA32_TSC_AUX MSR (address C0000103H) into the\n   destination register. The value of CS.D and operand-size prefixes (66H and\n   REX.W) do not affect the behavior of the RDPID instruction.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfcmaddcsh:vfmaddcsh", "   VFCMADDCSH/VFMADDCSH \u2014 Complex Multiply and Accumulate Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Complex multiply a   \n                                                         pair of FP16 values  \n                                                         from xmm2 and        \n                                                         complex conjugate of \n   EVEX.LLIG.F2.MAP6.W0 57 /r                            xmm3/m32, add to     \n   VFCMADDCSH xmm1{k1}{z}, xmm2,   A V/V     AVX512-FP16 xmm1 and store the   \n   xmm3/m32 {er}                                         result in xmm1       \n                                                         subject to writemask \n                                                         k1. Bits 127:32 of   \n                                                         xmm2 are copied to   \n                                                         xmm1[127:32].        \n                                                         Complex multiply a   \n                                                         pair of FP16 values  \n                                                         from xmm2 and        \n   EVEX.LLIG.F3.MAP6.W0 57 /r                            xmm3/m32, add to     \n   VFMADDCSH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 xmm1 and store the   \n   xmm3/m32 {er}                                         result in xmm1       \n                                                         subject to writemask \n                                                         k1. Bits 127:32 of   \n                                                         xmm2 are copied to   \n                                                         xmm1[127:32].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a complex multiply and accumulate operation.\n   There are normal and complex conjugate forms of the operation.\n\n   The masking for this operation is done on 32-bit quantities representing a\n   pair of FP16 values.\n\n   Bits 127:32 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   Rounding is performed at every FMA (fused multiply and add) boundary.\n   Execution occurs as if all MXCSR exceptions are masked. MXCSR status bits\n   are updated to reflect exceptional conditions.\n"],
	["enteraccs", "             GETSEC[ENTERACCS] \u2014 Execute Authenticated Chipset Code\n\n   Opcode          Instruction       Description                              \n                                     Enter authenticated code execution mode. \n   NP 0F 37 (EAX = GETSEC[ENTERACCS] EBX holds the authenticated code module  \n   2)                                physical base address. ECX holds the     \n                                     authenticated code module size (bytes).  \n\nDescription \u00b6\n\n   The GETSEC[ENTERACCS] function loads, authenticates, and executes an\n   authenticated code module using an Intel^\u00ae TXT platform chipset's public\n   key. The ENTERACCS leaf of GETSEC is selected with EAX set to 2 at entry.\n\n   There are certain restrictions enforced by the processor for the execution\n   of the GETSEC[ENTERACCS] instruction:\n\n     * Execution is not allowed unless the processor is in protected mode or\n       IA-32e mode with CPL = 0 and EFLAGS.VM = 0.\n     * Processor cache must be available and not disabled, that is, CR0.CD\n       and CR0.NW bits must be 0.\n     * For processor packages containing more than one logical processor,\n       CR0.CD is checked to ensure consistency between enabled logical\n       processors.\n     * For enforcing consistency of operation with numeric exception\n       reporting using Interrupt 16, CR0.NE must be set.\n     * An Intel TXT-capable chipset must be present as communicated to the\n       processor by sampling of the power-on configuration capability field\n       after reset.\n     * The processor can not already be in authenticated code execution mode\n       as launched by a previous GETSEC[ENTERACCS] or GETSEC[SENTER]\n       instruction without a subsequent exiting using GETSEC[EXITAC]).\n     * To avoid potential operability conflicts between modes, the processor\n       is not allowed to execute this instruction if it currently is in SMM\n       or VMX operation.\n     * To ensure consistent handling of SIPI messages, the processor\n       executing the GETSEC[ENTERACCS] instruction must also be designated\n       the BSP (boot-strap processor) as defined by IA32_APIC_BASE.BSP (Bit\n       8).\n\n   Failure to conform to the above conditions results in the processor\n   signaling a general protection exception.\n\n   Prior to execution of the ENTERACCS leaf, other logical processors, i.e.,\n   RLPs, in the platform must be:\n\n     * Idle in a wait-for-SIPI state (as initiated by an INIT assertion or\n       through reset for non-BSP designated processors), or\n     * In the SENTER sleep state as initiated by a GETSEC[SENTER] from the\n       initiating logical processor (ILP).\n\n   If other logical processor(s) in the same package are not idle in one of\n   these states, execution of ENTERACCS signals a general protection\n   exception. The same requirement and action applies if the other logical\n   processor(s) of the same package do not have CR0.CD = 0.\n\n   A successful execution of ENTERACCS results in the ILP entering an\n   authenticated code execution mode. Prior to reaching this point, the\n   processor performs several checks. These include:\n\n     * Establish and check the location and size of the specified\n       authenticated code module to be executed by the processor.\n     * Inhibit the ILP\u2019s response to the external events: INIT, A20M, NMI,\n       and SMI.\n     * Broadcast a message to enable protection of memory and I/O from other\n       processor agents.\n     * Load the designated code module into an authenticated code execution\n       area.\n     * Isolate the contents of the authenticated code execution area from\n       further state modification by external agents.\n     * Authenticate the authenticated code module.\n     * Initialize the initiating logical processor state based on information\n       contained in the authenticated code module header.\n     * Unlock the Intel^\u00ae TXT-capable chipset private configuration space and\n       TPM locality 3 space.\n     * Begin execution in the authenticated code module at the defined entry\n       point.\n\n   The GETSEC[ENTERACCS] function requires two additional input parameters in\n   the general purpose registers EBX and ECX. EBX holds the authenticated\n   code (AC) module physical base address (the AC module must reside below 4\n   GBytes in physical address space) and ECX holds the AC module size (in\n   bytes). The physical base address and size are used to retrieve the code\n   module from system memory and load it into the internal authenticated code\n   execution area. The base physical address is checked to verify it is on a\n   modulo-4096 byte boundary. The size is verified to be a multiple of 64,\n   that it does not exceed the internal authenticated code execution area\n   capacity (as reported by GETSEC[CAPABILITIES]), and that the top address\n   of the AC module does not exceed 32 bits. An error condition results in an\n   abort of the authenticated code execution launch and the signaling of a\n   general protection exception.\n\n   As an integrity check for proper processor hardware operation, execution\n   of GETSEC[ENTERACCS] will also check the contents of all the machine check\n   status registers (as reported by the MSRs IA32_MCi_STATUS) for any valid\n   uncorrectable error condition. In addition, the global machine check\n   status register IA32_MCG_STATUS MCIP bit must be cleared and the IERR\n   processor package pin (or its equivalent) must not be asserted, indicating\n   that no machine check exception processing is currently in progress. These\n   checks are performed prior to initiating the load of the authenticated\n   code module. Any outstanding valid uncorrectable machine check error\n   condition present in these status registers at this point will result in\n   the processor signaling a general protection violation.\n\n   The ILP masks the response to the assertion of the external signals INIT#,\n   A20M, NMI#, and SMI#. This masking remains active until optionally\n   unmasked by GETSEC[EXITAC] (this defined unmasking behavior assumes\n   GETSEC[ENTERACCS] was not executed by a prior GETSEC[SENTER]). The purpose\n   of this masking control is to prevent exposure to existing external event\n   handlers that may not be under the control of the authenticated code\n   module.\n\n   The ILP sets an internal flag to indicate it has entered authenticated\n   code execution mode. The state of the A20M pin is likewise masked and\n   forced internally to a de-asserted state so that any external assertion is\n   not recognized during authenticated code execution mode.\n\n   To prevent other (logical) processors from interfering with the ILP\n   operating in authenticated code execution mode, memory (excluding implicit\n   write-back transactions) access and I/O originating from other processor\n   agents are blocked. This protection starts when the ILP enters into\n   authenticated code execution mode. Only memory and I/O transactions\n   initiated from the ILP are allowed to proceed. Exiting authenticated code\n   execution mode is done by executing GETSEC[EXITAC]. The protection of\n   memory and I/O activities remains in effect until the ILP executes\n   GETSEC[EXITAC].\n\n   Prior to launching the authenticated execution module using\n   GETSEC[ENTERACCS] or GETSEC[SENTER], the processor\u2019s MTRRs (Memory Type\n   Range Registers) must first be initialized to map out the authenticated\n   RAM addresses as WB (writeback). Failure to do so may affect the ability\n   for the processor to maintain isolation of the loaded authenticated code\n   module. If the processor detected this requirement is not met, it will\n   signal an Intel\u00ae TXT reset condition with an error code during the loading\n   of the authenticated code module.\n\n   While physical addresses within the load module must be mapped as WB, the\n   memory type for locations outside of the module boundaries must be mapped\n   to one of the supported memory types as returned by GETSEC[PARAMETERS] (or\n   UC as default).\n\n   To conform to the minimum granularity of MTRR MSRs for specifying the\n   memory type, authenticated code RAM (ACRAM) is allocated to the processor\n   in 4096 byte granular blocks. If an AC module size as specified in ECX is\n   not a multiple of 4096 then the processor will allocate up to the next\n   4096 byte boundary for mapping as ACRAM with indeterminate data. This pad\n   area will not be visible to the authenticated code module as external\n   memory nor can it depend on the value of the data used to fill the pad\n   area.\n\n   At the successful completion of GETSEC[ENTERACCS], the architectural state\n   of the processor is partially initialized from contents held in the header\n   of the authenticated code module. The processor GDTR, CS, and DS selectors\n   are initialized from fields within the authenticated code module. Since\n   the authenticated code module must be relocatable, all address references\n   must be relative to the authenticated code module base address in EBX. The\n   processor GDTR base value is initialized to the AC module header field\n   GDTBasePtr + module base address held in EBX and the GDTR limit is set to\n   the value in the GDTLimit field. The CS selector is initialized to the AC\n   module header SegSel field, while the DS selector is initialized to CS +\n   8. The segment descriptor fields are implicitly initialized to BASE=0,\n   LIMIT=FFFFFh, G=1, D=1, P=1, S=1, read/write access for DS, and\n   execute/read access for CS. The processor begins the authenticated code\n   module execution with the EIP set to the AC module header EntryPoint field\n   + module base address (EBX). The AC module based fields used for\n   initializing the processor state are checked for consistency and any\n   failure results in a shutdown condition.\n\n   A summary of the register state initialization after successful completion\n   of GETSEC[ENTERACCS] is given for the processor in Table 7-4. The paging\n   is disabled upon entry into authenticated code execution mode. The\n   authenticated code module is loaded and initially executed using physical\n   addresses. It is up to the system software after execution of\n   GETSEC[ENTERACCS] to establish a new (or restore its previous) paging\n   environment with an appropriate mapping to meet new protection\n   requirements. EBP is initialized to the authenticated code module base\n   physical address for initial execution in the authenticated environment.\n   As a result, the authenticated code can reference EBP for relative address\n   based references, given that the authenticated code module must be\n   position independent.\n\n   Register State       Initialization Status    Comment                      \n                        PG\u21900, AM\u21900, WP\u21900: Others Paging, Alignment Check,     \n   CR0                  unchanged                Write-protection are         \n                                                 disabled.                    \n                                                 Machine Check Exceptions,    \n                        MCE\u21900, CET\u21900, PCIDE\u21900:   Control-flow Enforcement     \n   CR4                  Others unchanged         Technology, and              \n                                                 Process-context Identifiers  \n                                                 disabled.                    \n   EFLAGS               00000002H                \n   IA32_EFER            0H                       IA-32e mode disabled.        \n   EIP                  AC.base + EntryPoint     AC.base is in EBX as input   \n                                                 to GETSEC[ENTERACCS].        \n                        Pre-ENTERACCS state:     Carry forward 64-bit         \n   [E|R]BX              Next [E|R]IP prior to    processor state across       \n                        GETSEC[ENTERACCS]        GETSEC[ENTERACCS].           \n                        Pre-ENTERACCS state:     Carry forward processor      \n   ECX                  [31:16]=GDTR.limit;      state across                 \n                        [15:0]=CS.sel            GETSEC[ENTERACCS].           \n                        Pre-ENTERACCS state:     Carry forward 64-bit         \n   [E|R]DX              GDTR base                processor state across       \n                                                 GETSEC[ENTERACCS].           \n   EBP                  AC.base                  \n                        Sel=[SegSel], base=0,    \n   CS                   limit=FFFFFh, G=1, D=1,  \n                        AR=9BH                   \n                        Sel=[SegSel] +8, base=0, \n   DS                   limit=FFFFFh, G=1, D=1,  \n                        AR=93H                   \n                        Base= AC.base (EBX) +    \n   GDTR                 [GDTBasePtr],            \n                        Limit=[GDTLimit]         \n   DR7                  00000400H                \n   IA32_DEBUGCTL        0H                       \n                        See Table 7-5 for        The number of initialized    \n   IA32_MISC_ENABLE     example.                 fields may change due to     \n                                                 processor implementation.    \n   Performance counters                          \n   and counter control  0H\n   registers            \n\n   Table 7-4. Register State Initialization After GETSEC[ENTERACCS]\n\n   The segmentation related processor state that has not been initialized by\n   GETSEC[ENTERACCS] requires appropriate initialization before use. Since a\n   new GDT context has been established, the previous state of the segment\n   selector values held in ES, SS, FS, GS, TR, and LDTR might not be valid.\n\n   The MSR IA32_EFER is also unconditionally cleared as part of the processor\n   state initialized by ENTERACCS. Since paging is disabled upon entering\n   authenticated code execution mode, a new paging environment will have to\n   be reestablished in order to establish IA-32e mode while operating in\n   authenticated code execution mode.\n\n   Debug exception and trap related signaling is also disabled as part of\n   GETSEC[ENTERACCS]. This is achieved by resetting DR7, TF in EFLAGs, and\n   the MSR IA32_DEBUGCTL. These debug functions are free to be re-enabled\n   once supporting exception handler(s), descriptor tables, and debug\n   registers have been properly initialized following entry into\n   authenticated code execution mode. Also, any pending single-step trap\n   condition will have been cleared upon entry into this mode.\n\n   Performance related counters and counter control registers are cleared as\n   part of execution of ENTERACCS. This implies any active performance\n   counters at any time of ENTERACCS execution will be disabled. To reactive\n   the processor performance counters, this state must be re-initialized and\n   re-enabled.\n\n   The IA32_MISC_ENABLE MSR is initialized upon entry into authenticated\n   execution mode. Certain bits of this MSR are preserved because preserving\n   these bits may be important to maintain previously established platform\n   settings (See the footnote for Table 7-5.). The remaining bits are cleared\n   for the purpose of establishing a more consistent environment for the\n   execution of authenticated code modules. One of the impacts of\n   initializing this MSR is any previous condition established by the MONITOR\n   instruction will be cleared.\n\n   To support the possible return to the processor architectural state prior\n   to execution of GETSEC[ENTERACCS], certain critical processor state is\n   captured and stored in the general- purpose registers at instruction\n   completion. [E|R]BX holds effective address ([E|R]IP) of the instruction\n   that would execute next after GETSEC[ENTERACCS], ECX[15:0] holds the CS\n   selector value, ECX[31:16] holds the GDTR limit field, and [E|R]DX holds\n   the GDTR base field. The subsequent authenticated code can preserve the\n   contents of these registers so that this state can be manually restored if\n   needed, prior to exiting authenticated code execution mode with\n   GETSEC[EXITAC]. For the processor state after exiting authenticated code\n   execution mode, see the description of GETSEC[SEXIT].\n\n   Field                      Bit position Description                        \n   Fast strings enable        0            Clear to 0.                        \n   FOPCODE compatibility mode 2            Clear to 0.                        \n   enable                     \n   Thermal monitor enable     3            Set to 1 if other thermal monitor  \n                                           capability is not enabled.^2       \n   Split-lock disable         4            Clear to 0.                        \n   Bus lock on cache line     8            Clear to 0.                        \n   splits disable             \n   Hardware prefetch disable  9            Clear to 0.                        \n   GV1/2 legacy enable        15           Clear to 0.                        \n   MONITOR/MWAIT s/m enable   18           Clear to 0.                        \n   Adjacent sector prefetch   19           Clear to 0.                        \n   disable                    \n\n   Table 7-5. IA32_MISC_ENABLE MSR Initialization^1 by ENTERACCS and SENTER\n\n     1. The number of IA32_MISC_ENABLE fields that are initialized may vary\n     due to processor implementations.\n\n     2. ENTERACCS (and SENTER) initialize the state of processor thermal\n     throttling such that at least a minimum level is enabled. If thermal\n     throttling is already enabled when executing one of these GETSEC leaves,\n     then no change in the thermal throttling control settings will occur. If\n     thermal throttling is disabled, then it will be enabled via setting of\n     the thermal throttle control bit 3 as a result of executing these GETSEC\n     leaves.\n\n   The IDTR will also require reloading with a new IDT context after entering\n   authenticated code execution mode, before any exceptions or the external\n   interrupts INTR and NMI can be handled. Since external interrupts are\n   reenabled at the completion of authenticated code execution mode (as\n   terminated with EXITAC), it is recommended\n\n   that a new IDT context be established before this point. Until such a new\n   IDT context is established, the programmer must take care in not executing\n   an INT n instruction or any other operation that would result in an\n   exception or trap signaling.\n\n   Prior to completion of the GETSEC[ENTERACCS] instruction and after\n   successful authentication of the AC module, the private configuration\n   space of the Intel TXT chipset is unlocked. The authenticated code module\n   alone can gain access to this normally restricted chipset state for the\n   purpose of securing the platform.\n\n   Once the authenticated code module is launched at the completion of\n   GETSEC[ENTERACCS], it is free to enable interrupts by setting EFLAGS.IF\n   and enable NMI by execution of IRET. This presumes that it has\n   re-established interrupt handling support through initialization of the\n   IDT, GDT, and corresponding interrupt handling code.\n\nOperation in a Uni-Processor Platform \u00b6\n\n   (* The state of the internal flag ACMODEFLAG persists across instruction\n   boundary *)\n\n   IF (CR4.SMXE=0)\n\n   THEN #UD;\n\n   ELSIF (in VMX non-root operation)\n\n   THEN VM Exit (reason=\u201dGETSEC instruction\u201d);\n\n   ELSIF (GETSEC leaf unsupported)\n\n   THEN #UD;\n\n   ELSIF ((in VMX operation) or\n\n   (CR0.PE=0) or (CR0.CD=1) or (CR0.NW=1) or (CR0.NE=0) or\n\n   (CPL>0) or (EFLAGS.VM=1) or\n\n   (IA32_APIC_BASE.BSP=0) or\n\n   (TXT chipset not present) or\n\n   (ACMODEFLAG=1) or (IN_SMM=1))\n\n   THEN #GP(0);\n\n   IF (GETSEC[PARAMETERS].Parameter_Type = 5, MCA_Handling (bit 6) = 0)\n\n   FOR I = 0 to IA32_MCG_CAP.COUNT-1 DO\n\n   IF (IA32_MC[I]_STATUS = uncorrectable error)\n\n   THEN #GP(0);\n\n   OD;\n\n   FI;\n\n   IF (IA32_MCG_STATUS.MCIP=1) or (IERR pin is asserted)\n\n   THEN #GP(0);\n\n   ACBASE := EBX;\n\n   ACSIZE := ECX;\n\n   IF (((ACBASE MOD 4096) =\u0338 0) or ((ACSIZE MOD 64 ) =\u0338 0 ) or (ACSIZE <\n   minimum module size) OR (ACSIZE > authenticated RAM capacity)) or\n   ((ACBASE+ACSIZE) > (2^32 -1)))\n\n   THEN #GP(0);\n\n   IF (secondary thread(s) CR0.CD = 1) or ((secondary thread(s)\n   NOT(wait-for-SIPI)) and\n\n   (secondary thread(s) not in SENTER sleep state)\n\n   THEN #GP(0);\n\n   Mask SMI, INIT, A20M, and NMI external pin events;\n\n   IA32_MISC_ENABLE := (IA32_MISC_ENABLE & MASK_CONST*)\n\n   (* The hexadecimal value of MASK_CONST may vary due to processor\n   implementations *)\n\n   A20M := 0;\n\n   IA32_DEBUGCTL := 0;\n\n   Invalidate processor TLB(s);\n\n   Drain Outgoing Transactions;\n\n   ACMODEFLAG := 1;\n\n   SignalTXTMessage(ProcessorHold);\n\n   Load the internal ACRAM based on the AC module size;\n\n   (* Ensure that all ACRAM loads hit Write Back memory space *)\n\n   IF (ACRAM memory type =\u0338 WB)\n\n   THEN TXT-SHUTDOWN(#BadACMMType);\n\n   IF (AC module header version isnot supported) OR (ACRAM[ModuleType] =\u0338 2)\n\n   THEN TXT-SHUTDOWN(#UnsupportedACM);\n\n   (* Authenticate the AC Module and shutdown with an error if it fails *)\n\n   KEY := GETKEY(ACRAM, ACBASE);\n\n   KEYHASH := HASH(KEY);\n\n   CSKEYHASH := READ(TXT.PUBLIC.KEY);\n\n   IF (KEYHASH =\u0338 CSKEYHASH)\n\n   THEN TXT-SHUTDOWN(#AuthenticateFail);\n\n   SIGNATURE := DECRYPT(ACRAM, ACBASE, KEY);\n\n   (* The value of SIGNATURE_LEN_CONST is implementation-specific*)\n\n   FOR I=0 to SIGNATURE_LEN_CONST - 1 DO\n\n   ACRAM[SCRATCH.I] := SIGNATURE[I];\n\n   COMPUTEDSIGNATURE := HASH(ACRAM, ACBASE, ACSIZE);\n\n   FOR I=0 to SIGNATURE_LEN_CONST - 1 DO\n\n   ACRAM[SCRATCH.SIGNATURE_LEN_CONST+I] := COMPUTEDSIGNATURE[I];\n\n   IF (SIGNATURE =\u0338 COMPUTEDSIGNATURE)\n\n   THEN TXT-SHUTDOWN(#AuthenticateFail);\n\n   ACMCONTROL := ACRAM[CodeControl];\n\n   IF ((ACMCONTROL.0 = 0) and (ACMCONTROL.1 = 1) and (snoop hit to modified\n   line detected on ACRAM load))\n\n   THEN TXT-SHUTDOWN(#UnexpectedHITM);\n\n   IF (ACMCONTROL reserved bits are set)\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACRAM[GDTBasePtr] < (ACRAM[HeaderLen] * 4 + Scratch_size)) OR\n\n   ((ACRAM[GDTBasePtr] + ACRAM[GDTLimit]) >= ACSIZE))\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACMCONTROL.0 = 1) and (ACMCONTROL.1 = 1) and (snoop hit to modified\n   line detected on ACRAM load))\n\n   THEN ACEntryPoint := ACBASE+ACRAM[ErrorEntryPoint];\n\n   ELSE\n\n   ACEntryPoint := ACBASE+ACRAM[EntryPoint];\n\n   IF ((ACEntryPoint >= ACSIZE) OR (ACEntryPoint < (ACRAM[HeaderLen] * 4 +\n   Scratch_size)))THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF (ACRAM[GDTLimit] & FFFF0000h)\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACRAM[SegSel] > (ACRAM[GDTLimit] - 15)) OR (ACRAM[SegSel] < 8))\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACRAM[SegSel].TI=1) OR (ACRAM[SegSel].RPL=\u03380))\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   CR0.[PG.AM.WP] := 0;\n\n   CR4.MCE := 0;\n\n   EFLAGS := 00000002h;\n\n   IA32_EFER := 0h;\n\n   [E|R]BX := [E|R]IP of the instruction after GETSEC[ENTERACCS];\n\n   ECX := Pre-GETSEC[ENTERACCS] GDT.limit:CS.sel;\n\n   [E|R]DX := Pre-GETSEC[ENTERACCS] GDT.base;\n\n   EBP := ACBASE;\n\n   GDTR.BASE := ACBASE+ACRAM[GDTBasePtr];\n\n   GDTR.LIMIT := ACRAM[GDTLimit];\n\n   CS.SEL := ACRAM[SegSel];\n\n   CS.BASE := 0;\n\n   CS.LIMIT := FFFFFh;\n\n   CS.G := 1;\n\n   CS.D := 1;\n\n   CS.AR := 9Bh;\n\n   DS.SEL := ACRAM[SegSel]+8;\n\n   DS.BASE := 0;\n\n   DS.LIMIT := FFFFFh;\n\n   DS.G := 1;\n\n   DS.D := 1;\n\n   DS.AR := 93h;\n\n   DR7 := 00000400h;\n\n   IA32_DEBUGCTL := 0;\n\n   SignalTXTMsg(OpenPrivate);\n\n   SignalTXTMsg(OpenLocality3);\n\n   EIP := ACEntryPoint;\n\n   END;\n\nFlags Affected \u00b6\n\n   All flags are cleared.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX Ignored.\n\nVM-exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["movdiri", "                   MOVDIRI \u2014 Move Doubleword as Direct Store\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                Support   Flag    \n   NP 0F 38 F9 /r MOVDIRI A     V/V       MOVDIRI Move doubleword from r32 to \n   m32, r32                                       m32 using direct store.     \n   NP REX.W + 0F 38 F9 /r A     V/N.E.    MOVDIRI Move quadword from r64 to   \n   MOVDIRI m64, r64                               m64 using direct store.     \n\nInstruction Operand Encoding^1 \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the doubleword integer in the source operand (second operand) to the\n   destination operand (first operand) using a direct-store operation. The\n   source operand is a general purpose register. The destination operand is a\n   32-bit memory location. In 64-bit mode, the instruction\u2019s default\n   operation size is 32 bits. Use of the REX.R prefix permits access to\n   additional registers (R8-R15). Use of the REX.W prefix promotes operation\n   to 64 bits. See summary chart at the beginning of this section for\n   encoding data and limits.\n\n   The direct-store is implemented by using write combining (WC) memory type\n   protocol for writing data. Using this protocol, the processor does not\n   write the data into the cache hierarchy, nor does it fetch the\n   corresponding cache line from memory into the cache hierarchy. If the\n   destination address is cached, the line is written-back (if modified) and\n   invalidated from the cache, before the direct-store. Unlike stores with\n   non-temporal hint that allow uncached (UC) and write-protected (WP)\n   memory-type for the destination to override the non-temporal hint,\n   direct-stores always follow WC memory type protocol irrespective of the\n   destination address memory type (including UC and WP types).\n\n   Unlike WC stores and stores with non-temporal hint, direct-stores are\n   eligible for immediate eviction from the write-combining buffer, and thus\n   not combined with younger stores (including direct-stores) to the same\n   address. Older WC and non-temporal stores held in the write-combing buffer\n   may be combined with younger direct stores to the same address. Direct\n   stores are weakly ordered relative to other stores. Software that desires\n   stronger ordering should use a fencing instruction (MFENCE or SFENCE)\n   before or after a direct store to enforce the ordering desired.\n\n   Direct-stores issued by MOVDIRI to a destination aligned to a 4-byte\n   boundary (8-byte boundary if used with REX.W prefix) guarantee 4-byte\n   (8-byte with REX.W prefix) write-completion atomicity. This means that the\n   data arrives at the destination in a single undivided 4-byte (or 8-byte)\n   write transaction. If the destination is not aligned for the write size,\n   the direct-stores issued by MOVDIRI are split and arrive at the\n   destination in two parts. Each part of such split direct-store will not\n   merge with younger stores but can arrive at the destination in either\n   order. Availability of the MOVDIRI instruction is indicated by the\n   presence of the CPUID feature flag MOVDIRI (bit 27 of the ECX register in\n   leaf 07H, see \u201cCPUID\u2014CPU Identification\u201d in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 2A).\n\n     1. The Mod field of the ModR/M byte cannot have value 11B.\n"],
	["vpgatherdd:vpgatherdq", "  VPGATHERDD/VPGATHERDQ \u2014 Gather Packed Dword, Packed Qword With Signed Dword\n                                    Indices\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Using signed dword         \n   EVEX.128.66.0F38.W0 90                 AVX512VL indices, gather dword      \n   /vsib VPGATHERDD xmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm32x                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed dword         \n   EVEX.256.66.0F38.W0 90                 AVX512VL indices, gather dword      \n   /vsib VPGATHERDD ymm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm32y                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed dword         \n   EVEX.512.66.0F38.W0 90                          indices, gather dword      \n   /vsib VPGATHERDD zmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm32z                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed dword         \n   EVEX.128.66.0F38.W1 90                 AVX512VL indices, gather quadword   \n   /vsib VPGATHERDQ xmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm32x                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed dword         \n   EVEX.256.66.0F38.W1 90                 AVX512VL indices, gather quadword   \n   /vsib VPGATHERDQ ymm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm32x                                     writemask k1 for           \n                                                   merging-masking.           \n                                                   Using signed dword         \n   EVEX.512.66.0F38.W1 90                          indices, gather quadword   \n   /vsib VPGATHERDQ zmm1  A     V/V       AVX512F  values from memory using   \n   {k1}, vm32y                                     writemask k1 for           \n                                                   merging-masking.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2               Operand 3 Operand 4 \n         Tuple1                   BaseReg (R): VSIB:base,                     \n   A     Scalar     ModRM:reg (w) VectorReg(R):           N/A       N/A\n                                  VSIB:index              \n\n  Description \u00b6\n\n   A set of 16 or 8 doubleword/quadword memory locations pointed to by base\n   address BASE_ADDR and index vector VINDEX with scale SCALE are gathered.\n   The result is written into vector zmm1. The elements are specified via the\n   VSIB (i.e., the index register is a zmm, holding packed indices). Elements\n   will only be loaded if their corresponding mask bit is one. If an\n   element\u2019s mask bit is not set, the corresponding element of the\n   destination register (zmm1) is left unchanged. The entire mask register\n   will be set to zero by this instruction unless it triggers an exception.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask register (k1) are partially updated;\n   those elements that have been gathered are placed into the destination\n   register and have their mask bits set to zero. If any traps or interrupts\n   are pending from already gathered elements, they will be delivered in lieu\n   of the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data element size is less than the index element size, the higher\n   part of the destination register and the mask register do not correspond\n   to any elements being gathered. This instruction sets those higher parts\n   to zero. It may update these unused elements to one or both of those\n   registers even if the instruction triggers an exception, and even if the\n   instruction triggers the exception before gathering any elements.\n\n   Note that:\n\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination zmm will be completed (and non-faulting).\n       Individual elements closer to the MSB may or may not be completed. If\n       a given element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to-left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n     * These instructions do not accept zeroing-masking since the 0 values in\n       k1 are used to determine completion.\n\n   Note that the presence of VSIB byte is enforced in this instruction.\n   Hence, the instruction will #UD fault if ModRM.rm is different than 100b.\n\n   This instruction has the same disp8*N and alignment rules as for scalar\n   instructions (Tuple 1).\n\n   The instruction will #UD fault if the destination vector zmm1 is the same\n   as index vector VINDEX. The instruction will #UD fault if the k0 mask\n   register is specified.\n\n   The scaled index may require more bits to represent than the address bits\n   used by the processor (e.g., in 32-bit mode, if the scale is greater than\n   one). In this case, the most significant bits beyond the number of address\n   bits are ignored.\n"],
	["pinsrb:pinsrd:pinsrq", "                 PINSRB/PINSRD/PINSRQ \u2014 Insert Byte/Dword/Qword\n\n                                     64/32 bit CPUID                          \n   Opcode/Instruction         Op/ En Mode      Feature  Description\n                                     Support   Flag     \n                                                        Insert a byte integer \n                                                        value from r32/m8     \n   66 0F 3A 20 /r ib PINSRB   A      V/V       SSE4_1   into xmm1 at the      \n   xmm1, r32/m8, imm8                                   destination element   \n                                                        in xmm1 specified by  \n                                                        imm8.                 \n                                                        Insert a dword        \n                                                        integer value from    \n   66 0F 3A 22 /r ib PINSRD   A      V/V       SSE4_1   r/m32 into the xmm1   \n   xmm1, r/m32, imm8                                    at the destination    \n                                                        element specified by  \n                                                        imm8.                 \n                                                        Insert a qword        \n                                                        integer value from    \n   66 REX.W 0F 3A 22 /r ib    A      V/N. E.   SSE4_1   r/m64 into the xmm1   \n   PINSRQ xmm1, r/m64, imm8                             at the destination    \n                                                        element specified by  \n                                                        imm8.                 \n                                                        Merge a byte integer  \n   VEX.128.66.0F3A.W0 20 /r                             value from r32/m8 and \n   ib VPINSRB xmm1, xmm2,     B      V^1/V     AVX      rest from xmm2 into   \n   r32/m8, imm8                                         xmm1 at the byte      \n                                                        offset in imm8.       \n                                                        Insert a dword        \n   VEX.128.66.0F3A.W0 22 /r                             integer value from    \n   ib VPINSRD xmm1, xmm2,     B      V/V       AVX      r32/m32 and rest from \n   r/m32, imm8                                          xmm2 into xmm1 at the \n                                                        dword offset in imm8. \n                                                        Insert a qword        \n   VEX.128.66.0F3A.W1 22 /r                             integer value from    \n   ib VPINSRQ xmm1, xmm2,     B      V/I^2     AVX      r64/m64 and rest from \n   r/m64, imm8                                          xmm2 into xmm1 at the \n                                                        qword offset in imm8. \n                                                        Merge a byte integer  \n   EVEX.128.66.0F3A.WIG 20 /r                           value from r32/m8 and \n   ib VPINSRB xmm1, xmm2,     C      V/V       AVX512BW rest from xmm2 into   \n   r32/m8, imm8                                         xmm1 at the byte      \n                                                        offset in imm8.       \n                                                        Insert a dword        \n   EVEX.128.66.0F3A.W0 22 /r                            integer value from    \n   ib VPINSRD xmm1, xmm2,     C      V/V       AVX512DQ r32/m32 and rest from \n   r32/m32, imm8                                        xmm2 into xmm1 at the \n                                                        dword offset in imm8. \n                                                        Insert a qword        \n   EVEX.128.66.0F3A.W1 22 /r                            integer value from    \n   ib VPINSRQ xmm1, xmm2,     C      V/N.E.^2  AVX512DQ r64/m64 and rest from \n   r64/m64, imm8                                        xmm2 into xmm1 at the \n                                                        qword offset in imm8. \n\n     1. In 64-bit mode, VEX.W1 is ignored for VPINSRB (similar to legacy\n     REX.W=1 prefix with PINSRB).\n\n     2. VEX.W/EVEX.W in non-64 bit is ignored; the instructions behaves as if\n     the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   B     N/A           ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Copies a byte/dword/qword from the source operand (second operand) and\n   inserts it in the destination operand (first operand) at the location\n   specified with the count operand (third operand). (The other elements in\n   the destination register are left untouched.) The source operand can be a\n   general-purpose register or a memory location. (When the source operand is\n   a general-purpose register, PINSRB copies the low byte of the register.)\n   The destination operand is an XMM register. The count operand is an 8-bit\n   immediate. When specifying a qword[dword, byte] location in an XMM\n   register, the [2, 4] least-significant bit(s) of the count operand specify\n   the location.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15, R8-15). Use of REX.W permits the use of 64 bit general\n   purpose registers.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed. VEX.L must be 0, otherwise the instruction will #UD. Attempt\n   to execute VPINSRQ in non-64-bit mode will cause #UD.\n\n   EVEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed. EVEX.L\u2019L must be 0, otherwise the instruction will #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fnop", "                              FNOP \u2014 No Operation\n\n   Opcode  Mode Leg Mode Description                \n   D9 D0                 No operation is performed. \n\nDescription \u00b6\n\n   Performs no FPU operation. This instruction takes up space in the\n   instruction stream but does not affect the FPU or machine context, except\n   the EIP register and the FPU Instruction Pointer.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C0, C1, C2, C3 undefined. \n"],
	["aad", "                     AAD \u2014 ASCII Adjust AX Before Division\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description           \n   D5 0A  AAD         ZO    Invalid     Valid           ASCII adjust AX       \n                                                        before division.      \n                                                        Adjust AX before      \n   D5 ib  AAD imm8    ZO    Invalid     Valid           division to number    \n                                                        base imm8.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Adjusts two unpacked BCD digits (the least-significant digit in the AL\n   register and the most-significant digit in the AH register) so that a\n   division operation performed on the result will yield a correct unpacked\n   BCD value. The AAD instruction is only useful when it precedes a DIV\n   instruction that divides (binary division) the adjusted value in the AX\n   register by an unpacked BCD value.\n\n   The AAD instruction sets the value in the AL register to (AL + (10 * AH)),\n   and then clears the AH register to 00H. The value in the AX register is\n   then equal to the binary equivalent of the original unpacked two-digit\n   (base 10) number in registers AH and AL.\n\n   The generalized version of this instruction allows adjustment of two\n   unpacked digits of any number base (see the \u201cOperation\u201d section below), by\n   setting the imm8 byte to the selected number base (for example, 08H for\n   octal, 0AH for decimal, or 0CH for base 12 numbers). The AAD mnemonic is\n   interpreted by all assemblers to mean adjust ASCII (base 10) values. To\n   adjust values in another number base, the instruction must be hand coded\n   in machine code (D5 imm8).\n\n   This instruction executes as described in compatibility mode and legacy\n   mode. It is not valid in 64-bit mode.\n\nFlags Affected \u00b6\n\n   The SF, ZF, and PF flags are set according to the resulting binary value\n   in the AL register; the OF, AF, and CF flags are undefined.\n"],
	["einit", "                  EINIT \u2014 Initialize an Enclave for Execution\n\n                                64/32 bit    CPUID                            \n   Opcode/Instruction     Op/En Mode Support Feature Description\n                                             Flag    \n                                                     This leaf function       \n   EAX = 02H ENCLS[EINIT] IR    V/V          SGX1    initializes the enclave  \n                                                     and makes it ready to    \n                                                     execute enclave code.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX              RBX            RCX        RDX                       \n   IR    EINIT Error code Address of     Address of Address of EINITTOKEN     \n         (In)  (Out)      SIGSTRUCT (In) SECS (In)  (In)                      \n\n  Description \u00b6\n\n   This leaf function is the final instruction executed in the enclave build\n   process. After EINIT, the MRENCLAVE measurement is complete, and the\n   enclave is ready to start user code execution using the EENTER\n   instruction.\n\n   EINIT takes the effective address of a SIGSTRUCT and EINITTOKEN. The\n   SIGSTRUCT describes the enclave including MRENCLAVE, ATTRIBUTES, ISVSVN, a\n   3072 bit RSA key, and a signature using the included key. SIGSTRUCT must\n   be populated with two values, q1 and q2. These are calculated using the\n   formulas shown below:\n\n   q1 = floor(Signature^2 / Modulus);\n\n   q2 = floor((Signature^3 - q1 * Signature * Modulus) / Modulus);\n\n   The EINITTOKEN contains the MRENCLAVE, MRSIGNER, and ATTRIBUTES. These\n   values must match the corresponding values in the SECS. If the EINITTOKEN\n   was created with a debug launch key, the enclave must be in debug mode as\n   well.\n\n   Signature Verify Hashed PubKey ATTRIBUTES ATTRIBUTEMASK Check MRENCLAVE If\n   VALID=1, Check MRSIGNER SIGSTRUCT MRSIGNER DS:RBX ATTRIBUTES If VALID=1,\n   MRENCLAVE Check DS:RDX EINITTOKEN EINIT Copy ATTRIBUTES SECS DS:RCX\n   MRENCLAVE Check ENCLAVE EPC Figure 38-1. Relationships Between SECS,\n   SIGSTRUCT, and EINITTOKEN\n\nEINIT Memory Parameter Semantics \u00b6\n\n   SIGSTRUCT\n\n   SECS                         EINITTOKEN            \n   Read/Write access by Enclave Access by non-Enclave \n\n   Access by non-Enclave\n\n   EINIT performs the following steps, which can be seen in Figure 38-1:\n\n   1. Validates that SIGSTRUCT is signed using the enclosed public key.\n\n   2. Checks that the completed computation of SECS.MRENCLAVE equals\n   SIGSTRUCT.HASHENCLAVE.\n\n   3. Checks that no controlled ATTRIBUTES bits are set in\n   SIGSTRUCT.ATTRIBUTES unless the SHA256 digest of SIGSTRUCT.MODULUS equals\n   IA32_SGX_LEPUBKEYHASH.\n\n   4. Checks that the result of bitwise and-ing SIGSTRUCT.ATTRIBUTEMASK with\n   SIGSTRUCT.ATTRIBUTES equals the result of bitwise and-ing\n   SIGSTRUCT.ATTRIBUTEMASK with SECS.ATTRIBUTES.\n\n   5. If EINITTOKEN.VALID is 0, checks that the SHA256 digest of\n   SIGSTRUCT.MODULUS equals IA32_SGX_LEPUBKEYHASH.\n\n   6. If EINITTOKEN.VALID is 1, checks the validity of EINITTOKEN.\n\n   7. If EINITTOKEN.VALID is 1, checks that EINITTOKEN.MRENCLAVE equals\n   SECS.MRENCLAVE.\n\n   8. If EINITTOKEN.VALID is 1 and EINITTOKEN.ATTRIBUTES.DEBUG is 1,\n   SECS.ATTRIBUTES.DEBUG must be 1.\n\n   9. Commits SECS.MRENCLAVE, and sets SECS.MRSIGNER, SECS.ISVSVN, and\n   SECS.ISVPRODID based on SIGSTRUCT.\n\n   10. Update the SECS as Initialized.\n\n   Periodically, EINIT polls for certain asynchronous events. If such an\n   event is detected, it completes with failure code (ZF=1 and RAX =\n   SGX_UNMASKED_EVENT), and RIP is incremented to point to the next\n   instruction. These events includes external interrupts, non-maskable\n   interrupts, system-management interrupts, machine checks, INIT signals,\n   and the VMX-preemption timer. EINIT does not fail if the pending event is\n   inhibited (e.g., external interrupts could be inhibited due to blocking by\n   MOV SS blocking or by STI).\n\n   The following bits in RFLAGS are cleared: CF, PF, AF, OF, and SF. When the\n   instruction completes with an error, RFLAGS.ZF is set to 1, and the\n   corresponding error bit is set in RAX. If no error occurs, RFLAGS.ZF is\n   cleared and RAX is set to 0.\n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EINIT successful.                              \n   SGX_INVALID_SIG_STRUCT      If SIGSTRUCT contained an invalid value.       \n   SGX_INVALID_ATTRIBUTE       If SIGSTRUCT contains an unauthorized          \n                               attributes mask.                               \n                               If SIGSTRUCT contains an incorrect             \n   SGX_INVALID_MEASUREMENT     measurement. If EINITTOKEN contains an         \n                               incorrect measurement.                         \n   SGX_INVALID_SIGNATURE       If signature does not validate with enclosed   \n                               public key.                                    \n   SGX_INVALID_LICENSE         If license is invalid.                         \n   SGX_INVALID_CPUSVN          If license SVN is unsupported.                 \n   SGX_UNMASKED_EVENT          If an unmasked event is received before the    \n                               instruction completes its operation.           \n\n   Table 38-25. EINIT Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                           Parameter     Base Concurrency Restrictions\n                                                       On Conflict      \n   EINIT EINIT SECS [DS:RCX]      SECS [DS:RCX] \n   Shared EINIT SECS [DS:RCX]     \n\n   Table 38-26. Base Concurrency Restrictions of EINIT\n\n                            Additional Concurrency Restrictions\n                            vs. EACCEPT, EACCEPTCOPY,   vs. EADD,            \n   Leaf Access On           vs. EADD, EEXTEND, EINIT    EEXTEND,             \n   Conflict EINIT           vs. ETRACK, ETRACKC Access  EINIT vs.\n   SECS [DS:RCX]            vs. ETRACK, ETRACKC Access  EADD,     vs. ETRACK,\n   Concurrent               On Conflict Access vs.      EEXTEND,  ETRACKC\n   Exclusive      Parameter ETRACK, ETRACKC Access On   EINIT vs.\n   Access On                Conflict EMODPE, EMODPR,    ETRACK,\n   Conflict EINIT           EMODT                       ETRACKC\n   SECS [DS:RCX]            Access On Conflict Access \n   Concurrent               On Conflict Access Access \n                            On Conflict Access On     \n                            Conflict                  \n   EINIT          SECS      Concurrent                            Concurrent \n                  [DS:RCX]  \n\n   Table 38-27. Additional Concurrency Restrictions of ENIT\n\n  Flags Affected \u00b6\n\n   ZF is cleared if successful, otherwise ZF is set and RAX contains the\n   error code. CF, PF, AF, OF, SF are cleared.\n"],
	["rdrand", "                          RDRAND \u2014 Read Random Number\n\n                                 64/32 bit    CPUID                           \n   Opcode*/Instruction     Op/En Mode Support Feature Description\n                                              Flag    \n                                                      Read a 16-bit random    \n   NFx 0F C7 /6 RDRAND r16 M     V/V          RDRAND  number and store in the \n                                                      destination register.   \n                                                      Read a 32-bit random    \n   NFx 0F C7 /6 RDRAND r32 M     V/V          RDRAND  number and store in the \n                                                      destination register.   \n   NFx REX.W + 0F C7 /6                               Read a 64-bit random    \n   RDRAND r64              M     V/I          RDRAND  number and store in the \n                                                      destination register.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads a hardware generated random value and store it in the destination\n   register. The size of the random value is determined by the destination\n   register size and operating mode. The Carry Flag indicates whether a\n   random value is available at the time the instruction is executed. CF=1\n   indicates that the data in the destination is valid. Otherwise CF=0 and\n   the data in the destination operand will be returned as zeros for the\n   specified width. All other flags are forced to 0 in either situation.\n   Software must check the state of CF=1 for determining if a valid random\n   value has been returned, otherwise it is expected to loop and retry\n   execution of RDRAND (see Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1, Section 7.3.17, \u201cRandom Number Generator\n   Instructions\u201d).\n\n   This instruction is available at all privilege levels.\n\n   In 64-bit mode, the instruction's default operand size is 32 bits. Using a\n   REX prefix in the form of REX.B permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bit operands. See the summary chart at the beginning of this section for\n   encoding data and limits.\n\nFlags Affected \u00b6\n\n   The CF flag is set according to the result (see the \u201cOperation\u201d section\n   above). The OF, SF, ZF, AF, and PF flags are set to 0.\n"],
	["verr:verw", "              VERR/VERW \u2014 Verify a Segment for Reading or Writing\n\n   Opcode/Instruction  Op/En 64-Bit Mode Compat/Leg Description               \n                                         Mode       \n                                                    Set ZF=1 if segment       \n   0F 00 /4 VERR r/m16 M     Valid       Valid      specified with r/m16 can  \n                                                    be read.                  \n                                                    Set ZF=1 if segment       \n   0F 00 /5 VERW r/m16 M     Valid       Valid      specified with r/m16 can  \n                                                    be written.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Verifies whether the code or data segment specified with the source\n   operand is readable (VERR) or writable (VERW) from the current privilege\n   level (CPL). The source operand is a 16-bit register or a memory location\n   that contains the segment selector for the segment to be verified. If the\n   segment is accessible and readable (VERR) or writable (VERW), the ZF flag\n   is set; otherwise, the ZF flag is cleared. Code segments are never\n   verified as writable. This check cannot be performed on system segments.\n\n   To set the ZF flag, the following conditions must be met:\n\n     * The segment selector is not NULL.\n     * The selector must denote a descriptor within the bounds of the\n       descriptor table (GDT or LDT).\n     * The selector must denote the descriptor of a code or data segment (not\n       that of a system segment or gate).\n     * For the VERR instruction, the segment must be readable.\n     * For the VERW instruction, the segment must be a writable data segment.\n     * If the segment is not a conforming code segment, the segment\u2019s DPL\n       must be greater than or equal to (have less or the same privilege as)\n       both the CPL and the segment selector's RPL.\n\n   The validation performed is the same as is performed when a segment\n   selector is loaded into the DS, ES, FS, or GS register, and the indicated\n   access (read or write) is performed. The segment selector's value cannot\n   result in a protection exception, enabling the software to anticipate\n   possible segment access problems.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode. The operand size is fixed at 16 bits.\n\nFlags Affected \u00b6\n\n   The ZF flag is set to 1 if the segment is accessible and readable (VERR)\n   or writable (VERW); otherwise, it is set to 0.\n"],
	["vpermd:vpermw", "            VPERMD/VPERMW \u2014 Permute Packed Doubleword/Word Elements\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n   VEX.256.66.0F38.W0 36 /r                         Permute doublewords in    \n   VPERMD ymm1, ymm2,       A    V/V       AVX2     ymm3/m256 using indices   \n   ymm3/m256                                        in ymm2 and store the     \n                                                    result in ymm1.           \n                                                    Permute doublewords in    \n   EVEX.256.66.0F38.W0 36                  AVX512VL ymm3/m256/m32bcst using   \n   /r VPERMD ymm1 {k1}{z},  B    V/V       AVX512F  indexes in ymm2 and store \n   ymm2, ymm3/m256/m32bcst                          the result in ymm1 using  \n                                                    writemask k1.             \n                                                    Permute doublewords in    \n   EVEX.512.66.0F38.W0 36                           zmm3/m512/m32bcst using   \n   /r VPERMD zmm1 {k1}{z},  B    V/V       AVX512F  indices in zmm2 and store \n   zmm2, zmm3/m512/m32bcst                          the result in zmm1 using  \n                                                    writemask k1.             \n                                                    Permute word integers in  \n   EVEX.128.66.0F38.W1 8D                  AVX512VL xmm3/m128 using indexes   \n   /r VPERMW xmm1 {k1}{z},  C    V/V       AVX512BW in xmm2 and store the     \n   xmm2, xmm3/m128                                  result in xmm1 using      \n                                                    writemask k1.             \n                                                    Permute word integers in  \n   EVEX.256.66.0F38.W1 8D                  AVX512VL ymm3/m256 using indexes   \n   /r VPERMW ymm1 {k1}{z},  C    V/V       AVX512BW in ymm2 and store the     \n   ymm2, ymm3/m256                                  result in ymm1 using      \n                                                    writemask k1.             \n                                                    Permute word integers in  \n   EVEX.512.66.0F38.W1 8D                           zmm3/m512 using indexes   \n   /r VPERMW zmm1 {k1}{z},  C    V/V       AVX512BW in zmm2 and store the     \n   zmm2, zmm3/m512                                  result in zmm1 using      \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Copies doublewords (or words) from the second source operand (the third\n   operand) to the destination operand (the first operand) according to the\n   indices in the first source operand (the second operand). Note that this\n   instruction permits a doubleword (word) in the source operand to be copied\n   to more than one location in the destination operand.\n\n   VEX.256 encoded VPERMD: The first and second operands are YMM registers,\n   the third operand can be a YMM register or memory location. Bits\n   (MAXVL-1:256) of the corresponding destination register are zeroed.\n\n   EVEX encoded VPERMD: The first and second operands are ZMM/YMM registers,\n   the third operand can be a ZMM/YMM register, a 512/256-bit memory location\n   or a 512/256-bit vector broadcasted from a 32-bit memory location. The\n   elements in the destination are updated using the writemask k1.\n\n   VPERMW: first and second operands are ZMM/YMM/XMM registers, the third\n   operand can be a ZMM/YMM/XMM register, or a 512/256/128-bit memory\n   location. The destination is updated using the writemask k1.\n\n   EVEX.128 encoded versions: Bits (MAXVL-1:128) of the corresponding ZMM\n   register are zeroed.\n"],
	["vfixupimmss", "               VFIXUPIMMSS \u2014 Fix Up Special Scalar Float32 Value\n\n                                    64/32 Bit CPUID                           \n   Opcode/Instruction         Op/En Mode      Feature Description\n                                    Support   Flag    \n                                                      Fix up a float32 number \n   EVEX.LLIG.66.0F3A.W0 55 /r                         in the low doubleword   \n   ib VFIXUPIMMSS xmm1        A     V/V       AVX512F element in xmm2 using   \n   {k1}{z}, xmm2,                                     scalar int32 table in   \n   xmm3/m32{sae}, imm8                                xmm3/m32 and store the  \n                                                      result in xmm1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Perform a fix-up of the low doubleword element encoded in single precision\n   floating-point format in the first source operand (the second operand)\n   using a 32-bit, two-level look-up table specified in the low doubleword\n   element of the second source operand (the third operand) with exception\n   reporting specifier imm8. The element that is fixed-up is selected by mask\n   bit of 1 specified in the opmask k1. Mask bit of 0 in the opmask k1 or\n   table response action of 0000b preserves the corresponding element of the\n   first operand. The fixed-up element from the first source operand or the\n   preserved element in the first operand becomes the low doubleword element\n   of the destination operand (the first operand) Bits 127:32 of the\n   destination operand is copied from the corresponding bits of the first\n   source operand. The destination and first source operands are XMM\n   registers. The second source operand can be a XMM register or a 32-bit\n   memory location.\n\n   The two-level look-up table perform a fix-up of each single precision\n   floating-point input data in the first source operand by decoding the\n   input data encoding into 8 token types. A response table is defined for\n   each token type that converts the input encoding in the first source\n   operand with one of 16 response actions.\n\n   This instruction is specifically intended for use in fixing up the results\n   of arithmetic calculations involving one source so that they match the\n   spec, although it is generally useful for fixing up the results of\n   multiple-instruction sequences to reflect special-number inputs. For\n   example, consider rcp(0). Input 0 to rcp, and you should get INF according\n   to the DX10 spec. However, evaluating rcp via Newton-Raphson, where\n   x=approx(1/0), yields an incorrect result. To deal with this, VFIXUPIMMPD\n   can be used after the N-R reciprocal sequence to set the result to the\n   correct value (i.e., INF when the input is 0).\n\n   If MXCSR.DAZ is not set, denormal input elements in the first source\n   operand are considered as normal inputs and do not trigger any fixup nor\n   fault reporting.\n\n   Imm8 is used to set the required flags reporting. It supports #ZE and #IE\n   fault reporting (see details below).\n\n   MXCSR.DAZ is used and refer to zmm2 only (i.e., zmm1 is not considered as\n   zero in case MXCSR.DAZ is set).\n\n   MXCSR mask bits are ignored and are treated as if all mask bits are set to\n   masked response). If any of the imm8 bits is set and the condition met for\n   fault reporting, MXCSR.IE or MXCSR.ZE might be updated.\n"],
	["vmptrld", "          VMPTRLD \u2014 Load Pointer to Virtual-Machine Control Structure\n\n   Opcode/Instruction      Op/En Description                                 \n   NP 0F C7 /6 VMPTRLD m64 M     Loads the current VMCS pointer from memory. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) NA        NA        NA        \n\nDescription \u00b6\n\n   Marks the current-VMCS pointer valid and loads it with the physical\n   address in the instruction operand. The instruction fails if its operand\n   is not properly aligned, sets unsupported physical-address bits, or is\n   equal to the VMXON pointer. In addition, the instruction fails if the 32\n   bits in memory referenced by the operand do not match the VMCS revision\n   identifier supported by this processor.^1\n\n   The operand of this instruction is always 64 bits and is always in memory.\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["hreset", "                             HRESET \u2014 History Reset\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n   F3 0F 3A F0 C0 /ib                            Processor history reset      \n   HRESET imm8, <EAX> A     V/V          HRESET  request. Controlled by the   \n                                                 EAX implicit operand.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (r) N/A       N/A       N/A       \n\n  Description \u00b6\n\n   Requests the processor to selectively reset selected components of\n   hardware history maintained by the current logical processor. HRESET\n   operation is controlled by the implicit EAX operand. The value of the\n   explicit imm8 operand is ignored. This instruction can only be executed at\n   privilege level 0.\n\n   The HRESET instruction can be used to request reset of multiple components\n   of hardware history. Prior to the execution of HRESET, the system software\n   must take the following steps:\n\n   1. Enumerate the HRESET capabilities via CPUID.20H.0H:EBX, which indicates\n   what components of hardware history can be reset.\n\n   2. Only the bits enumerated by CPUID.20H.0H:EBX can be set in the\n   IA32_HRESET_ENABLE MSR.\n\n   HRESET causes a general-protection exception (#GP) if EAX sets any bits\n   that are not set in the IA32_HRESET_EN-ABLE MSR.\n\n   Any attempt to execute the HRESET instruction inside a transactional\n   region will result in a transaction abort.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["xsetbv", "                     XSETBV \u2014 Set Extended Control Register\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n   NP 0F 01 XSETBV      ZO    Valid  Valid      Write the value in EDX:EAX to \n   D1                                           the XCR specified by ECX.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Writes the contents of registers EDX:EAX into the 64-bit extended control\n   register (XCR) specified in the ECX register. (On processors that support\n   the Intel 64 architecture, the high-order 32 bits of RCX are ignored.) The\n   contents of the EDX register are copied to high-order 32 bits of the\n   selected XCR and the contents of the EAX register are copied to low-order\n   32 bits of the XCR. (On processors that support the Intel 64 architecture,\n   the high-order 32 bits of each of RAX and RDX are ignored.) Undefined or\n   reserved bits in an XCR should be set to values previously read.\n\n   This instruction must be executed at privilege level 0 or in real-address\n   mode; otherwise, a general protection exception #GP(0) is generated.\n   Specifying a reserved or unimplemented XCR in ECX will also cause a\n   general protection exception. The processor will also generate a general\n   protection exception if software attempts to write to reserved bits in an\n   XCR.\n\n   Currently, only XCR0 is supported. Thus, all other values of ECX are\n   reserved and will cause a #GP(0). Note that bit 0 of XCR0 (corresponding\n   to x87 state) must be set to 1; the instruction will cause a #GP(0) if an\n   attempt is made to clear this bit. In addition, the instruction causes a\n   #GP(0) if an attempt is made to set XCR0[2] (AVX state) while clearing\n   XCR0[1] (SSE state); it is necessary to set both bits to use AVX\n   instructions; Section 13.3, \u201cEnabling the XSAVE Feature Set and\n   XSAVE-Enabled Features,\u201d of Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["xsaves", "               XSAVES \u2014 Save Processor Extended States Supervisor\n\n   Opcode /           Op/En 64/32 bit    CPUID        Description             \n   Instruction              Mode Support Feature Flag \n                                                      Save state components   \n   NP 0F C7 /5 XSAVES M     V/V          XSS          specified by EDX:EAX to \n   mem                                                mem with compaction,    \n                                                      optimizing if possible. \n                                                      Save state components   \n   NP REX.W + 0F C7   M     V/N.E.       XSS          specified by EDX:EAX to \n   /5 XSAVES64 mem                                    mem with compaction,    \n                                                      optimizing if possible. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a full or partial save of processor state components to the XSAVE\n   area located at the memory address specified by the destination operand.\n   The implicit EDX:EAX register pair specifies a 64-bit instruction mask.\n   The specific state components saved correspond to the bits set in the\n   requested-feature bitmap (RFBM), the logicalAND of EDX:EAX and the\n   logical-OR of XCR0 with the IA32_XSS MSR. XSAVES may be executed only if\n   CPL = 0.\n\n   The format of the XSAVE area is detailed in Section 13.4, \u201cXSAVE Area,\u201d of\n   the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n   1. Like FXRSTOR and FXSAVE, the memory format used for x87 state depends\n   on a REX.W prefix; see Section 13.5.1, \u201cx87 State,\u201d of the Intel^\u00ae 64 and\n   IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n\n   Section 13.11, \u201cOperation of XSAVES,\u201d of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1 provides a detailed\n   description of the operation of the XSAVES instruction. The following\n   items provide a high-level outline:\n\n     * Execution of XSAVES is similar to that of XSAVEC. XSAVES differs from\n       XSAVEC in that it can save state components corresponding to bits set\n       in the IA32_XSS MSR and that it may use the modified optimization.\n     * XSAVES saves state component i only if RFBM[i] = 1 and XINUSE[i] =\n       1.^1 (XINUSE is a bitmap by which the processor tracks the status of\n       various state components. See Section 13.6, \u201cProcessor Tracking of\n       XSAVEManaged State,\u201d of the Intel^\u00ae 64 and IA-32 Architectures\n       Software Developer\u2019s Manual, Volume 1.) Even if both bits are 1,\n       XSAVES may optimize and not save state component i if (1) state\n       component i has not been modified since the last execution of XRSTOR\n       or XRSTORS; and (2) this execution of XSAVES correspond to that last\n       execution of XRSTOR or XRSTORS as determined by XRSTOR_INFO (see the\n       Operation section below).\n     * XSAVES does not modify bytes 511:464 of the legacy region of the XSAVE\n       area (see Section 13.4.1, \u201cLegacy Region of an XSAVE Area,\u201d of the\n       Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n       1).\n     * XSAVES writes the logical AND of RFBM and XINUSE to the XSTATE_BV\n       field of the XSAVE header.^2 (See Section 13.4.2, \u201cXSAVE Header,\u201d of\n       the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n       Volume 1.) XSAVES sets bit 63 of the XCOMP_BV field and sets bits 62:0\n       of that field to RFBM[62:0]. XSAVES does not write to any parts of the\n       XSAVE header other than the XSTATE_BV and XCOMP_BV fields.\n     * XSAVES always uses the compacted format of the extended region of the\n       XSAVE area (see Section 13.4.3, \u201cExtended Region of an XSAVE Area,\u201d of\n       the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n       Volume 1).\n\n     1. There is an exception for state component 1 (SSE). MXCSR is part of\n     SSE state, but XINUSE[1] may be 0 even if MXCSR does not have its\n     initial value of 1F80H. In this case, the init optimization does not\n     apply and XSAVEC will save SSE state as long as RFBM[1] = 1 and the\n     modified optimization is not being applied.\n\n     2. There is an exception for state component 1 (SSE). MXCSR is part of\n     SSE state, but XINUSE[1] may be 0 even if MXCSR does not have its\n     initial value of 1F80H. In this case, XSAVES sets XSTATE_BV[1] to 1 as\n     long as RFBM[1] = 1.\n\n   Use of a destination operand not aligned to 64-byte boundary (in either\n   64-bit or 32-bit modes) results in a general-protection (#GP) exception.\n   In 64-bit mode, the upper 32 bits of RDX and RAX are ignored.\n\n   See Section 13.6, \u201cProcessor Tracking of XSAVE-Managed State,\u201d of Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1 for\n   discussion of the bitmap XMODIFIED and of the quantity XRSTOR_INFO.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["rep:repe:repz:repne:repnz", "           REP/REPE/REPZ/REPNE/REPNZ \u2014 Repeat String Operation Prefix\n\n   Opcode   Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   F3 6C    REP INS m8, DX  ZO    Valid  Valid      Input (E)CX bytes from    \n                                                    port DX into ES:[(E)DI].  \n   F3 6C    REP INS m8, DX  ZO    Valid  N.E.       Input RCX bytes from port \n                                                    DX into [RDI].            \n   F3 6D    REP INS m16, DX ZO    Valid  Valid      Input (E)CX words from    \n                                                    port DX into ES:[(E)DI.]  \n                                                    Input (E)CX doublewords   \n   F3 6D    REP INS m32, DX ZO    Valid  Valid      from port DX into         \n                                                    ES:[(E)DI].               \n   F3 6D    REP INS r/m32,  ZO    Valid  N.E.       Input RCX default size    \n            DX                                      from port DX into [RDI].  \n   F3 A4    REP MOVS m8, m8 ZO    Valid  Valid      Move (E)CX bytes from     \n                                                    DS:[(E)SI] to ES:[(E)DI]. \n   F3 REX.W REP MOVS m8, m8 ZO    Valid  N.E.       Move RCX bytes from [RSI] \n   A4                                               to [RDI].                 \n   F3 A5    REP MOVS m16,   ZO    Valid  Valid      Move (E)CX words from     \n            m16                                     DS:[(E)SI] to ES:[(E)DI]. \n            REP MOVS m32,                           Move (E)CX doublewords    \n   F3 A5    m32             ZO    Valid  Valid      from DS:[(E)SI] to        \n                                                    ES:[(E)DI].               \n   F3 REX.W REP MOVS m64,   ZO    Valid  N.E.       Move RCX quadwords from   \n   A5       m64                                     [RSI] to [RDI].           \n   F3 6E    REP OUTS DX,    ZO    Valid  Valid      Output (E)CX bytes from   \n            r/m8                                    DS:[(E)SI] to port DX.    \n   F3 REX.W REP OUTS DX,    ZO    Valid  N.E.       Output RCX bytes from     \n   6E       r/m8^1                                  [RSI] to port DX.         \n   F3 6F    REP OUTS DX,    ZO    Valid  Valid      Output (E)CX words from   \n            r/m16                                   DS:[(E)SI] to port DX.    \n            REP OUTS DX,                            Output (E)CX doublewords  \n   F3 6F    r/m32           ZO    Valid  Valid      from DS:[(E)SI] to port   \n                                                    DX.                       \n   F3 REX.W REP OUTS DX,    ZO    Valid  N.E.       Output RCX default size   \n   6F       r/m32                                   from [RSI] to port DX.    \n   F3 AC    REP LODS AL     ZO    Valid  Valid      Load (E)CX bytes from     \n                                                    DS:[(E)SI] to AL.         \n   F3 REX.W REP LODS AL     ZO    Valid  N.E.       Load RCX bytes from [RSI] \n   AC                                               to AL.                    \n   F3 AD    REP LODS AX     ZO    Valid  Valid      Load (E)CX words from     \n                                                    DS:[(E)SI] to AX.         \n   F3 AD    REP LODS EAX    ZO    Valid  Valid      Load (E)CX doublewords    \n                                                    from DS:[(E)SI] to EAX.   \n   F3 REX.W REP LODS RAX    ZO    Valid  N.E.       Load RCX quadwords from   \n   AD                                               [RSI] to RAX.             \n   F3 AA    REP STOS m8     ZO    Valid  Valid      Fill (E)CX bytes at       \n                                                    ES:[(E)DI] with AL.       \n   F3 REX.W REP STOS m8     ZO    Valid  N.E.       Fill RCX bytes at [RDI]   \n   AA                                               with AL.                  \n   F3 AB    REP STOS m16    ZO    Valid  Valid      Fill (E)CX words at       \n                                                    ES:[(E)DI] with AX.       \n   F3 AB    REP STOS m32    ZO    Valid  Valid      Fill (E)CX doublewords at \n                                                    ES:[(E)DI] with EAX.      \n   F3 REX.W REP STOS m64    ZO    Valid  N.E.       Fill RCX quadwords at     \n   AB                                               [RDI] with RAX.           \n            REPE CMPS m8,                           Find nonmatching bytes in \n   F3 A6    m8              ZO    Valid  Valid      ES:[(E)DI] and            \n                                                    DS:[(E)SI].               \n   F3 REX.W REPE CMPS m8,   ZO    Valid  N.E.       Find non-matching bytes   \n   A6       m8                                      in [RDI] and [RSI].       \n            REPE CMPS m16,                          Find nonmatching words in \n   F3 A7    m16             ZO    Valid  Valid      ES:[(E)DI] and            \n                                                    DS:[(E)SI].               \n            REPE CMPS m32,                          Find nonmatching          \n   F3 A7    m32             ZO    Valid  Valid      doublewords in ES:[(E)DI] \n                                                    and DS:[(E)SI].           \n   F3 REX.W REPE CMPS m64,                          Find non-matching         \n   A7       m64             ZO    Valid  N.E.       quadwords in [RDI] and    \n                                                    [RSI].                    \n   F3 AE    REPE SCAS m8    ZO    Valid  Valid      Find non-AL byte starting \n                                                    at ES:[(E)DI].            \n   F3 REX.W REPE SCAS m8    ZO    Valid  N.E.       Find non-AL byte starting \n   AE                                               at [RDI].                 \n   F3 AF    REPE SCAS m16   ZO    Valid  Valid      Find non-AX word starting \n                                                    at ES:[(E)DI].            \n   F3 AF    REPE SCAS m32   ZO    Valid  Valid      Find non-EAX doubleword   \n                                                    starting at ES:[(E)DI].   \n   F3 REX.W REPE SCAS m64   ZO    Valid  N.E.       Find non-RAX quadword     \n   AF                                               starting at [RDI].        \n            REPNE CMPS m8,                          Find matching bytes in    \n   F2 A6    m8              ZO    Valid  Valid      ES:[(E)DI] and            \n                                                    DS:[(E)SI].               \n   F2 REX.W REPNE CMPS m8,  ZO    Valid  N.E.       Find matching bytes in    \n   A6       m8                                      [RDI] and [RSI].          \n            REPNE CMPS m16,                         Find matching words in    \n   F2 A7    m16             ZO    Valid  Valid      ES:[(E)DI] and            \n                                                    DS:[(E)SI].               \n            REPNE CMPS m32,                         Find matching doublewords \n   F2 A7    m32             ZO    Valid  Valid      in ES:[(E)DI] and         \n                                                    DS:[(E)SI].               \n   F2 REX.W REPNE CMPS m64, ZO    Valid  N.E.       Find matching doublewords \n   A7       m64                                     in [RDI] and [RSI].       \n   F2 AE    REPNE SCAS m8   ZO    Valid  Valid      Find AL, starting at      \n                                                    ES:[(E)DI].               \n   F2 REX.W REPNE SCAS m8   ZO    Valid  N.E.       Find AL, starting at      \n   AE                                               [RDI].                    \n   F2 AF    REPNE SCAS m16  ZO    Valid  Valid      Find AX, starting at      \n                                                    ES:[(E)DI].               \n   F2 AF    REPNE SCAS m32  ZO    Valid  Valid      Find EAX, starting at     \n                                                    ES:[(E)DI].               \n   F2 REX.W REPNE SCAS m64  ZO    Valid  N.E.       Find RAX, starting at     \n   AF                                               [RDI].                    \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Repeats a string instruction the number of times specified in the count\n   register or until the indicated condition of the ZF flag is no longer met.\n   The REP (repeat), REPE (repeat while equal), REPNE (repeat while not\n   equal), REPZ (repeat while zero), and REPNZ (repeat while not zero)\n   mnemonics are prefixes that can be added to one of the string\n   instructions. The REP prefix can be added to the INS, OUTS, MOVS, LODS,\n   and STOS instructions, and the REPE, REPNE, REPZ, and REPNZ prefixes can\n   be added to the CMPS and SCAS instructions. (The REPZ and REPNZ prefixes\n   are synonymous forms of the REPE and REPNE prefixes, respectively.) The\n   F3H prefix is defined for the following instructions and undefined for the\n   rest:\n\n     * F3H as REP/REPE/REPZ for string and input/output instruction.\n     * F3H is a mandatory prefix for POPCNT, LZCNT, and ADOX.\n\n   The REP prefixes apply only to one string instruction at a time. To repeat\n   a block of instructions, use the LOOP instruction or another looping\n   construct. All of these repeat prefixes cause the associated instruction\n   to be repeated until the count in register is decremented to 0. See Table\n   4-17.\n\n   Repeat Prefix Termination Condition 1* Termination Condition 2 \n   REP           RCX or (E)CX = 0         None                    \n   REPE/REPZ     RCX or (E)CX = 0         ZF = 0                  \n   REPNE/REPNZ   RCX or (E)CX = 0         ZF = 1                  \n\n   Table 4-17. Repeat Prefixes\n\n     *\n     CountregisterisCX,ECXorRCXbydefault,dependingonattributesoftheoperatingmodes.\n\n   The REPE, REPNE, REPZ, and REPNZ prefixes also check the state of the ZF\n   flag after each iteration and terminate the repeat loop if the ZF flag is\n   not in the specified state. When both termination conditions are tested,\n   the cause of a repeat termination can be determined either by testing the\n   count register with a JECXZ instruction or by testing the ZF flag (with a\n   JZ, JNZ, or JNE instruction).\n\n   When the REPE/REPZ and REPNE/REPNZ prefixes are used, the ZF flag does not\n   require initialization because both the CMPS and SCAS instructions affect\n   the ZF flag according to the results of the comparisons they make.\n\n   A repeating string operation can be suspended by an exception or\n   interrupt. When this happens, the state of the registers is preserved to\n   allow the string operation to be resumed upon a return from the exception\n   or interrupt handler. The source and destination registers point to the\n   next string elements to be operated on, the EIP register points to the\n   string instruction, and the ECX register has the value it held following\n   the last successful iteration of the instruction. This mechanism allows\n   long string operations to proceed without affecting the interrupt response\n   time of the system.\n\n   When a fault occurs during the execution of a CMPS or SCAS instruction\n   that is prefixed with REPE or REPNE, the EFLAGS value is restored to the\n   state prior to the execution of the instruction. Since the SCAS and CMPS\n   instructions do not use EFLAGS as an input, the processor can resume the\n   instruction after the page fault handler.\n\n   Use the REP INS and REP OUTS instructions with caution. Not all I/O ports\n   can handle the rate at which these instructions execute. Note that a REP\n   STOS instruction is the fastest way to initialize a large block of memory.\n\n   In 64-bit mode, the operand size of the count register is associated with\n   the address size attribute. Thus the default count register is RCX; REX.W\n   has no effect on the address size and the count register. In 64-bit mode,\n   if 67H is used to override address size attribute, the count register is\n   ECX and any implicit source/destination operand will use the corresponding\n   32-bit index register. See the summary chart at the beginning of this\n   section for encoding data and limits.\n\n   REP INS may read from the I/O port without writing to the memory location\n   if an exception or VM exit occurs due to the write (e.g., #PF). If this\n   would be problematic, for example because the I/O port read has\n   side-effects, software should ensure the write to the memory location does\n   not cause an exception or VM exit.\n\nFlags Affected \u00b6\n\n   None; however, the CMPS and SCAS instructions do set the status flags in\n   the EFLAGS register.\n"],
	["vpermilps", "  VPERMILPS \u2014 Permute In-Lane of Quadruples of Single Precision Floating-Point\n                                     Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Permute single-precision  \n   VEX.128.66.0F38.W0 0C /r                         floating-point values in  \n   VPERMILPS xmm1, xmm2,    A    V/V       AVX      xmm2 using controls from  \n   xmm3/m128                                        xmm3/m128 and store       \n                                                    result in xmm1.           \n                                                    Permute single-precision  \n   VEX.128.66.0F3A.W0 04 /r                         floating-point values in  \n   ib VPERMILPS xmm1,       B    V/V       AVX      xmm2/m128 using controls  \n   xmm2/m128, imm8                                  from imm8 and store       \n                                                    result in xmm1.           \n                                                    Permute single-precision  \n   VEX.256.66.0F38.W0 0C /r                         floating-point values in  \n   VPERMILPS ymm1, ymm2,    A    V/V       AVX      ymm2 using controls from  \n   ymm3/m256                                        ymm3/m256 and store       \n                                                    result in ymm1.           \n                                                    Permute single-precision  \n   VEX.256.66.0F3A.W0 04 /r                         floating-point values in  \n   ib VPERMILPS ymm1,       B    V/V       AVX      ymm2/m256 using controls  \n   ymm2/m256, imm8                                  from imm8 and store       \n                                                    result in ymm1.           \n                                                    Permute single-precision  \n   EVEX.128.66.0F38.W0 0C                           floating-point values     \n   /r VPERMILPS xmm1        C    V/V       AVX512VL xmm2 using control from   \n   {k1}{z}, xmm2,                          AVX512F  xmm3/m128/m32bcst and     \n   xmm3/m128/m32bcst                                store the result in xmm1  \n                                                    using writemask k1.       \n                                                    Permute single-precision  \n   EVEX.256.66.0F38.W0 0C                           floating-point values     \n   /r VPERMILPS ymm1        C    V/V       AVX512VL ymm2 using control from   \n   {k1}{z}, ymm2,                          AVX512F  ymm3/m256/m32bcst and     \n   ymm3/m256/m32bcst                                store the result in ymm1  \n                                                    using writemask k1.       \n                                                    Permute single-precision  \n   EVEX.512.66.0F38.W0 0C                           floating-point values     \n   /r VPERMILPS zmm1        C    V/V       AVX512F  zmm2 using control from   \n   {k1}{z}, zmm2,                                   zmm3/m512/m32bcst and     \n   zmm3/m512/m32bcst                                store the result in zmm1  \n                                                    using writemask k1.       \n                                                    Permute single-precision  \n   EVEX.128.66.0F3A.W0 04                           floating-point values     \n   /r ib VPERMILPS xmm1     D    V/V       AVX512VL xmm2/m128/m32bcst using   \n   {k1}{z},                                AVX512F  controls from imm8 and    \n   xmm2/m128/m32bcst, imm8                          store the result in xmm1  \n                                                    using writemask k1.       \n                                                    Permute single-precision  \n   EVEX.256.66.0F3A.W0 04                           floating-point values     \n   /r ib VPERMILPS ymm1     D    V/V       AVX512VL ymm2/m256/m32bcst using   \n   {k1}{z},                                AVX512F  controls from imm8 and    \n   ymm2/m256/m32bcst, imm8                          store the result in ymm1  \n                                                    using writemask k1.       \n                                                    Permute single-precision  \n   EVEX.512.66.0F3A.W0 04                           floating-point values     \n   /r ibVPERMILPS zmm1      D    V/V       AVX512F  zmm2/m512/m32bcst using   \n   {k1}{z},                                         controls from imm8 and    \n   zmm2/m512/m32bcst, imm8                          store the result in zmm1  \n                                                    using writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     N/A        ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   C     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n\n  Description \u00b6\n\n   Variable control version:\n\n   Permute quadruples of single-precision floating-point values in the first\n   source operand (second operand), each quadruplet using a 2-bit control\n   field in the corresponding dword element of the second source operand.\n   Permuted results are stored in the destination operand (first operand).\n\n   The 2-bit control fields are located at the low two bits of each dword\n   element (see Figure 5-26). Each control determines which of the source\n   element in an input quadruple is selected for the destination element.\n   Each quadruple of source elements must lie in the same 128-bit region as\n   the destination.\n\n   EVEX version: The second source operand (third operand) is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. Permuted results are written to\n   the destination under the writemask.\n\n   X7 X6 X5 X4 X3 X2 X1 X0 SRC1 X7..X4 X7..X4 X7..X4 X7..X4 X3..X0 X3..X0\n   DEST X3..X0 X3..X0 Figure 5-25. VPERMILPS Operation Bit 31 255 226 225 224\n   33 32 1 0 63 34 . . . ignored ignored sel sel sel Control Field 7 Control\n   Field 2 Control Field 1 Figure 5-26. VPERMILPS Shuffle Control\n\n   (immediate control version)\n\n   Permute quadruples of single-precision floating-point values in the first\n   source operand (second operand), each quadruplet using a 2-bit control\n   field in the imm8 byte. Each 128-bit lane in the destination operand\n   (first operand) use the four control fields of the same imm8 byte.\n\n   VEX version: The source operand is a YMM/XMM register or a 256/128-bit\n   memory location and the destination operand is a YMM/XMM register.\n\n   EVEX version: The source operand (second operand) is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. Permuted results are written to\n   the destination under the writemask.\n\n   Note: For the imm8 version, VEX.vvvv and EVEX.vvvv are reserved and must\n   be 1111b otherwise instruction will #UD.\n"],
	["cmpxchg8b:cmpxchg16b", "               CMPXCHG8B/CMPXCHG16B \u2014 Compare and Exchange Bytes\n\n   Opcode/Instruction     Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n                                                  Compare EDX:EAX with m64.   \n                                                  If equal, set ZF and load   \n   0F C7 /1 CMPXCHG8B m64 M     Valid  Valid*     ECX:EBX into m64. Else,     \n                                                  clear ZF and load m64 into  \n                                                  EDX:EAX.                    \n                                                  Compare RDX:RAX with m128.  \n   REX.W + 0F C7 /1                               If equal, set ZF and load   \n   CMPXCHG16B m128        M     Valid  N.E.       RCX:RBX into m128. Else,    \n                                                  clear ZF and load m128 into \n                                                  RDX:RAX.                    \n\n     *See IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Compares the 64-bit value in EDX:EAX (or 128-bit value in RDX:RAX if\n   operand size is 128 bits) with the operand (destination operand). If the\n   values are equal, the 64-bit value in ECX:EBX (or 128-bit value in\n   RCX:RBX) is stored in the destination operand. Otherwise, the value in the\n   destination operand is loaded into EDX:EAX (or RDX:RAX). The destination\n   operand is an 8-byte memory location (or 16-byte memory location if\n   operand size is 128 bits). For the EDX:EAX and ECX:EBX register pairs, EDX\n   and ECX contain the high-order 32 bits and EAX and EBX contain the\n   low-order 32 bits of a 64-bit value. For the RDX:RAX and RCX:RBX register\n   pairs, RDX and RCX contain the high-order 64 bits and RAX and RBX contain\n   the low-order 64bits of a 128-bit value.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically. To simplify the interface to the processor\u2019s\n   bus, the destination operand receives a write cycle without regard to the\n   result of the comparison. The destination operand is written back if the\n   comparison fails; otherwise, the source operand is written into the\n   destination. (The processor never produces a locked read without also\n   producing a locked write.)\n\n   In 64-bit mode, default operation size is 64 bits. Use of the REX.W prefix\n   promotes operation to 128 bits. Note that CMPXCHG16B requires that the\n   destination (memory) operand be 16-byte aligned. See the summary chart at\n   the beginning of this section for encoding data and limits. For\n   information on the CPUID flag that indicates CMPX-CHG16B, see page 3-243.\n\nIA-32 Architecture Compatibility \u00b6\n\n   This instruction encoding is not supported on Intel processors earlier\n   than the Pentium processors.\n\nFlags Affected \u00b6\n\n   The ZF flag is set if the destination operand and EDX:EAX are equal;\n   otherwise it is cleared. The CF, PF, AF, SF, and OF flags are unaffected.\n"],
	["vrndscalesd", " VRNDSCALESD \u2014 Round Scalar Float64 Value to Include a Given Number of Fraction\n                                      Bits\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Rounds scalar double       \n   EVEX.LLIG.66.0F3A.W1 0B                         precision floating-point   \n   /r ib VRNDSCALESD xmm1                          value in xmm3/m64 to a     \n   {k1}{z}, xmm2,          A     V/V       AVX512F number of fraction bits    \n   xmm3/m64{sae}, imm8                             specified by the imm8      \n                                                   field. Stores the result   \n                                                   in xmm1 register.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Rounds a double precision floating-point value in the low quadword (see\n   Figure 5-29) element of the second source operand (the third operand) by\n   the rounding mode specified in the immediate operand and places the result\n   in the corresponding element of the destination operand (the first\n   operand) according to the writemask. The quadword element at bits 127:64\n   of the destination is copied from the first source operand (the second\n   operand).\n\n   The destination and first source operands are XMM registers, the 2nd\n   source operand can be an XMM register or memory location. Bits MAXVL-1:128\n   of the destination register are cleared.\n\n   The rounding process rounds the input to an integral value, plus number\n   bits of fraction that are specified by imm8[7:4] (to be included in the\n   result) and returns the result as a double precision floating-point value.\n\n   It should be noticed that no overflow is induced while executing this\n   instruction (although the source is scaled by the imm8[7:4] value).\n\n   The immediate operand also specifies control fields for the rounding\n   operation, three bit fields are defined and shown in the \u201cImmediate\n   Control Description\u201d figure below. Bit 3 of the immediate byte controls\n   the processor behavior for a precision exception, bit 2 selects the source\n   of rounding mode control. Bits 1:0 specify a non-sticky rounding-mode\n   value (immediate control table below lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   The sign of the result of this instruction is preserved, including the\n   sign of zero.\n\n   The formula of the operation for VRNDSCALESD is\n\n   ROUND(x) = 2^-M*Round_to_INT(x*2^M, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   M=imm[7:4];\n\n   The operation of x*2^M is computed as if the exponent range is unlimited\n   (i.e., no overflow ever occurs).\n\n   VRNDSCALESD is a more general form of the VEX-encoded VROUNDSD\n   instruction. In VROUNDSD, the formula of the operation is\n\n   ROUND(x) = Round_to_INT(x, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   EVEX encoded version: The source operand is a XMM register or a 64-bit\n   memory location. The destination operand is a XMM register.\n\n   Handling of special case of input values are listed in Table 5-31.\n"],
	["vinsertf128:vinsertf32x4:vinsertf64x2:vinsertf32x8:vinsertf64x4", "    VINSERTF128/VINSERTF32x4/VINSERTF64x2/VINSERTF32x8/VINSERTF64x4 \u2014 Insert\n                          PackedFloating-Point Values\n\n                            Op / 64/32 Bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Insert 128 bits of packed \n   VEX.256.66.0F3A.W0 18 /r                         floating-point values     \n   ib VINSERTF128 ymm1,     A    V/V       AVX      from xmm3/m128 and the    \n   ymm2, xmm3/m128, imm8                            remaining values from     \n                                                    ymm2 into ymm1.           \n                                                    Insert 128 bits of packed \n   EVEX.256.66.0F3A.W0 18                           single-precision          \n   /r ib VINSERTF32X4 ymm1                 AVX512VL floating-point values     \n   {k1}{z}, ymm2,           C    V/V       AVX512F  from xmm3/m128 and the    \n   xmm3/m128, imm8                                  remaining values from     \n                                                    ymm2 into ymm1 under      \n                                                    writemask k1.             \n                                                    Insert 128 bits of packed \n   EVEX.512.66.0F3A.W0 18                           single-precision          \n   /r ib VINSERTF32X4 zmm1                          floating-point values     \n   {k1}{z}, zmm2,           C    V/V       AVX512F  from xmm3/m128 and the    \n   xmm3/m128, imm8                                  remaining values from     \n                                                    zmm2 into zmm1 under      \n                                                    writemask k1.             \n                                                    Insert 128 bits of packed \n   EVEX.256.66.0F3A.W1 18                           double precision          \n   /r ib VINSERTF64X2 ymm1                 AVX512VL floating-point values     \n   {k1}{z}, ymm2,           B    V/V       AVX512DQ from xmm3/m128 and the    \n   xmm3/m128, imm8                                  remaining values from     \n                                                    ymm2 into ymm1 under      \n                                                    writemask k1.             \n                                                    Insert 128 bits of packed \n   EVEX.512.66.0F3A.W1 18                           double precision          \n   /r ib VINSERTF64X2 zmm1                          floating-point values     \n   {k1}{z}, zmm2,           B    V/V       AVX512DQ from xmm3/m128 and the    \n   xmm3/m128, imm8                                  remaining values from     \n                                                    zmm2 into zmm1 under      \n                                                    writemask k1.             \n                                                    Insert 256 bits of packed \n   EVEX.512.66.0F3A.W0 1A                           single-precision          \n   /r ib VINSERTF32X8 zmm1                          floating-point values     \n   {k1}{z}, zmm2,           D    V/V       AVX512DQ from ymm3/m256 and the    \n   ymm3/m256, imm8                                  remaining values from     \n                                                    zmm2 into zmm1 under      \n                                                    writemask k1.             \n                                                    Insert 256 bits of packed \n   EVEX.512.66.0F3A.W1 1A                           double precision          \n   /r ib VINSERTF64X4 zmm1                          floating-point values     \n   {k1}{z}, zmm2,           C    V/V       AVX512F  from ymm3/m256 and the    \n   ymm3/m256, imm8                                  remaining values from     \n                                                    zmm2 into zmm1 under      \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   B     Tuple2     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n   C     Tuple4     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n   D     Tuple8     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   VINSERTF128/VINSERTF32x4 and VINSERTF64x2 insert 128-bits of packed\n   floating-point values from the second source operand (the third operand)\n   into the destination operand (the first operand) at an 128-bit granularity\n   offset multiplied by imm8[0] (256-bit) or imm8[1:0]. The remaining\n   portions of the destination operand are copied from the corresponding\n   fields of the first source operand (the second operand). The second source\n   operand can be either an XMM register or a 128-bit memory location. The\n   destination and first source operands are vector registers.\n\n   VINSERTF32x4: The destination operand is a ZMM/YMM register and updated at\n   32-bit granularity according to the writemask. The high 6/7 bits of the\n   immediate are ignored.\n\n   VINSERTF64x2: The destination operand is a ZMM/YMM register and updated at\n   64-bit granularity according to the writemask. The high 6/7 bits of the\n   immediate are ignored.\n\n   VINSERTF32x8 and VINSERTF64x4 inserts 256-bits of packed floating-point\n   values from the second source operand (the third operand) into the\n   destination operand (the first operand) at a 256-bit granular offset\n   multiplied by imm8[0]. The remaining portions of the destination are\n   copied from the corresponding fields of the first source operand (the\n   second operand). The second source operand can be either an YMM register\n   or a 256-bit memory location. The high 7 bits of the immediate are\n   ignored. The destination operand is a ZMM register and updated at\n   32/64-bit granularity according to the writemask.\n"],
	["rdfsbase:rdgsbase", "                  RDFSBASE/RDGSBASE \u2014 Read FS/GS Segment Base\n\n                              64/32-bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature  Description\n                                        Flag     \n   F3 0F AE /0 RDFSBASE                          Load the 32-bit destination  \n   r32                  M     V/I       FSGSBASE register with the FS base    \n                                                 address.                     \n   F3 REX.W 0F AE /0                             Load the 64-bit destination  \n   RDFSBASE r64         M     V/I       FSGSBASE register with the FS base    \n                                                 address.                     \n   F3 0F AE /1 RDGSBASE                          Load the 32-bit destination  \n   r32                  M     V/I       FSGSBASE register with the GS base    \n                                                 address.                     \n   F3 REX.W 0F AE /1                             Load the 64-bit destination  \n   RDGSBASE r64         M     V/I       FSGSBASE register with the GS base    \n                                                 address.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the general-purpose register indicated by the ModR/M:r/m field with\n   the FS or GS segment base address.\n\n   The destination operand may be either a 32-bit or a 64-bit general-purpose\n   register. The REX.W prefix indicates the operand size is 64 bits. If no\n   REX.W prefix is used, the operand size is 32 bits; the upper 32 bits of\n   the source base address (for FS or GS) are ignored and upper 32 bits of\n   the destination register are cleared.\n\n   This instruction is supported only in 64-bit mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vrcpsh", "                VRCPSH \u2014 Compute Reciprocal of Scalar FP16 Value\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   bit Mode Flag 64/32 CPUID       \n   Feature Instruction En bit Mode \n   Flag CPUID Feature Instruction  \n   En bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Compute the          \n                                                         approximate          \n                                                         reciprocal of the    \n   EVEX.LLIG.66.MAP6.W0 4D /r                            low FP16 value in    \n   VRCPSH xmm1{k1}{z}, xmm2,       A V/V     AVX512-FP16 xmm3/m16 and store   \n   xmm3/m16                                              the result in xmm1   \n                                                         subject to writemask \n                                                         k1. Bits 127:16 from \n                                                         xmm2 are copied to   \n                                                         xmm1[127:16].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate reciprocal\n   of the low FP16 value in the second source operand (the third operand) and\n   stores the result in the low word element of the destination operand (the\n   first operand) according to the writemask k1. Bits 127:16 of the XMM\n   register destination are copied from corresponding bits in the first\n   source operand (the second operand). The maximum relative error for this\n   approximation is less than 2^\u221211 + 2^\u221214.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   For special cases, see Table 5-28.\n"],
	["vminph", "                 VMINPH \u2014 Return Minimum of Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En bit     \n   Mode Flag CPUID Feature        \n   Instruction En bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En bit Mode Flag   \n   CPUID Feature Instruction En   \n   bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Return the minimum    \n                                                        packed FP16 values    \n   EVEX.128.NP.MAP5.W0 5D /r                AVX512-FP16 between xmm2 and      \n   VMINPH xmm1{k1}{z}, xmm2,      A V/V     AVX512VL    xmm3/m128/m16bcst and \n   xmm3/m128/m16bcst                                    store the result in   \n                                                        xmm1 subject to       \n                                                        writemask k1.         \n                                                        Return the minimum    \n                                                        packed FP16 values    \n   EVEX.256.NP.MAP5.W0 5D /r                AVX512-FP16 between ymm2 and      \n   VMINPH ymm1{k1}{z}, ymm2,      A V/V     AVX512VL    ymm3/m256/m16bcst and \n   ymm3/m256/m16bcst                                    store the result in   \n                                                        ymm1 subject to       \n                                                        writemask k1.         \n                                                        Return the minimum    \n                                                        packed FP16 values    \n   EVEX.512.NP.MAP5.W0 5D /r                            between zmm2 and      \n   VMINPH zmm1{k1}{z}, zmm2,      A V/V     AVX512-FP16 zmm3/m512/m16bcst and \n   zmm3/m512/m16bcst {sae}                              store the result in   \n                                                        zmm1 subject to       \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD compare of the packed FP16 values in the\n   first source operand and the second source operand and returns the minimum\n   value for each pair of values to the destination operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of VMINPH can be emulated using a sequence of\n   instructions, such as, a comparison followed by AND, ANDN and OR.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcast from a 16-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n"],
	["smctrl", "                       GETSEC[SMCTRL] \u2014 SMX Mode Control\n\n   Opcode             Instruction    Description                              \n   NP 0F 37 (EAX = 7) GETSEC[SMCTRL] Perform specified SMX mode control as    \n                                     selected with the input EBX.             \n\nDescription \u00b6\n\n   The GETSEC[SMCTRL] instruction is available for performing certain SMX\n   specific mode control operations. The operation to be performed is\n   selected through the input register EBX. Currently only an input value in\n   EBX of 0 is supported. All other EBX settings will result in the signaling\n   of a general protection violation.\n\n   If EBX is set to 0, then the SMCTRL leaf is used to re-enable SMI events.\n   SMI is masked by the ILP executing the GETSEC[SENTER] instruction (SMI is\n   also masked in the responding logical processors in response to SENTER\n   rendezvous messages.). The determination of when this instruction is\n   allowed and the events that are unmasked is dependent on the processor\n   context (See Table 7-11). For brevity, the usage of SMCTRL where EBX=0\n   will be referred to as GETSEC[SMCTRL(0)].\n\n   As part of support for launching a measured environment, the SMI, NMI, and\n   INIT events are masked after GETSEC[SENTER], and remain masked after\n   exiting authenticated execution mode. Unmasking these events should be\n   accompanied by securely enabling these event handlers. These security\n   concerns can be addressed in VMX operation by a MVMM.\n\n   The VM monitor can choose two approaches:\n\n     * In a dual monitor approach, the executive software will set up an SMM\n       monitor in parallel to the executive VMM (i.e., the MVMM), see Chapter\n       32, \u201cSystem Management Mode\u201a\u201d of Intel^\u00ae 64 and IA-32 Architectures\n       Software Developer\u2019s Manual, Volume 3C. The SMM monitor is dedicated\n       to handling SMI events without compromising the security of the MVMM.\n       This usage model of handling SMI while a measured environment is\n       active does not require the use of GETSEC[SMCTRL(0)] as event\n       re-enabling after the VMX environment launch is handled implicitly and\n       through separate VMX based controls.\n     * If a dedicated SMM monitor will not be established and SMIs are to be\n       handled within the measured environment, then GETSEC[SMCTRL(0)] can be\n       used by the executive software to re-enable SMI that has been masked\n       as a result of SENTER.\n\n   Table 7-11 defines the processor context in which GETSEC[SMCTRL(0)] can be\n   used and which events will be unmasked. Note that the events that are\n   unmasked are dependent upon the currently operating processor context.\n\n   ILP Mode of Operation                SMCTRL execution action               \n   In VMX non-root operation            VM exit                               \n   SENTERFLAG = 0                       #GP(0), illegal context               \n   In authenticated code execution mode #GP(0), illegal context               \n   (ACMODEFLAG = 1)                     \n   SENTERFLAG = 1, not in VMX           Unmask SMI                            \n   operation, not in SMM                \n   SENTERFLAG = 1, in VMX root          Unmask SMI if SMM monitor is not      \n   operation, not in SMM                configured, otherwise #GP(0)          \n   SENTERFLAG = 1, In VMX root          #GP(0), illegal context               \n   operation, in SMM                    \n\n   Table 7-11. Supported Actions for GETSEC[SMCTRL(0)]\n\nFlags Affected \u00b6\n\n   None.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX Ignored.\n\nVM-exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["movhlps", "    MOVHLPS \u2014 Move Packed Single Precision Floating-Point Values High to Low\n\n                        Op / 64/32 bit CPUID                                  \n   Opcode/Instruction   En   Mode      Feature Description\n                             Support   Flag    \n                                               Move two packed single         \n   NP 0F 12 /r MOVHLPS  RM   V/V       SSE     precision floating-point       \n   xmm1, xmm2                                  values from high quadword of   \n                                               xmm2 to low quadword of xmm1.  \n   VEX.128.0F.WIG 12 /r                        Merge two packed single        \n   VMOVHLPS xmm1, xmm2, RVM  V/V       AVX     precision floating-point       \n   xmm3                                        values from high quadword of   \n                                               xmm3 and low quadword of xmm2. \n   EVEX.128.0F.W0 12 /r                        Merge two packed single        \n   VMOVHLPS xmm1, xmm2, RVM  V/V       AVX512F precision floating-point       \n   xmm3                                        values from high quadword of   \n                                               xmm3 and low quadword of xmm2. \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. ModRM.MOD = 011B required.\n\n   Op/En Operand 1     Operand 2                    Operand 3     Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r)                N/A           N/A       \n   RVM   ModRM:reg (w) VEX.vvvv (r) / EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   This instruction cannot be used for memory to register moves.\n\n   128-bit two-argument form:\n\n   Moves two packed single precision floating-point values from the high\n   quadword of the second XMM argument (second operand) to the low quadword\n   of the first XMM register (first argument). The quadword at bits 127:64 of\n   the destination operand is left unchanged. Bits (MAXVL-1:128) of the\n   corresponding destination register remain unchanged.\n\n   128-bit and EVEX three-argument form:\n\n   Moves two packed single precision floating-point values from the high\n   quadword of the third XMM argument (third operand) to the low quadword of\n   the destination (first operand). Copies the high quadword from the second\n   XMM argument (second operand) to the high quadword of the destination\n   (first operand). Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   If VMOVHLPS is encoded with VEX.L or EVEX.L\u2019L= 1, an attempt to execute\n   the instruction encoded with VEX.L or EVEX.L\u2019L= 1 will cause an #UD\n   exception.\n"],
	["blendpd", "         BLENDPD \u2014 Blend Packed Double Precision Floating-Point Values\n\n                                  64/32-bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                            Flag    \n                                                    Select packed double      \n                                                    precision floating-point  \n   66 0F 3A 0D /r ib                                values from xmm1 and      \n   BLENDPD xmm1, xmm2/m128, RMI   V/V       SSE4_1  xmm2/m128 from mask       \n   imm8                                             specified in imm8 and     \n                                                    store the values into     \n                                                    xmm1.                     \n                                                    Select packed double      \n   VEX.128.66.0F3A.WIG 0D                           precision floating-point  \n   /r ib VBLENDPD xmm1,     RVMI  V/V       AVX     Values from xmm2 and      \n   xmm2, xmm3/m128, imm8                            xmm3/m128 from mask in    \n                                                    imm8 and store the values \n                                                    in xmm1.                  \n                                                    Select packed double      \n   VEX.256.66.0F3A.WIG 0D                           precision floating-point  \n   /r ib VBLENDPD ymm1,     RVMI  V/V       AVX     Values from ymm2 and      \n   ymm2, ymm3/m256, imm8                            ymm3/m256 from mask in    \n                                                    imm8 and store the values \n                                                    in ymm1.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8[3:0] \n\nDescription \u00b6\n\n   Double-precision floating-point values from the second source operand\n   (third operand) are conditionally merged with values from the first source\n   operand (second operand) and written to the destination operand (first\n   operand). The immediate bits [3:0] determine whether the corresponding\n   double precision floating-point value in the destination is copied from\n   the second source or first source. If a bit in the mask, corresponding to\n   a word, is \u201d1\u201d, then the double precision floating-point value in the\n   second source operand is copied, else the value in the first source\n   operand is copied.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding YMM register destination are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n"],
	["gf2p8affineinvqb", "         GF2P8AFFINEINVQB \u2014 Galois Field Affine Transformation Inverse\n\n                                         64/32 bit CPUID                      \n   Opcode/Instruction              Op/En Mode      Feature  Description\n                                         Support   Flag     \n                                                            Computes inverse  \n   66 0F3A CF /r /ib                                        affine            \n   GF2P8AFFINEINVQB xmm1,          A     V/V       GFNI     transformation in \n   xmm2/m128, imm8                                          the finite field  \n                                                            GF(2^8).          \n                                                            Computes inverse  \n   VEX.128.66.0F3A.W1 CF /r /ib                             affine            \n   VGF2P8AFFINEINVQB xmm1, xmm2,   B     V/V       AVX GFNI transformation in \n   xmm3/m128, imm8                                          the finite field  \n                                                            GF(2^8).          \n                                                            Computes inverse  \n   VEX.256.66.0F3A.W1 CF /r /ib                             affine            \n   VGF2P8AFFINEINVQB ymm1, ymm2,   B     V/V       AVX GFNI transformation in \n   ymm3/m256, imm8                                          the finite field  \n                                                            GF(2^8).          \n                                                            Computes inverse  \n   EVEX.128.66.0F3A.W1 CF /r /ib                   AVX512VL affine            \n   VGF2P8AFFINEINVQB xmm1{k1}{z},  C     V/V       GFNI     transformation in \n   xmm2, xmm3/m128/m64bcst, imm8                            the finite field  \n                                                            GF(2^8).          \n                                                            Computes inverse  \n   EVEX.256.66.0F3A.W1 CF /r /ib                   AVX512VL affine            \n   VGF2P8AFFINEINVQB ymm1{k1}{z},  C     V/V       GFNI     transformation in \n   ymm2, ymm3/m256/m64bcst, imm8                            the finite field  \n                                                            GF(2^8).          \n                                                            Computes inverse  \n   EVEX.512.66.0F3A.W1 CF /r /ib                   AVX512F  affine            \n   VGF2P8AFFINEINVQB zmm1{k1}{z},  C     V/V       GFNI     transformation in \n   zmm2, zmm3/m512/m64bcst, imm8                            the finite field  \n                                                            GF(2^8).          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) imm8 (r)      N/A       \n   B     N/A   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8 (r)  \n   C     Full  ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   The AFFINEINVB instruction computes an affine transformation in the Galois\n   Field 2^8. For this instruction, an affine transformation is defined by A\n   * inv(x) + b where \u201cA\u201d is an 8 by 8 bit matrix, and \u201cx\u201d and \u201cb\u201d are 8-bit\n   vectors. The inverse of the bytes in x is defined with respect to the\n   reduction polynomial x^8 + x^4 + x^3 + x + 1.\n\n   One SIMD register (operand 1) holds \u201cx\u201d as either 16, 32 or 64 8-bit\n   vectors. A second SIMD (operand 2) register or memory operand contains 2,\n   4, or 8 \u201cA\u201d values, which are operated upon by the correspondingly aligned\n   8 \u201cx\u201d values in the first register. The \u201cb\u201d vector is constant for all\n   calculations and contained in the immediate byte.\n\n   The EVEX encoded form of this instruction does not support memory fault\n   suppression. The SSE encoded forms of the instruction require 16B\n   alignment on their memory operations.\n\n   The inverse of each byte is given by the following table. The upper nibble\n   is on the vertical axis and the lower nibble is on the horizontal axis.\n   For example, the inverse of 0x95 is 0x8A.\n\n   - 0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F  \n   0 0  1  8D F6 CB 52 7B D1 E8 4F 29 C0 B0 E1 E5 C7 \n   1 74 B4 AA 4B 99 2B 60 5F 58 3F FD CC FF 40 EE B2 \n   2 3A 6E 5A F1 55 4D A8 C9 C1 A  98 15 30 44 A2 C2 \n   3 2C 45 92 6C F3 39 66 42 F2 35 20 6F 77 BB 59 19 \n   4 1D FE 37 67 2D 31 F5 69 A7 64 AB 13 54 25 E9 9  \n   5 ED 5C 5  CA 4C 24 87 BF 18 3E 22 F0 51 EC 61 17 \n   6 16 5E AF D3 49 A6 36 43 F4 47 91 DF 33 93 21 3B \n   7 79 B7 97 85 10 B5 BA 3C B6 70 D0 6  A1 FA 81 82 \n   8 83 7E 7F 80 96 73 BE 56 9B 9E 95 D9 F7 2  B9 A4 \n   9 DE 6A 32 6D D8 8A 84 72 2A 14 9F 88 F9 DC 89 9A \n   A FB 7C 2E C3 8F B8 65 48 26 C8 12 4A CE E7 D2 62 \n   B C  E0 1F EF 11 75 78 71 A5 8E 76 3D BD BC 86 57 \n   C B  28 2F A3 DA D4 E4 F  A9 27 53 4  1B FC AC E6 \n   D 7A 7  AE 63 C5 DB E2 EA 94 8B C4 D5 9D F8 90 6B \n   E B1 D  D6 EB C6 E  CF AD 8  4E D7 E3 5D 50 1E B3 \n   F 5B 23 38 34 68 46 3  8C DD 9C 7D A0 CD 1A 41 1C \n\n   Table 3-50. Inverse Byte Listings\n"],
	["epa", "                            EPA \u2014 Add Version Array\n\n   Opcode/Instruction   Op/En 64/32 bit    CPUID        Description           \n                              Mode Support Feature Flag \n                                                        This leaf function    \n   EAX = 0AH ENCLS[EPA] IR    V/V          SGX1         adds a Version Array  \n                                                        to the EPC.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX      RBX                  RCX                                    \n   IR    EPA (In) PT_VA (In, Constant) Effective address of the EPC page (In) \n\n  Description \u00b6\n\n   This leaf function creates an empty version array in the EPC page whose\n   logical address is given by DS:RCX, and sets up EPCM attributes for that\n   page. At the time of execution of this instruction, the register RBX must\n   be set to PT_VA.\n\n   The table below provides additional information on the memory parameter of\n   EPA leaf function.\n\nEPA Memory Parameter Semantics \u00b6\n\n   EPCPAGE                           \n   Write access permitted by Enclave \n\n  Concurrency Restrictions \u00b6\n\n   Leaf                             Parameter   Base Concurrency Restrictions\n                                                       On Conflict      \n   EPA EPA VA [DS:RCX] Exclusive    VA [DS:RCX] \n   #GP EPA VA [DS:RCX]              \n\n   Table 38-37. Base Concurrency Restrictions of EPA\n\n                              Additional Concurrency Restrictions\n                              vs. EACCEPT,                                   \n   Leaf Access On             EACCEPTCOPY, vs. EADD,  vs. EADD,              \n   Conflict                   EEXTEND, EINIT vs.      EEXTEND,   \n   Access On                  ETRACK, ETRACKC Access  EINIT vs.  \n   Conflict EPA               vs. ETRACK, ETRACKC     EADD,       vs. ETRACK,\n   VA [DS:RCX]                Access On Conflict      EEXTEND,    ETRACKC\n   Concurrent     Parameter   Access vs. ETRACK,      EINIT vs.  \n   Access On                  ETRACKC Access On       ETRACK,    \n   Conflict                   Conflict EMODPE,        ETRACKC\n   Access On                  EMODPR, EMODT         \n   Conflict EPA               Access On Conflict    \n   VA [DS:RCX]                Access On Conflict    \n                              Access Access On      \n                              Conflict Access On    \n                              Conflict              \n   EPA            VA [DS:RCX]                         Concurrent  Concurrent \n\n   Table 38-38. Additional Concurrency Restrictions of EPA\n\n  Flags Affected \u00b6\n\n   None\n"],
	["vrndscalepd", "VRNDSCALEPD \u2014 Round Packed Float64 Values to Include a Given Number of Fraction\n                                      Bits\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Rounds packed double    \n                                                      precision               \n                                                      floating-point values   \n   EVEX.128.66.0F3A.W1 09 /r                          in xmm2/m128/m64bcst to \n   ib VRNDSCALEPD xmm1       A     V/V       AVX512VL a number of fraction    \n   {k1}{z},                                  AVX512F  bits specified by the   \n   xmm2/m128/m64bcst, imm8                            imm8 field. Stores the  \n                                                      result in xmm1          \n                                                      register. Under         \n                                                      writemask.              \n                                                      Rounds packed double    \n                                                      precision               \n                                                      floating-point values   \n   EVEX.256.66.0F3A.W1 09 /r                          in ymm2/m256/m64bcst to \n   ib VRNDSCALEPD ymm1       A     V/V       AVX512VL a number of fraction    \n   {k1}{z},                                  AVX512F  bits specified by the   \n   ymm2/m256/m64bcst, imm8                            imm8 field. Stores the  \n                                                      result in ymm1          \n                                                      register. Under         \n                                                      writemask.              \n                                                      Rounds packed double    \n                                                      precision               \n   EVEX.512.66.0F3A.W1 09 /r                          floating-point values   \n   ib VRNDSCALEPD zmm1                                in zmm2/m512/m64bcst to \n   {k1}{z},                  A     V/V       AVX512F  a number of fraction    \n   zmm2/m512/m64bcst{sae},                            bits specified by the   \n   imm8                                               imm8 field. Stores the  \n                                                      result in zmm1 register \n                                                      using writemask k1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\n  Description \u00b6\n\n   Round the double precision floating-point values in the source operand by\n   the rounding mode specified in the immediate operand (see Figure 5-29) and\n   places the result in the destination operand.\n\n   The destination operand (the first operand) is a ZMM/YMM/XMM register\n   conditionally updated according to the writemask. The source operand (the\n   second operand) can be a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location, or a 512/256/128-bit vector broadcasted from a 64-bit memory\n   location.\n\n   The rounding process rounds the input to an integral value, plus number\n   bits of fraction that are specified by imm8[7:4] (to be included in the\n   result) and returns the result as a double precision floating-point value.\n\n   It should be noticed that no overflow is induced while executing this\n   instruction (although the source is scaled by the imm8[7:4] value).\n\n   The immediate operand also specifies control fields for the rounding\n   operation, three bit fields are defined and shown in the \u201cImmediate\n   Control Description\u201d figure below. Bit 3 of the immediate byte controls\n   the processor behavior for a precision exception, bit 2 selects the source\n   of rounding mode control. Bits 1:0 specify a non-sticky rounding-mode\n   value (immediate control table below lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   The sign of the result of this instruction is preserved, including the\n   sign of zero.\n\n   The formula of the operation on each data element for VRNDSCALEPD is\n\n   ROUND(x) = 2^-M*Round_to_INT(x*2^M, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   M=imm[7:4];\n\n   The operation of x*2^M is computed as if the exponent range is unlimited\n   (i.e., no overflow ever occurs).\n\n   VRNDSCALEPD is a more general form of the VEX-encoded VROUNDPD\n   instruction. In VROUNDPD, the formula of the operation on each element is\n\n   ROUND(x) = Round_to_INT(x, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n\n   0 imm8 SPE RS Round Control Override Fixed point length Suppress Precision\n   Exception: Imm8[3] Imm8[1:0] = 00b : Round nearest even Round Select:\n   Imm8[2] Imm8[3] = 0b : Use MXCSR exception mask Imm8[7:4] : Number of\n   fixed points to preserve Imm8[1:0] = 01b : Round down Imm8[2] = 0b : Use\n   Imm8[1:0] Imm8[3] = 1b : Suppress Imm8[1:0] = 10b : Round up Imm8[2] = 1b\n   : Use MXCSR Imm8[1:0] = 11b : Truncate Figure 5-29. Imm8 Controls for\n   VRNDSCALEPD/SD/PS/SS\n\n   Handling of special case of input values are listed in Table 5-31.\n\n             Returned value         \n   Src1=\u00b1inf Src1                   \n   Src1=\u00b1NAN Src1 converted to QNAN \n   Src1=\u00b10   Src1                   \n\n   Table 5-31. VRNDSCALEPD/SD/PS/SS Special Cases\n"],
	["pcmpestrm", "        PCMPESTRM \u2014 Packed Compare Explicit Length Strings, Return Mask\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Perform a packed          \n   66 0F 3A 60 /r imm8                              comparison of string data \n   PCMPESTRM xmm1,          RMI   V/V       SSE4_2  with explicit lengths,    \n   xmm2/m128, imm8                                  generating a mask, and    \n                                                    storing the result in     \n                                                    XMM0.                     \n                                                    Perform a packed          \n   VEX.128.66.0F3A 60 /r ib                         comparison of string data \n   VPCMPESTRM xmm1,         RMI   V/V       AVX     with explicit lengths,    \n   xmm2/m128, imm8                                  generating a mask, and    \n                                                    storing the result in     \n                                                    XMM0.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RMI   ModRM:reg (r) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   The instruction compares data from two string fragments based on the\n   encoded value in the imm8 contol byte (see Section 4.1, \u201cImm8 Control Byte\n   Operation for PCMPESTRI / PCMPESTRM / PCMPISTRI / PCMPISTRM\u201d), and\n   generates a mask stored to XMM0.\n\n   Each string fragment is represented by two values. The first value is an\n   xmm (or possibly m128 for the second operand) which contains the data\n   elements of the string (byte or word data). The second value is stored in\n   an input length register. The input length register is EAX/RAX (for xmm1)\n   or EDX/RDX (for xmm2/m128). The length represents the number of\n   bytes/words which are valid for the respective xmm/m128 data.\n\n   The length of each input is interpreted as being the absolute-value of the\n   value in the length register. The absolute-value computation saturates to\n   16 (for bytes) and 8 (for words), based on the value of imm8[bit3] when\n   the value in the length register is greater than 16 (8) or less than -16\n   (-8).\n\n   The comparison and aggregation operations are performed according to the\n   encoded value of imm8 bit fields (see Section 4.1). As defined by imm8[6],\n   IntRes2 is then either stored to the least significant bits of XMM0 (zero\n   extended to 128 bits) or expanded into a byte/word-mask and then stored to\n   XMM0.\n\n   Note that the Arithmetic Flags are written in a non-standard manner in\n   order to supply the most relevant information:\n\n   CFlag \u2013 Reset if IntRes2 is equal to zero, set otherwise\n\n   ZFlag \u2013 Set if absolute-value of EDX is < 16 (8), reset otherwise\n\n   SFlag \u2013 Set if absolute-value of EAX is < 16 (8), reset otherwise\n\n   OFlag \u2013IntRes2[0]\n\n   AFlag \u2013 Reset\n\n   PFlag \u2013 Reset\n\n   Note: In VEX.128 encoded versions, bits (MAXVL-1:128) of XMM0 are zeroed.\n   VEX.vvvv is reserved and must be 1111b, VEX.L must be 0, otherwise the\n   instruction will #UD.\n\nEffective Operand Size \u00b6\n\n   Operating mode/size Operand 1 Operand 2 Length 1 Length 2 Result \n   16 bit              xmm       xmm/m128  EAX      EDX      XMM0   \n   32 bit              xmm       xmm/m128  EAX      EDX      XMM0   \n   64 bit              xmm       xmm/m128  EAX      EDX      XMM0   \n   64 bit + REX.W      xmm       xmm/m128  RAX      RDX      XMM0   \n"],
	["cmpxchg", "                         CMPXCHG \u2014 Compare and Exchange\n\n   Opcode/Instruction      Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n                                                   Compare AL with r/m8. If   \n   0F B0/r CMPXCHG r/m8,                           equal, ZF is set and r8 is \n   r8                      MR    Valid  Valid*     loaded into r/m8. Else,    \n                                                   clear ZF and load r/m8     \n                                                   into AL.                   \n                                                   Compare AL with r/m8. If   \n   REX + 0F B0/r CMPXCHG                           equal, ZF is set and r8 is \n   r/m8**,r8               MR    Valid  N.E.       loaded into r/m8. Else,    \n                                                   clear ZF and load r/m8     \n                                                   into AL.                   \n                                                   Compare AX with r/m16. If  \n   0F B1/r CMPXCHG r/m16,                          equal, ZF is set and r16   \n   r16                     MR    Valid  Valid*     is loaded into r/m16.      \n                                                   Else, clear ZF and load    \n                                                   r/m16 into AX.             \n                                                   Compare EAX with r/m32. If \n   0F B1/r CMPXCHG r/m32,                          equal, ZF is set and r32   \n   r32                     MR    Valid  Valid*     is loaded into r/m32.      \n                                                   Else, clear ZF and load    \n                                                   r/m32 into EAX.            \n                                                   Compare RAX with r/m64. If \n   REX.W + 0F B1/r CMPXCHG                         equal, ZF is set and r64   \n   r/m64, r64              MR    Valid  N.E.       is loaded into r/m64.      \n                                                   Else, clear ZF and load    \n                                                   r/m64 into RAX.            \n\n     * SeetheIA-32ArchitectureCompatibilitysectionbelow.\n\n     ** In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Compares the value in the AL, AX, EAX, or RAX register with the first\n   operand (destination operand). If the two values are equal, the second\n   operand (source operand) is loaded into the destination operand.\n   Otherwise, the destination operand is loaded into the AL, AX, EAX or RAX\n   register. RAX register is available only in 64-bit mode.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically. To simplify the interface to the processor\u2019s\n   bus, the destination operand receives a write cycle without regard to the\n   result of the comparison. The destination operand is written back if the\n   comparison fails; otherwise, the source operand is written into the\n   destination. (The processor never produces a locked read without also\n   producing a locked write.)\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\nIA-32 Architecture Compatibility \u00b6\n\n   This instruction is not supported on Intel processors earlier than the\n   Intel486 processors.\n\nFlags Affected \u00b6\n\n   The ZF flag is set if the values in the destination operand and register\n   AL, AX, or EAX are equal; otherwise it is cleared. The CF, PF, AF, SF, and\n   OF flags are set according to the results of the comparison operation.\n"],
	["vfnmadd132ps:vfnmadd213ps:vfnmadd231ps", "    VFNMADD132PS/VFNMADD213PS/VFNMADD231PS \u2014 Fused Negative Multiply-Add of\n                  PackedSingle Precision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed single   \n                                                     precision floating-point \n   VEX.128.66.0F38.W0 9C /r                          values from xmm1 and     \n   VFNMADD132PS xmm1, xmm2, A     V/V       FMA      xmm3/mem, negate the     \n   xmm3/m128                                         multiplication result    \n                                                     and add to xmm2 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   VEX.128.66.0F38.W0 AC /r                          values from xmm1 and     \n   VFNMADD213PS xmm1, xmm2, A     V/V       FMA      xmm2, negate the         \n   xmm3/m128                                         multiplication result    \n                                                     and add to xmm3/mem and  \n                                                     put result in xmm1.      \n                                                     Multiply packed single   \n                                                     precision floating-point \n   VEX.128.66.0F38.W0 BC /r                          values from xmm2 and     \n   VFNMADD231PS xmm1, xmm2, A     V/V       FMA      xmm3/mem, negate the     \n   xmm3/m128                                         multiplication result    \n                                                     and add to xmm1 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   VEX.256.66.0F38.W0 9C /r                          values from ymm1 and     \n   VFNMADD132PS ymm1, ymm2, A     V/V       FMA      ymm3/mem, negate the     \n   ymm3/m256                                         multiplication result    \n                                                     and add to ymm2 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   VEX.256.66.0F38.W0 AC /r                          values from ymm1 and     \n   VFNMADD213PS ymm1, ymm2, A     V/V       FMA      ymm2, negate the         \n   ymm3/m256                                         multiplication result    \n                                                     and add to ymm3/mem and  \n                                                     put result in ymm1.      \n                                                     Multiply packed single   \n                                                     precision floating-point \n   VEX.256.66.0F38.0 BC /r                           values from ymm2 and     \n   VFNMADD231PS ymm1, ymm2, A     V/V       FMA      ymm3/mem, negate the     \n   ymm3/m256                                         multiplication result    \n                                                     and add to ymm1 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W0 9C                            values from xmm1 and     \n   /r VFNMADD132PS xmm1     B     V/V       AVX512VL xmm3/m128/m32bcst,       \n   {k1}{z}, xmm2,                           AVX512F  negate the               \n   xmm3/m128/m32bcst                                 multiplication result    \n                                                     and add to xmm2 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W0 AC                            values from xmm1 and     \n   /r VFNMADD213PS xmm1     B     V/V       AVX512VL xmm2, negate the         \n   {k1}{z}, xmm2,                           AVX512F  multiplication result    \n   xmm3/m128/m32bcst                                 and add to               \n                                                     xmm3/m128/m32bcst and    \n                                                     put result in xmm1.      \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W0 BC                            values from xmm2 and     \n   /r VFNMADD231PS xmm1     B     V/V       AVX512VL xmm3/m128/m32bcst,       \n   {k1}{z}, xmm2,                           AVX512F  negate the               \n   xmm3/m128/m32bcst                                 multiplication result    \n                                                     and add to xmm1 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W0 9C                            values from ymm1 and     \n   /r VFNMADD132PS ymm1     B     V/V       AVX512VL ymm3/m256/m32bcst,       \n   {k1}{z}, ymm2,                           AVX512F  negate the               \n   ymm3/m256/m32bcst                                 multiplication result    \n                                                     and add to ymm2 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W0 AC                            values from ymm1 and     \n   /r VFNMADD213PS ymm1     B     V/V       AVX512VL ymm2, negate the         \n   {k1}{z}, ymm2,                           AVX512F  multiplication result    \n   ymm3/m256/m32bcst                                 and add to               \n                                                     ymm3/m256/m32bcst and    \n                                                     put result in ymm1.      \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W0 BC                            values from ymm2 and     \n   /r VFNMADD231PS ymm1     B     V/V       AVX512VL ymm3/m256/m32bcst,       \n   {k1}{z}, ymm2,                           AVX512F  negate the               \n   ymm3/m256/m32bcst                                 multiplication result    \n                                                     and add to ymm1 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W0 9C                            values from zmm1 and     \n   /r VFNMADD132PS zmm1     B     V/V       AVX512VL zmm3/m512/m32bcst,       \n   {k1}{z}, zmm2,                           AVX512F  negate the               \n   zmm3/m512/m32bcst{er}                             multiplication result    \n                                                     and add to zmm2 and put  \n                                                     result in zmm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W0 AC                            values from zmm1 and     \n   /r VFNMADD213PS zmm1     B     V/V       AVX512F  zmm2, negate the         \n   {k1}{z}, zmm2,                                    multiplication result    \n   zmm3/m512/m32bcst{er}                             and add to               \n                                                     zmm3/m512/m32bcst and    \n                                                     put result in zmm1.      \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W0 BC                            values from zmm2 and     \n   /r VFNMADD231PS zmm1     B     V/V       AVX512F  zmm3/m512/m32bcst,       \n   {k1}{z}, zmm2,                                    negate the               \n   zmm3/m512/m32bcst{er}                             multiplication result    \n                                                     and add to zmm1 and put  \n                                                     result in zmm1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMADD132PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the first source operand to the four,\n   eight or sixteen packed single precision floating-point values in the\n   third source operand, adds the negated infinite precision intermediate\n   result to the four, eight or sixteen packed single precision\n   floating-point values in the second source operand, performs rounding and\n   stores the resulting four, eight or sixteen packed single precision\n   floating-point values to the destination operand (first source operand).\n\n   VFNMADD213PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the second source operand to the\n   four, eight or sixteen packed single precision floating-point values in\n   the first source operand, adds the negated infinite precision intermediate\n   result to the four, eight or sixteen packed single precision\n   floating-point values in the third source operand, performs rounding and\n   stores the resulting the four, eight or sixteen packed single precision\n   floating-point values to the destination operand (first source operand).\n\n   VFNMADD231PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the second source operand to the\n   four, eight or sixteen packed single precision floating-point values in\n   the third source operand, adds the negated infinite precision intermediate\n   result to the four, eight or sixteen packed single precision\n   floating-point values in the first source operand, performs rounding and\n   stores the resulting four, eight or sixteen packed single precision\n   floating-point values to the destination operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 32-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["aas", "                    AAS \u2014 ASCII Adjust AL After Subtraction\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description           \n   3F     AAS         ZO    Invalid     Valid           ASCII adjust AL after \n                                                        subtraction.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Adjusts the result of the subtraction of two unpacked BCD values to create\n   a unpacked BCD result. The AL register is the implied source and\n   destination operand for this instruction. The AAS instruction is only\n   useful when it follows a SUB instruction that subtracts (binary\n   subtraction) one unpacked BCD value from another and stores a byte result\n   in the AL register. The AAA instruction then adjusts the contents of the\n   AL register to contain the correct 1-digit unpacked BCD result.\n\n   If the subtraction produced a decimal carry, the AH register decrements by\n   1, and the CF and AF flags are set. If no decimal carry occurred, the CF\n   and AF flags are cleared, and the AH register is unchanged. In either\n   case, the AL register is left with its top four bits set to 0.\n\n   This instruction executes as described in compatibility mode and legacy\n   mode. It is not valid in 64-bit mode.\n\nFlags Affected \u00b6\n\n   The AF and CF flags are set to 1 if there is a decimal borrow; otherwise,\n   they are cleared to 0. The OF, SF, ZF, and PF flags are undefined.\n"],
	["aesdec", "              AESDEC \u2014 Perform One Round of an AES Decryption Flow\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                           Flag     \n                                                    Perform one round of an   \n                                                    AES decryption flow,      \n   66 0F 38 DE /r AESDEC                            using the Equivalent      \n   xmm1, xmm2/m128         A     V/V       AES      Inverse Cipher, using one \n                                                    128-bit data (state) from \n                                                    xmm1 with one 128-bit     \n                                                    round key from xmm2/m128. \n                                                    Perform one round of an   \n                                                    AES decryption flow,      \n   VEX.128.66.0F38.WIG DE                           using the Equivalent      \n   /r VAESDEC xmm1, xmm2,  B     V/V       AES AVX  Inverse Cipher, using one \n   xmm3/m128                                        128-bit data (state) from \n                                                    xmm2 with one 128-bit     \n                                                    round key from xmm3/m128; \n                                                    store the result in xmm1. \n                                                    Perform one round of an   \n                                                    AES decryption flow,      \n                                                    using the Equivalent      \n   VEX.256.66.0F38.WIG DE                           Inverse Cipher, using two \n   /r VAESDEC ymm1, ymm2,  B     V/V       VAES     128-bit data (state) from \n   ymm3/m256                                        ymm2 with two 128-bit     \n                                                    round keys from           \n                                                    ymm3/m256; store the      \n                                                    result in ymm1.           \n                                                    Perform one round of an   \n                                                    AES decryption flow,      \n   EVEX.128.66.0F38.WIG DE                          using the Equivalent      \n   /r VAESDEC xmm1, xmm2,  C     V/V       VAES     Inverse Cipher, using one \n   xmm3/m128                               AVX512VL 128-bit data (state) from \n                                                    xmm2 with one 128-bit     \n                                                    round key from xmm3/m128; \n                                                    store the result in xmm1. \n                                                    Perform one round of an   \n                                                    AES decryption flow,      \n                                                    using the Equivalent      \n   EVEX.256.66.0F38.WIG DE                 VAES     Inverse Cipher, using two \n   /r VAESDEC ymm1, ymm2,  C     V/V       AVX512VL 128-bit data (state) from \n   ymm3/m256                                        ymm2 with two 128-bit     \n                                                    round keys from           \n                                                    ymm3/m256; store the      \n                                                    result in ymm1.           \n                                                    Perform one round of an   \n                                                    AES decryption flow,      \n                                                    using the Equivalent      \n   EVEX.512.66.0F38.WIG DE                 VAES     Inverse Cipher, using     \n   /r VAESDEC zmm1, zmm2,  C     V/V       AVX512F  four 128-bit data (state) \n   zmm3/m512                                        from zmm2 with four       \n                                                    128-bit round keys from   \n                                                    zmm3/m512; store the      \n                                                    result in zmm1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A      ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A      ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   This instruction performs a single round of the AES decryption flow using\n   the Equivalent Inverse Cipher, using one/two/four (depending on vector\n   length) 128-bit data (state) from the first source operand with\n   one/two/four (depending on vector length) round key(s) from the second\n   source operand, and stores the result in the destination operand.\n\n   Use the AESDEC instruction for all but the last decryption round. For the\n   last decryption round, use the AESDECLAST instruction.\n\n   VEX and EVEX encoded versions of the instruction allow 3-operand\n   (non-destructive) operation. The legacy encoded versions of the\n   instruction require that the first source operand and the destination\n   operand are the same and must be an XMM register.\n\n   The EVEX encoded form of this instruction does not support memory fault\n   suppression.\n"],
	["hsubpd", "      HSUBPD \u2014 Packed Double Precision Floating-Point Horizontal Subtract\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Horizontal subtract packed \n   66 0F 7D /r HSUBPD      RM    V/V       SSE3    double precision           \n   xmm1, xmm2/m128                                 floating-point values from \n                                                   xmm2/m128 to xmm1.         \n   VEX.128.66.0F.WIG 7D /r                         Horizontal subtract packed \n   VHSUBPD xmm1,xmm2,      RVM   V/V       AVX     double precision           \n   xmm3/m128                                       floating-point values from \n                                                   xmm2 and xmm3/mem.         \n   VEX.256.66.0F.WIG 7D /r                         Horizontal subtract packed \n   VHSUBPD ymm1, ymm2,     RVM   V/V       AVX     double precision           \n   ymm3/m256                                       floating-point values from \n                                                   ymm2 and ymm3/mem.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   The HSUBPD instruction subtracts horizontally the packed double precision\n   floating-point numbers of both operands.\n\n   Subtracts the double precision floating-point value in the high quadword\n   of the destination operand from the low quadword of the destination\n   operand and stores the result in the low quadword of the destination\n   operand.\n\n   Subtracts the double precision floating-point value in the high quadword\n   of the source operand from the low quadword of the source operand and\n   stores the result in the high quadword of the destination operand.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n\n   See Figure 3-21 for HSUBPD; see Figure 3-22 for VHSUBPD.\n\n   HSUBPD xmm1, xmm2/m128 xmm2 [127:64] [63:0] /m128 xmm1 [127:64] [63:0]\n   Result: xmm2/m128[63:0] - xmm1[63:0] - xmm1[127:64] xmm1 xmm2/m128[127:64]\n   [127:64] [63:0] Figure 3-21. HSUBPD\u2014Packed Double Precision Floating-Point\n   Horizontal Subtract X3 X2 X1 X0 SRC1 Y3 Y2 Y1 Y0 SRC2 DEST Y2 - Y3 X2 - X3\n   Y0 - Y1 X0 - X1 Figure 3-22. VHSUBPD operation\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n"],
	["vpmovdb:vpmovsdb:vpmovusdb", "            VPMOVDB/VPMOVSDB/VPMOVUSDB \u2014 Down Convert DWord to Byte\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature  Description\n                               Support   Flag     \n                                                  Converts 4 packed           \n   EVEX.128.F3.0F38.W0 31                         double-word integers from   \n   /r VPMOVDB xmm1/m32    A    V/V       AVX512VL xmm2 into 4 packed byte     \n   {k1}{z}, xmm2                         AVX512F  integers in xmm1/m32 with   \n                                                  truncation under writemask  \n                                                  k1.                         \n                                                  Converts 4 packed signed    \n   EVEX.128.F3.0F38.W0 21                         double-word integers from   \n   /r VPMOVSDB xmm1/m32   A    V/V       AVX512VL xmm2 into 4 packed signed   \n   {k1}{z}, xmm2                         AVX512F  byte integers in xmm1/m32   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 4 packed unsigned  \n   EVEX.128.F3.0F38.W0 11                         double-word integers from   \n   /r VPMOVUSDB xmm1/m32  A    V/V       AVX512VL xmm2 into 4 packed unsigned \n   {k1}{z}, xmm2                         AVX512F  byte integers in xmm1/m32   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 8 packed           \n   EVEX.256.F3.0F38.W0 31                         double-word integers from   \n   /r VPMOVDB xmm1/m64    A    V/V       AVX512VL ymm2 into 8 packed byte     \n   {k1}{z}, ymm2                         AVX512F  integers in xmm1/m64 with   \n                                                  truncation under writemask  \n                                                  k1.                         \n                                                  Converts 8 packed signed    \n   EVEX.256.F3.0F38.W0 21                         double-word integers from   \n   /r VPMOVSDB xmm1/m64   A    V/V       AVX512VL ymm2 into 8 packed signed   \n   {k1}{z}, ymm2                         AVX512F  byte integers in xmm1/m64   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 8 packed unsigned  \n   EVEX.256.F3.0F38.W0 11                         double-word integers from   \n   /r VPMOVUSDB xmm1/m64  A    V/V       AVX512VL ymm2 into 8 packed unsigned \n   {k1}{z}, ymm2                         AVX512F  byte integers in xmm1/m64   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 16 packed          \n   EVEX.512.F3.0F38.W0 31                         double-word integers from   \n   /r VPMOVDB xmm1/m128   A    V/V       AVX512F  zmm2 into 16 packed byte    \n   {k1}{z}, zmm2                                  integers in xmm1/m128 with  \n                                                  truncation under writemask  \n                                                  k1.                         \n                                                  Converts 16 packed signed   \n   EVEX.512.F3.0F38.W0 21                         double-word integers from   \n   /r VPMOVSDB xmm1/m128  A    V/V       AVX512F  zmm2 into 16 packed signed  \n   {k1}{z}, zmm2                                  byte integers in xmm1/m128  \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 16 packed unsigned \n                                                  double-word integers from   \n   EVEX.512.F3.0F38.W0 11                         zmm2 into 16 packed         \n   /r VPMOVUSDB xmm1/m128 A    V/V       AVX512F  unsigned byte integers in   \n   {k1}{z}, zmm2                                  xmm1/m128 using unsigned    \n                                                  saturation under writemask  \n                                                  k1.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Quarter Mem ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   VPMOVDB down converts 32-bit integer elements in the source operand (the\n   second operand) into packed bytes using truncation. VPMOVSDB converts\n   signed 32-bit integers into packed signed bytes using signed saturation.\n   VPMOVUSDB convert unsigned double-word values into unsigned byte values\n   using unsigned saturation.\n\n   The source operand is a ZMM/YMM/XMM register. The destination operand is a\n   XMM register or a 128/64/32-bit memory location.\n\n   Down-converted byte elements are written to the destination operand (the\n   first operand) from the least-significant byte. Byte elements of the\n   destination operand are updated according to the writemask. Bits\n   (MAXVL-1:128/64/32) of the register destination are zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["vperm2f128", "                   VPERM2F128 \u2014 Permute Floating-Point Values\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Permute 128-bit           \n   VEX.256.66.0F3A.W0 06 /r                         floating-point fields in  \n   ib VPERM2F128 ymm1,      RV MI V/V       AVX     ymm2 and ymm3/mem using   \n   ymm2, ymm3/m256, imm8                            controls from imm8 and    \n                                                    store result in ymm1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVMI  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Permute 128 bit floating-point-containing fields from the first source\n   operand (second operand) and second source operand (third operand) using\n   bits in the 8-bit immediate and store results in the destination operand\n   (first operand). The first source operand is a YMM register, the second\n   source operand is a YMM register or a 256-bit memory location, and the\n   destination operand is a YMM register.\n\n   Y1 Y0 SRC2 X1 X0 SRC1 X0, X1, Y0, or Y1 DEST X0, X1, Y0, or Y1 Figure\n   5-21. VPERM2F128 Operation\n\n   Imm8[1:0] select the source for the first destination 128-bit field,\n   imm8[5:4] select the source for the second destination field. If imm8[3]\n   is set, the low 128-bit field is zeroed. If imm8[7] is set, the high\n   128-bit field is zeroed.\n\n   VEX.L must be 1, otherwise the instruction will #UD.\n"],
	["vcvtw2ph", "         VCVTW2PH \u2014 Convert Packed Signed Word Integers to FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert eight packed \n                                                         signed word integers \n   EVEX.128.F3.MAP5.W0 7D /r                             from                 \n   VCVTW2PH xmm1{k1}{z},           A V/V     AVX512-FP16 xmm2/m128/m16bcst to \n   xmm2/m128/m16bcst                         AVX512VL    FP16 values, and     \n                                                         store the result in  \n                                                         xmm1 subject to      \n                                                         writemask k1.        \n                                                         Convert sixteen      \n                                                         packed signed word   \n   EVEX.256.F3.MAP5.W0 7D /r                             integers from        \n   VCVTW2PH ymm1{k1}{z},           A V/V     AVX512-FP16 ymm2/m256/m16bcst to \n   ymm2/m256/m16bcst                         AVX512VL    FP16 values, and     \n                                                         store the result in  \n                                                         ymm1 subject to      \n                                                         writemask k1.        \n                                                         Convert thirty-two   \n                                                         packed signed word   \n   EVEX.512.F3.MAP5.W0 7D /r                             integers from        \n   VCVTW2PH zmm1{k1}{z},           A V/V     AVX512-FP16 zmm2/m512/m16bcst to \n   zmm2/m512/m16bcst {er}                                FP16 values, and     \n                                                         store the result in  \n                                                         zmm1 subject to      \n                                                         writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed signed word integers in the source\n   operand to FP16 values in the destination operand. When conversion is\n   inexact, the value returned is rounded according to the rounding control\n   bits in the MXCSR register or embedded rounding controls.\n\n   The destination elements are updated according to the writemask.\n"],
	["vpopcnt", " VPOPCNT \u2014 Return the Count of Number of Bits Set to 1 in BYTE/WORD/DWORD/QWORD\n\n                             64/32    CPUID Feature                           \n   Opcode/Instruction  Op/En bit Mode Flag             Description\n                             Support  \n   EVEX.128.66.0F38.W0                                 Counts the number of   \n   54 /r VPOPCNTB                     AVX512_BITALG    bits set to one in     \n   xmm1{k1}{z},        A     V/V      AVX512VL         xmm2/m128 and puts the \n   xmm2/m128                                           result in xmm1 with    \n                                                       writemask k1.          \n   EVEX.256.66.0F38.W0                                 Counts the number of   \n   54 /r VPOPCNTB                     AVX512_BITALG    bits set to one in     \n   ymm1{k1}{z},        A     V/V      AVX512VL         ymm2/m256 and puts the \n   ymm2/m256                                           result in ymm1 with    \n                                                       writemask k1.          \n   EVEX.512.66.0F38.W0                                 Counts the number of   \n   54 /r VPOPCNTB                                      bits set to one in     \n   zmm1{k1}{z},        A     V/V      AVX512_BITALG    zmm2/m512 and puts the \n   zmm2/m512                                           result in zmm1 with    \n                                                       writemask k1.          \n   EVEX.128.66.0F38.W1                                 Counts the number of   \n   54 /r VPOPCNTW                     AVX512_BITALG    bits set to one in     \n   xmm1{k1}{z},        A     V/V      AVX512VL         xmm2/m128 and puts the \n   xmm2/m128                                           result in xmm1 with    \n                                                       writemask k1.          \n   EVEX.256.66.0F38.W1                                 Counts the number of   \n   54 /r VPOPCNTW                     AVX512_BITALG    bits set to one in     \n   ymm1{k1}{z},        A     V/V      AVX512VL         ymm2/m256 and puts the \n   ymm2/m256                                           result in ymm1 with    \n                                                       writemask k1.          \n   EVEX.512.66.0F38.W1                                 Counts the number of   \n   54 /r VPOPCNTW                                      bits set to one in     \n   zmm1{k1}{z},        A     V/V      AVX512_BITALG    zmm2/m512 and puts the \n   zmm2/m512                                           result in zmm1 with    \n                                                       writemask k1.          \n                                                       Counts the number of   \n   EVEX.128.66.0F38.W0                                 bits set to one in     \n   55 /r VPOPCNTD      B     V/V      AVX512_VPOPCNTDQ xmm2/m128/m32bcst and  \n   xmm1{k1}{z},                       AVX512VL         puts the result in     \n   xmm2/m128/m32bcst                                   xmm1 with writemask    \n                                                       k1.                    \n                                                       Counts the number of   \n   EVEX.256.66.0F38.W0                                 bits set to one in     \n   55 /r VPOPCNTD      B     V/V      AVX512_VPOPCNTDQ ymm2/m256/m32bcst and  \n   ymm1{k1}{z},                       AVX512VL         puts the result in     \n   ymm2/m256/m32bcst                                   ymm1 with writemask    \n                                                       k1.                    \n                                                       Counts the number of   \n   EVEX.512.66.0F38.W0                                 bits set to one in     \n   55 /r VPOPCNTD      B     V/V      AVX512_VPOPCNTDQ zmm2/m512/m32bcst and  \n   zmm1{k1}{z},                                        puts the result in     \n   zmm2/m512/m32bcst                                   zmm1 with writemask    \n                                                       k1.                    \n                                                       Counts the number of   \n   EVEX.128.66.0F38.W1                                 bits set to one in     \n   55 /r VPOPCNTQ      B     V/V      AVX512_VPOPCNTDQ xmm2/m128/m32bcst and  \n   xmm1{k1}{z},                       AVX512VL         puts the result in     \n   xmm2/m128/m64bcst                                   xmm1 with writemask    \n                                                       k1.                    \n                                                       Counts the number of   \n   EVEX.256.66.0F38.W1                                 bits set to one in     \n   55 /r VPOPCNTQ      B     V/V      AVX512_VPOPCNTDQ ymm2/m256/m32bcst and  \n   ymm1{k1}{z},                       AVX512VL         puts the result in     \n   ymm2/m256/m64bcst                                   ymm1 with writemask    \n                                                       k1.                    \n                                                       Counts the number of   \n   EVEX.512.66.0F38.W1                                 bits set to one in     \n   55 /r VPOPCNTQ      B     V/V      AVX512_VPOPCNTDQ zmm2/m512/m64bcst and  \n   zmm1{k1}{z},                                        puts the result in     \n   zmm2/m512/m64bcst                                   zmm1 with writemask    \n                                                       k1.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full Mem ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full     ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction counts the number of bits set to one in each byte, word,\n   dword or qword element of its source (e.g., zmm2 or memory) and places the\n   results in the destination register (zmm1). This instruction supports\n   memory fault suppression.\n"],
	["fdivr:fdivrp:fidivr", "                      FDIVR/FDIVRP/FIDIVR \u2014 Reverse Divide\n\n   Opcode  Instruction   64-Bit Compat/Leg Mode Description                   \n                         Mode   \n   D8 /7   FDIVR m32fp   Valid  Valid           Divide m32fp by ST(0) and     \n                                                store result in ST(0).        \n   DC /7   FDIVR m64fp   Valid  Valid           Divide m64fp by ST(0) and     \n                                                store result in ST(0).        \n   D8 F8+i FDIVR ST(0),  Valid  Valid           Divide ST(i) by ST(0) and     \n           ST(i)                                store result in ST(0).        \n   DC F0+i FDIVR ST(i),  Valid  Valid           Divide ST(0) by ST(i) and     \n           ST(0)                                store result in ST(i).        \n           FDIVRP ST(i),                        Divide ST(0) by ST(i), store  \n   DE F0+i ST(0)         Valid  Valid           result in ST(i), and pop the  \n                                                register stack.               \n                                                Divide ST(0) by ST(1), store  \n   DE F1   FDIVRP        Valid  Valid           result in ST(1), and pop the  \n                                                register stack.               \n   DA /7   FIDIVR m32int Valid  Valid           Divide m32int by ST(0) and    \n                                                store result in ST(0).        \n   DE /7   FIDIVR m16int Valid  Valid           Divide m16int by ST(0) and    \n                                                store result in ST(0).        \n\nDescription \u00b6\n\n   Divides the source operand by the destination operand and stores the\n   result in the destination location. The destination operand (divisor) is\n   always in an FPU register; the source operand (dividend) can be a register\n   or a memory location. Source operands in memory can be in single precision\n   or double precision floating-point format, word or doubleword integer\n   format.\n\n   These instructions perform the reverse operations of the FDIV, FDIVP, and\n   FIDIV instructions. They are provided to support more efficient coding.\n\n   The no-operand version of the instruction divides the contents of the\n   ST(0) register by the contents of the ST(1) register. The one-operand\n   version divides the contents of a memory location (either a floating-point\n   or an integer value) by the contents of the ST(0) register. The\n   two-operand version, divides the contents of the ST(i) register by the\n   contents of the ST(0) register or vice versa.\n\n   The FDIVRP instructions perform the additional operation of popping the\n   FPU register stack after storing the result. To pop the register stack,\n   the processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1. The no-operand version of the floating-point divide\n   instructions always results in the register stack being popped. In some\n   assemblers, the mnemonic for this instruction is FDIVR rather than FDIVRP.\n\n   The FIDIVR instructions convert an integer source operand to double\n   extended-precision floating-point format before performing the division.\n\n   If an unmasked divide-by-zero exception (#Z) is generated, no result is\n   stored; if the exception is masked, an \u221e of the appropriate sign is stored\n   in the destination operand.\n\n   The following table shows the results obtained when dividing various\n   classes of numbers, assuming that neither overflow nor underflow occurs.\n\n   DEST\n           \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n       \u2212\u221e  *   +\u221e  +\u221e  \u2212\u221e  \u2212\u221e  *   NaN \n       \u2212F  +0  +F  **  **  \u2212F  \u22120  NaN \n       \u2212I  +0  +F  **  **  \u2212F  \u22120  NaN \n   SRC \u22120  +0  +0  *   *   \u22120  \u22120  NaN \n       +0  \u22120  \u22120  *   *   +0  +0  NaN \n       +I  \u22120  \u2212F  **  **  +F  +0  NaN \n       +F  \u22120  \u2212F  **  **  +F  +0  NaN \n       +\u221e  *   \u2212\u221e  \u2212\u221e  +\u221e  +\u221e  *   NaN \n       NaN NaN NaN NaN NaN NaN NaN NaN \n\n   Table 3-25. FDIVR/FDIVRP/FIDIVR Results\n\n     F Means finite floating-point value.\n\n     I Means integer.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n     ** Indicates floating-point zero-divide (#Z) exception.\n\n   When the source operand is an integer 0, it is treated as a +0. This\n   instruction\u2019s operation is the same in non-64-bit modes and 64-bit mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["prefetchw", "        PREFETCHW \u2014 Prefetch Data Into Caches in Anticipation of a Write\n\n   Opcode/Instruction    Op/En 64/32 bit    CPUID Feature Description         \n                               Mode Support Flag          \n                                                          Move data from m8   \n                                                          closer to the       \n   0F 0D /1 PREFETCHW m8 M     V/V          PREFETCHW     processor in        \n                                                          anticipation of a   \n                                                          write.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Fetches the cache line of data from memory that contains the byte\n   specified with the source operand to a location in the 1st or 2nd level\n   cache and invalidates other cached instances of the line.\n\n   The source operand is a byte memory location. If the line selected is\n   already present in the lowest level cache and is already in an exclusively\n   owned state, no data movement occurs. Prefetches from non-writeback memory\n   are ignored.\n\n   The PREFETCHW instruction is merely a hint and does not affect program\n   behavior. If executed, this instruction moves data closer to the processor\n   and invalidates other cached copies in anticipation of the line being\n   written to in the future.\n\n   The characteristic of prefetch locality hints is implementation-dependent,\n   and can be overloaded or ignored by a processor implementation. The amount\n   of data prefetched is also processor implementation-dependent. It will,\n   however, be a minimum of 32 bytes. Additional details of the\n   implementation-dependent locality hints are described in Section 7.4 of\n   Intel\u00ae 64 and IA-32 Architectures Optimization Reference Manual.\n\n   It should be noted that processors are free to speculatively fetch and\n   cache data with exclusive ownership from system memory regions that permit\n   such accesses (that is, the WB memory type). A PREFETCHW instruction is\n   considered a hint to this speculative behavior. Because this speculative\n   fetching can occur at any time and is not tied to instruction execution, a\n   PREFETCHW instruction is not ordered with respect to the fence\n   instructions (MFENCE, SFENCE, and LFENCE) or locked memory references. A\n   PREFETCHW instruction is also unordered with respect to CLFLUSH and\n   CLFLUSHOPT instructions, other PREFETCHW instructions, or any other\n   general instruction\n\n   It is ordered with respect to serializing instructions such as CPUID,\n   WRMSR, OUT, and MOV CR.\n\n   This instruction's operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["enter", "               ENTER \u2014 Make Stack Frame for Procedure Parameters\n\n   Opcode   Instruction    Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   C8 iw 00 ENTER imm16, 0 II    Valid  Valid      Create a stack frame for a \n                                                   procedure.                 \n                                                   Create a stack frame with  \n   C8 iw 01 ENTER imm16,1  II    Valid  Valid      a nested pointer for a     \n                                                   procedure.                 \n            ENTER imm16,                           Create a stack frame with  \n   C8 iw ib imm8           II    Valid  Valid      nested pointers for a      \n                                                   procedure.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   II    iw        imm8      N/A       N/A       \n\nDescription \u00b6\n\n   Creates a stack frame (comprising of space for dynamic storage and 1-32\n   frame pointer storage) for a procedure. The first operand (imm16)\n   specifies the size of the dynamic storage in the stack frame (that is, the\n   number of bytes of dynamically allocated on the stack for the procedure).\n   The second operand (imm8) gives the lexical nesting level (0 to 31) of the\n   procedure. The nesting level (imm8 mod 32) and the OperandSize attribute\n   determine the size in bytes of the storage space for frame pointers.\n\n   The nesting level determines the number of frame pointers that are copied\n   into the \u201cdisplay area\u201d of the new stack frame from the preceding frame.\n   The default size of the frame pointer is the StackAddrSize attribute, but\n   can be overridden using the 66H prefix. Thus, the OperandSize attribute\n   determines the size of each frame pointer that will be copied into the\n   stack frame and the data being transferred from SP/ESP/RSP register into\n   the BP/EBP/RBP register.\n\n   The ENTER and companion LEAVE instructions are provided to support block\n   structured languages. The ENTER instruction (when used) is typically the\n   first instruction in a procedure and is used to set up a new stack frame\n   for a procedure. The LEAVE instruction is then used at the end of the\n   procedure (just before the RET instruction) to release the stack frame.\n\n   If the nesting level is 0, the processor pushes the frame pointer from the\n   BP/EBP/RBP register onto the stack, copies the current stack pointer from\n   the SP/ESP/RSP register into the BP/EBP/RBP register, and loads the\n   SP/ESP/RSP register with the current stack-pointer value minus the value\n   in the size operand. For nesting levels of 1 or greater, the processor\n   pushes additional frame pointers on the stack before adjusting the stack\n   pointer. These additional frame pointers provide the called procedure with\n   access points to other nested frames on the stack. See \u201cProcedure Calls\n   for Block-Structured Languages\u201d in Chapter 6 of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for more information\n   about the actions of the ENTER instruction.\n\n   The ENTER instruction causes a page fault whenever a write using the final\n   value of the stack pointer (within the current stack segment) would do so.\n\n   In 64-bit mode, default operation size is 64 bits; 32-bit operation size\n   cannot be encoded. Use of 66H prefix changes frame pointer operand size to\n   16 bits.\n\n   When the 66H prefix is used and causing the OperandSize attribute to be\n   less than the StackAddrSize, software is responsible for the following:\n\n     * The companion LEAVE instruction must also use the 66H prefix,\n     * The value in the RBP/EBP register prior to executing \u201c66H ENTER\u201d must\n       be within the same 16KByte region of the current stack pointer\n       (RSP/ESP), such that the value of RBP/EBP after \u201c66H ENTER\u201d remains a\n       valid address in the stack. This ensures \u201c66H LEAVE\u201d can restore\n       16-bits of data from the stack.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fsubr:fsubrp:fisubr", "                     FSUBR/FSUBRP/FISUBR \u2014 Reverse Subtract\n\n   Opcode  Instruction   64-Bit Compat/Leg Mode Description                   \n                         Mode   \n   D8 /5   FSUBR m32fp   Valid  Valid           Subtract ST(0) from m32fp and \n                                                store result in ST(0).        \n   DC /5   FSUBR m64fp   Valid  Valid           Subtract ST(0) from m64fp and \n                                                store result in ST(0).        \n   D8 E8+i FSUBR ST(0),  Valid  Valid           Subtract ST(0) from ST(i) and \n           ST(i)                                store result in ST(0).        \n   DC E0+i FSUBR ST(i),  Valid  Valid           Subtract ST(i) from ST(0) and \n           ST(0)                                store result in ST(i).        \n           FSUBRP ST(i),                        Subtract ST(i) from ST(0),    \n   DE E0+i ST(0)         Valid  Valid           store result in ST(i), and    \n                                                pop register stack.           \n                                                Subtract ST(1) from ST(0),    \n   DE E1   FSUBRP        Valid  Valid           store result in ST(1), and    \n                                                pop register stack.           \n   DA /5   FISUBR m32int Valid  Valid           Subtract ST(0) from m32int    \n                                                and store result in ST(0).    \n   DE /5   FISUBR m16int Valid  Valid           Subtract ST(0) from m16int    \n                                                and store result in ST(0).    \n\nDescription \u00b6\n\n   Subtracts the destination operand from the source operand and stores the\n   difference in the destination location. The destination operand is always\n   an FPU register; the source operand can be a register or a memory\n   location. Source operands in memory can be in single precision or double\n   precision floating-point format or in word or doubleword integer format.\n\n   These instructions perform the reverse operations of the FSUB, FSUBP, and\n   FISUB instructions. They are provided to support more efficient coding.\n\n   The no-operand version of the instruction subtracts the contents of the\n   ST(1) register from the ST(0) register and stores the result in ST(1). The\n   one-operand version subtracts the contents of the ST(0) register from the\n   contents of a memory location (either a floating-point or an integer\n   value) and stores the result in ST(0). The two-operand version, subtracts\n   the contents of the ST(i) register from the ST(0) register or vice versa.\n\n   The FSUBRP instructions perform the additional operation of popping the\n   FPU register stack following the subtraction. To pop the register stack,\n   the processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1. The no-operand version of the floating-point reverse\n   subtract instructions always results in the register stack being popped.\n   In some assemblers, the mnemonic for this instruction is FSUBR rather than\n   FSUBRP.\n\n   The FISUBR instructions convert an integer source operand to double\n   extended-precision floating-point format before performing the\n   subtraction.\n\n   The following table shows the results obtained when subtracting various\n   classes of numbers from one another, assuming that neither overflow nor\n   underflow occurs. Here, the DEST value is subtracted from the SRC value\n   (SRC \u2212 DEST = result).\n\n   When the difference between two operands of like sign is 0, the result is\n   +0, except for the round toward \u2212\u221e mode, in which case the result is \u22120.\n   This instruction also guarantees that +0 \u2212 (\u22120) = +0, and that \u22120 \u2212 (+0) =\n   \u22120. When the source operand is an integer 0, it is treated as a +0.\n\n   When one operand is \u221e, the result is \u221e of the expected sign. If both\n   operands are \u221e of the same sign, an invalidoperation exception is\n   generated.\n\n   SRC  \n            \u2212\u221e  \u2212F or \u2212I \u22120    +0    +F or +I +\u221e  NaN \n        \u2212\u221e  *   +\u221e       +\u221e    +\u221e    +\u221e       +\u221e  NaN \n        \u2212F  \u2212\u221e  \u00b1F or \u00b10 \u2212DEST \u2212DEST +F       +\u221e  NaN \n   DEST \u22120  \u2212\u221e  SRC      \u00b10    +0    SRC      +\u221e  NaN \n        +0  \u2212\u221e  SRC      \u22120    \u00b10    SRC      +\u221e  NaN \n        +F  \u2212\u221e  \u2212F       \u2212DEST \u2212DEST \u00b1F or \u00b10 +\u221e  NaN \n        +\u221e  \u2212\u221e  \u2212\u221e       \u2212\u221e    \u2212\u221e    \u2212\u221e       *   NaN \n        NaN NaN NaN      NaN   NaN   NaN      NaN NaN \n\n   Table 3-39. FSUBR/FSUBRP/FISUBR Results\n\n     F Meansfinitefloating-pointvalue.\n\n     I Means integer.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["vcvttph2dq", "  VCVTTPH2DQ \u2014 Convert with Truncation Packed FP16 Values to Signed Doubleword\n                                    Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert four packed   \n                                                        FP16 values in        \n                                                        xmm2/m64/m16bcst to   \n   EVEX.128.F3.MAP5.W0 5B /r                AVX512-FP16 four signed           \n   VCVTTPH2DQ xmm1{k1}{z},        A V/V     AVX512VL    doubleword integers,  \n   xmm2/m64/m16bcst                                     and store the result  \n                                                        in xmm1 using         \n                                                        truncation subject to \n                                                        writemask k1.         \n                                                        Convert eight packed  \n                                                        FP16 values in        \n                                                        xmm2/m128/m16bcst to  \n   EVEX.256.F3.MAP5.W0 5B /r                AVX512-FP16 eight signed          \n   VCVTTPH2DQ ymm1{k1}{z},        A V/V     AVX512VL    doubleword integers,  \n   xmm2/m128/m16bcst                                    and store the result  \n                                                        in ymm1 using         \n                                                        truncation subject to \n                                                        writemask k1.         \n                                                        Convert sixteen       \n                                                        packed FP16 values in \n                                                        ymm2/m256/m16bcst to  \n   EVEX.512.F3.MAP5.W0 5B /r                            sixteen signed        \n   VCVTTPH2DQ zmm1{k1}{z},        A V/V     AVX512-FP16 doubleword integers,  \n   ymm2/m256/m16bcst {sae}                              and store the result  \n                                                        in zmm1 using         \n                                                        truncation subject to \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   signed doubleword integers in destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result is larger than the maximum signed\n   doubleword integer, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["vfcmulcph:vfmulcph", "               VFCMULCPH/VFMULCPH \u2014 Complex Multiply FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.128.F2.MAP6.W0 D6 /r                           from xmm2 and complex  \n   VFCMULCPH xmm1{k1}{z}, xmm2,  A V/V     AVX512-FP16 conjugate of           \n   xmm3/m128/m32bcst                       AVX512VL    xmm3/m128/m32bcst, and \n                                                       store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.256.F2.MAP6.W0 D6 /r                           from ymm2 and complex  \n   VFCMULCPH ymm1{k1}{z}, ymm2,  A V/V     AVX512-FP16 conjugate of           \n   ymm3/m256/m32bcst                       AVX512VL    ymm3/m256/m32bcst, and \n                                                       store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.512.F2.MAP6.W0 D6 /r                           from zmm2 and complex  \n   VFCMULCPH zmm1{k1}{z}, zmm2,  A V/V     AVX512-FP16 conjugate of           \n   zmm3/m512/m32bcst {er}                              zmm3/m512/m32bcst, and \n                                                       store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.128.F3.MAP6.W0 D6 /r               AVX512-FP16 from xmm2 and          \n   VFMULCPH xmm1{k1}{z}, xmm2,   A V/V     AVX512VL    xmm3/m128/m32bcst, and \n   xmm3/m128/m32bcst                                   store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.256.F3.MAP6.W0 D6 /r               AVX512-FP16 from ymm2 and          \n   VFMULCPH ymm1{k1}{z}, ymm2,   A V/V     AVX512VL    ymm3/m256/m32bcst, and \n   ymm3/m256/m32bcst                                   store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.512.F3.MAP6.W0 D6 /r                           from zmm2 and          \n   VFMULCPH zmm1{k1}{z}, zmm2,   A V/V     AVX512-FP16 zmm3/m512/m32bcst, and \n   zmm3/m512/m32bcst {er}                              store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a complex multiply operation. There are normal\n   and complex conjugate forms of the operation. The broadcasting and masking\n   for this operation is done on 32-bit quantities representing a pair of\n   FP16 values.\n\n   Rounding is performed at every FMA (fused multiply and add) boundary.\n   Execution occurs as if all MXCSR exceptions are masked. MXCSR status bits\n   are updated to reflect exceptional conditions.\n"],
	["vfmaddsub132ph:vfmaddsub213ph:vfmaddsub231ph", "              VFMADDSUB132PH/VFMADDSUB213PH/VFMADDSUB231PH \u2014 Fused\n             Multiply-AlternatingAdd/Subtract of Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 96 /r               AVX512-FP16 xmm3/m128/m16bcst,     \n   VFMADDSUB132PH xmm1{k1}{z},   A V/V     AVX512VL    add/subtract elements  \n   xmm2, xmm3/m128/m16bcst                             in xmm2, and store the \n                                                       result in xmm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 96 /r               AVX512-FP16 ymm3/m256/m16bcst,     \n   VFMADDSUB132PH ymm1{k1}{z},   A V/V     AVX512VL    add/subtract elements  \n   ymm2, ymm3/m256/m16bcst                             in ymm2, and store the \n                                                       result in ymm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 96 /r                           zmm3/m512/m16bcst,     \n   VFMADDSUB132PH zmm1{k1}{z},   A V/V     AVX512-FP16 add/subtract elements  \n   zmm2, zmm3/m512/m16bcst {er}                        in zmm2, and store the \n                                                       result in zmm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 A6 /r                           xmm2, add/subtract     \n   VFMADDSUB213PH xmm1{k1}{z},   A V/V     AVX512-FP16 elements in            \n   xmm2, xmm3/m128/m16bcst                 AVX512VL    xmm3/m128/m16bcst, and \n                                                       store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 A6 /r                           ymm2, add/subtract     \n   VFMADDSUB213PH ymm1{k1}{z},   A V/V     AVX512-FP16 elements in            \n   ymm2, ymm3/m256/m16bcst                 AVX512VL    ymm3/m256/m16bcst, and \n                                                       store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 A6 /r                           zmm2, add/subtract     \n   VFMADDSUB213PH zmm1{k1}{z},   A V/V     AVX512-FP16 elements in            \n   zmm2, zmm3/m512/m16bcst {er}                        zmm3/m512/m16bcst, and \n                                                       store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from xmm2 and   \n   EVEX.128.66.MAP6.W0 B6 /r               AVX512-FP16 xmm3/m128/m16bcst,     \n   VFMADDSUB231PH xmm1{k1}{z},   A V/V     AVX512VL    add/subtract elements  \n   xmm2, xmm3/m128/m16bcst                             in xmm1, and store the \n                                                       result in xmm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from ymm2 and   \n   EVEX.256.66.MAP6.W0 B6 /r               AVX512-FP16 ymm3/m256/m16bcst,     \n   VFMADDSUB231PH ymm1{k1}{z},   A V/V     AVX512VL    add/subtract elements  \n   ymm2, ymm3/m256/m16bcst                             in ymm1, and store the \n                                                       result in ymm1 subject \n                                                       to writemask k1.       \n                                                       Multiply packed FP16   \n                                                       values from zmm2 and   \n   EVEX.512.66.MAP6.W0 B6 /r                           zmm3/m512/m16bcst,     \n   VFMADDSUB231PH zmm1{k1}{z},   A V/V     AVX512-FP16 add/subtract elements  \n   zmm2, zmm3/m512/m16bcst {er}                        in zmm1, and store the \n                                                       result in zmm1 subject \n                                                       to writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a packed multiply-add (odd elements) or\n   multiply-subtract (even elements) computation on FP16 values using three\n   source operands and writes the results in the destination operand. The\n   destination operand is also the first source operand. The notation\u2019 \u201c132\u201d,\n   \u201c213\u201d and \u201c231\u201d indicate the use of the operands in A * B \u00b1 C, where each\n   digit corresponds to the operand number, with the destination being\n   operand 1; see Table 5-8.\n\n   The destination elements are updated according to the writemask.\n\n   Notation Odd Elements          Even Elements         \n   132      dest = dest*src3+src2 dest = dest*src3-src2 \n   231      dest = src2*src3+dest dest = src2*src3-dest \n   213      dest = src2*dest+src3 dest = src2*dest-src3 \n\n   Table 5-5. VFMADDSUB[132,213,231]PH Notation for Odd and Even Elements\n"],
	["vrangepd", "  VRANGEPD \u2014 Range Restriction Calculation for Packed Pairs of Float64 Values\n\n                                   64/32    CPUID                             \n   Opcode/Instruction        Op/En bit Mode Feature  Description\n                                   Support  Flag     \n                                                     Calculate two RANGE      \n                                                     operation output value   \n                                                     from 2 pairs of double   \n   EVEX.128.66.0F3A.W1 50 /r                         precision floating-point \n   ib VRANGEPD xmm1 {k1}{z},                AVX512VL values in xmm2 and       \n   xmm2, xmm3/m128/m64bcst,  A     V/V      AVX512DQ xmm3/m128/m32bcst, store \n   imm8                                              the results to xmm1      \n                                                     under the writemask k1.  \n                                                     Imm8 specifies the       \n                                                     comparison and sign of   \n                                                     the range operation.     \n                                                     Calculate four RANGE     \n                                                     operation output value   \n                                                     from 4pairs of double    \n   EVEX.256.66.0F3A.W1 50 /r                         precision floating-point \n   ib VRANGEPD ymm1 {k1}{z},                AVX512VL values in ymm2 and       \n   ymm2, ymm3/m256/m64bcst,  A     V/V      AVX512DQ ymm3/m256/m32bcst, store \n   imm8                                              the results to ymm1      \n                                                     under the writemask k1.  \n                                                     Imm8 specifies the       \n                                                     comparison and sign of   \n                                                     the range operation.     \n                                                     Calculate eight RANGE    \n                                                     operation output value   \n                                                     from 8 pairs of double   \n   EVEX.512.66.0F3A.W1 50 /r                         precision floating-point \n   ib VRANGEPD zmm1 {k1}{z},                         values in zmm2 and       \n   zmm2,                     A     V/V      AVX512DQ zmm3/m512/m32bcst, store \n   zmm3/m512/m64bcst{sae},                           the results to zmm1      \n   imm8                                              under the writemask k1.  \n                                                     Imm8 specifies the       \n                                                     comparison and sign of   \n                                                     the range operation.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   This instruction calculates 2/4/8 range operation outputs from two sets of\n   packed input double precision floating-point values in the first source\n   operand (the second operand) and the second source operand (the third\n   operand). The range outputs are written to the destination operand (the\n   first operand) under the writemask k1.\n\n   Bits7:4 of imm8 byte must be zero. The range operation output is performed\n   in two parts, each configured by a two-bit control field within imm8[3:0]:\n\n     * Imm8[1:0] specifies the initial comparison operation to be one of max,\n       min, max absolute value or min absolute value of the input value pair.\n       Each comparison of two input values produces an intermediate result\n       that combines with the sign selection control (imm8[3:2]) to determine\n       the final range operation output.\n     * Imm8[3:2] specifies the sign of the range operation output to be one\n       of the following: from the first input value, from the comparison\n       result, set or clear.\n\n   The encodings of imm8[1:0] and imm8[3:2] are shown in Figure 5-27.\n\n   0 imm8 Must Be Zero Sign Control (SC) Compare Operation Select Imm8[1:0] =\n   00b : Select Min value Imm8[3:2] = 00b : Select sign(SRC1) Imm8[1:0] = 01b\n   : Select Max value Imm8[3:2] = 01b : Select sign(Compare_Result) Imm8[1:0]\n   = 10b : Select Min-Abs value Imm8[3:2] = 10b : Set sign to 0 Imm8[1:0] =\n   11b : Select Max-Abs value Imm8[3:2] = 11b : Set sign to 1 Figure 5-27.\n   Imm8 Controls for VRANGEPD/SD/PS/SS\n\n   When one or more of the input value is a NAN, the comparison operation may\n   signal invalid exception (IE). Details with one of more input value is NAN\n   is listed in Table 5-23. If the comparison raises an IE, the sign select\n   control (imm8[3:2]) has no effect to the range operation output; this is\n   indicated also in Table 5-23.\n\n   When both input values are zeros of opposite signs, the comparison\n   operation of MIN/MAX in the range compare operation is slightly different\n   from the conceptually similar floating-point MIN/MAX operation that are\n   found in the instructions VMAXPD/VMINPD. The details of\n   MIN/MAX/MIN_ABS/MAX_ABS operation for VRANGEPD/PS/SD/SS for magnitude-0,\n   opposite-signed input cases are listed in Table 5-24.\n\n   Additionally, non-zero, equal-magnitude with opposite-sign input values\n   perform MIN_ABS or MAX_ABS comparison operation with result listed in\n   Table 5-25.\n\n   Src1  Src2  Result       IE Signaling Due to Imm8[3:2] Effect to Range     \n                            Comparison          Output                        \n   sNaN1 sNaN2 Quiet(sNaN1) Yes                 Ignored                       \n   sNaN1 qNaN2 Quiet(sNaN1) Yes                 Ignored                       \n   sNaN1 Norm2 Quiet(sNaN1) Yes                 Ignored                       \n   qNaN1 sNaN2 Quiet(sNaN2) Yes                 Ignored                       \n   qNaN1 qNaN2 qNaN1        No                  Applicable                    \n   qNaN1 Norm2 Norm2        No                  Applicable                    \n   Norm1 sNaN2 Quiet(sNaN2) Yes                 Ignored                       \n   Norm1 qNaN2 Norm1        No                  Applicable                    \n\n   Table 5-23. Signaling of Comparison Operation of One or More NaN Input\n   Values and Effect of Imm8[3:2]\n\n   MIN and MIN_ABS  MAX and MAX_ABS\n   Src1 Src2 Result Src1 Src2 Result \n   +0   -0   -0     +0   -0   +0     \n   -0   +0   -0     -0   +0   +0     \n\n   Table 5-24. Comparison Result for Opposite-Signed Zero Cases for MIN,\n   MIN_ABS, and MAX, MAX_ABS\n\n   MIN_ABS (|a| = |b|, a>0, b<0) MAX_ABS (|a| = |b|, a>0, b<0)\n   Src1      Src2     Result     Src1      Src2     Result     \n   a         b        b          a         b        a          \n   b         a        b          b         a        a          \n\n   Table 5-25. Comparison Result of Equal-Magnitude Input Cases for MIN_ABS\n   and MAX_ABS, (|a| = |b|, a>0, b<0)\n"],
	["pcmpestri", "        PCMPESTRI \u2014 Packed Compare Explicit Length Strings, Return Index\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Perform a packed          \n   66 0F 3A 61 /r imm8                              comparison of string data \n   PCMPESTRI xmm1,          RMI   V/V       SSE4_2  with explicit lengths,    \n   xmm2/m128, imm8                                  generating an index, and  \n                                                    storing the result in     \n                                                    ECX.                      \n                                                    Perform a packed          \n   VEX.128.66.0F3A 61 /r ib                         comparison of string data \n   VPCMPESTRI xmm1,         RMI   V/V       AVX     with explicit lengths,    \n   xmm2/m128, imm8                                  generating an index, and  \n                                                    storing the result in     \n                                                    ECX.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RMI   ModRM:reg (r) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   The instruction compares and processes data from two string fragments\n   based on the encoded value in the imm8 control byte (see Section 4.1,\n   \u201cImm8 Control Byte Operation for PCMPESTRI / PCMPESTRM / PCMPISTRI /\n   PCMPISTRM\u201d), and generates an index stored to the count register (ECX).\n\n   Each string fragment is represented by two values. The first value is an\n   xmm (or possibly m128 for the second operand) which contains the data\n   elements of the string (byte or word data). The second value is stored in\n   an input length register. The input length register is EAX/RAX (for xmm1)\n   or EDX/RDX (for xmm2/m128). The length represents the number of\n   bytes/words which are valid for the respective xmm/m128 data.\n\n   The length of each input is interpreted as being the absolute-value of the\n   value in the length register. The absolute-value computation saturates to\n   16 (for bytes) and 8 (for words), based on the value of imm8[bit3] when\n   the value in the length register is greater than 16 (8) or less than -16\n   (-8).\n\n   The comparison and aggregation operations are performed according to the\n   encoded value of imm8 bit fields (see Section 4.1). The index of the first\n   (or last, according to imm8[6]) set bit of IntRes2 (see Section 4.1.4) is\n   returned in ECX. If no bits are set in IntRes2, ECX is set to 16 (8).\n\n   Note that the Arithmetic Flags are written in a non-standard manner in\n   order to supply the most relevant information:\n\n   CFlag \u2013 Reset if IntRes2 is equal to zero, set otherwise\n\n   ZFlag \u2013 Set if absolute-value of EDX is < 16 (8), reset otherwise\n\n   SFlag \u2013 Set if absolute-value of EAX is < 16 (8), reset otherwise\n\n   OFlag \u2013 IntRes2[0]\n\n   AFlag \u2013 Reset\n\n   PFlag \u2013 Reset\n\nEffective Operand Size \u00b6\n\n   Operating mode/size Operand 1 Operand 2 Length 1 Length 2 Result \n   16 bit              xmm       xmm/m128  EAX      EDX      ECX    \n   32 bit              xmm       xmm/m128  EAX      EDX      ECX    \n   64 bit              xmm       xmm/m128  EAX      EDX      ECX    \n   64 bit + REX.W      xmm       xmm/m128  RAX      RDX      ECX    \n"],
	["pextrw", "                             PEXTRW \u2014 Extract Word\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Extract the word        \n                                                      specified by imm8 from  \n   NP 0F C5 /r ib^1 PEXTRW   A     V/V       SSE      mm and move it to reg,  \n   reg, mm, imm8                                      bits 15-0. The upper    \n                                                      bits of r32 or r64 is   \n                                                      zeroed.                 \n                                                      Extract the word        \n                                                      specified by imm8 from  \n   66 0F C5 /r ib PEXTRW     A     V/V       SSE2     xmm and move it to reg, \n   reg, xmm, imm8                                     bits 15-0. The upper    \n                                                      bits of r32 or r64 is   \n                                                      zeroed.                 \n                                                      Extract the word        \n                                                      specified by imm8 from  \n                                                      xmm and copy it to      \n   66 0F 3A 15 /r ib PEXTRW  B     V/V       SSE4_1   lowest 16 bits of reg   \n   reg/m16, xmm, imm8                                 or m16. Zero-extend the \n                                                      result in the           \n                                                      destination, r32 or     \n                                                      r64.                    \n                                                      Extract the word        \n                                                      specified by imm8 from  \n                                                      xmm1 and move it to     \n   VEX.128.66.0F.W0 C5 /r ib A     V^2/V     AVX      reg, bits 15:0.         \n   VPEXTRW reg, xmm1, imm8                            Zero-extend the result. \n                                                      The upper bits of       \n                                                      r64/r32 is filled with  \n                                                      zeros.                  \n                                                      Extract a word integer  \n                                                      value from xmm2 at the  \n   VEX.128.66.0F3A.W0 15 /r                           source word offset      \n   ib VPEXTRW reg/m16, xmm2, B     V/V       AVX      specified by imm8 into  \n   imm8                                               reg or m16. The upper   \n                                                      bits of r64/r32 is      \n                                                      filled with zeros.      \n                                                      Extract the word        \n                                                      specified by imm8 from  \n   EVEX.128.66.0F.WIG C5 /r                           xmm1 and move it to     \n   ib VPEXTRW reg, xmm1,     A     V/V       AVX512BW reg, bits 15:0.         \n   imm8                                               Zero-extend the result. \n                                                      The upper bits of       \n                                                      r64/r32 is filled with  \n                                                      zeros.                  \n                                                      Extract a word integer  \n                                                      value from xmm2 at the  \n   EVEX.128.66.0F3A.WIG 15                            source word offset      \n   /r ib VPEXTRW reg/m16,    C     V/V       AVX512BW specified by imm8 into  \n   xmm2, imm8                                         reg or m16. The upper   \n                                                      bits of r64/r32 is      \n                                                      filled with zeros.      \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\n     2. In 64-bit mode, VEX.W1 is ignored for VPEXTRW (similar to legacy\n     REX.W=1 prefix in PEXTRW).\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n   B     N/A           ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   C     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n\nDescription \u00b6\n\n   Copies the word in the source operand (second operand) specified by the\n   count operand (third operand) to the destination operand (first operand).\n   The source operand can be an MMX technology register or an XMM register.\n   The destination operand can be the low word of a general-purpose register\n   or a 16-bit memory address. The count operand is an 8-bit immediate. When\n   specifying a word location in an MMX technology register, the 2\n   least-significant bits of the count operand specify the location; for an\n   XMM register, the 3 least-significant bits specify the location. The\n   content of the destination register above bit 16 is cleared (set to all\n   0s).\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15, R8-15). If the\n   destination operand is a general-purpose register, the default operand\n   size is 64-bits in 64-bit mode.\n\n   Note: In VEX.128 encoded versions, VEX.vvvv is reserved and must be 1111b,\n   VEX.L must be 0, otherwise the instruction will #UD. In EVEX.128 encoded\n   versions, EVEX.vvvv is reserved and must be 1111b, EVEX.L must be 0,\n   otherwise the instruction will #UD. If the destination operand is a\n   register, the default operand size in 64-bit mode for VPEXTRW is 64 bits,\n   the bits above the least significant byte/word/dword data are filled with\n   zeros.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vgetmantph", "   VGETMANTPH \u2014 Extract FP16 Vector of Normalized Mantissas from FP16 Vector\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Get normalized         \n                                                       mantissa from FP16     \n                                                       vector                 \n   EVEX.128.NP.0F3A.W0 26 /r /ib                       xmm2/m128/m16bcst and  \n   VGETMANTPH xmm1{k1}{z},       A V/V     AVX512-FP16 store the result in    \n   xmm2/m128/m16bcst, imm8                 AVX512VL    xmm1, using imm8 for   \n                                                       sign control and       \n                                                       mantissa interval      \n                                                       normalization, subject \n                                                       to writemask k1.       \n                                                       Get normalized         \n                                                       mantissa from FP16     \n                                                       vector                 \n   EVEX.256.NP.0F3A.W0 26 /r /ib                       ymm2/m256/m16bcst and  \n   VGETMANTPH ymm1{k1}{z},       A V/V     AVX512-FP16 store the result in    \n   ymm2/m256/m16bcst, imm8                 AVX512VL    ymm1, using imm8 for   \n                                                       sign control and       \n                                                       mantissa interval      \n                                                       normalization, subject \n                                                       to writemask k1.       \n                                                       Get normalized         \n                                                       mantissa from FP16     \n                                                       vector                 \n   EVEX.512.NP.0F3A.W0 26 /r /ib                       zmm2/m512/m16bcst and  \n   VGETMANTPH zmm1{k1}{z},       A V/V     AVX512-FP16 store the result in    \n   zmm2/m512/m16bcst {sae}, imm8                       zmm1, using imm8 for   \n                                                       sign control and       \n                                                       mantissa interval      \n                                                       normalization, subject \n                                                       to writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) imm8 (r)  N/A       \n\n  Description \u00b6\n\n   This instruction converts the FP16 values in the source operand (the\n   second operand) to FP16 values with the mantissa normalization and sign\n   control specified by the imm8 byte, see Table 5-19. The converted results\n   are written to the destination operand (the first operand) using writemask\n   k1. The normalized mantissa is specified by interv (imm8[1:0]) and the\n   sign control (SC) is specified by bits 3:2 of the immediate byte.\n\n   The destination elements are updated according to the writemask.\n\n   imm8 Bits Definition                                                       \n   imm8[7:4] Must be zero.                                                    \n   imm8[3:2] Sign Control (SC) 0b00: Sign(SRC) 0b01: 0 0b1x: QNaN_Indefinite  \n             if sign(SRC)!=0                                                  \n   imm8[1:0] Interv 0b00: Interval is [1, 2) 0b01: Interval is [1/2, 2) 0b10: \n             Interval is [1/2, 1) 0b11: Interval is [3/4, 3/2)                \n\n   Table 5-19. imm8 Controls for VGETMANTPH/VGETMANTSH\n\n   For each input FP16 value x, The conversion operation is:\n\n   GetMant(x) = \u00b12^k|x.significand|\n\n   where:\n\n   1 \u2264 |x.significand| < 2\n\n   Unbiased exponent k depends on the interval range defined by interv and\n   whether the exponent of the source is even or odd. The sign of the final\n   result is determined by the sign control and the source sign and the\n   leading fraction bit.\n\n   The encoded value of imm8[1:0] and sign control are shown in Table 5-19.\n\n   Each converted FP16 result is encoded according to the sign control, the\n   unbiased exponent k (adding bias) and a mantissa normalized to the range\n   specified by interv.\n\n   The GetMant() function follows Table 5-20 when dealing with floating-point\n   special numbers.\n\n   Input    Result                                   Exceptions / Comments    \n   NaN      QNaN(SRC)                                Ignore interv. If (SRC = \n                                                     SNaN), then #IE.         \n   +\u221e       1.0                                      Ignore interv.           \n   +0       1.0                                      Ignore interv.           \n   -0       IF (SC[0]) THEN +1.0 ELSE -1.0           Ignore interv.           \n   -\u221e       IF (SC[1]) THEN {QNaN_Indefinite} ELSE { Ignore interv. If        \n            IF (SC[0]) THEN +1.0 ELSE -1.0           (SC[1]), then #IE.       \n   negative SC[1] ? QNaN_Indefinite : Getmant(SRC)^1 If (SC[1]), then #IE.    \n\n   Table 5-20. GetMant() Special Float Values Behavior\n\n     1. In case SC[1]==0, the sign of Getmant(SRC) is declared according to\n     SC[0].\n"],
	["aesenc256kl", "  AESENC256KL \u2014 Perform 14 Rounds of AES Encryption Flow With Key Locker Using\n                                  256-Bit Key\n\n                               64/32-bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                                         Flag    \n   F3 0F 38 DE                                   Encrypt xmm using 256-bit    \n   !(11):rrr:bbb         A     V/V       AESKLE  AES key indicated by handle  \n   AESENC256KL xmm, m512                         at m512 and store result in  \n                                                 xmm.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   The AESENC256KL^1 instruction performs 14 rounds of AES to encrypt the\n   first operand using the 256-bit key indicated by the handle from the\n   second operand. It stores the result in the first operand if the operation\n   succeeds (e.g., does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n"],
	["vcvtpd2udq", "  VCVTPD2UDQ \u2014 Convert Packed Double Precision Floating-Point Values to Packed\n                          UnsignedDoubleword Integers\n\n                                  64/32 Bit CPUID                             \n   Opcode Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     double precision         \n   EVEX.128.0F.W1 79 /r                     AVX512VL floating-point values in \n   VCVTPD2UDQ xmm1 {k1}{z}, A     V/V       AVX512F  xmm2/m128/m64bcst to two \n   xmm2/m128/m64bcst                                 unsigned doubleword      \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Convert four packed      \n                                                     double precision         \n   EVEX.256.0F.W1 79 /r                     AVX512VL floating-point values in \n   VCVTPD2UDQ xmm1 {k1}{z}, A     V/V       AVX512F  ymm2/m256/m64bcst to     \n   ymm2/m256/m64bcst                                 four unsigned doubleword \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Convert eight packed     \n                                                     double precision         \n   EVEX.512.0F.W1 79 /r                              floating-point values in \n   VCVTPD2UDQ ymm1 {k1}{z}, A     V/V       AVX512F  zmm2/m512/m64bcst to     \n   zmm2/m512/m64bcst{er}                             eight unsigned           \n                                                     doubleword integers in   \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed double precision floating-point values in the source\n   operand (the second operand) to packed unsigned doubleword integers in the\n   destination operand (the first operand).\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   The source operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location, or a 512/256/128-bit vector broadcasted from a 64-bit memory\n   location. The destination operand is a ZMM/YMM/XMM register conditionally\n   updated with writemask k1. The upper bits (MAXVL-1:256) of the\n   corresponding destination are zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["xend", "                            XEND \u2014 Transactional End\n\n   Opcode/Instruction Op/En 64/32bit Mode CPUID        Description            \n                            Support       Feature Flag \n   NP 0F 01 D5 XEND   A     V/V           RTM          Specifies the end of   \n                                                       an RTM code region.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand2 Operand3 Operand4 \n   A     N/A       N/A      N/A      N/A      \n\nDescription \u00b6\n\n   The instruction marks the end of an RTM code region. If this corresponds\n   to the outermost scope (that is, including this XEND instruction, the\n   number of XBEGIN instructions is the same as number of XEND instructions),\n   the logical processor will attempt to commit the logical processor state\n   atomically. If the commit fails, the logical processor will rollback all\n   architectural register and memory updates performed during the RTM\n   execution. The logical processor will resume execution at the fallback\n   address computed from the outermost XBEGIN instruction. The EAX register\n   is updated to reflect RTM abort information.\n\n   Execution of XEND outside a transactional region causes a\n   general-protection exception (#GP). Execution of XEND while in a suspend\n   read address tracking region causes a transactional abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["capabilities", "               GETSEC[CAPABILITIES] \u2014 Report the SMX Capabilities\n\n   Opcode          Instruction          Description                           \n   NP 0F 37 (EAX =                      Report the SMX capabilities. The      \n   0)              GETSEC[CAPABILITIES] capabilities index is input in EBX    \n                                        with the result returned in EAX.      \n\nDescription \u00b6\n\n   The GETSEC[CAPABILITIES] function returns a bit vector of supported GETSEC\n   leaf functions. The CAPABILITIES leaf of GETSEC is selected with EAX set\n   to 0 at entry. EBX is used as the selector for returning the bit vector\n   field in EAX. GETSEC[CAPABILITIES] may be executed at all privilege\n   levels, but the CR4.SMXE bit must be set or an undefined opcode exception\n   (#UD) is returned.\n\n   With EBX = 0 upon execution of GETSEC[CAPABILITIES], EAX returns the a bit\n   vector representing status on the presence of a Intel^\u00ae TXT-capable\n   chipset and the first 30 available GETSEC leaf functions. The format of\n   the returned bit vector is provided in Table 7-3.\n\n   If bit 0 is set to 1, then an Intel^\u00ae TXT-capable chipset has been sampled\n   present by the processor. If bits in the range of 1-30 are set, then the\n   corresponding GETSEC leaf function is available. If the bit value at a\n   given bit index is 0, then the GETSEC leaf function corresponding to that\n   index is unsupported and attempted execution results in a #UD.\n\n   Bit 31 of EAX indicates if further leaf indexes are supported. If the\n   Extended Leafs bit 31 is set, then additional leaf functions are accessed\n   by repeating GETSEC[CAPABILITIES] with EBX incremented by one. When the\n   most significant bit of EAX is not set, then additional GETSEC leaf\n   functions are not supported; indexing EBX to a higher value results in EAX\n   returning zero.\n\n   Field           Bit position Description                                   \n   Chipset Present 0            Intel\u00ae TXT-capable chipset is present.        \n   Undefined       1            Reserved                                      \n   ENTERACCS       2            GETSEC[ENTERACCS] is available.               \n   EXITAC          3            GETSEC[EXITAC] is available.                  \n   SENTER          4            GETSEC[SENTER] is available.                  \n   SEXIT           5            GETSEC[SEXIT] is available.                   \n   PARAMETERS      6            GETSEC[PARAMETERS] is available.              \n   SMCTRL          7            GETSEC[SMCTRL] is available.                  \n   WAKEUP          8            GETSEC[WAKEUP] is available.                  \n   Undefined       30:9         Reserved                                      \n   Extended Leafs  31           Reserved for extended information reporting   \n                                of GETSEC capabilities.                       \n\n   Table 7-3. GETSEC Capability Result Encoding (EBX = 0)\n\nFlags Affected \u00b6\n\n   None.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX Ignored.\n\nVM-exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["vpmovqd:vpmovsqd:vpmovusqd", "            VPMOVQD/VPMOVSQD/VPMOVUSQD \u2014 Down Convert QWord to DWord\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Converts 2 packed          \n   EVEX.128.F3.0F38.W0 35                          quad-word integers from    \n   /r VPMOVQD xmm1/m128   A     V/V       AVX512VL xmm2 into 2 packed         \n   {k1}{z}, xmm2                          AVX512F  double-word integers in    \n                                                   xmm1/m128 with truncation  \n                                                   subject to writemask k1.   \n                                                   Converts 2 packed signed   \n                                                   quad-word integers from    \n   EVEX.128.F3.0F38.W0 25                 AVX512VL xmm2 into 2 packed signed  \n   /r VPMOVSQD xmm1/m64   A     V/V       AVX512F  double-word integers in    \n   {k1}{z}, xmm2                                   xmm1/m64 using signed      \n                                                   saturation subject to      \n                                                   writemask k1.              \n                                                   Converts 2 packed unsigned \n                                                   quad-word integers from    \n   EVEX.128.F3.0F38.W0 15                 AVX512VL xmm2 into 2 packed         \n   /r VPMOVUSQD xmm1/m64  A     V/V       AVX512F  unsigned double-word       \n   {k1}{z}, xmm2                                   integers in xmm1/m64 using \n                                                   unsigned saturation        \n                                                   subject to writemask k1.   \n                                                   Converts 4 packed          \n   EVEX.256.F3.0F38.W0 35                          quad-word integers from    \n   /r VPMOVQD xmm1/m128   A     V/V       AVX512VL ymm2 into 4 packed         \n   {k1}{z}, ymm2                          AVX512F  double-word integers in    \n                                                   xmm1/m128 with truncation  \n                                                   subject to writemask k1.   \n                                                   Converts 4 packed signed   \n                                                   quad-word integers from    \n   EVEX.256.F3.0F38.W0 25                 AVX512VL ymm2 into 4 packed signed  \n   /r VPMOVSQD xmm1/m128  A     V/V       AVX512F  double-word integers in    \n   {k1}{z}, ymm2                                   xmm1/m128 using signed     \n                                                   saturation subject to      \n                                                   writemask k1.              \n                                                   Converts 4 packed unsigned \n                                                   quad-word integers from    \n   EVEX.256.F3.0F38.W0 15                 AVX512VL ymm2 into 4 packed         \n   /r VPMOVUSQD xmm1/m128 A     V/V       AVX512F  unsigned double-word       \n   {k1}{z}, ymm2                                   integers in xmm1/m128      \n                                                   using unsigned saturation  \n                                                   subject to writemask k1.   \n                                                   Converts 8 packed          \n   EVEX.512.F3.0F38.W0 35                          quad-word integers from    \n   /r VPMOVQD ymm1/m256   A     V/V       AVX512F  zmm2 into 8 packed         \n   {k1}{z}, zmm2                                   double-word integers in    \n                                                   ymm1/m256 with truncation  \n                                                   subject to writemask k1.   \n                                                   Converts 8 packed signed   \n                                                   quad-word integers from    \n   EVEX.512.F3.0F38.W0 25                          zmm2 into 8 packed signed  \n   /r VPMOVSQD ymm1/m256  A     V/V       AVX512F  double-word integers in    \n   {k1}{z}, zmm2                                   ymm1/m256 using signed     \n                                                   saturation subject to      \n                                                   writemask k1.              \n                                                   Converts 8 packed unsigned \n                                                   quad-word integers from    \n   EVEX.512.F3.0F38.W0 15                          zmm2 into 8 packed         \n   /r VPMOVUSQD ymm1/m256 A     V/V       AVX512F  unsigned double-word       \n   {k1}{z}, zmm2                                   integers in ymm1/m256      \n                                                   using unsigned saturation  \n                                                   subject to writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   VPMOVQW down converts 64-bit integer elements in the source operand (the\n   second operand) into packed double-words using truncation. VPMOVSQW\n   converts signed 64-bit integers into packed signed doublewords using\n   signed saturation. VPMOVUSQW convert unsigned quad-word values into\n   unsigned double-word values using unsigned saturation.\n\n   The source operand is a ZMM/YMM/XMM register. The destination operand is a\n   YMM/XMM/XMM register or a 256/128/64-bit memory location.\n\n   Down-converted doubleword elements are written to the destination operand\n   (the first operand) from the least-significant doubleword. Doubleword\n   elements of the destination operand are updated according to the\n   writemask. Bits (MAXVL-1:256/128/64) of the register destination are\n   zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["sldt", "                  SLDT \u2014 Store Local Descriptor Table Register\n\n   Opcode*  Instruction Op/En 64-Bit Compat/Leg Mode Description              \n                              Mode   \n   0F 00 /0 SLDT r/m16  M     Valid  Valid           Stores segment selector  \n                                                     from LDTR in r/m16.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Stores the segment selector from the local descriptor table register\n   (LDTR) in the destination operand. The destination operand can be a\n   general-purpose register or a memory location. The segment selector stored\n   with this instruction points to the segment descriptor (located in the\n   GDT) for the current LDT. This instruction can only be executed in\n   protected mode.\n\n   Outside IA-32e mode, when the destination operand is a 32-bit register,\n   the 16-bit segment selector is copied into the low-order 16 bits of the\n   register. The high-order 16 bits of the register are cleared for the\n   Pentium 4, Intel Xeon, and P6 family processors. They are undefined for\n   Pentium, Intel486, and Intel386 processors. When the destination operand\n   is a memory location, the segment selector is written to memory as a\n   16-bit quantity, regardless of the operand size.\n\n   In compatibility mode, when the destination operand is a 32-bit register,\n   the 16-bit segment selector is copied into the low-order 16 bits of the\n   register. The high-order 16 bits of the register are cleared. When the\n   destination operand is a memory location, the segment selector is written\n   to memory as a 16-bit quantity, regardless of the operand size.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits access to\n   additional registers (R8-R15). The behavior of SLDT with a 64-bit register\n   is to zero-extend the 16-bit selector and store it in the register. If the\n   destination is memory and operand size is 64, SLDT will write the 16-bit\n   selector to memory as a 16-bit quantity, regardless of the operand size.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["iret:iretd:iretq", "                      IRET/IRETD/IRETQ \u2014 Interrupt Return\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   CF         IRET        ZO    Valid  Valid      Interrupt return (16-bit    \n                                                  operand size).              \n   CF         IRETD       ZO    Valid  Valid      Interrupt return (32-bit    \n                                                  operand size).              \n   REX.W + CF IRETQ       ZO    Valid  N.E.       Interrupt return (64-bit    \n                                                  operand size).              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Returns program control from an exception or interrupt handler to a\n   program or procedure that was interrupted by an exception, an external\n   interrupt, or a software-generated interrupt. These instructions are also\n   used to perform a return from a nested task. (A nested task is created\n   when a CALL instruction is used to initiate a task switch or when an\n   interrupt or exception causes a task switch to an interrupt or exception\n   handler.) See the section titled \u201cTask Linking\u201d in Chapter 8 of the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A.\n\n   IRET and IRETD are mnemonics for the same opcode. The IRETD mnemonic\n   (interrupt return double) is intended for use when returning from an\n   interrupt when using the 32-bit operand size; however, most assemblers use\n   the IRET mnemonic interchangeably for both operand sizes.\n\n   In Real-Address Mode, the IRET instruction performs a far return to the\n   interrupted program or procedure. During this operation, the processor\n   pops the return instruction pointer, return code segment selector, and\n   EFLAGS image from the stack to the EIP, CS, and EFLAGS registers,\n   respectively, and then resumes execution of the interrupted program or\n   procedure.\n\n   In Protected Mode, the action of the IRET instruction depends on the\n   settings of the NT (nested task) and VM flags in the EFLAGS register and\n   the VM flag in the EFLAGS image stored on the current stack. Depending on\n   the setting of these flags, the processor performs the following types of\n   interrupt returns:\n\n     * Return from virtual-8086 mode.\n     * Return to virtual-8086 mode.\n     * Intra-privilege level return.\n     * Inter-privilege level return.\n     * Return from nested task (task switch).\n\n   If the NT flag (EFLAGS register) is cleared, the IRET instruction performs\n   a far return from the interrupt procedure, without a task switch. The code\n   segment being returned to must be equally or less privileged than the\n   interrupt handler routine (as indicated by the RPL field of the code\n   segment selector popped from the stack).\n\n   As with a real-address mode interrupt return, the IRET instruction pops\n   the return instruction pointer, return code segment selector, and EFLAGS\n   image from the stack to the EIP, CS, and EFLAGS registers, respectively,\n   and then resumes execution of the interrupted program or procedure. If the\n   return is to another privilege level, the IRET instruction also pops the\n   stack pointer and SS from the stack, before resuming program execution. If\n   the return is to virtual-8086 mode, the processor also pops the data\n   segment registers from the stack.\n\n   If the NT flag is set, the IRET instruction performs a task switch\n   (return) from a nested task (a task called with a CALL instruction, an\n   interrupt, or an exception) back to the calling or interrupted task. The\n   updated state of the task executing the IRET instruction is saved in its\n   TSS. If the task is re-entered later, the code that follows the IRET\n   instruction is executed.\n\n   If the NT flag is set and the processor is in IA-32e mode, the IRET\n   instruction causes a general protection exception.\n\n   If nonmaskable interrupts (NMIs) are blocked (see Section 6.7.1, \u201cHandling\n   Multiple NMIs\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3A), execution of the IRET instruction unblocks\n   NMIs.\n\n   This unblocking occurs even if the instruction causes a fault. In such a\n   case, NMIs are unmasked before the exception handler is invoked.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.W prefix promotes operation to 64 bits (IRETQ). See the summary\n   chart at the beginning of this section for encoding data and limits.\n\n   Refer to Chapter 6, \u201cProcedure Calls, Interrupts, and Exceptions\u201d and\n   Chapter 17, \u201cControl-flow Enforcement Technology (CET)\u201d in the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for CET\n   details.\n\n   Instruction ordering. IRET is a serializing instruction. See Section 9.3\n   of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3A.\n\n   See \u201cChanges to Instruction Behavior in VMX Non-Root Operation\u201d in Chapter\n   26 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3C, for more information about the behavior of this instruction in\n   VMX non-root operation.\n\nFlags Affected \u00b6\n\n   All the flags and fields in the EFLAGS register are potentially modified,\n   depending on the mode of operation of the processor. If performing a\n   return from a nested task to a previous task, the EFLAGS register will be\n   modified according to the EFLAGS image stored in the previous task\u2019s TSS.\n"],
	["movsldup", "          MOVSLDUP \u2014 Replicate Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Move even index single     \n   F3 0F 12 /r MOVSLDUP                            precision floating-point   \n   xmm1, xmm2/m128         A    V/V       SSE3     values from xmm2/mem and   \n                                                   duplicate each element     \n                                                   into xmm1.                 \n                                                   Move even index single     \n   VEX.128.F3.0F.WIG 12 /r                         precision floating-point   \n   VMOVSLDUP xmm1,         A    V/V       AVX      values from xmm2/mem and   \n   xmm2/m128                                       duplicate each element     \n                                                   into xmm1.                 \n                                                   Move even index single     \n   VEX.256.F3.0F.WIG 12 /r                         precision floating-point   \n   VMOVSLDUP ymm1,         A    V/V       AVX      values from ymm2/mem and   \n   ymm2/m256                                       duplicate each element     \n                                                   into ymm1.                 \n                                                   Move even index single     \n   EVEX.128.F3.0F.W0 12 /r                AVX512VL precision floating-point   \n   VMOVSLDUP xmm1 {k1}{z}, B    V/V       AVX512F  values from xmm2/m128 and  \n   xmm2/m128                                       duplicate each element     \n                                                   into xmm1 under writemask. \n                                                   Move even index single     \n   EVEX.256.F3.0F.W0 12 /r                AVX512VL precision floating-point   \n   VMOVSLDUP ymm1 {k1}{z}, B    V/V       AVX512F  values from ymm2/m256 and  \n   ymm2/m256                                       duplicate each element     \n                                                   into ymm1 under writemask. \n                                                   Move even index single     \n   EVEX.512.F3.0F.W0 12 /r                         precision floating-point   \n   VMOVSLDUP zmm1 {k1}{z}, B    V/V       AVX512F  values from zmm2/m512 and  \n   zmm2/m512                                       duplicate each element     \n                                                   into zmm1 under writemask. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Duplicates even-indexed single precision floating-point values from the\n   source operand (the second operand). See Figure 4-4. The source operand is\n   an XMM, YMM or ZMM register or 128, 256 or 512-bit memory location and the\n   destination operand is an XMM, YMM or ZMM register.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed.\n\n   VEX.256 encoded version: Bits (MAXVL-1:256) of the destination register\n   are zeroed.\n\n   EVEX encoded version: The destination operand is updated at 32-bit\n   granularity according to the writemask.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   X7 X6 X5 X4 X3 X2 X1 X0 SRC DEST X6 X6 X4 X4 X2 X2 X0 X0 Figure 4-4.\n   MOVSLDUP Operation\n"],
	["fld1:fldl2t:fldl2e:fldpi:fldlg2:fldln2:fldz", "          FLD1/FLDL2T/FLDL2E/FLDPI/FLDLG2/FLDLN2/FLDZ \u2014 Load Constant\n\n   Opcode* Instruction 64-Bit Mode Compat/Leg Mode Description                \n   D9 E8   FLD1        Valid       Valid           Push +1.0 onto the FPU     \n                                                   register stack.            \n   D9 E9   FLDL2T      Valid       Valid           Push log_210 onto the FPU  \n                                                   register stack.            \n   D9 EA   FLDL2E      Valid       Valid           Push log_2e onto the FPU   \n                                                   register stack.            \n   D9 EB   FLDPI       Valid       Valid           Push \u03c0 onto the FPU        \n                                                   register stack.            \n   D9 EC   FLDLG2      Valid       Valid           Push log_102 onto the FPU  \n                                                   register stack.            \n   D9 ED   FLDLN2      Valid       Valid           Push log_e2 onto the FPU   \n                                                   register stack.            \n   D9 EE   FLDZ        Valid       Valid           Push +0.0 onto the FPU     \n                                                   register stack.            \n\n     * SeeIA-32ArchitectureCompatibilitysectionbelow.\n\nDescription \u00b6\n\n   Push one of seven commonly used constants (in double extended-precision\n   floating-point format) onto the FPU register stack. The constants that can\n   be loaded with these instructions include +1.0, +0.0, log_210, log_2e, \u03c0,\n   log_102, and log_e2. For each constant, an internal 66-bit constant is\n   rounded (as specified by the RC field in the FPU control word) to double\n   extended-precision floating-point format. The inexact-result exception\n   (#P) is not generated as a result of the rounding, nor is the C1 flag set\n   in the x87 FPU status word if the value is rounded up.\n\n   See the section titled \u201cApproximation of Pi\u201d in Chapter 8 of the Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for a\n   description of the \u03c0 constant.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   When the RC field is set to round-to-nearest, the FPU produces the same\n   constants that is produced by the Intel 8087 and Intel 287 math\n   coprocessors.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 1 if stack overflow occurred; otherwise, set to 0. \n   C0, C2, C3 Undefined.                                                \n"],
	["vcvtph2ps:vcvtph2psx", "     VCVTPH2PS/VCVTPH2PSX \u2014 Convert Packed FP16 Values to Single Precision\n                              Floating-PointValues\n\n                           Op 64/32 Bit CPUID Feature                         \n   Opcode/Instruction      /  Mode      Flag          Description\n                           En Support   \n                                                      Convert four packed     \n   VEX.128.66.0F38.W0 13                              FP16 values in xmm2/m64 \n   /r VCVTPH2PS xmm1,      A  V/V       F16C          to packed single        \n   xmm2/m64                                           precision               \n                                                      floating-point value in \n                                                      xmm1.                   \n                                                      Convert eight packed    \n   VEX.256.66.0F38.W0 13                              FP16 values in          \n   /r VCVTPH2PS ymm1,      A  V/V       F16C          xmm2/m128 to packed     \n   xmm2/m128                                          single precision        \n                                                      floating-point value in \n                                                      ymm1.                   \n                                                      Convert four packed     \n                                                      FP16 values in xmm2/m64 \n   EVEX.128.66.0F38.W0 13               AVX512VL      to packed single        \n   /r VCVTPH2PS xmm1       B  V/V       AVX512F       precision               \n   {k1}{z}, xmm2/m64                                  floating-point values   \n                                                      in xmm1 subject to      \n                                                      writemask k1.           \n                                                      Convert eight packed    \n                                                      FP16 values in          \n   EVEX.256.66.0F38.W0 13               AVX512VL      xmm2/m128 to packed     \n   /r VCVTPH2PS ymm1       B  V/V       AVX512F       single precision        \n   {k1}{z}, xmm2/m128                                 floating-point values   \n                                                      in ymm1 subject to      \n                                                      writemask k1.           \n                                                      Convert sixteen packed  \n   EVEX.512.66.0F38.W0 13                             FP16 values in          \n   /r VCVTPH2PS zmm1                                  ymm2/m256 to packed     \n   {k1}{z}, ymm2/m256      B  V/V       AVX512F       single precision        \n   {sae}                                              floating-point values   \n                                                      in zmm1 subject to      \n                                                      writemask k1.           \n                                                      Convert four packed     \n                                                      FP16 values in          \n   EVEX.128.66.MAP6.W0 13                             xmm2/m64/m16bcst to     \n   /r VCVTPH2PSX                        AVX512-FP16   four packed single      \n   xmm1{k1}{z},            C  V/V       AVX512VL      precision               \n   xmm2/m64/m16bcst                                   floating-point values,  \n                                                      and store result in     \n                                                      xmm1 subject to         \n                                                      writemask k1.           \n                                                      Convert eight packed    \n                                                      FP16 values in          \n   EVEX.256.66.MAP6.W0 13                             xmm2/m128/m16bcst to    \n   /r VCVTPH2PSX                        AVX512-FP16   eight packed single     \n   ymm1{k1}{z},            C  V/V       AVX512VL      precision               \n   xmm2/m128/m16bcst                                  floating-point values,  \n                                                      and store result in     \n                                                      ymm1 subject to         \n                                                      writemask k1.           \n                                                      Convert sixteen packed  \n                                                      FP16 values in          \n   EVEX.512.66.MAP6.W0 13                             ymm2/m256/m16bcst to    \n   /r VCVTPH2PSX                                      sixteen packed single   \n   zmm1{k1}{z},            C  V/V       AVX512-FP16   precision               \n   ymm2/m256/m16bcst {sae}                            floating-point values,  \n                                                      and store result in     \n                                                      zmm1 subject to         \n                                                      writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Half Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   C     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed half precision (16-bits) floating-point\n   values in the low-order bits of the source operand (the second operand) to\n   packed single precision floating-point values and writes the converted\n   values into the destination operand (the first operand).\n\n   If case of a denormal operand, the correct normal result is returned.\n   MXCSR.DAZ is ignored and is treated as if it 0. No denormal exception is\n   reported on MXCSR.\n\n   VEX.128 version: The source operand is a XMM register or 64-bit memory\n   location. The destination operand is a XMM register. The upper bits\n   (MAXVL-1:128) of the corresponding destination register are zeroed.\n\n   VEX.256 version: The source operand is a XMM register or 128-bit memory\n   location. The destination operand is a YMM register. Bits (MAXVL-1:256) of\n   the corresponding destination register are zeroed.\n\n   EVEX encoded versions: The source operand is a YMM/XMM/XMM (low 64-bits)\n   register or a 256/128/64-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   The diagram below illustrates how data is converted from four packed half\n   precision (in 64 bits) to four single precision (in 128 bits)\n   floating-point values.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved (must be 1111b).\n\n   VCVTPH2PSxmm1,xmm2/mem64, imm8 127 96 95 64 63 48 47 32 31 \n   16 15 0                                                    \n   xmm2/mem64 VH3 VH2 VH1 VH0                                 \n   convert convert convert convert 127 96 95 64 63 32 31 0    VS3 VS2 VS1 VS0 \n                                                              xmm1            \n\n   Figure 5-6. VCVTPH2PS (128-bit Version)\n\n   The VCVTPH2PSX instruction is a new form of the PH to PS conversion\n   instruction, encoded in map 6. The previous version of the instruction,\n   VCVTPH2PS, that is present in AVX512F (encoded in map 2, 0F38) does not\n   support embedded broadcasting. The VCVTPH2PSX instruction has the embedded\n   broadcasting option available.\n\n   The instructions associated with AVX512_FP16 always handle FP16 denormal\n   number inputs; denormal inputs are not treated as zero.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["phaddw:phaddd", "                     PHADDW/PHADDD \u2014 Packed Horizontal Add\n\n                                         64/32 bit CPUID                      \n   Opcode/Instruction              Op/En Mode      Feature Description\n                                         Support   Flag    \n                                                           Add 16-bit         \n   NP 0F 38 01 /r^1 PHADDW mm1,    RM    V/V       SSSE3   integers           \n   mm2/m64                                                 horizontally, pack \n                                                           to mm1.            \n                                                           Add 16-bit         \n   66 0F 38 01 /r PHADDW xmm1,     RM    V/V       SSSE3   integers           \n   xmm2/m128                                               horizontally, pack \n                                                           to xmm1.           \n                                                           Add 32-bit         \n   NP 0F 38 02 /r PHADDD mm1,      RM    V/V       SSSE3   integers           \n   mm2/m64                                                 horizontally, pack \n                                                           to mm1.            \n                                                           Add 32-bit         \n   66 0F 38 02 /r PHADDD xmm1,     RM    V/V       SSSE3   integers           \n   xmm2/m128                                               horizontally, pack \n                                                           to xmm1.           \n                                                           Add 16-bit         \n   VEX.128.66.0F38.WIG 01 /r       RVM   V/V       AVX     integers           \n   VPHADDW xmm1, xmm2, xmm3/m128                           horizontally, pack \n                                                           to xmm1.           \n                                                           Add 32-bit         \n   VEX.128.66.0F38.WIG 02 /r       RVM   V/V       AVX     integers           \n   VPHADDD xmm1, xmm2, xmm3/m128                           horizontally, pack \n                                                           to xmm1.           \n                                                           Add 16-bit signed  \n   VEX.256.66.0F38.WIG 01 /r       RVM   V/V       AVX2    integers           \n   VPHADDW ymm1, ymm2, ymm3/m256                           horizontally, pack \n                                                           to ymm1.           \n                                                           Add 32-bit signed  \n   VEX.256.66.0F38.WIG 02 /r       RVM   V/V       AVX2    integers           \n   VPHADDD ymm1, ymm2, ymm3/m256                           horizontally, pack \n                                                           to ymm1.           \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   (V)PHADDW adds two adjacent 16-bit signed integers horizontally from the\n   source and destination operands and packs the 16-bit signed results to the\n   destination operand (first operand). (V)PHADDD adds two adjacent 32-bit\n   signed integers horizontally from the source and destination operands and\n   packs the 32-bit signed results to the destination operand (first\n   operand). When the source operand is a 128-bit memory operand, the operand\n   must be aligned on a 16-byte boundary or a general-protection exception\n   (#GP) will be generated.\n\n   Note that these instructions can operate on either unsigned or signed\n   (two\u2019s complement notation) integers; however, it does not set bits in the\n   EFLAGS register to indicate overflow and/or a carry. To prevent undetected\n   overflow conditions, software must control the ranges of the values\n   operated on.\n\n   Legacy SSE instructions: Both operands can be MMX registers. The second\n   source operand can be an MMX register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand can be an XMM register or a\n   128-bit memory location. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   In 64-bit mode, use the REX prefix to access additional registers.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand can be an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM register are\n   zeroed.\n\n   VEX.256 encoded version: Horizontal addition of two adjacent data elements\n   of the low 16-bytes of the first and second source operands are packed\n   into the low 16-bytes of the destination operand. Horizontal addition of\n   two adjacent data elements of the high 16-bytes of the first and second\n   source operands are packed into the high 16-bytes of the destination\n   operand. The first source and destination operands are YMM registers. The\n   second source operand can be an YMM register or a 256-bit memory location.\n\n   SRC2 Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 X7 X6 X5 X4 X3 X2 X1 X0 SRC1\n\n   S7 S3 S3 S4 S3 S2 S1 S0\n\n   255 0 Dest Figure 4-10. 256-bit VPHADDD Instruction Operation\n"],
	["vshuff32x4:vshuff64x2:vshufi32x4:vshufi64x2", "     VSHUFF32x4/VSHUFF64x2/VSHUFI32x4/VSHUFI64x2 \u2014 Shuffle Packed Values at\n                               128-BitGranularity\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Shuffle 128-bit packed    \n                                                    single-precision          \n   EVEX.256.66.0F3A.W0 23                           floating-point values     \n   /r ib VSHUFF32X4        A     V/V       AVX512VL selected by imm8 from     \n   ymm1{k1}{z}, ymm2,                      AVX512F  ymm2 and                  \n   ymm3/m256/m32bcst, imm8                          ymm3/m256/m32bcst and     \n                                                    place results in ymm1     \n                                                    subject to writemask k1.  \n                                                    Shuffle 128-bit packed    \n                                                    single-precision          \n   EVEX.512.66.0F3A.W0 23                           floating-point values     \n   /r ib VSHUFF32x4        A     V/V       AVX512F  selected by imm8 from     \n   zmm1{k1}{z}, zmm2,                               zmm2 and                  \n   zmm3/m512/m32bcst, imm8                          zmm3/m512/m32bcst and     \n                                                    place results in zmm1     \n                                                    subject to writemask k1.  \n                                                    Shuffle 128-bit packed    \n                                                    double precision          \n   EVEX.256.66.0F3A.W1 23                           floating-point values     \n   /r ib VSHUFF64X2        A     V/V       AVX512VL selected by imm8 from     \n   ymm1{k1}{z}, ymm2,                      AVX512F  ymm2 and                  \n   ymm3/m256/m64bcst, imm8                          ymm3/m256/m64bcst and     \n                                                    place results in ymm1     \n                                                    subject to writemask k1.  \n                                                    Shuffle 128-bit packed    \n                                                    double precision          \n   EVEX.512.66.0F3A.W1 23                           floating-point values     \n   /r ib VSHUFF64x2        A     V/V       AVX512F  selected by imm8 from     \n   zmm1{k1}{z}, zmm2,                               zmm2 and                  \n   zmm3/m512/m64bcst, imm8                          zmm3/m512/m64bcst and     \n                                                    place results in zmm1     \n                                                    subject to writemask k1.  \n                                                    Shuffle 128-bit packed    \n   EVEX.256.66.0F3A.W0 43                           double-word values        \n   /r ib VSHUFI32X4                        AVX512VL selected by imm8 from     \n   ymm1{k1}{z}, ymm2,      A     V/V       AVX512F  ymm2 and                  \n   ymm3/m256/m32bcst, imm8                          ymm3/m256/m32bcst and     \n                                                    place results in ymm1     \n                                                    subject to writemask k1.  \n                                                    Shuffle 128-bit packed    \n   EVEX.512.66.0F3A.W0 43                           double-word values        \n   /r ib VSHUFI32x4                                 selected by imm8 from     \n   zmm1{k1}{z}, zmm2,      A     V/V       AVX512F  zmm2 and                  \n   zmm3/m512/m32bcst, imm8                          zmm3/m512/m32bcst and     \n                                                    place results in zmm1     \n                                                    subject to writemask k1.  \n                                                    Shuffle 128-bit packed    \n   EVEX.256.66.0F3A.W1 43                           quad-word values selected \n   /r ib VSHUFI64X2        A     V/V       AVX512VL by imm8 from ymm2 and     \n   ymm1{k1}{z}, ymm2,                      AVX512F  ymm3/m256/m64bcst and     \n   ymm3/m256/m64bcst, imm8                          place results in ymm1     \n                                                    subject to writemask k1.  \n                                                    Shuffle 128-bit packed    \n   EVEX.512.66.0F3A.W1 43                           quad-word values selected \n   /r ib VSHUFI64x2        A     V/V       AVX512F  by imm8 from zmm2 and     \n   zmm1{k1}{z}, zmm2,                               zmm3/m512/m64bcst and     \n   zmm3/m512/m64bcst, imm8                          place results in zmm1     \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   256-bit Version: Moves one of the two 128-bit packed single-precision\n   floating-point values from the first source operand (second operand) into\n   the low 128-bit of the destination operand (first operand); moves one of\n   the two packed 128-bit floating-point values from the second source\n   operand (third operand) into the high 128-bit of the destination operand.\n   The selector operand (third operand) determines which values are moved to\n   the destination operand.\n\n   512-bit Version: Moves two of the four 128-bit packed single-precision\n   floating-point values from the first source operand (second operand) into\n   the low 256-bit of each double qword of the destination operand (first\n   operand); moves two of the four packed 128-bit floating-point values from\n   the second source operand (third operand) into the high 256-bit of the\n   destination operand. The selector operand (third operand) determines which\n   values are moved to the destination operand.\n\n   The first source operand is a vector register. The second source operand\n   can be a ZMM register, a 512-bit memory location or a 512-bit vector\n   broadcasted from a 32/64-bit memory location. The destination operand is a\n   vector register.\n\n   The writemask updates the destination operand with the granularity of\n   32/64-bit data elements.\n"],
	["vcvtph2udq", "    VCVTPH2UDQ \u2014 Convert Packed FP16 Values to Unsigned Doubleword Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert four packed   \n                                                        FP16 values in        \n   EVEX.128.NP.MAP5.W0 79 /r                            xmm2/m64/m16bcst to   \n   VCVTPH2UDQ xmm1{k1}{z},        A V/V     AVX512-FP16 four unsigned         \n   xmm2/m64/m16bcst                         AVX512VL    doubleword integers,  \n                                                        and store the result  \n                                                        in xmm1 subject to    \n                                                        writemask k1.         \n                                                        Convert eight packed  \n                                                        FP16 values in        \n   EVEX.256.NP.MAP5.W0 79 /r                            xmm2/m128/m16bcst to  \n   VCVTPH2UDQ ymm1{k1}{z},        A V/V     AVX512-FP16 eight unsigned        \n   xmm2/m128/m16bcst                        AVX512VL    doubleword integers,  \n                                                        and store the result  \n                                                        in ymm1 subject to    \n                                                        writemask k1.         \n                                                        Convert sixteen       \n                                                        packed FP16 values in \n   EVEX.512.NP.MAP5.W0 79 /r                            ymm2/m256/m16bcst to  \n   VCVTPH2UDQ zmm1{k1}{z},        A V/V     AVX512-FP16 sixteen unsigned      \n   ymm2/m256/m16bcst {er}                               doubleword integers,  \n                                                        and store the result  \n                                                        in zmm1 subject to    \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   unsigned doubleword integers in destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["sqrtps", "         SQRTPS \u2014 Square Root of Single Precision Floating-Point Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes Square Roots of  \n                                                    the packed single         \n   NP 0F 51 /r SQRTPS xmm1, A    V/V       SSE      precision floating-point  \n   xmm2/m128                                        values in xmm2/m128 and   \n                                                    stores the result in      \n                                                    xmm1.                     \n                                                    Computes Square Roots of  \n                                                    the packed single         \n   VEX.128.0F.WIG 51 /r     A    V/V       AVX      precision floating-point  \n   VSQRTPS xmm1, xmm2/m128                          values in xmm2/m128 and   \n                                                    stores the result in      \n                                                    xmm1.                     \n                                                    Computes Square Roots of  \n                                                    the packed single         \n   VEX.256.0F.WIG 51/r      A    V/V       AVX      precision floating-point  \n   VSQRTPS ymm1, ymm2/m256                          values in ymm2/m256 and   \n                                                    stores the result in      \n                                                    ymm1.                     \n                                                    Computes Square Roots of  \n                                                    the packed single         \n   EVEX.128.0F.W0 51 /r                    AVX512VL precision floating-point  \n   VSQRTPS xmm1 {k1}{z},    B    V/V       AVX512F  values in                 \n   xmm2/m128/m32bcst                                xmm2/m128/m32bcst and     \n                                                    stores the result in xmm1 \n                                                    subject to writemask k1.  \n                                                    Computes Square Roots of  \n                                                    the packed single         \n   EVEX.256.0F.W0 51 /r                    AVX512VL precision floating-point  \n   VSQRTPS ymm1 {k1}{z},    B    V/V       AVX512F  values in                 \n   ymm2/m256/m32bcst                                ymm2/m256/m32bcst and     \n                                                    stores the result in ymm1 \n                                                    subject to writemask k1.  \n                                                    Computes Square Roots of  \n                                                    the packed single         \n   EVEX.512.0F.W0 51/r                              precision floating-point  \n   VSQRTPS zmm1 {k1}{z},    B    V/V       AVX512F  values in                 \n   zmm2/m512/m32bcst{er}                            zmm2/m512/m32bcst and     \n                                                    stores the result in zmm1 \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs a SIMD computation of the square roots of the four, eight or\n   sixteen packed single precision floating-point values in the source\n   operand (second operand) stores the packed single precision floating-point\n   results in the destination operand.\n\n   EVEX.512 encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location or a 512/256/128-bit vector broadcasted\n   from a 32-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register updated according to the writemask.\n\n   VEX.256 encoded version: The source operand is a YMM register or a 256-bit\n   memory location. The destination operand is a YMM register. The upper bits\n   (MAXVL-1:256) of the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: the source operand second source operand or a\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["rdmsr", "                   RDMSR \u2014 Read From Model Specific Register\n\n   Opcode^1\n\n         Instruction Op/En 64-Bit Mode Compat/Leg Mode Description            \n   0F 32                   Valid       Valid           Read MSR specified by  \n                                                       ECX into EDX:EAX.      \n\n   1. See the IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reads the contents of a 64-bit model specific register (MSR) specified in\n   the ECX register into registers EDX:EAX. (On processors that support the\n   Intel 64 architecture, the high-order 32 bits of RCX are ignored.) The EDX\n   register is loaded with the high-order 32 bits of the MSR and the EAX\n   register is loaded with the low-order 32 bits. (On processors that support\n   the Intel 64 architecture, the high-order 32 bits of each of RAX and RDX\n   are cleared.) If fewer than 64 bits are implemented in the MSR being read,\n   the values returned to EDX:EAX in unimplemented bit locations are\n   undefined.\n\n   This instruction must be executed at privilege level 0 or in real-address\n   mode; otherwise, a general protection exception #GP(0) will be generated.\n   Specifying a reserved or unimplemented MSR address in ECX will also cause\n   a general protection exception.\n\n   The MSRs control functions for testability, execution tracing,\n   performance-monitoring, and machine check errors. Chapter 2,\n   \u201cModel-Specific Registers (MSRs)\u201d of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 4, lists all the MSRs\n   that can be read with this instruction and their addresses. Note that each\n   processor family has its own set of MSRs.\n\n   The CPUID instruction should be used to determine whether MSRs are\n   supported (CPUID.01H:EDX[5] = 1) before using this instruction.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The MSRs and the ability to read them with the RDMSR instruction were\n   introduced into the IA-32 Architecture with the Pentium processor.\n   Execution of this instruction by an IA-32 processor earlier than the\n   Pentium processor results in an invalid opcode exception #UD.\n\n   See \u201cChanges to Instruction Behavior in VMX Non-Root Operation\u201d in Chapter\n   26 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3C, for more information about the behavior of this instruction in\n   VMX non-root operation.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vrangesd", " VRANGESD \u2014 Range Restriction Calculation From a Pair of Scalar Float64 Values\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Calculate a RANGE         \n                                                    operation output value    \n   EVEX.LLIG.66.0F3A.W1 51                          from 2 double precision   \n   /r VRANGESD xmm1                                 floating-point values in  \n   {k1}{z}, xmm2,          A     V/V       AVX512DQ xmm2 and xmm3/m64, store  \n   xmm3/m64{sae}, imm8                              the output to xmm1 under  \n                                                    writemask. Imm8 specifies \n                                                    the comparison and sign   \n                                                    of the range operation.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   This instruction calculates a range operation output from two input double\n   precision floating-point values in the low qword element of the first\n   source operand (the second operand) and second source operand (the third\n   operand). The range output is written to the low qword element of the\n   destination operand (the first operand) under the writemask k1.\n\n   Bits7:4 of imm8 byte must be zero. The range operation output is performed\n   in two parts, each configured by a two-bit control field within imm8[3:0]:\n\n     * Imm8[1:0] specifies the initial comparison operation to be one of max,\n       min, max absolute value or min absolute value of the input value pair.\n       Each comparison of two input values produces an intermediate result\n       that combines with the sign selection control (imm8[3:2]) to determine\n       the final range operation output.\n     * Imm8[3:2] specifies the sign of the range operation output to be one\n       of the following: from the first input value, from the comparison\n       result, set or clear.\n\n   The encodings of imm8[1:0] and imm8[3:2] are shown in Figure 5-27.\n\n   Bits 128:63 of the destination operand are copied from the respective\n   element of the first source operand.\n\n   When one or more of the input value is a NAN, the comparison operation may\n   signal invalid exception (IE). Details with one of more input value is NAN\n   is listed in Table 5-23. If the comparison raises an IE, the sign select\n   control (imm8[3:2]) has no effect to the range operation output; this is\n   indicated also in Table 5-23.\n\n   When both input values are zeros of opposite signs, the comparison\n   operation of MIN/MAX in the range compare operation is slightly different\n   from the conceptually similar floating-point MIN/MAX operation that are\n   found in the instructions VMAXPD/VMINPD. The details of\n   MIN/MAX/MIN_ABS/MAX_ABS operation for VRANGEPD/PS/SD/SS for magnitude-0,\n   opposite-signed input cases are listed in Table 5-24.\n\n   Additionally, non-zero, equal-magnitude with opposite-sign input values\n   perform MIN_ABS or MAX_ABS comparison operation with result listed in\n   Table 5-25.\n"],
	["movupd", "     MOVUPD \u2014 Move Unaligned Packed Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Move unaligned packed      \n   66 0F 10 /r MOVUPD      A    V/V       SSE2     double precision           \n   xmm1, xmm2/m128                                 floating-point from        \n                                                   xmm2/mem to xmm1.          \n                                                   Move unaligned packed      \n   66 0F 11 /r MOVUPD      B    V/V       SSE2     double precision           \n   xmm2/m128, xmm1                                 floating-point from xmm1   \n                                                   to xmm2/mem.               \n                                                   Move unaligned packed      \n   VEX.128.66.0F.WIG 10 /r A    V/V       AVX      double precision           \n   VMOVUPD xmm1, xmm2/m128                         floating-point from        \n                                                   xmm2/mem to xmm1.          \n                                                   Move unaligned packed      \n   VEX.128.66.0F.WIG 11 /r B    V/V       AVX      double precision           \n   VMOVUPD xmm2/m128, xmm1                         floating-point from xmm1   \n                                                   to xmm2/mem.               \n                                                   Move unaligned packed      \n   VEX.256.66.0F.WIG 10 /r A    V/V       AVX      double precision           \n   VMOVUPD ymm1, ymm2/m256                         floating-point from        \n                                                   ymm2/mem to ymm1.          \n                                                   Move unaligned packed      \n   VEX.256.66.0F.WIG 11 /r B    V/V       AVX      double precision           \n   VMOVUPD ymm2/m256, ymm1                         floating-point from ymm1   \n                                                   to ymm2/mem.               \n                                                   Move unaligned packed      \n   EVEX.128.66.0F.W1 10 /r                AVX512VL double precision           \n   VMOVUPD xmm1 {k1}{z},   C    V/V       AVX512F  floating-point from        \n   xmm2/m128                                       xmm2/m128 to xmm1 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.128.66.0F.W1 11 /r                AVX512VL double precision           \n   VMOVUPD xmm2/m128       D    V/V       AVX512F  floating-point from xmm1   \n   {k1}{z}, xmm1                                   to xmm2/m128 using         \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.256.66.0F.W1 10 /r                AVX512VL double precision           \n   VMOVUPD ymm1 {k1}{z},   C    V/V       AVX512F  floating-point from        \n   ymm2/m256                                       ymm2/m256 to ymm1 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.256.66.0F.W1 11 /r                AVX512VL double precision           \n   VMOVUPD ymm2/m256       D    V/V       AVX512F  floating-point from ymm1   \n   {k1}{z}, ymm1                                   to ymm2/m256 using         \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.512.66.0F.W1 10 /r                         double precision           \n   VMOVUPD zmm1 {k1}{z},   C    V/V       AVX512F  floating-point values from \n   zmm2/m512                                       zmm2/m512 to zmm1 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.512.66.0F.W1 11 /r                         double precision           \n   VMOVUPD zmm2/m512       D    V/V       AVX512F  floating-point values from \n   {k1}{z}, zmm1                                   zmm1 to zmm2/m512 using    \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Note: VEX.vvvv and EVEX.vvvv is reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   EVEX.512 encoded version:\n\n   Moves 512 bits of packed double precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a ZMM register from a\n   float64 memory location, to store the contents of a ZMM register into a\n   memory. The destination operand is updated according to the writemask.\n\n   VEX.256 encoded version:\n\n   Moves 256 bits of packed double precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a YMM register from a\n   256-bit memory location, to store the contents of a YMM register into a\n   256-bit memory location, or to move data between two YMM registers. Bits\n   (MAXVL-1:256) of the destination register are zeroed.\n\n   128-bit versions:\n\n   Moves 128 bits of packed double precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load an XMM register from a\n   128-bit memory location, to store the contents of an XMM register into a\n   128-bit memory location, or to move data between two XMM registers.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   When the source or destination operand is a memory operand, the operand\n   may be unaligned on a 16-byte boundary without causing a\n   general-protection exception (#GP) to be generated\n\n   VEX.128 and EVEX.128 encoded versions: Bits (MAXVL-1:128) of the\n   destination register are zeroed.\n"],
	["vpmovb2m:vpmovw2m:vpmovd2m:vpmovq2m", "   VPMOVB2M/VPMOVW2M/VPMOVD2M/VPMOVQ2M \u2014 Convert a Vector Register to a Mask\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Sets each bit in k1 to 1   \n   EVEX.128.F3.0F38.W0 29                 AVX512VL or 0 based on the value of \n   /r VPMOVB2M k1, xmm1   RM    V/V       AVX512BW the most significant bit   \n                                                   of the corresponding byte  \n                                                   in XMM1.                   \n                                                   Sets each bit in k1 to 1   \n   EVEX.256.F3.0F38.W0 29                 AVX512VL or 0 based on the value of \n   /r VPMOVB2M k1, ymm1   RM    V/V       AVX512BW the most significant bit   \n                                                   of the corresponding byte  \n                                                   in YMM1.                   \n                                                   Sets each bit in k1 to 1   \n   EVEX.512.F3.0F38.W0 29                          or 0 based on the value of \n   /r VPMOVB2M k1, zmm1   RM    V/V       AVX512BW the most significant bit   \n                                                   of the corresponding byte  \n                                                   in ZMM1.                   \n                                                   Sets each bit in k1 to 1   \n   EVEX.128.F3.0F38.W1 29                 AVX512VL or 0 based on the value of \n   /r VPMOVW2M k1, xmm1   RM    V/V       AVX512BW the most significant bit   \n                                                   of the corresponding word  \n                                                   in XMM1.                   \n                                                   Sets each bit in k1 to 1   \n   EVEX.256.F3.0F38.W1 29                 AVX512VL or 0 based on the value of \n   /r VPMOVW2M k1, ymm1   RM    V/V       AVX512BW the most significant bit   \n                                                   of the corresponding word  \n                                                   in YMM1.                   \n                                                   Sets each bit in k1 to 1   \n   EVEX.512.F3.0F38.W1 29                          or 0 based on the value of \n   /r VPMOVW2M k1, zmm1   RM    V/V       AVX512BW the most significant bit   \n                                                   of the corresponding word  \n                                                   in ZMM1.                   \n                                                   Sets each bit in k1 to 1   \n   EVEX.128.F3.0F38.W0 39                 AVX512VL or 0 based on the value of \n   /r VPMOVD2M k1, xmm1   RM    V/V       AVX512DQ the most significant bit   \n                                                   of the corresponding       \n                                                   doubleword in XMM1.        \n                                                   Sets each bit in k1 to 1   \n   EVEX.256.F3.0F38.W0 39                 AVX512VL or 0 based on the value of \n   /r VPMOVD2M k1, ymm1   RM    V/V       AVX512DQ the most significant bit   \n                                                   of the corresponding       \n                                                   doubleword in YMM1.        \n                                                   Sets each bit in k1 to 1   \n   EVEX.512.F3.0F38.W0 39                          or 0 based on the value of \n   /r VPMOVD2M k1, zmm1   RM    V/V       AVX512DQ the most significant bit   \n                                                   of the corresponding       \n                                                   doubleword in ZMM1.        \n                                                   Sets each bit in k1 to 1   \n   EVEX.128.F3.0F38.W1 39                 AVX512VL or 0 based on the value of \n   /r VPMOVQ2M k1, xmm1   RM    V/V       AVX512DQ the most significant bit   \n                                                   of the corresponding       \n                                                   quadword in XMM1.          \n                                                   Sets each bit in k1 to 1   \n   EVEX.256.F3.0F38.W1 39                 AVX512VL or 0 based on the value of \n   /r VPMOVQ2M k1, ymm1   RM    V/V       AVX512DQ the most significant bit   \n                                                   of the corresponding       \n                                                   quadword in YMM1.          \n                                                   Sets each bit in k1 to 1   \n   EVEX.512.F3.0F38.W1 39                          or 0 based on the value of \n   /r VPMOVQ2M k1, zmm1   RM    V/V       AVX512DQ the most significant bit   \n                                                   of the corresponding       \n                                                   quadword in ZMM1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts a vector register to a mask register. Each element in the\n   destination register is set to 1 or 0 depending on the value of most\n   significant bit of the corresponding element in the source register.\n\n   The source operand is a ZMM/YMM/XMM register. The destination operand is a\n   mask register.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["paddusb:paddusw", "    PADDUSB/PADDUSW \u2014 Add Packed Unsigned Integers With Unsigned Saturation\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Add packed unsigned byte \n   NP 0F DC /r^1 PADDUSB    A     V/V       MMX      integers from mm/m64 and \n   mm, mm/m64                                        mm and saturate the      \n                                                     results.                 \n                                                     Add packed unsigned byte \n   66 0F DC /r PADDUSB      A     V/V       SSE2     integers from xmm2/m128  \n   xmm1, xmm2/m128                                   and xmm1 saturate the    \n                                                     results.                 \n                                                     Add packed unsigned word \n   NP 0F DD /r^1 PADDUSW    A     V/V       MMX      integers from mm/m64 and \n   mm, mm/m64                                        mm and saturate the      \n                                                     results.                 \n                                                     Add packed unsigned word \n   66 0F DD /r PADDUSW      A     V/V       SSE2     integers from xmm2/m128  \n   xmm1, xmm2/m128                                   to xmm1 and saturate the \n                                                     results.                 \n   VEX.128.660F.WIG DC /r                            Add packed unsigned byte \n   VPADDUSB xmm1, xmm2,     B     V/V       AVX      integers from xmm3/m128  \n   xmm3/m128                                         to xmm2 and saturate the \n                                                     results.                 \n   VEX.128.66.0F.WIG DD /r                           Add packed unsigned word \n   VPADDUSW xmm1, xmm2,     B     V/V       AVX      integers from xmm3/m128  \n   xmm3/m128                                         to xmm2 and saturate the \n                                                     results.                 \n                                                     Add packed unsigned byte \n   VEX.256.66.0F.WIG DC /r                           integers from ymm2, and  \n   VPADDUSB ymm1, ymm2,     B     V/V       AVX2     ymm3/m256 and store the  \n   ymm3/m256                                         saturated results in     \n                                                     ymm1.                    \n                                                     Add packed unsigned word \n   VEX.256.66.0F.WIG DD /r                           integers from ymm2, and  \n   VPADDUSW ymm1, ymm2,     B     V/V       AVX2     ymm3/m256 and store the  \n   ymm3/m256                                         saturated results in     \n                                                     ymm1.                    \n                                                     Add packed unsigned byte \n   EVEX.128.66.0F.WIG DC /r                 AVX512VL integers from xmm2, and  \n   VPADDUSB xmm1 {k1}{z},   C     V/V       AVX512BW xmm3/m128 and store the  \n   xmm2, xmm3/m128                                   saturated results in     \n                                                     xmm1 under writemask k1. \n                                                     Add packed unsigned byte \n   EVEX.256.66.0F.WIG DC /r                 AVX512VL integers from ymm2, and  \n   VPADDUSB ymm1 {k1}{z},   C     V/V       AVX512BW ymm3/m256 and store the  \n   ymm2, ymm3/m256                                   saturated results in     \n                                                     ymm1 under writemask k1. \n                                                     Add packed unsigned byte \n   EVEX.512.66.0F.WIG DC /r                          integers from zmm2, and  \n   VPADDUSB zmm1 {k1}{z},   C     V/V       AVX512BW zmm3/m512 and store the  \n   zmm2, zmm3/m512                                   saturated results in     \n                                                     zmm1 under writemask k1. \n                                                     Add packed unsigned word \n   EVEX.128.66.0F.WIG DD /r                 AVX512VL integers from xmm2, and  \n   VPADDUSW xmm1 {k1}{z},   C     V/V       AVX512BW xmm3/m128 and store the  \n   xmm2, xmm3/m128                                   saturated results in     \n                                                     xmm1 under writemask k1. \n                                                     Add packed unsigned word \n   EVEX.256.66.0F.WIG DD /r                 AVX512VL integers from ymm2, and  \n   VPADDUSW ymm1 {k1}{z},   C     V/V       AVX512BW ymm3/m256 and store the  \n   ymm2, ymm3/m256                                   saturated results in     \n                                                     ymm1 under writemask k1. \n                                                     Add packed unsigned word \n   EVEX.512.66.0F.WIG DD /r                          integers from zmm2, and  \n   VPADDUSW zmm1 {k1}{z},   C     V/V       AVX512BW zmm3/m512 and store the  \n   zmm2, zmm3/m512                                   saturated results in     \n                                                     zmm1 under writemask k1. \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD add of the packed unsigned integers from the source\n   operand (second operand) and the destination operand (first operand), and\n   stores the packed integer results in the destination operand. See Figure\n   9-4 in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 1, for an illustration of a SIMD operation. Overflow is handled\n   with unsigned saturation, as described in the following paragraphs.\n\n   (V)PADDUSB performs a SIMD add of the packed unsigned integers with\n   saturation from the first source operand and second source operand and\n   stores the packed integer results in the destination operand. When an\n   individual byte result is beyond the range of an unsigned byte integer\n   (that is, greater than FFH), the saturated value of FFH is written to the\n   destination operand.\n\n   (V)PADDUSW performs a SIMD add of the packed unsigned word integers with\n   saturation from the first source operand and second source operand and\n   stores the packed integer results in the destination operand. When an\n   individual word result is beyond the range of an unsigned word integer\n   (that is, greater than FFFFH), the saturated value of FFFFH is written to\n   the destination operand.\n\n   EVEX encoded versions: The first source operand is an ZMM/YMM/XMM\n   register. The second source operand is an ZMM/YMM/XMM register or a\n   512/256/128-bit memory location. The destination is an ZMM/YMM/XMM\n   register.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding destination register destination are zeroed.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding register destination are\n   unmodified.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtph2w", "         VCVTPH2W \u2014 Convert Packed FP16 Values to Signed Word Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert packed FP16   \n   EVEX.128.66.MAP5.W0 7D /r                            values in             \n   VCVTPH2W xmm1{k1}{z},          A V/V     AVX512-FP16 xmm2/m128/m16bcst to  \n   xmm2/m128/m16bcst                        AVX512VL    signed word integers, \n                                                        and store the result  \n                                                        in xmm1.              \n                                                        Convert packed FP16   \n   EVEX.256.66.MAP5.W0 7D /r                            values in             \n   VCVTPH2W ymm1{k1}{z},          A V/V     AVX512-FP16 ymm2/m256/m16bcst to  \n   ymm2/m256/m16bcst                        AVX512VL    signed word integers, \n                                                        and store the result  \n                                                        in ymm1.              \n                                                        Convert packed FP16   \n   EVEX.512.66.MAP5.W0 7D /r                            values in             \n   VCVTPH2W zmm1{k1}{z},          A V/V     AVX512-FP16 zmm2/m512/m16bcst to  \n   zmm2/m512/m16bcst {er}                               signed word integers, \n                                                        and store the result  \n                                                        in zmm1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   signed word integers in the destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["pmaxub:pmaxuw", "              PMAXUB/PMAXUW \u2014 Maximum of Packed Unsigned Integers\n\n                              Op / 64/32 bit CPUID                            \n   Opcode/Instruction         En   Mode      Feature  Description\n                                   Support   Flag     \n                                                      Compare unsigned byte   \n   NP 0F DE /r^1 PMAXUB mm1,  A    V/V       SSE      integers in mm2/m64 and \n   mm2/m64                                            mm1 and returns maximum \n                                                      values.                 \n                                                      Compare packed unsigned \n   66 0F DE /r PMAXUB xmm1,                           byte integers in xmm1   \n   xmm2/m128                  A    V/V       SSE2     and xmm2/m128 and store \n                                                      packed maximum values   \n                                                      in xmm1.                \n                                                      Compare packed unsigned \n   66 0F 38 3E/r PMAXUW xmm1,                         word integers in        \n   xmm2/m128                  A    V/V       SSE4_1   xmm2/m128 and xmm1 and  \n                                                      stores maximum packed   \n                                                      values in xmm1.         \n                                                      Compare packed unsigned \n   VEX.128.66.0F DE /r                                byte integers in xmm2   \n   VPMAXUB xmm1, xmm2,        B    V/V       AVX      and xmm3/m128 and store \n   xmm3/m128                                          packed maximum values   \n                                                      in xmm1.                \n                                                      Compare packed unsigned \n   VEX.128.66.0F38 3E/r                               word integers in        \n   VPMAXUW xmm1, xmm2,        B    V/V       AVX      xmm3/m128 and xmm2 and  \n   xmm3/m128                                          store maximum packed    \n                                                      values in xmm1.         \n                                                      Compare packed unsigned \n   VEX.256.66.0F DE /r                                byte integers in ymm2   \n   VPMAXUB ymm1, ymm2,        B    V/V       AVX2     and ymm3/m256 and store \n   ymm3/m256                                          packed maximum values   \n                                                      in ymm1.                \n                                                      Compare packed unsigned \n   VEX.256.66.0F38 3E/r                               word integers in        \n   VPMAXUW ymm1, ymm2,        B    V/V       AVX2     ymm3/m256 and ymm2 and  \n   ymm3/m256                                          store maximum packed    \n                                                      values in ymm1.         \n                                                      Compare packed unsigned \n   EVEX.128.66.0F.WIG DE /r                           byte integers in xmm2   \n   VPMAXUB xmm1{k1}{z}, xmm2, C    V/V       AVX512VL and xmm3/m128 and store \n   xmm3/m128                                 AVX512BW packed maximum values   \n                                                      in xmm1 under writemask \n                                                      k1.                     \n                                                      Compare packed unsigned \n   EVEX.256.66.0F.WIG DE /r                           byte integers in ymm2   \n   VPMAXUB ymm1{k1}{z}, ymm2, C    V/V       AVX512VL and ymm3/m256 and store \n   ymm3/m256                                 AVX512BW packed maximum values   \n                                                      in ymm1 under writemask \n                                                      k1.                     \n                                                      Compare packed unsigned \n   EVEX.512.66.0F.WIG DE /r                           byte integers in zmm2   \n   VPMAXUB zmm1{k1}{z}, zmm2, C    V/V       AVX512BW and zmm3/m512 and store \n   zmm3/m512                                          packed maximum values   \n                                                      in zmm1 under writemask \n                                                      k1.                     \n                                                      Compare packed unsigned \n   EVEX.128.66.0F38.WIG 3E /r                         word integers in xmm2   \n   VPMAXUW xmm1{k1}{z}, xmm2, C    V/V       AVX512VL and xmm3/m128 and store \n   xmm3/m128                                 AVX512BW packed maximum values   \n                                                      in xmm1 under writemask \n                                                      k1.                     \n                                                      Compare packed unsigned \n   EVEX.256.66.0F38.WIG 3E /r                         word integers in ymm2   \n   VPMAXUW ymm1{k1}{z}, ymm2, C    V/V       AVX512VL and ymm3/m256 and store \n   ymm3/m256                                 AVX512BW packed maximum values   \n                                                      in ymm1 under writemask \n                                                      k1.                     \n                                                      Compare packed unsigned \n   EVEX.512.66.0F38.WIG 3E /r                         word integers in zmm2   \n   VPMAXUW zmm1{k1}{z}, zmm2, C    V/V       AVX512BW and zmm3/m512 and store \n   zmm3/m512                                          packed maximum values   \n                                                      in zmm1 under writemask \n                                                      k1.                     \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed unsigned byte, word integers in the\n   second source operand and the first source operand and returns the maximum\n   value for each pair of integers to the destination operand.\n\n   Legacy SSE version PMAXUB: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register;\n   The second source operand is a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n"],
	["vpermt2w:vpermt2d:vpermt2q:vpermt2ps:vpermt2pd", " VPERMT2W/VPERMT2D/VPERMT2Q/VPERMT2PS/VPERMT2PD \u2014 Full Permute From Two Tables\n                             Overwriting One Table\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Permute word integers from \n   EVEX.128.66.0F38.W1 7D                          two tables in xmm3/m128    \n   /r VPERMT2W xmm1       A     V/V       AVX512VL and xmm1 using indexes in  \n   {k1}{z}, xmm2,                         AVX512BW xmm2 and store the result  \n   xmm3/m128                                       in xmm1 using writemask    \n                                                   k1.                        \n                                                   Permute word integers from \n   EVEX.256.66.0F38.W1 7D                          two tables in ymm3/m256    \n   /r VPERMT2W ymm1       A     V/V       AVX512VL and ymm1 using indexes in  \n   {k1}{z}, ymm2,                         AVX512BW ymm2 and store the result  \n   ymm3/m256                                       in ymm1 using writemask    \n                                                   k1.                        \n                                                   Permute word integers from \n   EVEX.512.66.0F38.W1 7D                          two tables in zmm3/m512    \n   /r VPERMT2W zmm1       A     V/V       AVX512BW and zmm1 using indexes in  \n   {k1}{z}, zmm2,                                  zmm2 and store the result  \n   zmm3/m512                                       in zmm1 using writemask    \n                                                   k1.                        \n                                                   Permute double-words from  \n   EVEX.128.66.0F38.W0 7E                          two tables in              \n   /r VPERMT2D xmm1       B     V/V       AVX512VL xmm3/m128/m32bcst and xmm1 \n   {k1}{z}, xmm2,                         AVX512F  using indexes in xmm2 and  \n   xmm3/m128/m32bcst                               store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute double-words from  \n   EVEX.256.66.0F38.W0 7E                          two tables in              \n   /r VPERMT2D ymm1       B     V/V       AVX512VL ymm3/m256/m32bcst and ymm1 \n   {k1}{z}, ymm2,                         AVX512F  using indexes in ymm2 and  \n   ymm3/m256/m32bcst                               store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute double-words from  \n   EVEX.512.66.0F38.W0 7E                          two tables in              \n   /r VPERMT2D zmm1       B     V/V       AVX512F  zmm3/m512/m32bcst and zmm1 \n   {k1}{z}, zmm2,                                  using indices in zmm2 and  \n   zmm3/m512/m32bcst                               store the result in zmm1   \n                                                   using writemask k1.        \n                                                   Permute quad-words from    \n   EVEX.128.66.0F38.W1 7E                          two tables in              \n   /r VPERMT2Q xmm1       B     V/V       AVX512VL xmm3/m128/m64bcst and xmm1 \n   {k1}{z}, xmm2,                         AVX512F  using indexes in xmm2 and  \n   xmm3/m128/m64bcst                               store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute quad-words from    \n   EVEX.256.66.0F38.W1 7E                          two tables in              \n   /r VPERMT2Q ymm1       B     V/V       AVX512VL ymm3/m256/m64bcst and ymm1 \n   {k1}{z}, ymm2,                         AVX512F  using indexes in ymm2 and  \n   ymm3/m256/m64bcst                               store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute quad-words from    \n   EVEX.512.66.0F38.W1 7E                          two tables in              \n   /r VPERMT2Q zmm1       B     V/V       AVX512F  zmm3/m512/m64bcst and zmm1 \n   {k1}{z}, zmm2,                                  using indices in zmm2 and  \n   zmm3/m512/m64bcst                               store the result in zmm1   \n                                                   using writemask k1.        \n                                                   Permute single-precision   \n   EVEX.128.66.0F38.W0 7F                          floating-point values from \n   /r VPERMT2PS xmm1                      AVX512VL two tables in              \n   {k1}{z}, xmm2,         B     V/V       AVX512F  xmm3/m128/m32bcst and xmm1 \n   xmm3/m128/m32bcst                               using indexes in xmm2 and  \n                                                   store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute single-precision   \n   EVEX.256.66.0F38.W0 7F                          floating-point values from \n   /r VPERMT2PS ymm1                      AVX512VL two tables in              \n   {k1}{z}, ymm2,         B     V/V       AVX512F  ymm3/m256/m32bcst and ymm1 \n   ymm3/m256/m32bcst                               using indexes in ymm2 and  \n                                                   store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute single-precision   \n   EVEX.512.66.0F38.W0 7F                          floating-point values from \n   /r VPERMT2PS zmm1                               two tables in              \n   {k1}{z}, zmm2,         B     V/V       AVX512F  zmm3/m512/m32bcst and zmm1 \n   zmm3/m512/m32bcst                               using indices in zmm2 and  \n                                                   store the result in zmm1   \n                                                   using writemask k1.        \n                                                   Permute double precision   \n   EVEX.128.66.0F38.W1 7F                          floating-point values from \n   /r VPERMT2PD xmm1                      AVX512VL two tables in              \n   {k1}{z}, xmm2,         B     V/V       AVX512F  xmm3/m128/m64bcst and xmm1 \n   xmm3/m128/m64bcst                               using indexes in xmm2 and  \n                                                   store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute double precision   \n   EVEX.256.66.0F38.W1 7F                          floating-point values from \n   /r VPERMT2PD ymm1                      AVX512VL two tables in              \n   {k1}{z}, ymm2,         B     V/V       AVX512F  ymm3/m256/m64bcst and ymm1 \n   ymm3/m256/m64bcst                               using indexes in ymm2 and  \n                                                   store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute double precision   \n   EVEX.512.66.0F38.W1 7F                          floating-point values from \n   /r VPERMT2PD zmm1                               two tables in              \n   {k1}{z}, zmm2,         B     V/V       AVX512F  zmm3/m512/m64bcst and zmm1 \n   zmm3/m512/m64bcst                               using indices in zmm2 and  \n                                                   store the result in zmm1   \n                                                   using writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (r,w)  EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Permutes 16-bit/32-bit/64-bit values in the first operand and the third\n   operand (the second source operand) using indices in the second operand\n   (the first source operand) to select elements from the first and third\n   operands. The selected elements are written to the destination operand\n   (the first operand) according to the writemask k1.\n\n   The first and second operands are ZMM/YMM/XMM registers. The second\n   operand contains input indices to select elements from the two input\n   tables in the 1st and 3rd operands. The first operand is also the\n   destination of the result.\n\n   D/Q/PS/PD element versions: The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32/64-bit memory location. Broadcast from the low\n   32/64-bit memory location is performed if EVEX.b and the id bit for table\n   selection are set (selecting table_2).\n\n   Dword/PS versions: The id bit for table selection is bit 4/3/2, depending\n   on VL=512, 256, 128. Bits [3:0]/[2:0]/[1:0] of each element in the input\n   index vector select an element within the two source operands, If the id\n   bit is 0, table_1 (the first source) is selected; otherwise the second\n   source operand is selected.\n\n   Qword/PD versions: The id bit for table selection is bit 3/2/1, and bits\n   [2:0]/[1:0] /bit 0 selects element within each input table.\n\n   Word element versions: The second source operand can be a ZMM/YMM/XMM\n   register, or a 512/256/128-bit memory location. The id bit for table\n   selection is bit 5/4/3, and bits [4:0]/[3:0]/[2:0] selects element within\n   each input table.\n\n   Note that these instructions permit a 16-bit/32-bit/64-bit value in the\n   source operands to be copied to more than one location in the destination\n   operand. Note also that in this case, the same index can be reused for\n   example for a second iteration, while the table elements being permuted\n   are overwritten.\n\n   Bits (MAXVL-1:256/128) of the destination are zeroed for VL=256,128.\n"],
	["rdpkru", "               RDPKRU \u2014 Read Protection Key Rights for User Pages\n\n   Opcode*     Instruction Op/En 64/32bit Mode   CPUID        Description     \n                                 Support         Feature Flag \n   NP 0F 01 EE RDPKRU      ZO    V/V             OSPKE        Reads PKRU into \n                                                              EAX.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reads the value of PKRU into EAX and clears EDX. ECX must be 0 when RDPKRU\n   is executed; otherwise, a general-protection exception (#GP) occurs.\n\n   RDPKRU can be executed only if CR4.PKE = 1; otherwise, an invalid-opcode\n   exception (#UD) occurs. Software can discover the value of CR4.PKE by\n   examining CPUID.(EAX=07H,ECX=0H):ECX.OSPKE [bit 4].\n\n   On processors that support the Intel 64 Architecture, the high-order\n   32-bits of RCX are ignored and the high-order 32-bits of RDX and RAX are\n   cleared.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["aesdecwide256kl", "AESDECWIDE256KL \u2014 Perform 14 Rounds of AES Decryption Flow With Key Locker on 8\n                            BlocksUsing 256-Bit Key\n\n   Opcode/Instruction    Op/En 64/32-bit CPUID Feature Description            \n                               Mode      Flag          \n                                                       Decrypt XMM0-7 using   \n   F3 0F 38 D8                                         256-bit AES key        \n   !(11):011:bbb                                       indicated by handle at \n   AESDECWIDE256KL m512, A     V/V       AESKLEWIDE_KL m512 and store each    \n   <XMM0-7>                                            resultant block back   \n                                                       to its corresponding   \n                                                       register.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operands 2\u20149           \n   A     N/A   ModRM:r/m (r) Implicit XMM0-7 (r, w) \n\nDescription \u00b6\n\n   The AESDECWIDE256KL^1 instruction performs 14 rounds of AES to decrypt\n   each of the eight blocks in XMM0-7 using the 256-bit key indicated by the\n   handle from the second operand. It replaces each input block in XMM0-7\n   with its corresponding decrypted block if the operation succeeds (e.g.,\n   does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n\n   1. Further details on Key Locker and usage of this instruction can be\n   found here:\n\n  https://software.intel.com/content/www/us/en/develop/download/intel-key-locker-specification.html.\n  \u00b6\n"],
	["vpbroadcastm", "                VPBROADCASTM \u2014 Broadcast Mask to Vector Register\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Flag Description\n                                   Support   \n   EVEX.128.F3.0F38.W1 2A /r                 AVX512VL     Broadcast low byte  \n   VPBROADCASTMB2Q xmm1, k1  RM    V/V       AVX512CD     value in k1 to two  \n                                                          locations in xmm1.  \n   EVEX.256.F3.0F38.W1 2A /r                 AVX512VL     Broadcast low byte  \n   VPBROADCASTMB2Q ymm1, k1  RM    V/V       AVX512CD     value in k1 to four \n                                                          locations in ymm1.  \n                                                          Broadcast low byte  \n   EVEX.512.F3.0F38.W1 2A /r RM    V/V       AVX512CD     value in k1 to      \n   VPBROADCASTMB2Q zmm1, k1                               eight locations in  \n                                                          zmm1.               \n   EVEX.128.F3.0F38.W0 3A /r                 AVX512VL     Broadcast low word  \n   VPBROADCASTMW2D xmm1, k1  RM    V/V       AVX512CD     value in k1 to four \n                                                          locations in xmm1.  \n                                                          Broadcast low word  \n   EVEX.256.F3.0F38.W0 3A /r RM    V/V       AVX512VL     value in k1 to      \n   VPBROADCASTMW2D ymm1, k1                  AVX512CD     eight locations in  \n                                                          ymm1.               \n                                                          Broadcast low word  \n   EVEX.512.F3.0F38.W0 3A /r RM    V/V       AVX512CD     value in k1 to      \n   VPBROADCASTMW2D zmm1, k1                               sixteen locations   \n                                                          in zmm1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Broadcasts the zero-extended 64/32 bit value of the low byte/word of the\n   source operand (the second operand) to each 64/32 bit element of the\n   destination operand (the first operand). The source operand is an opmask\n   register. The destination operand is a ZMM register (EVEX.512), YMM\n   register (EVEX.256), or XMM register (EVEX.128).\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["vscalefsd", "          VSCALEFSD \u2014 Scale Scalar Float64 Values With Float64 Values\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n   EVEX.LLIG.66.0F38.W1 2D                         Scale the scalar double    \n   /r VSCALEFSD xmm1                               precision floating-point   \n   {k1}{z}, xmm2,          A     V/V       AVX512F values in xmm2 using the   \n   xmm3/m64{er}                                    value from xmm3/m64. Under \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a floating-point scale of the scalar double precision\n   floating-point value in the first source operand by multiplying it by 2 to\n   the power of the double precision floating-point value in second source\n   operand.\n\n   The equation of this operation is given by:\n\n   xmm1 := xmm2*2^floor(xmm3).\n\n   Floor(xmm3) means maximum integer value \u2264 xmm3.\n\n   If the result cannot be represented in double precision, then the proper\n   overflow response (for positive scaling operand), or the proper underflow\n   response (for negative scaling operand) is issued. The overflow and\n   underflow responses are dependent on the rounding mode (for IEEE-compliant\n   rounding), as well as on other settings in MXCSR (exception mask bits, FTZ\n   bit), and on the SAE bit.\n\n   EVEX encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or a memory location. The\n   destination operand is an XMM register conditionally updated with\n   writemask k1.\n\n   Handling of special-case input values are listed in Table 5-39 and Table\n   5-40.\n"],
	["vgatherqps:vgatherqpd", " VGATHERQPS/VGATHERQPD \u2014 Gather Packed Single, Packed Double with Signed Qword\n                                    Indices\n\n                                64/32 Bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Using signed qword         \n   EVEX.128.66.0F38.W0 93                          indices, gather            \n   /vsib VGATHERQPS xmm1  A     V/V       AVX512VL single-precision           \n   {k1}, vm64x                            AVX512F  floating-point values from \n                                                   memory using k1 as         \n                                                   completion mask.           \n                                                   Using signed qword         \n   EVEX.256.66.0F38.W0 93                          indices, gather            \n   /vsib VGATHERQPS xmm1  A     V/V       AVX512VL single-precision           \n   {k1}, vm64y                            AVX512F  floating-point values from \n                                                   memory using k1 as         \n                                                   completion mask.           \n                                                   Using signed qword         \n   EVEX.512.66.0F38.W0 93                          indices, gather            \n   /vsib VGATHERQPS ymm1  A     V/V       AVX512F  single-precision           \n   {k1}, vm64z                                     floating-point values from \n                                                   memory using k1 as         \n                                                   completion mask.           \n                                                   Using signed qword         \n   EVEX.128.66.0F38.W1 93                 AVX512VL indices, gather float64    \n   /vsib VGATHERQPD xmm1  A     V/V       AVX512F  vector into float64 vector \n   {k1}, vm64x                                     xmm1 using k1 as           \n                                                   completion mask.           \n                                                   Using signed qword         \n   EVEX.256.66.0F38.W1 93                 AVX512VL indices, gather float64    \n   /vsib VGATHERQPD ymm1  A     V/V       AVX512F  vector into float64 vector \n   {k1}, vm64y                                     ymm1 using k1 as           \n                                                   completion mask.           \n                                                   Using signed qword         \n   EVEX.512.66.0F38.W1 93                          indices, gather float64    \n   /vsib VGATHERQPD zmm1  A     V/V       AVX512F  vector into float64 vector \n   {k1}, vm64z                                     zmm1 using k1 as           \n                                                   completion mask.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2               Operand 3 Operand 4 \n         Tuple1                   BaseReg (R): VSIB:base,                     \n   A     Scalar     ModRM:reg (w) VectorReg(R):           N/A       N/A\n                                  VSIB:index              \n\n  Description \u00b6\n\n   A set of 8 single-precision/double precision faulting-point memory\n   locations pointed by base address BASE_ADDR and index vector V_INDEX with\n   scale SCALE are gathered. The result is written into vector a register.\n   The elements are specified via the VSIB (i.e., the index register is a\n   vector register, holding packed indices). Elements will only be loaded if\n   their corresponding mask bit is one. If an element\u2019s mask bit is not set,\n   the corresponding element of the destination register is left unchanged.\n   The entire mask register will be set to zero by this instruction unless it\n   triggers an exception.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask register (k1) are partially updated;\n   those elements that have been gathered are placed into the destination\n   register and have their mask bits set to zero. If any traps or interrupts\n   are pending from already gathered elements, they will be delivered in lieu\n   of the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data element size is less than the index element size, the higher\n   part of the destination register and the mask register do not correspond\n   to any elements being gathered. This instruction sets those higher parts\n   to zero. It may update these unused elements to one or both of those\n   registers even if the instruction triggers an exception, and even if the\n   instruction triggers the exception before gathering any elements.\n\n   Note that:\n\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination zmm will be completed (and non-faulting).\n       Individual elements closer to the MSB may or may not be completed. If\n       a given element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n\n   Note that the presence of VSIB byte is enforced in this instruction.\n   Hence, the instruction will #UD fault if ModRM.rm is different than 100b.\n\n   This instruction has special disp8*N and alignment rules. N is considered\n   to be the size of a single vector element.\n\n   The scaled index may require more bits to represent than the address bits\n   used by the processor (e.g., in 32-bit mode, if the scale is greater than\n   one). In this case, the most significant bits beyond the number of address\n   bits are ignored.\n\n   The instruction will #UD fault if the destination vector zmm1 is the same\n   as index vector VINDEX. The instruction will #UD fault if the k0 mask\n   register is specified.\n"],
	["addsubpd", "         ADDSUBPD \u2014 Packed Double Precision Floating-Point Add/Subtract\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Add/subtract double        \n   66 0F D0 /r ADDSUBPD    RM    V/V       SSE3    precision floating-point   \n   xmm1, xmm2/m128                                 values from xmm2/m128 to   \n                                                   xmm1.                      \n                                                   Add/subtract packed double \n   VEX.128.66.0F.WIG D0 /r                         precision floating-point   \n   VADDSUBPD xmm1, xmm2,   RVM   V/V       AVX     values from xmm3/mem to    \n   xmm3/m128                                       xmm2 and stores result in  \n                                                   xmm1.                      \n                                                   Add / subtract packed      \n   VEX.256.66.0F.WIG D0 /r                         double precision           \n   VADDSUBPD ymm1, ymm2,   RVM   V/V       AVX     floating-point values from \n   ymm3/m256                                       ymm3/mem to ymm2 and       \n                                                   stores result in ymm1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds odd-numbered double precision floating-point values of the first\n   source operand (second operand) with the corresponding double precision\n   floating-point values from the second source operand (third operand);\n   stores the result in the odd-numbered values of the destination operand\n   (first operand). Subtracts the even-numbered double precision\n   floating-point values from the second source operand from the\n   corresponding double precision floating values in the first source\n   operand; stores the result into the even-numbered values of the\n   destination operand.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified. See Figure 3-3.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   ADDSUBPD xmm1, xmm2/m128 xmm2/m128 [127:64] [63:0] RESULT: xmm1[127:64] +\n   xmm2/m128[127:64] xmm1[63:0] - xmm2/m128[63:0] xmm1 [127:64] [63:0] Figure\n   3-3. ADDSUBPD\u2014Packed Double Precision Floating-Point Add/Subtract\n"],
	["maxsd", "      MAXSD \u2014 Return Maximum Scalar Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Return the maximum scalar  \n   F2 0F 5F /r MAXSD xmm1,  A    V/V       SSE2    double precision           \n   xmm2/m64                                        floating-point value       \n                                                   between xmm2/m64 and xmm1. \n   VEX.LIG.F2.0F.WIG 5F /r                         Return the maximum scalar  \n   VMAXSD xmm1, xmm2,       B    V/V       AVX     double precision           \n   xmm3/m64                                        floating-point value       \n                                                   between xmm3/m64 and xmm2. \n   EVEX.LLIG.F2.0F.W1 5F /r                        Return the maximum scalar  \n   VMAXSD xmm1 {k1}{z},     C    V/V       AVX512F double precision           \n   xmm2, xmm3/m64{sae}                             floating-point value       \n                                                   between xmm3/m64 and xmm2. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Compares the low double precision floating-point values in the first\n   source operand and the second source operand, and returns the maximum\n   value to the low quadword of the destination operand. The second source\n   operand can be an XMM register or a 64-bit memory location. The first\n   source and destination operands are XMM registers. When the second source\n   operand is a memory operand, only 64 bits are accessed.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second source operand is returned. If a value in the second source\n   operand is an SNaN, that SNaN is returned unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   source operand, either a NaN or a valid floating-point value, is written\n   to the result. If instead of this behavior, it is required that the NaN of\n   either source operand be returned, the action of MAXSD can be emulated\n   using a sequence of instructions, such as, a comparison followed by AND,\n   ANDN, and OR.\n\n   128-bit Legacy SSE version: The destination and first source operand are\n   the same. Bits (MAXVL-1:64) of the corresponding destination register\n   remain unchanged.\n\n   VEX.128 and EVEX encoded version: Bits (127:64) of the XMM register\n   destination are copied from corresponding bits in the first source\n   operand. Bits (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination operand\n   is updated according to the writemask.\n\n   Software should ensure VMAXSD is encoded with VEX.L=0. Encoding VMAXSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["fsave:fnsave", "                       FSAVE/FNSAVE \u2014 Store x87 FPU State\n\n   Opcode   Instruction 64-Bit Compat/Leg Description                         \n                        Mode   Mode       \n                                          Store FPU state to m94byte or       \n   9B DD /6 FSAVE       Valid  Valid      m108byte after checking for pending \n            m94/108byte                   unmasked floating-point exceptions. \n                                          Then re-initialize the FPU.         \n                                          Store FPU environment to m94byte or \n            FNSAVE^1                      m108byte without checking for       \n   DD /6    m94/108byte Valid  Valid      pending unmasked floating-point     \n                                          exceptions. Then re-initialize the  \n                                          FPU.                                \n\n     1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Stores the current FPU state (operating environment and register stack) at\n   the specified destination in memory, and then re-initializes the FPU. The\n   FSAVE instruction checks for and handles pending unmasked floating-point\n   exceptions before storing the FPU state; the FNSAVE instruction does not.\n\n   The FPU operating environment consists of the FPU control word, status\n   word, tag word, instruction pointer, data pointer, and last opcode.\n   Figures 8-9 through 8-12 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, show the layout in memory of the\n   stored environment, depending on the operating mode of the processor\n   (protected or real) and the current operand-size attribute (16-bit or\n   32-bit). In virtual-8086 mode, the real mode layouts are used. The\n   contents of the FPU register stack are stored in the 80 bytes immediately\n   follow the operating environment image.\n\n   The saved image reflects the state of the FPU after all floating-point\n   instructions preceding the FSAVE/FNSAVE instruction in the instruction\n   stream have been executed.\n\n   After the FPU state has been saved, the FPU is reset to the same default\n   values it is set to with the FINIT/FNINIT instructions (see\n   \u201cFINIT/FNINIT\u2014Initialize Floating-Point Unit\u201d in this chapter).\n\n   The FSAVE/FNSAVE instructions are typically used when the operating system\n   needs to perform a context switch, an exception handler needs to use the\n   FPU, or an application program needs to pass a \u201cclean\u201d FPU to a procedure.\n\n   The assembler issues two instructions for the FSAVE instruction (an FWAIT\n   instruction followed by an FNSAVE instruction), and the processor executes\n   each of these instructions separately. If an exception is generated for\n   either of these instructions, the save EIP points to the instruction that\n   caused the exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   For Intel math coprocessors and FPUs prior to the Intel Pentium processor,\n   an FWAIT instruction should be executed before attempting to read from the\n   memory image stored with a prior FSAVE/FNSAVE instruction. This FWAIT\n   instruction helps ensure that the storage operation has been completed.\n\n   When operating a Pentium or Intel486 processor in MS-DOS compatibility\n   mode, it is possible (under unusual circumstances) for an FNSAVE\n   instruction to be interrupted prior to being executed to handle a pending\n   FPU exception. See the section titled \u201cNo-Wait FPU Instructions Can Get\n   FPU Interrupt in Window\u201d in Appendix D of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a description of\n   these circumstances. An FNSAVE instruction cannot be interrupted in this\n   way on later Intel processors, except for the Intel Quark^TM X1000\n   processor.\n\nFPU Flags Affected \u00b6\n\n   The C0, C1, C2, and C3 flags are saved and then cleared.\n"],
	["jmp", "                                   JMP \u2014 Jump\n\n   Opcode   Instruction  Op/En 64-Bit Compat/Leg Description                  \n                               Mode   Mode       \n                                                 Jump short, RIP = RIP +      \n   EB cb    JMP rel8     D     Valid  Valid      8-bit displacement sign      \n                                                 extended to 64-bits.         \n                                                 Jump near, relative,         \n   E9 cw    JMP rel16    D     N.S.   Valid      displacement relative to     \n                                                 next instruction. Not        \n                                                 supported in 64-bit mode.    \n                                                 Jump near, relative, RIP =   \n   E9 cd    JMP rel32    D     Valid  Valid      RIP + 32-bit displacement    \n                                                 sign extended to 64-bits.    \n                                                 Jump near, absolute          \n   FF /4    JMP r/m16    M     N.S.   Valid      indirect, address =          \n                                                 zero-extended r/m16. Not     \n                                                 supported in 64-bit mode.    \n                                                 Jump near, absolute          \n   FF /4    JMP r/m32    M     N.S.   Valid      indirect, address given in   \n                                                 r/m32. Not supported in      \n                                                 64-bit mode.                 \n                                                 Jump near, absolute          \n   FF /4    JMP r/m64    M     Valid  N.E.       indirect, RIP = 64-Bit       \n                                                 offset from register or      \n                                                 memory.                      \n   EA cd    JMP ptr16:16 S     Inv.   Valid      Jump far, absolute, address  \n                                                 given in operand.            \n   EA cp    JMP ptr16:32 S     Inv.   Valid      Jump far, absolute, address  \n                                                 given in operand.            \n   FF /5    JMP m16:16   M     Valid  Valid      Jump far, absolute indirect, \n                                                 address given in m16:16.     \n   FF /5    JMP m16:32   M     Valid  Valid      Jump far, absolute indirect, \n                                                 address given in m16:32.     \n   REX.W FF JMP m16:64   M     Valid  N.E.       Jump far, absolute indirect, \n   /5                                            address given in m16:64.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1                  Operand 2 Operand 3 Operand 4 \n   S     Segment + Absolute Address N/A       N/A       N/A       \n   D     Offset                     N/A       N/A       N/A       \n   M     ModRM:r/m (r)              N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Transfers program control to a different point in the instruction stream\n   without recording return information. The destination (target) operand\n   specifies the address of the instruction being jumped to. This operand can\n   be an immediate value, a general-purpose register, or a memory location.\n\n   This instruction can be used to execute four different types of jumps:\n\n     * Near jump\u2014A jump to an instruction within the current code segment\n       (the segment currently pointed to by the CS register), sometimes\n       referred to as an intrasegment jump.\n     * Short jump\u2014A near jump where the jump range is limited to \u2013128 to +127\n       from the current EIP value.\n     * Far jump\u2014A jump to an instruction located in a different segment than\n       the current code segment but at the same privilege level, sometimes\n       referred to as an intersegment jump.\n     * Task switch\u2014A jump to an instruction located in a different task.\n\n   A task switch can only be executed in protected mode (see Chapter 8, in\n   the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n   3A, for information on performing task switches with the JMP instruction).\n\n   Near and Short Jumps. When executing a near jump, the processor jumps to\n   the address (within the current code segment) that is specified with the\n   target operand. The target operand specifies either an absolute offset\n   (that is an offset from the base of the code segment) or a relative offset\n   (a signed displacement relative to the current\n\n   value of the instruction pointer in the EIP register). A near jump to a\n   relative offset of 8-bits (rel8) is referred to as a short jump. The CS\n   register is not changed on near and short jumps.\n\n   An absolute offset is specified indirectly in a general-purpose register\n   or a memory location (r/m16 or r/m32). The operand-size attribute\n   determines the size of the target operand (16 or 32 bits). Absolute\n   offsets are loaded directly into the EIP register. If the operand-size\n   attribute is 16, the upper two bytes of the EIP register are cleared,\n   resulting in a maximum instruction pointer size of 16 bits.\n\n   A relative offset (rel8, rel16, or rel32) is generally specified as a\n   label in assembly code, but at the machine code level, it is encoded as a\n   signed 8-, 16-, or 32-bit immediate value. This value is added to the\n   value in the EIP register. (Here, the EIP register contains the address of\n   the instruction following the JMP instruction). When using relative\n   offsets, the opcode (for short vs. near jumps) and the operand-size\n   attribute (for near relative jumps) determines the size of the target\n   operand (8, 16, or 32 bits).\n\n   Far Jumps in Real-Address or Virtual-8086 Mode. When executing a far jump\n   in real-address or virtual-8086 mode, the processor jumps to the code\n   segment and offset specified with the target operand. Here the target\n   operand specifies an absolute far address either directly with a pointer\n   (ptr16:16 or ptr16:32) or indirectly with a memory location (m16:16 or\n   m16:32). With the pointer method, the segment and address of the called\n   procedure is encoded in the instruction, using a 4-byte (16-bit operand\n   size) or 6-byte (32-bit operand size) far address immediate. With the\n   indirect method, the target operand specifies a memory location that\n   contains a 4-byte (16-bit operand size) or 6-byte (32-bit operand size)\n   far address. The far address is loaded directly into the CS and EIP\n   registers. If the operand-size attribute is 16, the upper two bytes of the\n   EIP register are cleared.\n\n   Far Jumps in Protected Mode. When the processor is operating in protected\n   mode, the JMP instruction can be used to perform the following three types\n   of far jumps:\n\n     * A far jump to a conforming or non-conforming code segment.\n     * A far jump through a call gate.\n     * A task switch.\n\n   (The JMP instruction cannot be used to perform inter-privilege-level far\n   jumps.)\n\n   In protected mode, the processor always uses the segment selector part of\n   the far address to access the corresponding descriptor in the GDT or LDT.\n   The descriptor type (code segment, call gate, task gate, or TSS) and\n   access rights determine the type of jump to be performed.\n\n   If the selected descriptor is for a code segment, a far jump to a code\n   segment at the same privilege level is performed. (If the selected code\n   segment is at a different privilege level and the code segment is\n   non-conforming, a general-protection exception is generated.) A far jump\n   to the same privilege level in protected mode is very similar to one\n   carried out in real-address or virtual-8086 mode. The target operand\n   specifies an absolute far address either directly with a pointer (ptr16:16\n   or ptr16:32) or indirectly with a memory location (m16:16 or m16:32). The\n   operand-size attribute determines the size of the offset (16 or 32 bits)\n   in the far address. The new code segment selector and its descriptor are\n   loaded into CS register, and the offset from the instruction is loaded\n   into the EIP register. Note that a call gate (described in the next\n   paragraph) can also be used to perform far call to a code segment at the\n   same privilege level. Using this mechanism provides an extra level of\n   indirection and is the preferred method of making jumps between 16-bit and\n   32-bit code segments.\n\n   When executing a far jump through a call gate, the segment selector\n   specified by the target operand identifies the call gate. (The offset part\n   of the target operand is ignored.) The processor then jumps to the code\n   segment specified in the call gate descriptor and begins executing the\n   instruction at the offset specified in the call gate. No stack switch\n   occurs. Here again, the target operand can specify the far address of the\n   call gate either directly with a pointer (ptr16:16 or ptr16:32) or\n   indirectly with a memory location (m16:16 or m16:32).\n\n   Executing a task switch with the JMP instruction is somewhat similar to\n   executing a jump through a call gate. Here the target operand specifies\n   the segment selector of the task gate for the task being switched to (and\n   the offset part of the target operand is ignored). The task gate in turn\n   points to the TSS for the task, which contains the segment selectors for\n   the task\u2019s code and stack segments. The TSS also contains the EIP value\n   for the next instruction that was to be executed before the task was\n   suspended. This instruction pointer value is loaded into the EIP register\n   so that the task begins executing again at this next instruction.\n\n   The JMP instruction can also specify the segment selector of the TSS\n   directly, which eliminates the indirection of the task gate. See Chapter 8\n   in Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n   3A, for detailed information on the mechanics of a task switch.\n\n   Note that when you execute at task switch with a JMP instruction, the\n   nested task flag (NT) is not set in the EFLAGS register and the new TSS\u2019s\n   previous task link field is not loaded with the old task\u2019s TSS selector. A\n   return to the previous task can thus not be carried out by executing the\n   IRET instruction. Switching tasks with the JMP instruction differs in this\n   regard from the CALL instruction which does set the NT flag and save the\n   previous task link information, allowing a return to the calling task with\n   an IRET instruction.\n\n   Refer to Chapter 6, \u201cProcedure Calls, Interrupts, and Exceptions\u201d and\n   Chapter 17, \u201cControl-flow Enforcement Technology (CET)\u201d in the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for CET\n   details.\n\n   In 64-Bit Mode. The instruction\u2019s operation size is fixed at 64 bits. If a\n   selector points to a gate, then RIP equals the 64-bit displacement taken\n   from gate; else RIP equals the zero-extended offset from the far pointer\n   referenced in the instruction.\n\n   See the summary chart at the beginning of this section for encoding data\n   and limits.\n\n   Instruction ordering. Instructions following a far jump may be fetched\n   from memory before earlier instructions complete execution, but they will\n   not execute (even speculatively) until all instructions prior to the far\n   jump have completed execution (the later instructions may execute before\n   data stored by the earlier instructions have become globally visible).\n\n   Instructions sequentially following a near indirect JMP instruction (i.e.,\n   those not at the target) may be executed speculatively. If software needs\n   to prevent this (e.g., in order to prevent a speculative execution side\n   channel), then an INT3 or LFENCE instruction opcode can be placed after\n   the near indirect JMP in order to block speculative execution.\n\nFlags Affected \u00b6\n\n   All flags are affected if a task switch occurs; no flags are affected if a\n   task switch does not occur.\n"],
	["eenter", "                           EENTER \u2014 Enters an Enclave\n\n                                 64/32 bit    CPUID                           \n   Opcode/Instruction      Op/En Mode Support Feature Description\n                                              Flag    \n                                                      This leaf function is   \n   EAX = 02H ENCLU[EENTER] IR    V/V          SGX1    used to enter an        \n                                                      enclave.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                    RBX          RCX        \n                     Content of Address of a Address of Address of IP         \n   IR    EENTER (In) RBX.CSSA   TCS (In)     AEP (In)   following EENTER      \n                     (Out)                              (Out)                 \n\n  Description \u00b6\n\n   The ENCLU[EENTER] instruction transfers execution to an enclave. At the\n   end of the instruction, the logical processor is executing in enclave mode\n   at the RIP computed as EnclaveBase + TCS.OENTRY. If the target address is\n   not within the CS segment (32-bit) or is not canonical (64-bit), a #GP(0)\n   results.\n\nEENTER Memory Parameter Semantics \u00b6\n\n   TCS            \n   Enclave access \n\n   EENTER is a serializing instruction. The instruction faults if any of the\n   following occurs:\n\n   Address in RBX is not properly         Any TCS.FLAGS\u2019s must-be-zero bit is \n   aligned.                               not zero.                           \n   TCS pointed to by RBX is not valid or  Current 32/64 mode does not match   \n   available or locked.                   the enclave mode in                 \n                                          SECS.ATTRIBUTES.MODE64.             \n                                          Either of TCS-specified FS and GS   \n   The SECS is in use.                    segment is not a subsets of the     \n                                          current DS segment.                 \n   Any one of DS, ES, CS, SS is not zero. If XSAVE available, CR4.OSXSAVE =   \n                                          0, but SECS.ATTRIBUTES.XFRM =\u0338 3.   \n                                          If CR4.OSXSAVE = 1,                 \n   CR4.OSFXSR =\u0338 1.                       SECS.ATTRIBUTES.XFRM is not a       \n                                          subset of XCR0.                     \n   If SECS.ATTRIBUTES.AEXNOTIFY =\u0338        \n   TCS.FLAGS.AEXNOTIFY and                \n   TCS.FLAGS.DBGOPTIN = 0.                \n\n   The following operations are performed by EENTER:\n\n     * RSP and RBP are saved in the current SSA frame on EENTER and are\n       automatically restored on EEXIT or interrupt.\n     * The AEP contained in RCX is stored into the TCS for use by AEXs.FS and\n       GS (including hidden portions) are saved and new values are\n       constructed using TCS.OFSBASE/GSBASE (32 and 64-bit mode) and\n       TCS.OFSLIMIT/GSLIMIT (32-bit mode only). The resulting segments must\n       be a subset of the DS segment.\n     * If CR4.OSXSAVE == 1, XCR0 is saved and replaced by\n       SECS.ATTRIBUTES.XFRM. The effect of RFLAGS.TF depends on whether the\n       enclave entry is opt-in or opt-out (see Section 40.1.2):\n          * On opt-out entry, TF is saved and cleared (it is restored on\n            EEXIT or AEX). Any attempt to set TF via a POPF instruction while\n            inside the enclave clears TF (see Section 40.2.5).\n          * On opt-out entry, TF is saved and cleared (it is restored on\n            EEXIT or AEX). Any attempt to set TF via a POPF instruction while\n            inside the enclave clears TF (see Section 40.2.5).\n          * On opt-in entry, a single-step debug exception is pended on the\n            instruction boundary immediately after EENTER (see Section\n            40.2.2).\n          * On opt-in entry, a single-step debug exception is pended on the\n            instruction boundary immediately after EENTER (see Section\n            40.2.2).\n     * All code breakpoints that do not overlap with ELRANGE are also\n       suppressed. If the entry is an opt-out entry, all code and data\n       breakpoints that overlap with the ELRANGE are suppressed.\n     * On opt-out entry, a number of performance monitoring counters and\n       behaviors are modified or suppressed (see Section 40.2.3):\n          * All performance monitoring activity on the current thread is\n            suppressed except for incrementing and firing of FIXED_CTR1 and\n            FIXED_CTR2.\n          * All performance monitoring activity on the current thread is\n            suppressed except for incrementing and firing of FIXED_CTR1 and\n            FIXED_CTR2.\n          * PEBS is suppressed.\n          * PEBS is suppressed.\n          * AnyThread counting on other threads is demoted to MyThread mode\n            and IA32_PERF_GLOBAL_STATUS[60] on that thread is set\n          * AnyThread counting on other threads is demoted to MyThread mode\n            and IA32_PERF_GLOBAL_STATUS[60] on that thread is set\n          * If the opt-out entry on a hardware thread results in suppression\n            of any performance monitoring, then the processor sets\n            IA32_PERF_GLOBAL_STATUS[60] and IA32_PERF_GLOBAL_STATUS[63].\n          * If the opt-out entry on a hardware thread results in suppression\n            of any performance monitoring, then the processor sets\n            IA32_PERF_GLOBAL_STATUS[60] and IA32_PERF_GLOBAL_STATUS[63].\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                            Parameter    Base Concurrency Restrictions\n                                                       On Conflict      \n   EENTER EENTER TCS [DS:RBX]      TCS [DS:RBX] \n   Shared EENTER TCS [DS:RBX]      \n\n   Table 38-62. Base Concurrency Restrictions of EENTER\n\n                    Additional Concurrency Restrictions\n                    vs. EACCEPT, EACCEPTCOPY, vs.  vs. EADD,                 \n                    EADD, EEXTEND, EINIT vs.       EEXTEND, EINIT            \n                    ETRACK, ETRACKC Access vs.     vs. EADD,      vs. ETRACK,\n                    ETRACK, ETRACKC Access On      EEXTEND, EINIT ETRACKC\n   Leaf   Parameter Conflict Access vs. ETRACK,    vs. ETRACK,  \n                    ETRACKC Access On Conflict     ETRACKC      \n                    EMODPE, EMODPR, EMODT       \n                    Access On Conflict Access   \n                    On Conflict Access Access   \n                    On Conflict Access On       \n                    Conflict                    \n   EENTER TCS       Concurrent                     Concurrent     Concurrent \n          [DS:RBX]  \n\n   Table 38-63. Additional Concurrency Restrictions of EENTER\n\n  Flags Affected \u00b6\n\n   RFLAGS.TF is cleared on opt-out entry.\n"],
	["kunpckbw:kunpckwd:kunpckdq", "             KUNPCKBW/KUNPCKWD/KUNPCKDQ \u2014 Unpack for Mask Registers\n\n                               64/32 bit    CPUID                             \n   Opcode/Instruction    Op/En Mode Support Feature  Description\n                                            Flag     \n   VEX.L1.66.0F.W0 4B /r                             Unpack 8-bit masks in k2 \n   KUNPCKBW k1, k2, k3   RVR   V/V          AVX512F  and k3 and write word    \n                                                     result in k1.            \n   VEX.L1.0F.W0 4B /r                                Unpack 16-bit masks in   \n   KUNPCKWD k1, k2, k3   RVR   V/V          AVX512BW k2 and k3 and write      \n                                                     doubleword result in k1. \n   VEX.L1.0F.W1 4B /r                                Unpack 32-bit masks in   \n   KUNPCKDQ k1, k2, k3   RVR   V/V          AVX512BW k2 and k3 and write      \n                                                     quadword result in k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3                              \n   RVR   ModRM:reg (w) VEX.1vvv (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Unpacks the lower 8/16/32 bits of the second and third operands (source\n   operands) into the low part of the first operand (destination operand),\n   starting from the low bytes. The result is zero-extended in the\n   destination.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vrndscaleph", "  VRNDSCALEPH \u2014 Round Packed FP16 Values to Include a Given Number of Fraction\n                                      Bits\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En bit     \n   Mode Flag CPUID Feature        \n   Instruction En bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En bit Mode Flag   \n   CPUID Feature Instruction En   \n   bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Round packed FP16     \n                                                        values in             \n                                                        xmm2/m128/m16bcst to  \n   EVEX.128.NP.0F3A.W0 08 /r /ib            AVX512-FP16 a number of fraction  \n   VRNDSCALEPH xmm1{k1}{z},       A V/V     AVX512VL    bits specified by the \n   xmm2/m128/m16bcst, imm8                              imm8 field. Store the \n                                                        result in xmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Round packed FP16     \n                                                        values in             \n                                                        ymm2/m256/m16bcst to  \n   EVEX.256.NP.0F3A.W0 08 /r /ib            AVX512-FP16 a number of fraction  \n   VRNDSCALEPH ymm1{k1}{z},       A V/V     AVX512VL    bits specified by the \n   ymm2/m256/m16bcst, imm8                              imm8 field. Store the \n                                                        result in ymm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Round packed FP16     \n                                                        values in             \n                                                        zmm2/m512/m16bcst to  \n   EVEX.512.NP.0F3A.W0 08 /r /ib                        a number of fraction  \n   VRNDSCALEPH zmm1{k1}{z},       A V/V     AVX512-FP16 bits specified by the \n   zmm2/m512/m16bcst {sae}, imm8                        imm8 field. Store the \n                                                        result in zmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) imm8 (r)  N/A       \n\n  Description \u00b6\n\n   This instruction rounds the FP16 values in the source operand by the\n   rounding mode specified in the immediate operand (see Table 5-32) and\n   places the result in the destination operand. The destination operand is\n   conditionally updated according to the writemask.\n\n   The rounding process rounds the input to an integral value, plus number\n   bits of fraction that are specified by imm8[7:4] (to be included in the\n   result), and returns the result as an FP16 value.\n\n   Note that no overflow is induced while executing this instruction\n   (although the source is scaled by the imm8[7:4] value).\n\n   The immediate operand also specifies control fields for the rounding\n   operation. Three bit fields are defined and shown in Table 5-32, \u201cImm8\n   Controls for VRNDSCALEPH/VRNDSCALESH.\u201d Bit 3 of the immediate byte\n   controls the processor behavior for a precision exception, bit 2 selects\n   the source of rounding mode control, and bits 1:0 specify a non-sticky\n   rounding-mode value.\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN.\n\n   The sign of the result of this instruction is preserved, including the\n   sign of zero. Special cases are described in Table 5-33.\n\n   The formula of the operation on each data element for VRNDSCALEPH is\n\n   ROUND(x) = 2^\u2212M *Round_to_INT(x * 2^M, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   M=imm[7:4];\n\n   The operation of x * 2^M is computed as if the exponent range is unlimited\n   (i.e., no overflow ever occurs).\n\n   If this instruction encoding\u2019s SPE bit (bit 3) in the immediate operand is\n   1, VRNDSCALEPH can set MXCSR.UE without MXCSR.PE.\n\n   EVEX.vvvv is reserved and must be 1111b, otherwise instructions will #UD.\n\n   Imm8 Bits Description                                                      \n   imm8[7:4] Number of fixed points to preserve.                              \n   imm8[3]   Suppress Precision Exception (SPE) 0b00: Implies use of MXCSR    \n             exception mask. 0b01: Implies suppress.                          \n   imm8[2]   Round Select (RS) 0b00: Implies use of imm8[1:0]. 0b01: Implies  \n             use of MXCSR.                                                    \n   imm8[1:0] Round Control Override: 0b00: Round nearest even. 0b01: Round    \n             down. 0b10: Round up. 0b11: Truncate.                            \n\n   Table 5-32. Imm8 Controls for VRNDSCALEPH/VRNDSCALESH\n\n   Input Value Returned Value         \n   Src1 = \u00b1\u221e   Src1                   \n   Src1 = \u00b1NaN Src1 converted to QNaN \n   Src1 = \u00b10   Src1                   \n\n   Table 5-33. VRNDSCALEPH/VRNDSCALESH Special Cases\n"],
	["tpause", "                              TPAUSE \u2014 Timed PAUSE\n\n   Opcode /           64/32 bit CPUID                                         \n   Instruction  Op/En Mode      Feature Description\n                      Support   Flag    \n   66 0F AE /6                          Directs the processor to enter an     \n   TPAUSE r32,  A     V/V       WAITPKG implementation-dependent optimized    \n   <edx>, <eax>                         state until the TSC reaches the value \n                                        in EDX:EAX.                           \n\nInstruction Operand Encoding^1 \u00b6\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   TPAUSE instructs the processor to enter an implementation-dependent\n   optimized state. There are two such optimized states to choose from:\n   light-weight power/performance optimized state, and improved\n   power/performance optimized state. The selection between the two is\n   governed by the explicit input register bit[0] source operand.\n\n   TPAUSE is available when CPUID.7.0:ECX.WAITPKG[bit 5] is enumerated as 1.\n   TPAUSE may be executed at any privilege level. This instruction\u2019s\n   operation is the same in non-64-bit modes and in 64-bit mode.\n\n   Unlike PAUSE, the TPAUSE instruction will not cause an abort when used\n   inside a transactional region, described in the chapter Chapter 16,\n   \u201cProgramming with Intel\u00ae Transactional Synchronization Extensions,\u201d of the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n\n     1. The Mod field of the ModR/M byte must have value 11B.\n\n   The input register contains information such as the preferred optimized\n   state the processor should enter as described in the following table. Bits\n   other than bit 0 are reserved and will result in #GP if non-zero.\n\n   Bit Value  State Name Wakeup Time Power Savings Other Benefits             \n                                                   Improves performance of    \n   bit[0] = 0 C0.2       Slower      Larger        the other SMT thread(s) on \n                                                   the same core.             \n   bit[0] = 1 C0.1       Faster      Smaller       N/A                        \n   bits[31:1] N/A        N/A         N/A           Reserved                   \n\n   Table 4-20. TPAUSE Input Register Bit Definitions\n\n   The instruction execution wakes up when the time-stamp counter reaches or\n   exceeds the implicit EDX:EAX 64-bit input value.\n\n   Prior to executing the TPAUSE instruction, an operating system may specify\n   the maximum delay it allows the processor to suspend its operation. It can\n   do so by writing TSC-quanta value to the following 32-bit MSR\n   (IA32_UMWAIT_CONTROL at MSR index E1H):\n\n     * IA32_UMWAIT_CONTROL[31:2] \u2014 Determines the maximum time in TSC-quanta\n       that the processor can reside in either C0.1 or C0.2. A zero value\n       indicates no maximum time. The maximum time value is a 32-bit value\n       where the upper 30 bits come from this field and the lower two bits\n       are zero.\n     * IA32_UMWAIT_CONTROL[1] \u2014 Reserved.\n     * IA32_UMWAIT_CONTROL[0] \u2014 C0.2 is not allowed by the OS. Value of \u201c1\u201d\n       means all C0.2 requests revert to C0.1.\n\n   If the processor that executed a TPAUSE instruction wakes due to the\n   expiration of the operating system time-limit, the instructions sets\n   RFLAGS.CF; otherwise, that flag is cleared.\n\n   The following additional events cause the processor to exit the\n   implementation-dependent optimized state: a store to the read-set range\n   within the transactional region, an NMI or SMI, a debug exception, a\n   machine check exception, the BINIT# signal, the INIT# signal, and the\n   RESET# signal.\n\n   Other implementation-dependent events may cause the processor to exit the\n   implementation-dependent optimized state proceeding to the instruction\n   following TPAUSE. In addition, an external interrupt causes the processor\n   to exit the implementation-dependent optimized state regardless of whether\n   maskable-interrupts are inhibited (EFLAGS.IF =0). It should be noted that\n   if maskable-interrupts are inhibited execution will proceed to the\n   instruction following TPAUSE.\n"],
	["cvtpi2pd", "      CVTPI2PD \u2014 Convert Packed Dword Integers to Packed Double Precision\n                             Floating-Point Values\n\n   Opcode/Instruction   Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                Convert two packed signed     \n   66 0F 2A /r CVTPI2PD                         doubleword integers from      \n   xmm, mm/m64^1        RM    Valid  Valid      mm/mem64 to two packed double \n                                                precision floating-point      \n                                                values in xmm.                \n\n     1. Operation is different for different operand sets; see the\n     Description section.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two packed signed doubleword integers in the source operand\n   (second operand) to two packed double precision floating-point values in\n   the destination operand (first operand).\n\n   The source operand can be an MMX technology register or a 64-bit memory\n   location. The destination operand is an XMM register. In addition,\n   depending on the operand configuration:\n\n     * For operands xmm, mm: the instruction causes a transition from x87 FPU\n       to MMX technology operation (that is, the x87 FPU top-of-stack pointer\n       is set to 0 and the x87 FPU tag word is set to all 0s [valid]). If\n       this instruction is executed while an x87 FPU floating-point exception\n       is pending, the exception is handled before the CVTPI2PD instruction\n       is executed.\n     * For operands xmm, m64: the instruction does not cause a transition to\n       MMX technology and does not take x87 FPU exceptions.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["out", "                              OUT \u2014 Output to Port\n\n   Opcode^1\n\n         Instruction   Op/En 64-Bit Mode Compat/Leg Mode Description          \n                                                         Output byte in AL to \n   E6 ib OUT imm8, AL  I     Valid       Valid           I/O port address     \n                                                         imm8.                \n                                                         Output word in AX to \n   E7 ib OUT imm8, AX  I     Valid       Valid           I/O port address     \n                                                         imm8.                \n                                                         Output doubleword in \n   E7 ib OUT imm8, EAX I     Valid       Valid           EAX to I/O port      \n                                                         address imm8.        \n                                                         Output byte in AL to \n   EE    OUT DX, AL    ZO    Valid       Valid           I/O port address in  \n                                                         DX.                  \n                                                         Output word in AX to \n   EF    OUT DX, AX    ZO    Valid       Valid           I/O port address in  \n                                                         DX.                  \n                                                         Output doubleword in \n   EF    OUT DX, EAX   ZO    Valid       Valid           EAX to I/O port      \n                                                         address in DX.       \n\n     1. See the IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   I     imm8      N/A       N/A       N/A       \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Copies the value from the second operand (source operand) to the I/O port\n   specified with the destination operand (first operand). The source operand\n   can be register AL, AX, or EAX, depending on the size of the port being\n   accessed (8, 16, or 32 bits, respectively); the destination operand can be\n   a byte-immediate or the DX register. Using a byte immediate allows I/O\n   port addresses 0 to 255 to be accessed; using the DX register as a source\n   operand allows I/O ports from 0 to 65,535 to be accessed.\n\n   The size of the I/O port being accessed is determined by the opcode for an\n   8-bit I/O port or by the operand-size attribute of the instruction for a\n   16- or 32-bit I/O port.\n\n   At the machine code level, I/O instructions are shorter when accessing\n   8-bit I/O ports. Here, the upper eight bits of the port address will be 0.\n\n   This instruction is only useful for accessing I/O ports located in the\n   processor\u2019s I/O address space. See Chapter 19, \u201cInput/Output,\u201d in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1,\n   for more information on accessing I/O ports in the I/O address space.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   After executing an OUT instruction, the Pentium^\u00ae processor ensures that\n   the EWBE# pin has been sampled active before it begins to execute the next\n   instruction. (Note that the instruction can be prefetched if EWBE# is not\n   active, but it will not be executed until the EWBE# pin is sampled\n   active.) Only the Pentium processor family has the EWBE# pin.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["rdseed", "                           RDSEED \u2014 Read Random SEED\n\n                                 64/32 bit    CPUID                           \n   Opcode/Instruction      Op/En Mode Support Feature Description\n                                              Flag    \n                                                      Read a 16-bit NIST      \n                                                      SP800-90B & C compliant \n   NFx 0F C7 /7 RDSEED r16 M     V/V          RDSEED  random value and store  \n                                                      in the destination      \n                                                      register.               \n                                                      Read a 32-bit NIST      \n                                                      SP800-90B & C compliant \n   NFx 0F C7 /7 RDSEED r32 M     V/V          RDSEED  random value and store  \n                                                      in the destination      \n                                                      register.               \n                                                      Read a 64-bit NIST      \n   NFx REX.W + 0F C7 /7                               SP800-90B & C compliant \n   RDSEED r64              M     V/I          RDSEED  random value and store  \n                                                      in the destination      \n                                                      register.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads a hardware generated random value and store it in the destination\n   register. The random value is generated from an Enhanced NRBG (Non\n   Deterministic Random Bit Generator) that is compliant to NIST SP800-90B\n   and NIST SP800-90C in the XOR construction mode. The size of the random\n   value is determined by the destination register size and operating mode.\n   The Carry Flag indicates whether a random value is available at the time\n   the instruction is executed. CF=1 indicates that the data in the\n   destination is valid. Otherwise CF=0 and the data in the destination\n   operand will be returned as zeros for the specified width. All other flags\n   are forced to 0 in either situation. Software must check the state of CF=1\n   for determining if a valid random seed value has been returned, otherwise\n   it is expected to loop and retry execution of RDSEED (see Section 1.2).\n\n   The RDSEED instruction is available at all privilege levels. The RDSEED\n   instruction executes normally either inside or outside a transaction\n   region.\n\n   In 64-bit mode, the instruction's default operand size is 32 bits. Using a\n   REX prefix in the form of REX.B permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bit operands. See the summary chart at the beginning of this section for\n   encoding data and limits.\n\nFlags Affected \u00b6\n\n   The CF flag is set according to the result (see the \u201cOperation\u201d section\n   above). The OF, SF, ZF, AF, and PF flags are set to 0.\n"],
	["rsqrtss", "     RSQRTSS \u2014 Compute Reciprocal of Square Root of Scalar Single Precision\n                              Floating-Point Value\n\n                                 64/32 bit CPUID                              \n   Opcode*/Instruction     Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Computes the approximate   \n                                                   reciprocal of the square   \n   F3 0F 52 /r RSQRTSS                             root of the low single     \n   xmm1, xmm2/m32          RM    V/V       SSE     precision floating-point   \n                                                   value in xmm2/m32 and      \n                                                   stores the results in      \n                                                   xmm1.                      \n                                                   Computes the approximate   \n                                                   reciprocal of the square   \n                                                   root of the low single     \n                                                   precision floating-point   \n   VEX.LIG.F3.0F.WIG 52 /r                         value in xmm3/m32 and      \n   VRSQRTSS xmm1, xmm2,    RVM   V/V       AVX     stores the results in      \n   xmm3/m32                                        xmm1. Also, upper single   \n                                                   precision floating-point   \n                                                   values (bits[127:32]) from \n                                                   xmm2 are copied to         \n                                                   xmm1[127:32].              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Computes an approximate reciprocal of the square root of the low single\n   precision floating-point value in the source operand (second operand)\n   stores the single precision floating-point result in the destination\n   operand. The source operand can be an XMM register or a 32-bit memory\n   location. The destination operand is an XMM register. The three high-order\n   doublewords of the destination operand remain unchanged. See Figure 10-6\n   in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 1, for an illustration of a scalar single precision floating-point\n   operation.\n\n   The relative error for this approximation is:\n\n   |Relative Error| \u2264 1.5 \u2217 2^\u221212\n\n   The RSQRTSS instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e of the sign of the\n   source value is returned. A denormal source value is treated as a 0.0 (of\n   the same sign). When a source value is a negative value (other than \u22120.0),\n   a floating-point indefinite is returned. When a source value is an SNaN or\n   QNaN, the SNaN is converted to a QNaN or the source QNaN is returned.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:32) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n"],
	["vrsqrt28ss", "   VRSQRT28SS \u2014 Approximation to the Reciprocal Square Root of Scalar Single\n       Precision Floating-Point Value With Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes approximate      \n                                                    reciprocal square root    \n                                                    (<2^-28 relative error)   \n                                                    of the scalar             \n                                                    single-precision          \n   EVEX.LLIG.66.0F38.W0 CD                          floating-point value from \n   /r VRSQRT28SS xmm1      A     V/V       AVX512ER xmm3/m32 and stores       \n   {k1}{z}, xmm2, xmm3/m32                          result in xmm1with        \n   {sae}                                            writemask k1. Also, upper \n                                                    3 single-precision        \n                                                    floating-point value      \n                                                    (bits[127:32]) from xmm2  \n                                                    is copied to              \n                                                    xmm1[127:32].             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4      \n   A Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   Computes the reciprocal square root of the low float32 value in the second\n   source operand (the third operand) and store the result to the destination\n   operand (the first operand). The approximate reciprocal square root is\n   evaluated with less than 2^-28 of maximum relative error prior to final\n   rounding. The final result is rounded to < 2^-23 relative error before\n   written to the low float32 element of the destination according to the\n   writemask k1. Bits 127:32 of the destination is copied from the\n   corresponding bits of the first source operand (the second operand).\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. Negative (non-zero) source numbers, as well as -\u221e,\n   return the canonical NaN and set the Invalid Flag (#I).\n\n   A value of -0 must return -\u221e and set the DivByZero flags (#Z). Negative\n   numbers should return NaN and set the Invalid flag (#I). Note however that\n   the instruction flush input denormals to zero of the same sign, so\n   negative denormals return -\u221e and set the DivByZero flag.\n\n   The first source operand is an XMM register. The second source operand is\n   an XMM register or a 32-bit memory location. The destination operand is a\n   XMM register.\n\n  A numerically exact implementation of VRSQRT28xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["paddsb:paddsw", "       PADDSB/PADDSW \u2014 Add Packed Signed Integers with Signed Saturation\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Add packed signed byte   \n   NP 0F EC /r^1 PADDSB mm, A     V/V       MMX      integers from mm/m64 and \n   mm/m64                                            mm and saturate the      \n                                                     results.                 \n                                                     Add packed signed byte   \n   66 0F EC /r PADDSB xmm1, A     V/V       SSE2     integers from xmm2/m128  \n   xmm2/m128                                         and xmm1 saturate the    \n                                                     results.                 \n                                                     Add packed signed word   \n   NP 0F ED /r^1 PADDSW mm, A     V/V       MMX      integers from mm/m64 and \n   mm/m64                                            mm and saturate the      \n                                                     results.                 \n                                                     Add packed signed word   \n   66 0F ED /r PADDSW xmm1, A     V/V       SSE2     integers from xmm2/m128  \n   xmm2/m128                                         and xmm1 and saturate    \n                                                     the results.             \n   VEX.128.66.0F.WIG EC /r                           Add packed signed byte   \n   VPADDSB xmm1, xmm2,      B     V/V       AVX      integers from xmm3/m128  \n   xmm3/m128                                         and xmm2 saturate the    \n                                                     results.                 \n   VEX.128.66.0F.WIG ED /r                           Add packed signed word   \n   VPADDSW xmm1, xmm2,      B     V/V       AVX      integers from xmm3/m128  \n   xmm3/m128                                         and xmm2 and saturate    \n                                                     the results.             \n                                                     Add packed signed byte   \n   VEX.256.66.0F.WIG EC /r                           integers from ymm2, and  \n   VPADDSB ymm1, ymm2,      B     V/V       AVX2     ymm3/m256 and store the  \n   ymm3/m256                                         saturated results in     \n                                                     ymm1.                    \n                                                     Add packed signed word   \n   VEX.256.66.0F.WIG ED /r                           integers from ymm2, and  \n   VPADDSW ymm1, ymm2,      B     V/V       AVX2     ymm3/m256 and store the  \n   ymm3/m256                                         saturated results in     \n                                                     ymm1.                    \n                                                     Add packed signed byte   \n   EVEX.128.66.0F.WIG EC /r                 AVX512VL integers from xmm2, and  \n   VPADDSB xmm1 {k1}{z},    C     V/V       AVX512BW xmm3/m128 and store the  \n   xmm2, xmm3/m128                                   saturated results in     \n                                                     xmm1 under writemask k1. \n                                                     Add packed signed byte   \n   EVEX.256.66.0F.WIG EC /r                 AVX512VL integers from ymm2, and  \n   VPADDSB ymm1 {k1}{z},    C     V/V       AVX512BW ymm3/m256 and store the  \n   ymm2, ymm3/m256                                   saturated results in     \n                                                     ymm1 under writemask k1. \n                                                     Add packed signed byte   \n   EVEX.512.66.0F.WIG EC /r                          integers from zmm2, and  \n   VPADDSB zmm1 {k1}{z},    C     V/V       AVX512BW zmm3/m512 and store the  \n   zmm2, zmm3/m512                                   saturated results in     \n                                                     zmm1 under writemask k1. \n                                                     Add packed signed word   \n   EVEX.128.66.0F.WIG ED /r                 AVX512VL integers from xmm2, and  \n   VPADDSW xmm1 {k1}{z},    C     V/V       AVX512BW xmm3/m128 and store the  \n   xmm2, xmm3/m128                                   saturated results in     \n                                                     xmm1 under writemask k1. \n                                                     Add packed signed word   \n   EVEX.256.66.0F.WIG ED /r                 AVX512VL integers from ymm2, and  \n   VPADDSW ymm1 {k1}{z},    C     V/V       AVX512BW ymm3/m256 and store the  \n   ymm2, ymm3/m256                                   saturated results in     \n                                                     ymm1 under writemask k1. \n                                                     Add packed signed word   \n   EVEX.512.66.0F.WIG ED /r                          integers from zmm2, and  \n   VPADDSW zmm1 {k1}{z},    C     V/V       AVX512BW zmm3/m512 and store the  \n   zmm2, zmm3/m512                                   saturated results in     \n                                                     zmm1 under writemask k1. \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD add of the packed signed integers from the source operand\n   (second operand) and the destination operand (first operand), and stores\n   the packed integer results in the destination operand. See Figure 9-4 in\n   the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n   1, for an illustration of a SIMD operation. Overflow is handled with\n   signed saturation, as described in the following paragraphs.\n\n   (V)PADDSB performs a SIMD add of the packed signed integers with\n   saturation from the first source operand and second source operand and\n   stores the packed integer results in the destination operand. When an\n   individual byte result is beyond the range of a signed byte integer (that\n   is, greater than 7FH or less than 80H), the saturated value of 7FH or 80H,\n   respectively, is written to the destination operand.\n\n   (V)PADDSW performs a SIMD add of the packed signed word integers with\n   saturation from the first source operand and second source operand and\n   stores the packed integer results in the destination operand. When an\n   individual word result is beyond the range of a signed word integer (that\n   is, greater than 7FFFH or less than 8000H), the saturated value of 7FFFH\n   or 8000H, respectively, is written to the destination operand.\n\n   EVEX encoded versions: The first source operand is an ZMM/YMM/XMM\n   register. The second source operand is an ZMM/YMM/XMM register or a memory\n   location. The destination operand is an ZMM/YMM/XMM register.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding register destination are zeroed.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding register destination are\n   unmodified.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vptestnmb:vptestnmw:vptestnmd:vptestnmq", "         VPTESTNMB/VPTESTNMW/VPTESTNMD/VPTESTNMQ \u2014 Logical NAND and Set\n\n                                 64/32 bit                                    \n   Opcode/Instruction      Op/En Mode      CPUID    Description\n                                 Support   \n                                                    Bitwise NAND of packed    \n                                                    byte integers in xmm2 and \n   EVEX.128.F3.0F38.W0 26                           xmm3/m128 and set mask k2 \n   /r VPTESTNMB k2 {k1},   A     V/V       AVX512VL to reflect the            \n   xmm2, xmm3/m128                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    byte integers in ymm2 and \n   EVEX.256.F3.0F38.W0 26                           ymm3/m256 and set mask k2 \n   /r VPTESTNMB k2 {k1},   A     V/V       AVX512VL to reflect the            \n   ymm2, ymm3/m256                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    byte integers in zmm2 and \n   EVEX.512.F3.0F38.W0 26                           zmm3/m512 and set mask k2 \n   /r VPTESTNMB k2 {k1},   A     V/V       AVX512F  to reflect the            \n   zmm2, zmm3/m512                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    word integers in xmm2 and \n   EVEX.128.F3.0F38.W1 26                           xmm3/m128 and set mask k2 \n   /r VPTESTNMW k2 {k1},   A     V/V       AVX512VL to reflect the            \n   xmm2, xmm3/m128                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    word integers in ymm2 and \n   EVEX.256.F3.0F38.W1 26                           ymm3/m256 and set mask k2 \n   /r VPTESTNMW k2 {k1},   A     V/V       AVX512VL to reflect the            \n   ymm2, ymm3/m256                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    word integers in zmm2 and \n   EVEX.512.F3.0F38.W1 26                           zmm3/m512 and set mask k2 \n   /r VPTESTNMW k2 {k1},   A     V/V       AVX512F  to reflect the            \n   zmm2, zmm3/m512                         AVX512BW zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    doubleword integers in    \n                                                    xmm2 and                  \n   EVEX.128.F3.0F38.W0 27                  AVX512VL xmm3/m128/m32bcst and set \n   /r VPTESTNMD k2 {k1},   B     V/V       AVX512F  mask k2 to reflect the    \n   xmm2, xmm3/m128/m32bcst                          zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    doubleword integers in    \n                                                    ymm2 and                  \n   EVEX.256.F3.0F38.W0 27                  AVX512VL ymm3/m256/m32bcst and set \n   /r VPTESTNMD k2 {k1},   B     V/V       AVX512F  mask k2 to reflect the    \n   ymm2, ymm3/m256/m32bcst                          zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    doubleword integers in    \n                                                    zmm2 and                  \n   EVEX.512.F3.0F38.W0 27                           zmm3/m512/m32bcst and set \n   /r VPTESTNMD k2 {k1},   B     V/V       AVX512F  mask k2 to reflect the    \n   zmm2, zmm3/m512/m32bcst                          zero/non-zero status of   \n                                                    each element of the       \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    quadword integers in xmm2 \n   EVEX.128.F3.0F38.W1 27                           and xmm3/m128/m64bcst and \n   /r VPTESTNMQ k2 {k1},   B     V/V       AVX512VL set mask k2 to reflect    \n   xmm2, xmm3/m128/m64bcst                 AVX512F  the zero/non-zero status  \n                                                    of each element of the    \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    quadword integers in ymm2 \n   EVEX.256.F3.0F38.W1 27                           and ymm3/m256/m64bcst and \n   /r VPTESTNMQ k2 {k1},   B     V/V       AVX512VL set mask k2 to reflect    \n   ymm2, ymm3/m256/m64bcst                 AVX512F  the zero/non-zero status  \n                                                    of each element of the    \n                                                    result, under writemask   \n                                                    k1.                       \n                                                    Bitwise NAND of packed    \n                                                    quadword integers in zmm2 \n   EVEX.512.F3.0F38.W1 27                           and zmm3/m512/m64bcst and \n   /r VPTESTNMQ k2 {k1},   B     V/V       AVX512F  set mask k2 to reflect    \n   zmm2, zmm3/m512/m64bcst                          the zero/non-zero status  \n                                                    of each element of the    \n                                                    result, under writemask   \n                                                    k1.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a bitwise logical NAND operation on the\n   byte/word/doubleword/quadword element of the first source operand (the\n   second operand) with the corresponding element of the second source\n   operand (the third operand) and stores the logical comparison result into\n   each bit of the destination operand (the first operand) according to the\n   writemask k1. Each bit of the result is set to 1 if the bitwise AND of the\n   corresponding elements of the first and second src operands is zero;\n   otherwise it is set to 0.\n\n   EVEX encoded VPTESTNMD/Q: The first source operand is a ZMM/YMM/XMM\n   registers. The second source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 32/64-bit memory location. The destination is updated according to\n   the writemask.\n\n   EVEX encoded VPTESTNMB/W: The first source operand is a ZMM/YMM/XMM\n   registers. The second source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location. The destination is updated according to\n   the writemask.\n"],
	["xrstor", "                   XRSTOR \u2014 Restore Processor Extended States\n\n   Opcode /           Op/En 64/32 bit Mode CPUID        Description           \n   Instruction              Support        Feature Flag \n   NP 0F AE /5 XRSTOR                                   Restore state         \n   mem                M     V/V            XSAVE        components specified  \n                                                        by EDX:EAX from mem.  \n   NP REX.W + 0F AE                                     Restore state         \n   /5 XRSTOR64 mem    M     V/N.E.         XSAVE        components specified  \n                                                        by EDX:EAX from mem.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a full or partial restore of processor state components from the\n   XSAVE area located at the memory address specified by the source operand.\n   The implicit EDX:EAX register pair specifies a 64-bit instruction mask.\n   The specific state components restored correspond to the bits set in the\n   requested-feature bitmap (RFBM), which is the logical-AND of EDX:EAX and\n   XCR0.\n\n   The format of the XSAVE area is detailed in Section 13.4, \u201cXSAVE Area,\u201d of\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n   Like FXRSTOR and FXSAVE, the memory format used for x87 state depends on a\n   REX.W prefix; see Section 13.5.1, \u201cx87 State\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1.\n\n   Section 13.8, \u201cOperation of XRSTOR,\u201d of Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1 provides a detailed description of\n   the operation of the XRSTOR instruction. The following items provide a\n   highlevel outline:\n\n     * Execution of XRSTOR may take one of two forms: standard and compacted.\n       Bit 63 of the XCOMP_BV field in the XSAVE header determines which form\n       is used: value 0 specifies the standard form, while value 1 specifies\n       the compacted form.\n     * If RFBM[i] = 0, XRSTOR does not update state component i.^1\n     * If RFBM[i] = 1 and bit i is clear in the XSTATE_BV field in the XSAVE\n       header, XRSTOR initializes state component i.\n     * If RFBM[i] = 1 and XSTATE_BV[i] = 1, XRSTOR loads state component i\n       from the XSAVE area.\n     * The standard form of XRSTOR treats MXCSR (which is part of state\n       component 1 \u2014 SSE) differently from the XMM registers. If either form\n       attempts to load MXCSR with an illegal value, a general-protection\n       exception (#GP) occurs.\n     * XRSTOR loads the internal value XRSTOR_INFO, which may be used to\n       optimize a subsequent execution of XSAVEOPT or XSAVES.\n     * Immediately following an execution of XRSTOR, the processor tracks as\n       in-use (not in initial configuration) any state component i for which\n       RFBM[i] = 1 and XSTATE_BV[i] = 1; it tracks as modified any state\n       component i for which RFBM[i] = 0.\n\n   Use of a source operand not aligned to 64-byte boundary (for 64-bit and\n   32-bit modes) results in a general-protection (#GP) exception. In 64-bit\n   mode, the upper 32 bits of RDX and RAX are ignored.\n\n   See Section 13.6, \u201cProcessor Tracking of XSAVE-Managed State,\u201d of Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1 for\n   discussion of the bitmaps XINUSE and XMODIFIED and of the quantity\n   XRSTOR_INFO.\n\n     1. There is an exception if RFBM[1] = 0 and RFBM[2] = 1. In this case,\n     the standard form of XRSTOR will load MXCSR from memory, even though\n     MXCSR is part of state component 1 \u2014 SSE. The compacted form of XRSTOR\n     does not make this exception.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfcmaddcph:vfmaddcph", "       VFCMADDCPH/VFMADDCPH \u2014 Complex Multiply and Accumulate FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.128.F2.MAP6.W0 56 /r                           from xmm2 and complex  \n   VFCMADDCPH xmm1{k1}{z}, xmm2, A V/V     AVX512-FP16 conjugate of           \n   xmm3/m128/m32bcst                       AVX512VL    xmm3/m128/m32bcst, add \n                                                       to xmm1 and store the  \n                                                       result in xmm1 subject \n                                                       to writemask k1.       \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.256.F2.MAP6.W0 56 /r                           from ymm2 and complex  \n   VFCMADDCPH ymm1{k1}{z}, ymm2, A V/V     AVX512-FP16 conjugate of           \n   ymm3/m256/m32bcst                       AVX512VL    ymm3/m256/m32bcst, add \n                                                       to ymm1 and store the  \n                                                       result in ymm1 subject \n                                                       to writemask k1.       \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.512.F2.MAP6.W0 56 /r                           from zmm2 and complex  \n   VFCMADDCPH zmm1{k1}{z}, zmm2, A V/V     AVX512-FP16 conjugate of           \n   zmm3/m512/m32bcst {er}                              zmm3/m512/m32bcst, add \n                                                       to zmm1 and store the  \n                                                       result in zmm1 subject \n                                                       to writemask k1.       \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.128.F3.MAP6.W0 56 /r               AVX512-FP16 from xmm2 and          \n   VFMADDCPH xmm1{k1}{z}, xmm2,  A V/V     AVX512VL    xmm3/m128/m32bcst, add \n   xmm3/m128/m32bcst                                   to xmm1 and store the  \n                                                       result in xmm1 subject \n                                                       to writemask k1.       \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.256.F3.MAP6.W0 56 /r               AVX512-FP16 from ymm2 and          \n   VFMADDCPH ymm1{k1}{z}, ymm2,  A V/V     AVX512VL    ymm3/m256/m32bcst, add \n   ymm3/m256/m32bcst                                   to ymm1 and store the  \n                                                       result in ymm1 subject \n                                                       to writemask k1.       \n                                                       Complex multiply a     \n                                                       pair of FP16 values    \n   EVEX.512.F3.MAP6.W0 56 /r                           from zmm2 and          \n   VFMADDCPH zmm1{k1}{z}, zmm2,  A V/V     AVX512-FP16 zmm3/m512/m32bcst, add \n   zmm3/m512/m32bcst {er}                              to zmm1 and store the  \n                                                       result in zmm1 subject \n                                                       to writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a complex multiply and accumulate operation.\n   There are normal and complex conjugate forms of the operation.\n\n   The broadcasting and masking for this operation is done on 32-bit\n   quantities representing a pair of FP16 values.\n\n   Rounding is performed at every FMA (fused multiply and add) boundary.\n   Execution occurs as if all MXCSR exceptions are masked. MXCSR status bits\n   are updated to reflect exceptional conditions.\n"],
	["bswap", "                               BSWAP \u2014 Byte Swap\n\n   Opcode     Instruction Op/En 64-bit Compat/Leg Description                 \n                                Mode   Mode       \n   0F C8+rd   BSWAP r32   O     Valid* Valid      Reverses the byte order of  \n                                                  a 32-bit register.          \n   REX.W + 0F BSWAP r64   O     Valid  N.E.       Reverses the byte order of  \n   C8+rd                                          a 64-bit register.          \n\n     * SeeIA-32ArchitectureCompatibilitysectionbelow.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1          Operand 2 Operand 3 Operand 4 \n   O     opcode + rd (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reverses the byte order of a 32-bit or 64-bit (destination) register. This\n   instruction is provided for converting little-endian values to big-endian\n   format and vice versa. To swap bytes in a word value (16-bit register),\n   use the XCHG instruction. When the BSWAP instruction references a 16-bit\n   register, the result is undefined.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nIA-32 Architecture Legacy Compatibility \u00b6\n\n   The BSWAP instruction is not supported on IA-32 processors earlier than\n   the Intel486TM processor family. For compatibility with this instruction,\n   software should include functionally equivalent code for execution on\n   Intel processors earlier than the Intel486 processor family.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cvtss2sd", "CVTSS2SD \u2014 Convert Scalar Single Precision Floating-Point Value to Scalar Double\n                         PrecisionFloating-Point Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Convert one single          \n                                                  precision floating-point    \n   F3 0F 5A /r CVTSS2SD    A    V/V       SSE2    value in xmm2/m32 to one    \n   xmm1, xmm2/m32                                 double precision            \n                                                  floating-point value in     \n                                                  xmm1.                       \n                                                  Convert one single          \n                                                  precision floating-point    \n   VEX.LIG.F3.0F.WIG 5A /r                        value in xmm3/m32 to one    \n   VCVTSS2SD xmm1, xmm2,   B    V/V       AVX     double precision            \n   xmm3/m32                                       floating-point value and    \n                                                  merge with high bits of     \n                                                  xmm2.                       \n                                                  Convert one single          \n   EVEX.LLIG.F3.0F.W0 5A                          precision floating-point    \n   /r VCVTSS2SD xmm1                              value in xmm3/m32 to one    \n   {k1}{z}, xmm2,          C    V/V       AVX512F double precision            \n   xmm3/m32{sae}                                  floating-point value and    \n                                                  merge with high bits of     \n                                                  xmm2 under writemask k1.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Converts a single precision floating-point value in the \u201cconvert-from\u201d\n   source operand to a double precision floating-point value in the\n   destination operand. When the \u201cconvert-from\u201d source operand is an XMM\n   register, the single precision floating-point value is contained in the\n   low doubleword of the register. The result is stored in the low quadword\n   of the destination operand.\n\n   128-bit Legacy SSE version: The \u201cconvert-from\u201d source operand (the second\n   operand) is an XMM register or memory location. Bits (MAXVL-1:64) of the\n   corresponding destination register remain unchanged. The destination\n   operand is an XMM register.\n\n   VEX.128 and EVEX encoded versions: The \u201cconvert-from\u201d source operand (the\n   third operand) can be an XMM register or a 32-bit memory location. The\n   first source and destination operands are XMM registers. Bits (127:64) of\n   the XMM register destination are copied from the corresponding bits in the\n   first source operand. Bits (MAXVL-1:128) of the destination register are\n   zeroed.\n\n   Software should ensure VCVTSS2SD is encoded with VEX.L=0. Encoding\n   VCVTSS2SD with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["pcmpeqq", "                 PCMPEQQ \u2014 Compare Packed Qword Data for Equal\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   66 0F 38 29 /r PCMPEQQ                           Compare packed qwords in  \n   xmm1, xmm2/m128         A     V/V       SSE4_1   xmm2/m128 and xmm1 for    \n                                                    equality.                 \n   VEX.128.66.0F38.WIG 29                           Compare packed quadwords  \n   /r VPCMPEQQ xmm1, xmm2, B     V/V       AVX      in xmm3/m128 and xmm2 for \n   xmm3/m128                                        equality.                 \n   VEX.256.66.0F38.WIG 29                           Compare packed quadwords  \n   /r VPCMPEQQ ymm1, ymm2, B     V/V       AVX2     in ymm3/m256 and ymm2 for \n   ymm3 /m256                                       equality.                 \n                                                    Compare Equal between     \n                                                    int64 vector xmm2 and     \n                                                    int64 vector              \n   EVEX.128.66.0F38.W1 29                  AVX512VL xmm3/m128/m64bcst, and    \n   /r VPCMPEQQ k1 {k2},    C     V/V       AVX512F  set vector mask k1 to     \n   xmm2, xmm3/m128/m64bcst                          reflect the zero/nonzero  \n                                                    status of each element of \n                                                    the result, under         \n                                                    writemask.                \n                                                    Compare Equal between     \n                                                    int64 vector ymm2 and     \n                                                    int64 vector              \n   EVEX.256.66.0F38.W1 29                  AVX512VL ymm3/m256/m64bcst, and    \n   /r VPCMPEQQ k1 {k2},    C     V/V       AVX512F  set vector mask k1 to     \n   ymm2, ymm3/m256/m64bcst                          reflect the zero/nonzero  \n                                                    status of each element of \n                                                    the result, under         \n                                                    writemask.                \n                                                    Compare Equal between     \n                                                    int64 vector zmm2 and     \n                                                    int64 vector              \n   EVEX.512.66.0F38.W1 29                           zmm3/m512/m64bcst, and    \n   /r VPCMPEQQ k1 {k2},    C     V/V       AVX512F  set vector mask k1 to     \n   zmm2, zmm3/m512/m64bcst                          reflect the zero/nonzero  \n                                                    status of each element of \n                                                    the result, under         \n                                                    writemask.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs an SIMD compare for equality of the packed quadwords in the\n   destination operand (first operand) and the source operand (second\n   operand). If a pair of data elements is equal, the corresponding data\n   element in the destination is set to all 1s; otherwise, it is set to 0s.\n\n   128-bit Legacy SSE version: The second source operand can be an XMM\n   register or a 128-bit memory location. The first source and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand can be an XMM register\n   or a 128-bit memory location. The first source and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM register\n   are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n\n   EVEX encoded VPCMPEQQ: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. The destination operand (first\n   operand) is a mask register updated according to the writemask k2.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["xadd", "                            XADD \u2014 Exchange and Add\n\n   Opcode     Instruction     Op/En 64-Bit Compat/Leg Description             \n                                    Mode   Mode       \n   0F C0 /r   XADD r/m8, r8   MR    Valid  Valid      Exchange r8 and r/m8;   \n                                                      load sum into r/m8.     \n   REX + 0F   XADD r/m8*, r8* MR    Valid  N.E.       Exchange r8 and r/m8;   \n   C0 /r                                              load sum into r/m8.     \n   0F C1 /r   XADD r/m16, r16 MR    Valid  Valid      Exchange r16 and r/m16; \n                                                      load sum into r/m16.    \n   0F C1 /r   XADD r/m32, r32 MR    Valid  Valid      Exchange r32 and r/m32; \n                                                      load sum into r/m32.    \n   REX.W + 0F XADD r/m64, r64 MR    Valid  N.E.       Exchange r64 and r/m64; \n   C1 /r                                              load sum into r/m64.    \n\n     *\n     In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2        Operand 3 Operand 4 \n   MR    ModRM:r/m (r, w) ModRM:reg (r, w) N/A       N/A       \n\nDescription \u00b6\n\n   Exchanges the first operand (destination operand) with the second operand\n   (source operand), then loads the sum of the two values into the\n   destination operand. The destination operand can be a register or a memory\n   location; the source operand is a register.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\nIA-32 Architecture Compatibility \u00b6\n\n   IA-32 processors earlier than the Intel486 processor do not recognize this\n   instruction. If this instruction is used, you should provide an equivalent\n   code sequence that runs on earlier processors.\n\nFlags Affected \u00b6\n\n   The CF, PF, AF, SF, ZF, and OF flags are set according to the result of\n   the addition, which is stored in the destination operand.\n"],
	["pcmpistrm", "        PCMPISTRM \u2014 Packed Compare Implicit Length Strings, Return Mask\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n                                                     Perform a packed         \n   66 0F 3A 62 /r imm8                               comparison of string     \n   PCMPISTRM xmm1,           RM    V/V       SSE4_2  data with implicit       \n   xmm2/m128, imm8                                   lengths, generating a    \n                                                     mask, and storing the    \n                                                     result in XMM0.          \n                                                     Perform a packed         \n   VEX.128.66.0F3A.WIG 62 /r                         comparison of string     \n   ib VPCMPISTRM xmm1,       RM    V/V       AVX     data with implicit       \n   xmm2/m128, imm8                                   lengths, generating a    \n                                                     Mask, and storing the    \n                                                     result in XMM0.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   The instruction compares data from two strings based on the encoded value\n   in the imm8 byte (see Section 4.1, \u201cImm8 Control Byte Operation for\n   PCMPESTRI / PCMPESTRM / PCMPISTRI / PCMPISTRM\u201d) generating a mask stored\n   to XMM0.\n\n   Each string is represented by a single value. The value is an xmm (or\n   possibly m128 for the second operand) which contains the data elements of\n   the string (byte or word data). Each input byte/word is augmented with a\n   valid/invalid tag. A byte/word is considered valid only if it has a lower\n   index than the least significant null byte/word. (The least significant\n   null byte/word is also considered invalid.)\n\n   The comparison and aggregation operation are performed according to the\n   encoded value of imm8 bit fields (see Section 4.1). As defined by imm8[6],\n   IntRes2 is then either stored to the least significant bits of XMM0 (zero\n   extended to 128 bits) or expanded into a byte/word-mask and then stored to\n   XMM0.\n\n   Note that the Arithmetic Flags are written in a non-standard manner in\n   order to supply the most relevant information:\n\n   CFlag \u2013 Reset if IntRes2 is equal to zero, set otherwise\n\n   ZFlag \u2013 Set if any byte/word of xmm2/mem128 is null, reset otherwise\n\n   SFlag \u2013 Set if any byte/word of xmm1 is null, reset otherwise\n\n   OFlag \u2013 IntRes2[0]\n\n   AFlag \u2013 Reset\n\n   PFlag \u2013 Reset\n\n   Note: In VEX.128 encoded versions, bits (MAXVL-1:128) of XMM0 are zeroed.\n   VEX.vvvv is reserved and must be 1111b, VEX.L must be 0, otherwise the\n   instruction will #UD.\n\nEffective Operand Size \u00b6\n\n   Operating mode/size Operand 1 Operand 2 Result \n   16 bit              xmm       xmm/m128  XMM0   \n   32 bit              xmm       xmm/m128  XMM0   \n   64 bit              xmm       xmm/m128  XMM0   \n"],
	["vpexpandb:vpexpandw", "                 VPEXPANDB/VPEXPANDW \u2014 Expand Byte/Word Values\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Expands up to 128     \n   EVEX.128.66.0F38.W0 62                 AVX512_VBMI2  bits of packed byte   \n   /r VPEXPANDB           A     V/V       AVX512VL      values from m128 to   \n   xmm1{k1}{z}, m128                                    xmm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 128     \n   EVEX.128.66.0F38.W0 62                 AVX512_VBMI2  bits of packed byte   \n   /r VPEXPANDB           B     V/V       AVX512VL      values from xmm2 to   \n   xmm1{k1}{z}, xmm2                                    xmm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 256     \n   EVEX.256.66.0F38.W0 62                 AVX512_VBMI2  bits of packed byte   \n   /r VPEXPANDB           A     V/V       AVX512VL      values from m256 to   \n   ymm1{k1}{z}, m256                                    ymm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 256     \n   EVEX.256.66.0F38.W0 62                 AVX512_VBMI2  bits of packed byte   \n   /r VPEXPANDB           B     V/V       AVX512VL      values from ymm2 to   \n   ymm1{k1}{z}, ymm2                                    ymm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 512     \n   EVEX.512.66.0F38.W0 62                               bits of packed byte   \n   /r VPEXPANDB           A     V/V       AVX512_VBMI2  values from m512 to   \n   zmm1{k1}{z}, m512                                    zmm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 512     \n   EVEX.512.66.0F38.W0 62                               bits of packed byte   \n   /r VPEXPANDB           B     V/V       AVX512_VBMI2  values from zmm2 to   \n   zmm1{k1}{z}, zmm2                                    zmm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 128     \n   EVEX.128.66.0F38.W1 62                 AVX512_VBMI2  bits of packed word   \n   /r VPEXPANDW           A     V/V       AVX512VL      values from m128 to   \n   xmm1{k1}{z}, m128                                    xmm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 128     \n   EVEX.128.66.0F38.W1 62                 AVX512_VBMI2  bits of packed word   \n   /r VPEXPANDW           B     V/V       AVX512VL      values from xmm2 to   \n   xmm1{k1}{z}, xmm2                                    xmm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 256     \n   EVEX.256.66.0F38.W1 62                 AVX512_VBMI2  bits of packed word   \n   /r VPEXPANDW           A     V/V       AVX512VL      values from m256 to   \n   ymm1{k1}{z}, m256                                    ymm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 256     \n   EVEX.256.66.0F38.W1 62                 AVX512_VBMI2  bits of packed word   \n   /r VPEXPANDW           B     V/V       AVX512VL      values from ymm2 to   \n   ymm1{k1}{z}, ymm2                                    ymm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 512     \n   EVEX.512.66.0F38.W1 62                               bits of packed word   \n   /r VPEXPANDW           A     V/V       AVX512_VBMI2  values from m512 to   \n   zmm1{k1}{z}, m512                                    zmm1 with writemask   \n                                                        k1.                   \n                                                        Expands up to 512     \n   EVEX.512.66.0F38.W1 62                               bits of packed byte   \n   /r VPEXPANDW           B     V/V       AVX512_VBMI2  integer values from   \n   zmm1{k1}{z}, zmm2                                    zmm2 to zmm1 with     \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple         Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A           ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Expands (loads) up to 64 byte integer values or 32 word integer values\n   from the source operand (memory operand) to the destination operand\n   (register operand), based on the active elements determined by the\n   writemask operand.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n\n   Moves 128, 256 or 512 bits of packed byte integer values from the source\n   operand (memory operand) to the destination operand (register operand).\n   This instruction is used to load from an int8 vector register or memory\n   location while inserting the data into sparse elements of destination\n   vector register using the active elements pointed out by the operand\n   writemask.\n\n   This instruction supports memory fault suppression.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["vfpclasssd", "               VFPCLASSSD \u2014 Tests Type of a Scalar Float64 Value\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Tests the input for the \n                                                      following categories:   \n                                                      NaN, +0, -0, +Infinity, \n                                                      -Infinity, denormal,    \n   EVEX.LLIG.66.0F3A.W1 67                            finite negative. The    \n   /r ib VFPCLASSSD k2 {k1}, A     V/V       AVX512DQ immediate field         \n   xmm2/m64, imm8                                     provides a mask bit for \n                                                      each of these category  \n                                                      tests. The masked test  \n                                                      results are OR-ed       \n                                                      together to form a mask \n                                                      result.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   The FPCLASSSD instruction checks the low double precision floating-point\n   value in the source operand for special categories, specified by the set\n   bits in the imm8 byte. Each set bit in imm8 specifies a category of\n   floating-point values that the input data element is classified against.\n   The classified results of all specified categories of an input value are\n   ORed together to form the final boolean result for the input element. The\n   result is written to the low bit in a mask register k2 according to the\n   writemask k1. Bits MAX_KL-1: 1 of the destination are cleared.\n\n   The classification categories specified by imm8 are shown in Figure 5-13.\n   The classification test for each category is listed in Table 5-14.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["vmaxph", "                 VMAXPH \u2014 Return Maximum of Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En bit     \n   Mode Flag CPUID Feature        \n   Instruction En bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En bit Mode Flag   \n   CPUID Feature Instruction En   \n   bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Return the maximum    \n                                                        packed FP16 values    \n   EVEX.128.NP.MAP5.W0 5F /r                AVX512-FP16 between xmm2 and      \n   VMAXPH xmm1{k1}{z}, xmm2,      A V/V     AVX512VL    xmm3/m128/m16bcst and \n   xmm3/m128/m16bcst                                    store the result in   \n                                                        xmm1 subject to       \n                                                        writemask k1.         \n                                                        Return the maximum    \n                                                        packed FP16 values    \n   EVEX.256.NP.MAP5.W0 5F /r                AVX512-FP16 between ymm2 and      \n   VMAXPH ymm1{k1}{z}, ymm2,      A V/V     AVX512VL    ymm3/m256/m16bcst and \n   ymm3/m256/m16bcst                                    store the result in   \n                                                        ymm1 subject to       \n                                                        writemask k1.         \n                                                        Return the maximum    \n                                                        packed FP16 values    \n   EVEX.512.NP.MAP5.W0 5F /r                            between zmm2 and      \n   VMAXPH zmm1{k1}{z}, zmm2,      A V/V     AVX512-FP16 zmm3/m512/m16bcst and \n   zmm3/m512/m16bcst {sae}                              store the result in   \n                                                        zmm1 subject to       \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD compare of the packed FP16 values in the\n   first source operand and the second source operand and returns the maximum\n   value for each pair of values to the destination operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of VMAXPH can be emulated using a sequence of\n   instructions, such as, a comparison followed by AND, ANDN and OR.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcast from a 16-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n"],
	["pinsrw", "                              PINSRW \u2014 Insert Word\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction       Op/ En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Insert the low word     \n   NP 0F C4 /r ib^1 PINSRW                            from r32 or from m16    \n   mm, r32/m16, imm8        A      V/V       SSE      into mm at the word     \n                                                      position specified by   \n                                                      imm8.                   \n                                                      Move the low word of    \n   66 0F C4 /r ib PINSRW                              r32 or from m16 into    \n   xmm, r32/m16, imm8       A      V/V       SSE2     xmm at the word         \n                                                      position specified by   \n                                                      imm8.                   \n                                                      Insert the word from    \n   VEX.128.66.0F.W0 C4 /r                             r32/m16 at the offset   \n   ib VPINSRW xmm1, xmm2,   B      V^2/V     AVX      indicated by imm8 into  \n   r32/m16, imm8                                      the value from xmm2 and \n                                                      store result in xmm1.   \n                                                      Insert the word from    \n   EVEX.128.66.0F.WIG C4 /r                           r32/m16 at the offset   \n   ib VPINSRW xmm1, xmm2,   C      V/V       AVX512BW indicated by imm8 into  \n   r32/m16, imm8                                      the value from xmm2 and \n                                                      store result in xmm1.   \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\n     2. In 64-bit mode, VEX.W1 is ignored for VPINSRW (similar to legacy\n     REX.W=1 prefix in PINSRW).\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   B     N/A           ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Three operand MMX and SSE instructions:\n\n   Copies a word from the source operand and inserts it in the destination\n   operand at the location specified with the count operand. (The other words\n   in the destination register are left untouched.) The source operand can be\n   a general-purpose register or a 16-bit memory location. (When the source\n   operand is a general-purpose register, the low word of the register is\n   copied.) The destination operand can be an MMX technology register or an\n   XMM register. The count operand is an 8-bit immediate. When specifying a\n   word location in an MMX technology register, the 2 least-significant bits\n   of the count operand specify the location; for an XMM register, the 3\n   least-significant bits specify the location.\n\n   Bits (MAXVL-1:128) of the corresponding YMM destination register remain\n   unchanged.\n\n   Four operand AVX and AVX-512 instructions:\n\n   Combines a word from the first source operand with the second source\n   operand, and inserts it in the destination operand at the location\n   specified with the count operand. The second source operand can be a\n   general-purpose register or a 16-bit memory location. (When the source\n   operand is a general-purpose register, the low word of the register is\n   copied.) The first source and destination operands are XMM registers. The\n   count operand is an 8-bit immediate. When specifying a word location, the\n   3 least-significant bits specify the location.\n\n   Bits (MAXVL-1:128) of the destination YMM register are zeroed.\n   VEX.L/EVEX.L\u2019L must be 0, otherwise the instruction will #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pmaddubsw", "         PMADDUBSW \u2014 Multiply and Add Packed Signed and Unsigned Bytes\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Multiply signed and     \n                                                      unsigned bytes, add     \n   NP 0F 38 04 /r^1          A     V/V       SSSE3    horizontal pair of      \n   PMADDUBSW mm1, mm2/m64                             signed words, pack      \n                                                      saturated signed-words  \n                                                      to mm1.                 \n                                                      Multiply signed and     \n                                                      unsigned bytes, add     \n   66 0F 38 04 /r PMADDUBSW  A     V/V       SSSE3    horizontal pair of      \n   xmm1, xmm2/m128                                    signed words, pack      \n                                                      saturated signed-words  \n                                                      to xmm1.                \n                                                      Multiply signed and     \n   VEX.128.66.0F38.WIG 04 /r                          unsigned bytes, add     \n   VPMADDUBSW xmm1, xmm2,    B     V/V       AVX      horizontal pair of      \n   xmm3/m128                                          signed words, pack      \n                                                      saturated signed-words  \n                                                      to xmm1.                \n                                                      Multiply signed and     \n   VEX.256.66.0F38.WIG 04 /r                          unsigned bytes, add     \n   VPMADDUBSW ymm1, ymm2,    B     V/V       AVX2     horizontal pair of      \n   ymm3/m256                                          signed words, pack      \n                                                      saturated signed-words  \n                                                      to ymm1.                \n                                                      Multiply signed and     \n                                                      unsigned bytes, add     \n   EVEX.128.66.0F38.WIG 04                   AVX512VL horizontal pair of      \n   /r VPMADDUBSW xmm1        C     V/V       AVX512BW signed words, pack      \n   {k1}{z}, xmm2, xmm3/m128                           saturated signed-words  \n                                                      to xmm1 under writemask \n                                                      k1.                     \n                                                      Multiply signed and     \n                                                      unsigned bytes, add     \n   EVEX.256.66.0F38.WIG 04                   AVX512VL horizontal pair of      \n   /r VPMADDUBSW ymm1        C     V/V       AVX512BW signed words, pack      \n   {k1}{z}, ymm2, ymm3/m256                           saturated signed-words  \n                                                      to ymm1 under writemask \n                                                      k1.                     \n                                                      Multiply signed and     \n                                                      unsigned bytes, add     \n   EVEX.512.66.0F38.WIG 04                            horizontal pair of      \n   /r VPMADDUBSW zmm1        C     V/V       AVX512BW signed words, pack      \n   {k1}{z}, zmm2, zmm3/m512                           saturated signed-words  \n                                                      to zmm1 under writemask \n                                                      k1.                     \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   (V)PMADDUBSW multiplies vertically each unsigned byte of the destination\n   operand (first operand) with the corresponding signed byte of the source\n   operand (second operand), producing intermediate signed 16-bit integers.\n   Each adjacent pair of signed words is added and the saturated result is\n   packed to the destination operand. For example, the lowest-order bytes\n   (bits 7-0) in the source and destination operands are multiplied and the\n   intermediate signed word result is added with the corresponding\n   intermediate result from the 2nd lowest-order bytes (bits 15-8) of the\n   operands; the sign-saturated result is stored in the lowest word of the\n   destination register (15-0). The same operation is performed on the other\n   pairs of adjacent bytes. Both operands can be MMX register or XMM\n   registers. When the source operand is a 128-bit memory operand, the\n   operand must be aligned on a 16-byte boundary or a general-protection\n   exception (#GP) will be generated.\n\n   In 64-bit mode and not encoded with VEX/EVEX, use the REX prefix to access\n   XMM8-XMM15.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 and EVEX.128 encoded versions: The first source and destination\n   operands are XMM registers. The second source operand is an XMM register\n   or a 128-bit memory location. Bits (MAXVL-1:128) of the corresponding\n   destination register are zeroed.\n\n   VEX.256 and EVEX.256 encoded versions: The second source operand can be an\n   YMM register or a 256-bit memory location. The first source and\n   destination operands are YMM registers. Bits (MAXVL-1:256) of the\n   corresponding ZMM register are zeroed.\n\n   EVEX.512 encoded version: The second source operand can be an ZMM register\n   or a 512-bit memory location. The first source and destination operands\n   are ZMM registers.\n"],
	["wrfsbase:wrgsbase", "                  WRFSBASE/WRGSBASE \u2014 Write FS/GS Segment Base\n\n                              64/32-bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature  Description\n                                        Flag     \n   F3 0F AE /2 WRFSBASE                          Load the FS base address     \n   r32                  M     V/I       FSGSBASE with the 32-bit value in the \n                                                 source register.             \n   F3 REX.W 0F AE /2                             Load the FS base address     \n   WRFSBASE r64         M     V/I       FSGSBASE with the 64-bit value in the \n                                                 source register.             \n   F3 0F AE /3 WRGSBASE                          Load the GS base address     \n   r32                  M     V/I       FSGSBASE with the 32-bit value in the \n                                                 source register.             \n   F3 REX.W 0F AE /3                             Load the GS base address     \n   WRGSBASE r64         M     V/I       FSGSBASE with the 64-bit value in the \n                                                 source register.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the FS or GS segment base address with the general-purpose register\n   indicated by the modR/M:r/m field.\n\n   The source operand may be either a 32-bit or a 64-bit general-purpose\n   register. The REX.W prefix indicates the operand size is 64 bits. If no\n   REX.W prefix is used, the operand size is 32 bits; the upper 32 bits of\n   the source register are ignored and upper 32 bits of the base address (for\n   FS or GS) are cleared.\n\n   This instruction is supported only in 64-bit mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["senduipi", "                 SENDUIPI \u2014 Send User Interprocessor Interrupt\n\n                              64/32 bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                              Support   Flag    \n   F3 0F C7 /6 SENDUIPI A     V/I       UINTR   Send interprocessor user      \n   reg                                          interrupt.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:reg (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The SENDUIPI instruction sends the user interprocessor interrupt (IPI)\n   indicated by its register operand. (The operand always has 64 bits;\n   operand-size overrides such as the prefix 66 are ignored.)\n\n   SENDUIPI uses a data structure called the user-interrupt target table\n   (UITT). This table is located at the linear address UITTADDR (in the\n   IA32_UINTR_TT MSR); it comprises UITTSZ+1 16-byte entries, where UITTSZ =\n   IA32_UINT_MISC[31:0]. SENDUIPI uses the UITT entry (UITTE) indexed by the\n   instruction's register operand. Each UITTE has the following format:\n\n     * Bit 0: V, a valid bit.\n     * Bits 7:1 are reserved and must be 0.\n     * Bits 15:8: UV, the user-interrupt vector (in the range 0\u201363, so bits\n       15:14 must be 0).\n     * Bits 63:16 are reserved.\n     * Bits 127:64: UPIDADDR, the linear address of a user posted-interrupt\n       descriptor (UPID). (UPIDADDR is 64-byte aligned, so bits 69:64 of each\n       UITTE must be 0.)\n\n   Each UPID has the following format (fields and bits not referenced are\n   reserved):\n\n     * Bit 0 (ON) indicates an outstanding notification. If this bit is set,\n       there is a notification outstanding for one or more user interrupts in\n       PIR.\n     * Bit 1 (SN) indicates that notifications should be suppressed. If this\n       bit is set, agents (including SENDUIPI) should not send notifications\n       when posting user interrupts in this descriptor.\n     * Bits 23:16 (NV) contain the notification vector. This is used by\n       agents sending user-interrupt notifications (including SENDUIPI).\n     * Bits 63:32 (NDST) contain the notification destination. This is the\n       target physical APIC ID (in xAPIC mode, bits 47:40 are the 8-bit APIC\n       ID; in x2APIC mode, the entire field forms the 32-bit APIC ID).\n     * Bits 127:64 (PIF) contain posted-interrupt requests. There is one bit\n       for each user-interrupt vector. There is a user-interrupt request for\n       a vector if the corresponding bit is 1.\n\n   Although SENDUIPI may be executed at any privilege level, all of the\n   instruction\u2019s memory accesses (to a UITTE and a UPID) are performed with\n   supervisor privilege.\n\n   SENDUIPI sends a user interrupt by posting a user interrupt with vector V\n   in the UPID referenced by UPIDADDR and then sending, as an ordinary IPI,\n   any notification interrupt specified in that UPID.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcmpsh", "                      VCMPSH \u2014 Compare Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode   \n   Flag Support 64/32 CPUID Feature  \n   Instruction En Bit Mode Flag      \n   CPUID Feature Instruction En Bit  \n   Mode Flag Op/ 64/32 CPUID Feature   Support             Description\n   Instruction En Bit Mode Flag      \n   64/32 CPUID Feature Instruction   \n   En Bit Mode Flag CPUID Feature    \n   Instruction En Bit Mode Flag Op/  \n   64/32 CPUID Feature               \n                                                           Compare low FP16   \n                                                           values in xmm3/m16 \n                                                           and xmm2 using     \n   EVEX.LLIG.F3.0F3A.W0 C2 /r /ib                          bits 4:0 of imm8   \n   VCMPSH k1{k2}, xmm2, xmm3/m16     A V/V     AVX512-FP16 as a comparison    \n   {sae}, imm8                                             predicate subject  \n                                                           to writemask k2,   \n                                                           and store the      \n                                                           result in mask     \n                                                           register k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   This instruction compares the FP16 values from the lowest element of the\n   source operands and stores the result in the destination mask operand. The\n   comparison predicate operand (immediate byte bits 4:0) specifies the type\n   of comparison performed on the pair of packed FP16 values. The low\n   destination bit is updated according to the writemask. Bits MAXKL-1:1 of\n   the destination operand are zeroed.\n"],
	["std", "                            STD \u2014 Set Direction Flag\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description  \n   FD     STD         ZO    Valid       Valid           Set DF flag. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Sets the DF flag in the EFLAGS register. When the DF flag is set to 1,\n   string operations decrement the index registers (ESI and/or EDI).\n   Operation is the same in all modes.\n\nFlags Affected \u00b6\n\n   The DF flag is set. The CF, OF, ZF, SF, AF, and PF flags are unaffected.\n"],
	["vexpandps", "VEXPANDPS \u2014 Load Sparse Packed Single Precision Floating-Point Values From Dense\n                                     Memory\n\n                                64/32 Bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n   EVEX.128.66.0F38.W0 88                          Expand packed single       \n   /r VEXPANDPS xmm1      A     V/V       AVX512VL precision floating-point   \n   {k1}{z}, xmm2/m128                     AVX512F  values from xmm2/m128 to   \n                                                   xmm1 using writemask k1.   \n   EVEX.256.66.0F38.W0 88                          Expand packed single       \n   /r VEXPANDPS ymm1      A     V/V       AVX512VL precision floating-point   \n   {k1}{z}, ymm2/m256                     AVX512F  values from ymm2/m256 to   \n                                                   ymm1 using writemask k1.   \n   EVEX.512.66.0F38.W0 88                          Expand packed single       \n   /r VEXPANDPS zmm1      A     V/V       AVX512F  precision floating-point   \n   {k1}{z}, zmm2/m512                              values from zmm2/m512 to   \n                                                   zmm1 using writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Expand (load) up to 16/8/4, contiguous, single precision floating-point\n   values of the input vector in the source operand (the second operand) to\n   sparse elements of the destination operand (the first operand) selected by\n   the writemask k1.\n\n   The destination operand is a ZMM/YMM/XMM register, the source operand can\n   be a ZMM/YMM/XMM register or a 512/256/128-bit memory location.\n\n   The input vector starts from the lowest element in the source operand. The\n   writemask k1 selects the destination elements (a partial vector or sparse\n   elements if less than 16 elements) to be replaced by the ascending\n   elements in the input vector. Destination elements not selected by the\n   writemask k1 are either unmodified or zeroed, depending on EVEX.z.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["pslldq", "                  PSLLDQ \u2014 Shift Double Quadword Left Logical\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n   66 0F 73 /7 ib PSLLDQ                             Shift xmm1 left by imm8  \n   xmm1, imm8               A     V/V       SSE2     bytes while shifting in  \n                                                     0s.                      \n   VEX.128.66.0F.WIG 73 /7                           Shift xmm2 left by imm8  \n   ib VPSLLDQ xmm1, xmm2,   B     V/V       AVX      bytes while shifting in  \n   imm8                                              0s and store result in   \n                                                     xmm1.                    \n   VEX.256.66.0F.WIG 73 /7                           Shift ymm2 left by imm8  \n   ib VPSLLDQ ymm1, ymm2,   B     V/V       AVX2     bytes while shifting in  \n   imm8                                              0s and store result in   \n                                                     ymm1.                    \n   EVEX.128.66.0F.WIG 73 /7                          Shift xmm2/m128 left by  \n   ib VPSLLDQ xmm1,xmm2/    C     V/V       AVX512VL imm8 bytes while         \n   m128, imm8                               AVX512BW shifting in 0s and store \n                                                     result in xmm1.          \n   EVEX.256.66.0F.WIG 73 /7                          Shift ymm2/m256 left by  \n   ib VPSLLDQ ymm1,         C     V/V       AVX512VL imm8 bytes while         \n   ymm2/m256, imm8                          AVX512BW shifting in 0s and store \n                                                     result in ymm1.          \n   EVEX.512.66.0F.WIG 73 /7                          Shift zmm2/m512 left by  \n   ib VPSLLDQ zmm1,         C     V/V       AVX512BW imm8 bytes while         \n   zmm2/m512, imm8                                   shifting in 0s and store \n                                                     result in zmm1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (r, w) imm8          N/A       N/A       \n   B     N/A        VEX.vvvv (w)     ModRM:r/m (r) imm8      N/A       \n   C     Full Mem   EVEX.vvvv (w)    ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Shifts the destination operand (first operand) to the left by the number\n   of bytes specified in the count operand (second operand). The empty\n   low-order bytes are cleared (set to all 0s). If the value specified by the\n   count operand is greater than 15, the destination operand is set to all\n   0s. The count operand is an 8-bit immediate.\n\n   128-bit Legacy SSE version: The source and destination operands are the\n   same. Bits (MAXVL-1:128) of the corresponding YMM destination register\n   remain unchanged.\n\n   VEX.128 encoded version: The source and destination operands are XMM\n   registers. Bits (MAXVL-1:128) of the destination YMM register are zeroed.\n\n   VEX.256 encoded version: The source operand is YMM register. The\n   destination operand is an YMM register. Bits (MAXVL-1:256) of the\n   corresponding ZMM register are zeroed. The count operand applies to both\n   the low and high 128-bit lanes.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register or a\n   512/256/128-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register. The count operand applies to each 128-bit lanes.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpcmpq:vpcmpuq", "            VPCMPQ/VPCMPUQ \u2014 Compare Packed Integer Values Into Mask\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Compare packed signed     \n                                                    quadword integer values   \n   EVEX.128.66.0F3A.W1 1F                           in xmm3/m128/m64bcst and  \n   /r ib VPCMPQ k1 {k2},   A     V/V       AVX512VL xmm2 using bits 2:0 of    \n   xmm2,                                   AVX512F  imm8 as a comparison      \n   xmm3/m128/m64bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed signed     \n                                                    quadword integer values   \n   EVEX.256.66.0F3A.W1 1F                           in ymm3/m256/m64bcst and  \n   /r ib VPCMPQ k1 {k2},   A     V/V       AVX512VL ymm2 using bits 2:0 of    \n   ymm2,                                   AVX512F  imm8 as a comparison      \n   ymm3/m256/m64bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed signed     \n                                                    quadword integer values   \n   EVEX.512.66.0F3A.W1 1F                           in zmm3/m512/m64bcst and  \n   /r ib VPCMPQ k1 {k2},   A     V/V       AVX512F  zmm2 using bits 2:0 of    \n   zmm2,                                            imm8 as a comparison      \n   zmm3/m512/m64bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed unsigned   \n                                                    quadword integer values   \n   EVEX.128.66.0F3A.W1 1E                           in xmm3/m128/m64bcst and  \n   /r ib VPCMPUQ k1 {k2},  A     V/V       AVX512VL xmm2 using bits 2:0 of    \n   xmm2,                                   AVX512F  imm8 as a comparison      \n   xmm3/m128/m64bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed unsigned   \n                                                    quadword integer values   \n   EVEX.256.66.0F3A.W1 1E                           in ymm3/m256/m64bcst and  \n   /r ib VPCMPUQ k1 {k2},  A     V/V       AVX512VL ymm2 using bits 2:0 of    \n   ymm2,                                   AVX512F  imm8 as a comparison      \n   ymm3/m256/m64bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed unsigned   \n                                                    quadword integer values   \n   EVEX.512.66.0F3A.W1 1E                           in zmm3/m512/m64bcst and  \n   /r ib VPCMPUQ k1 {k2},  A     V/V       AVX512F  zmm2 using bits 2:0 of    \n   zmm2,                                            imm8 as a comparison      \n   zmm3/m512/m64bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Performs a SIMD compare of the packed integer values in the second source\n   operand and the first source operand and returns the results of the\n   comparison to the mask destination operand. The comparison predicate\n   operand (immediate byte) specifies the type of comparison performed on\n   each pair of packed values in the two source operands. The result of each\n   comparison is a single mask bit result of 1 (comparison true) or 0\n   (comparison false).\n\n   VPCMPQ/VPCMPUQ performs a comparison between pairs of signed/unsigned\n   quadword integer values.\n\n   The first source operand (second operand) is a ZMM/YMM/XMM register. The\n   second source operand can be a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location or a 512-bit vector broadcasted from a 64-bit memory\n   location. The destination operand (first operand) is a mask register k1.\n   Up to 8/4/2 comparisons are performed with results written to the\n   destination operand under the writemask k2.\n\n   The comparison predicate operand is an 8-bit immediate: bits 2:0 define\n   the type of comparison to be performed. Bits 3 through 7 of the immediate\n   are reserved. Compiler can implement the pseudo-op mnemonic listed in\n   Table 5-21.\n"],
	["psignb:psignw:psignd", "                       PSIGNB/PSIGNW/PSIGND \u2014 Packed SIGN\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Negate/zero/preserve       \n   NP 0F 38 08 /r^1 PSIGNB                         packed byte integers in    \n   mm1, mm2/m64            RM    V/V       SSSE3   mm1 depending on the       \n                                                   corresponding sign in      \n                                                   mm2/m64.                   \n                                                   Negate/zero/preserve       \n   66 0F 38 08 /r PSIGNB                           packed byte integers in    \n   xmm1, xmm2/m128         RM    V/V       SSSE3   xmm1 depending on the      \n                                                   corresponding sign in      \n                                                   xmm2/m128.                 \n                                                   Negate/zero/preserve       \n   NP 0F 38 09 /r^1 PSIGNW                         packed word integers in    \n   mm1, mm2/m64            RM    V/V       SSSE3   mm1 depending on the       \n                                                   corresponding sign in      \n                                                   mm2/m128.                  \n                                                   Negate/zero/preserve       \n   66 0F 38 09 /r PSIGNW                           packed word integers in    \n   xmm1, xmm2/m128         RM    V/V       SSSE3   xmm1 depending on the      \n                                                   corresponding sign in      \n                                                   xmm2/m128.                 \n                                                   Negate/zero/preserve       \n   NP 0F 38 0A /r^1 PSIGND                         packed doubleword integers \n   mm1, mm2/m64            RM    V/V       SSSE3   in mm1 depending on the    \n                                                   corresponding sign in      \n                                                   mm2/m128.                  \n                                                   Negate/zero/preserve       \n   66 0F 38 0A /r PSIGND                           packed doubleword integers \n   xmm1, xmm2/m128         RM    V/V       SSSE3   in xmm1 depending on the   \n                                                   corresponding sign in      \n                                                   xmm2/m128.                 \n                                                   Negate/zero/preserve       \n   VEX.128.66.0F38.WIG 08                          packed byte integers in    \n   /r VPSIGNB xmm1, xmm2,  RVM   V/V       AVX     xmm2 depending on the      \n   xmm3/m128                                       corresponding sign in      \n                                                   xmm3/m128.                 \n                                                   Negate/zero/preserve       \n   VEX.128.66.0F38.WIG 09                          packed word integers in    \n   /r VPSIGNW xmm1, xmm2,  RVM   V/V       AVX     xmm2 depending on the      \n   xmm3/m128                                       corresponding sign in      \n                                                   xmm3/m128.                 \n                                                   Negate/zero/preserve       \n   VEX.128.66.0F38.WIG 0A                          packed doubleword integers \n   /r VPSIGND xmm1, xmm2,  RVM   V/V       AVX     in xmm2 depending on the   \n   xmm3/m128                                       corresponding sign in      \n                                                   xmm3/m128.                 \n                                                   Negate packed byte         \n   VEX.256.66.0F38.WIG 08                          integers in ymm2 if the    \n   /r VPSIGNB ymm1, ymm2,  RVM   V/V       AVX2    corresponding sign in      \n   ymm3/m256                                       ymm3/m256 is less than     \n                                                   zero.                      \n                                                   Negate packed 16-bit       \n   VEX.256.66.0F38.WIG 09                          integers in ymm2 if the    \n   /r VPSIGNW ymm1, ymm2,  RVM   V/V       AVX2    corresponding sign in      \n   ymm3/m256                                       ymm3/m256 is less than     \n                                                   zero.                      \n                                                   Negate packed doubleword   \n   VEX.256.66.0F38.WIG 0A                          integers in ymm2 if the    \n   /r VPSIGND ymm1, ymm2,  RVM   V/V       AVX2    corresponding sign in      \n   ymm3/m256                                       ymm3/m256 is less than     \n                                                   zero.                      \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   (V)PSIGNB/(V)PSIGNW/(V)PSIGND negates each data element of the destination\n   operand (the first operand) if the signed integer value of the\n   corresponding data element in the source operand (the second operand) is\n   less than zero. If the signed integer value of a data element in the\n   source operand is positive, the corresponding data element in the\n   destination operand is unchanged. If a data element in the source operand\n   is zero, the corresponding data element in the destination operand is set\n   to zero.\n\n   (V)PSIGNB operates on signed bytes. (V)PSIGNW operates on 16-bit signed\n   words. (V)PSIGND operates on signed 32-bit integers.\n\n   Legacy SSE instructions: Both operands can be MMX registers. In 64-bit\n   mode, use the REX prefix to access additional registers.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed. VEX.L must be 0, otherwise instructions will #UD.\n\n   VEX.256 encoded version: The first source and destination operands are YMM\n   registers. The second source operand is an YMM register or a 256-bit\n   memory location.\n"],
	["tilestored", "                            TILESTORED \u2014 Store Tile\n\n                                       64/32 bit CPUID                        \n   Opcode/Instruction            Op/En Mode      Feature Flag Description\n                                       Support   \n   VEX.128.F3.0F38.W0 4B                                      Store a tile in \n   !(11):rrr:100 TILESTORED      A     V/N.E.    AMX-TILE     sibmem as       \n   sibmem, tmm1                                               specified in    \n                                                              tmm1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   This instruction is required to use SIB addressing. The index register\n   serves as a stride indicator. If the SIB encoding omits an index register,\n   the value zero is assumed for the content of the index register.\n\n   This instruction stores a tile source of rows and columns as specified by\n   the tile configuration.\n\n   The TILECFG.start_row in the TILECFG data should be initialized to '0' in\n   order to store the entire tile and are set to zero on successful\n   completion of the TILESTORED instruction. TILESTORED is a restartable\n   instruction and the TILECFG.start_row will be non-zero when restartable\n   events occur during the instruction execution.\n\n   Only memory operands are supported and they can only be accessed using a\n   SIB addressing mode, similar to the V[P]GATHER*/V[P]SCATTER* instructions.\n\n   Any attempt to execute the TILESTORED instruction inside an Intel TSX\n   transaction will result in a transaction abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtqq2ps", "    VCVTQQ2PS \u2014 Convert Packed Quadword Integers to Packed Single Precision\n                              Floating-PointValues\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Convert two packed        \n   EVEX.128.0F.W1 5B /r                             quadword integers from    \n   VCVTQQ2PS xmm1 {k1}{z}, A     V/V       AVX512VL xmm2/mem to packed single \n   xmm2/m128/m64bcst                       AVX512DQ precision floating-point  \n                                                    values in xmm1 with       \n                                                    writemask k1.             \n                                                    Convert four packed       \n   EVEX.256.0F.W1 5B /r                             quadword integers from    \n   VCVTQQ2PS xmm1 {k1}{z}, A     V/V       AVX512VL ymm2/mem to packed single \n   ymm2/m256/m64bcst                       AVX512DQ precision floating-point  \n                                                    values in xmm1 with       \n                                                    writemask k1.             \n                                                    Convert eight packed      \n   EVEX.512.0F.W1 5B /r                             quadword integers from    \n   VCVTQQ2PS ymm1 {k1}{z}, A     V/V       AVX512DQ zmm2/mem to eight packed  \n   zmm2/m512/m64bcst{er}                            single precision          \n                                                    floating-point values in  \n                                                    ymm1 with writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed quadword integers in the source operand (second operand)\n   to packed single precision floating-point values in the destination\n   operand (first operand).\n\n   The source operand is a ZMM/YMM/XMM register or a 512/256/128-bit memory\n   location. The destination operation is a YMM/XMM/XMM (lower 64 bits)\n   register conditionally updated with writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["fisttp", "                     FISTTP \u2014 Store Integer With Truncation\n\n   Opcode Instruction   64-Bit Mode Compat/Leg Mode Description               \n   DF /1  FISTTP m16int Valid       Valid           Store ST(0) in m16int     \n                                                    with truncation.          \n   DB /1  FISTTP m32int Valid       Valid           Store ST(0) in m32int     \n                                                    with truncation.          \n   DD /1  FISTTP m64int Valid       Valid           Store ST(0) in m64int     \n                                                    with truncation.          \n\nDescription \u00b6\n\n   FISTTP converts the value in ST into a signed integer using truncation\n   (chop) as rounding mode, transfers the result to the destination, and pop\n   ST. FISTTP accepts word, short integer, and long integer destinations.\n\n   The following table shows the results obtained when storing various\n   classes of numbers in integer format.\n\n   ST(0)                                  DEST \n   \u2212 \u221e or Value Too Large for DEST Format *    \n   F\u2264 \u22121                                  \u2212I   \n   \u22121<F<+1                                0    \n   FS\u030c+1                                  +I   \n   + \u221e or Value Too Large for DEST Format *    \n   NaN                                    *    \n\n   Table 3-28. FISTTP Results\n\n     F Meansfinitefloating-pointvalue.\n\n     \u0399 Means integer.\n\n     \u2217 Indicates floating-point invalid-operation (#IA) exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFlags Affected \u00b6\n\n   C1 is cleared; C0, C2, C3 undefined.\n"],
	["vtestpd:vtestps", "                       VTESTPD/VTESTPS \u2014 Packed Bit Test\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction    Op /En Mode      Feature Description\n                                Support   Flag    \n   VEX.128.66.0F38.W0 0E                          Set ZF and CF depending on  \n   /r VTESTPS xmm1,      RM     V/V       AVX     sign bit AND and ANDN of    \n   xmm2/m128                                      packed single-precision     \n                                                  floating-point sources.     \n   VEX.256.66.0F38.W0 0E                          Set ZF and CF depending on  \n   /r VTESTPS ymm1,      RM     V/V       AVX     sign bit AND and ANDN of    \n   ymm2/m256                                      packed single-precision     \n                                                  floating-point sources.     \n   VEX.128.66.0F38.W0 0F                          Set ZF and CF depending on  \n   /r VTESTPD xmm1,      RM     V/V       AVX     sign bit AND and ANDN of    \n   xmm2/m128                                      packed double precision     \n                                                  floating-point sources.     \n   VEX.256.66.0F38.W0 0F                          Set ZF and CF depending on  \n   /r VTESTPD ymm1,      RM     V/V       AVX     sign bit AND and ANDN of    \n   ymm2/m256                                      packed double precision     \n                                                  floating-point sources.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   VTESTPS performs a bitwise comparison of all the sign bits of the packed\n   single-precision elements in the first source operation and corresponding\n   sign bits in the second source operand. If the AND of the source sign bits\n   with the dest sign bits produces all zeros, the ZF is set else the ZF is\n   clear. If the AND of the source sign bits with the inverted dest sign bits\n   produces all zeros the CF is set else the CF is clear. An attempt to\n   execute VTESTPS with VEX.W=1 will cause #UD.\n\n   VTESTPD performs a bitwise comparison of all the sign bits of the double\n   precision elements in the first source operation and corresponding sign\n   bits in the second source operand. If the AND of the source sign bits with\n   the dest sign bits produces all zeros, the ZF is set else the ZF is clear.\n   If the AND the source sign bits with the inverted dest sign bits produces\n   all zeros the CF is set else the CF is clear. An attempt to execute\n   VTESTPS with VEX.W=1 will cause #UD.\n\n   The first source register is specified by the ModR/M reg field.\n\n   128-bit version: The first source register is an XMM register. The second\n   source register can be an XMM register or a 128-bit memory location. The\n   destination register is not modified.\n\n   VEX.256 encoded version: The first source register is a YMM register. The\n   second source register can be a YMM register or a 256-bit memory location.\n   The destination register is not modified.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n\nFlags Affected \u00b6\n\n   The OF, AF, PF, SF flags are cleared and the ZF, CF flags are set\n   according to the operation.\n"],
	["vcvttph2uqq", " VCVTTPH2UQQ \u2014 Convert with Truncation Packed FP16 Values to Unsigned Quadword\n                                    Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert two packed    \n                                                        FP16 values in        \n                                                        xmm2/m32/m16bcst to   \n   EVEX.128.66.MAP5.W0 78 /r                AVX512-FP16 two unsigned quadword \n   VCVTTPH2UQQ xmm1{k1}{z},       A V/V     AVX512VL    integers, and store   \n   xmm2/m32/m16bcst                                     the result in xmm1    \n                                                        using truncation      \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert four packed   \n                                                        FP16 values in        \n                                                        xmm2/m64/m16bcst to   \n   EVEX.256.66.MAP5.W0 78 /r                AVX512-FP16 four unsigned         \n   VCVTTPH2UQQ ymm1{k1}{z},       A V/V     AVX512VL    quadword integers,    \n   xmm2/m64/m16bcst                                     and store the result  \n                                                        in ymm1 using         \n                                                        truncation subject to \n                                                        writemask k1.         \n                                                        Convert eight packed  \n                                                        FP16 values in        \n                                                        xmm2/m128/m16bcst to  \n   EVEX.512.66.MAP5.W0 78 /r                            eight unsigned        \n   VCVTTPH2UQQ zmm1{k1}{z},       A V/V     AVX512-FP16 quadword integers,    \n   xmm2/m128/m16bcst {sae}                              and store the result  \n                                                        in zmm1 using         \n                                                        truncation subject to \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Quarter ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   unsigned quadword integers in the destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer indefinite value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["vpshld", "            VPSHLD \u2014 Concatenate and Shift Packed Data Left Logical\n\n                                 64/32 bit CPUID Feature                      \n   Opcode/Instruction      Op/En Mode      Flag          Description\n                                 Support   \n                                                         Concatenate          \n   EVEX.128.66.0F3A.W1 70                                destination and      \n   /r /ib VPSHLDW                          AVX512_VBMI2  source operands,     \n   xmm1{k1}{z}, xmm2,      A     V/V       AVX512VL      extract result       \n   xmm3/m128, imm8                                       shifted to the left  \n                                                         by constant value in \n                                                         imm8 into xmm1.      \n                                                         Concatenate          \n   EVEX.256.66.0F3A.W1 70                                destination and      \n   /r /ib VPSHLDW                          AVX512_VBMI2  source operands,     \n   ymm1{k1}{z}, ymm2,      A     V/V       AVX512VL      extract result       \n   ymm3/m256, imm8                                       shifted to the left  \n                                                         by constant value in \n                                                         imm8 into ymm1.      \n                                                         Concatenate          \n   EVEX.512.66.0F3A.W1 70                                destination and      \n   /r /ib VPSHLDW                                        source operands,     \n   zmm1{k1}{z}, zmm2,      A     V/V       AVX512_VBMI2  extract result       \n   zmm3/m512, imm8                                       shifted to the left  \n                                                         by constant value in \n                                                         imm8 into zmm1.      \n                                                         Concatenate          \n   EVEX.128.66.0F3A.W0 71                                destination and      \n   /r /ib VPSHLDD                          AVX512_VBMI2  source operands,     \n   xmm1{k1}{z}, xmm2,      B     V/V       AVX512VL      extract result       \n   xmm3/m128/m32bcst, imm8                               shifted to the left  \n                                                         by constant value in \n                                                         imm8 into xmm1.      \n                                                         Concatenate          \n   EVEX.256.66.0F3A.W0 71                                destination and      \n   /r /ib VPSHLDD                          AVX512_VBMI2  source operands,     \n   ymm1{k1}{z}, ymm2,      B     V/V       AVX512VL      extract result       \n   ymm3/m256/m32bcst, imm8                               shifted to the left  \n                                                         by constant value in \n                                                         imm8 into ymm1.      \n                                                         Concatenate          \n   EVEX.512.66.0F3A.W0 71                                destination and      \n   /r /ib VPSHLDD                                        source operands,     \n   zmm1{k1}{z}, zmm2,      B     V/V       AVX512_VBMI2  extract result       \n   zmm3/m512/m32bcst, imm8                               shifted to the left  \n                                                         by constant value in \n                                                         imm8 into zmm1.      \n                                                         Concatenate          \n   EVEX.128.66.0F3A.W1 71                                destination and      \n   /r /ib VPSHLDQ                          AVX512_VBMI2  source operands,     \n   xmm1{k1}{z}, xmm2,      B     V/V       AVX512VL      extract result       \n   xmm3/m128/m64bcst, imm8                               shifted to the left  \n                                                         by constant value in \n                                                         imm8 into xmm1.      \n                                                         Concatenate          \n   EVEX.256.66.0F3A.W1 71                                destination and      \n   /r /ib VPSHLDQ                          AVX512_VBMI2  source operands,     \n   ymm1{k1}{z}, ymm2,      B     V/V       AVX512VL      extract result       \n   ymm3/m256/m64bcst, imm8                               shifted to the left  \n                                                         by constant value in \n                                                         imm8 into ymm1.      \n                                                         Concatenate          \n   EVEX.512.66.0F3A.W1 71                                destination and      \n   /r /ib VPSHLDQ                                        source operands,     \n   zmm1{k1}{z}, zmm2,      B     V/V       AVX512_VBMI2  extract result       \n   zmm3/m512/m64bcst, imm8                               shifted to the left  \n                                                         by constant value in \n                                                         imm8 into zmm1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n   B     Full     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   Concatenate packed data, extract result shifted to the left by constant\n   value.\n\n   This instruction supports memory fault suppression.\n"],
	["cvttpd2pi", "   CVTTPD2PI \u2014 Convert With Truncation Packed Double Precision Floating-Point\n                         Values to PackedDword Integers\n\n   Opcode/Instruction    Op/En 64-Bit Compat/Leg Description                  \n                               Mode   Mode       \n                                                 Convert two packer double    \n                                                 precision floating-point     \n   66 0F 2C /r CVTTPD2PI RM    Valid  Valid      values from xmm/m128 to two  \n   mm, xmm/m128                                  packed signed doubleword     \n                                                 integers in mm using         \n                                                 truncation.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two packed double precision floating-point values in the source\n   operand (second operand) to two packed signed doubleword integers in the\n   destination operand (first operand). The source operand can be an XMM\n   register or a 128-bit memory location. The destination operand is an MMX\n   technology register.\n\n   When a conversion is inexact, a truncated (round toward zero) result is\n   returned. If a converted result is larger than the maximum signed\n   doubleword integer, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (80000000H) is\n   returned.\n\n   This instruction causes a transition from x87 FPU to MMX technology\n   operation (that is, the x87 FPU top-of-stack pointer is set to 0 and the\n   x87 FPU tag word is set to all 0s [valid]). If this instruction is\n   executed while an x87 FPU floating-point exception is pending, the\n   exception is handled before the CVTTPD2PI instruction is executed.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["fpatan", "                          FPATAN \u2014 Partial Arctangent\n\n   Opcode^1\n\n         Instruction 64-Bit Mode Compat/Leg Description                       \n                                 Mode       \n                                            Replace ST(1) with                \n   D9 F3                         Valid      arctan(ST(1)/ST(0)) and pop the   \n                                            register stack.                   \n\n   1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Computes the arctangent of the source operand in register ST(1) divided by\n   the source operand in register ST(0), stores the result in ST(1), and pops\n   the FPU register stack. The result in register ST(0) has the same sign as\n   the source operand ST(1) and a magnitude less than +\u03c0.\n\n   The FPATAN instruction returns the angle between the X axis and the line\n   from the origin to the point (X,Y), where Y (the ordinate) is ST(1) and X\n   (the abscissa) is ST(0). The angle depends on the sign of X and Y\n   independently, not just on the sign of the ratio Y/X. This is because a\n   point (\u2212X,Y) is in the second quadrant, resulting in an angle between \u03c0/2\n   and \u03c0, while a point (X,\u2212Y) is in the fourth quadrant, resulting in an\n   angle between 0 and \u2212\u03c0/2. A point (\u2212X,\u2212Y) is in the third quadrant, giving\n   an angle between \u2212\u03c0/2 and \u2212\u03c0.\n\n   The following table shows the results obtained when computing the\n   arctangent of various classes of numbers, assuming that underflow does not\n   occur.\n\n   ST(0) \n             \u2212\u221e      \u2212F         \u22120    +0    +F         +\u221e     NaN \n         \u2212\u221e  \u2212 3\u03c0/4* \u2212 \u03c0/2      \u2212 \u03c0/2 \u2212 \u03c0/2 \u2212 \u03c0/2      \u2212 \u03c0/4* NaN \n         \u2212F  -p      \u2212\u03c0 to \u2212\u03c0/2 \u2212\u03c0/2  \u2212\u03c0/2  \u2212\u03c0/2 to \u22120 -0     NaN \n   ST(1) \u22120  -p      -p         -p*   \u2212 0*  \u22120         \u22120     NaN \n         +0  +p      +p         + \u03c0*  + 0*  +0         +0     NaN \n         +F  +p      +\u03c0 to +\u03c0/2 + \u03c0/2 +\u03c0/2  +\u03c0/2 to +0 +0     NaN \n         +\u221e  +3\u03c0/4*  +\u03c0/2       +\u03c0/2  +\u03c0/2  + \u03c0/2      + \u03c0/4* NaN \n         NaN NaN     NaN        NaN   NaN   NaN        NaN    NaN \n\n   Table 3-30. FPATAN Results\n\n     F Means finite floating-point value. *\n     Table8-10intheIntel^\u00ae64andIA-32ArchitecturesSoftwareDeveloper\u2019sManual,Volume1,specifiesthattheratios0/0and\u221e/\u221e\n     generate the floating-point invalid arithmetic-operation exception and,\n     if this exception is masked, the floating-point QNaN indefinite value is\n     returned. With the FPATAN instruction, the 0/0 or \u221e/\u221e value is actually\n     not calculated using division. Instead, the arctangent of the two\n     variables is derived from a standard mathematical formulation that is\n     generalized to allow complex numbers as arguments. In this complex\n     variable formulation, arctangent(0,0) etc. has well defined values.\n     These values are needed to develop a library to compute transcendental\n     functions with complex arguments, based on the FPU functions that only\n     allow floating-point values as arguments.\n\n   There is no restriction on the range of source operands that FPATAN can\n   accept.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The source operands for this instruction are restricted for the 80287 math\n   coprocessor to the following range:\n\n   0 \u2264 |ST(1)| < |ST(0)| < +\u221e\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["edbgwr", "                       EDBGWR \u2014 Write to a Debug Enclave\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   This leaf function writes  \n   EAX = 05H ENCLS[EDBGWR] IR    V/V       SGX1    a dword/quadword to a      \n                                                   debug enclave.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                      RBX                       RCX               \n                     Return error Data to be written to a   Address of Target \n   IR    EDBGWR (In) code (Out)   debug enclave (In)        memory in the EPC \n                                                            (In)              \n\n  Description \u00b6\n\n   This leaf function copies the content in EBX/RBX to an EPC page belonging\n   to a debug enclave. Eight bytes are written in 64-bit mode, four bytes are\n   written in non-64-bit modes. The size of data cannot be overridden.\n\n   The effective address of the target location inside the EPC is provided in\n   the register RCX.\n\nEDBGWR Memory Parameter Semantics \u00b6\n\n   EPCQW                             \n   Write access permitted by Enclave \n\n   The instruction faults if any of the following:\n\nEDBGWR Faulting Conditions \u00b6\n\n   RCX points into a page that is an SECS.  RCX does not resolve to a         \n                                            naturally aligned linear address. \n   RCX points to a page that does not       RCX points to a location inside a \n   belong to an enclave that is in debug    TCS that is not the FLAGS word.   \n   mode.                                    \n   An operand causing any segment           May page fault.                   \n   violation.                               \n   CPL > 0.                                 \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EDBGWR successful.                             \n   SGX_PAGE_NOT_DEBUGGABLE     The EPC page cannot be accessed because it is  \n                               in the PENDING or MODIFIED state.              \n\n   Table 38-20. EDBGWR Return Value in RAX\n\n   This instruction ignores the EPCM RWX attributes on the enclave page.\n   Consequently, violation of EPCM RWX attributes via EDBGRD does not result\n   in a #GP.\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                         Parameter       Base Concurrency Restrictions\n                                                       On Conflict      \n   EDBGWR EDBGWR Target                         \n   [DS:RCX] Shared EDBGWR       Target [DS:RCX]\n   Target [DS:RCX]              \n\n   Table 38-21. Base Concurrency Restrictions of EDBGWR\n\n                    Additional Concurrency Restrictions\n                    vs. EACCEPT, EACCEPTCOPY, vs.  vs. EADD,                 \n                    EADD, EEXTEND, EINIT vs.       EEXTEND, EINIT            \n                    ETRACK, ETRACKC Access vs.     vs. EADD,      vs. ETRACK,\n                    ETRACK, ETRACKC Access On      EEXTEND, EINIT ETRACKC\n   Leaf   Parameter Conflict Access vs. ETRACK,    vs. ETRACK,  \n                    ETRACKC Access On Conflict     ETRACKC      \n                    EMODPE, EMODPR, EMODT       \n                    Access On Conflict Access   \n                    On Conflict Access Access   \n                    On Conflict Access On       \n                    Conflict                    \n   EDBGWR Target    Concurrent                     Concurrent     Concurrent \n          [DS:RCX]  \n\n   Table 38-22. Additional Concurrency Restrictions of EDBGWR\n\n  Flags Affected \u00b6\n\n   ZF is set if the page is MODIFIED or PENDING; RAX contains the error code.\n   Otherwise ZF is cleared and RAX is set to 0. CF, PF, AF, OF, SF are\n   cleared.\n"],
	["vfixupimmps", "               VFIXUPIMMPS \u2014 Fix Up Special Packed Float32 Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Fix up special numbers  \n   EVEX.128.66.0F3A.W0 54 /r                          in float32 vector xmm1, \n   VFIXUPIMMPS xmm1 {k1}{z},                 AVX512VL float32 vector xmm2 and \n   xmm2, xmm3/m128/m32bcst,  A     V/V       AVX512F  int32 vector            \n   imm8                                               xmm3/m128/m32bcst and   \n                                                      store the result in     \n                                                      xmm1, under writemask.  \n                                                      Fix up special numbers  \n   EVEX.256.66.0F3A.W0 54 /r                          in float32 vector ymm1, \n   VFIXUPIMMPS ymm1 {k1}{z},                 AVX512VL float32 vector ymm2 and \n   ymm2, ymm3/m256/m32bcst,  A     V/V       AVX512F  int32 vector            \n   imm8                                               ymm3/m256/m32bcst and   \n                                                      store the result in     \n                                                      ymm1, under writemask.  \n                                                      Fix up elements of      \n                                                      float32 vector in zmm2  \n   EVEX.512.66.0F3A.W0 54 /r                          using int32 vector      \n   ib VFIXUPIMMPS zmm1                                table in                \n   {k1}{z}, zmm2,            A     V/V       AVX512F  zmm3/m512/m32bcst,      \n   zmm3/m512/m32bcst{sae},                            combine with preserved  \n   imm8                                               elements from zmm1, and \n                                                      store the result in     \n                                                      zmm1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Perform fix-up of doubleword elements encoded in single precision\n   floating-point format in the first source operand (the second operand)\n   using a 32-bit, two-level look-up table specified in the corresponding\n   doubleword element of the second source operand (the third operand) with\n   exception reporting specifier imm8. The elements that are fixed-up are\n   selected by mask bits of 1 specified in the opmask k1. Mask bits of 0 in\n   the opmask k1 or table response action of 0000b preserves the\n   corresponding element of the first operand. The fixed-up elements from the\n   first source operand and the preserved element in the first operand are\n   combined as the final results in the destination operand (the first\n   operand).\n\n   The destination and the first source operands are ZMM/YMM/XMM registers.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 64-bit\n   memory location.\n\n   The two-level look-up table perform a fix-up of each single precision\n   floating-point input data in the first source operand by decoding the\n   input data encoding into 8 token types. A response table is defined for\n   each token type that converts the input encoding in the first source\n   operand with one of 16 response actions.\n\n   This instruction is specifically intended for use in fixing up the results\n   of arithmetic calculations involving one source so that they match the\n   spec, although it is generally useful for fixing up the results of\n   multiple-instruction sequences to reflect special-number inputs. For\n   example, consider rcp(0). Input 0 to rcp, and you should get INF according\n   to the DX10 spec. However, evaluating rcp via Newton-Raphson, where\n   x=approx(1/0), yields an incorrect result. To deal with this, VFIXUPIMMPS\n   can be used after the N-R reciprocal sequence to set the result to the\n   correct value (i.e., INF when the input is 0).\n\n   If MXCSR.DAZ is not set, denormal input elements in the first source\n   operand are considered as normal inputs and do not trigger any fixup nor\n   fault reporting.\n\n   Imm8 is used to set the required flags reporting. It supports #ZE and #IE\n   fault reporting (see details below).\n\n   MXCSR.DAZ is used and refer to zmm2 only (i.e., zmm1 is not considered as\n   zero in case MXCSR.DAZ is set).\n\n   MXCSR mask bits are ignored and are treated as if all mask bits are set to\n   masked response). If any of the imm8 bits is set and the condition met for\n   fault reporting, MXCSR.IE or MXCSR.ZE might be updated.\n"],
	["fldenv", "                       FLDENV \u2014 Load x87 FPU Environment\n\n   Opcode  Mode Leg Mode Description                                   \n   D9 /4                 Load FPU environment from m14byte or m28byte. \n\nDescription \u00b6\n\n   Loads the complete x87 FPU operating environment from memory into the FPU\n   registers. The source operand specifies the first byte of the\n   operating-environment data in memory. This data is typically written to\n   the specified memory location by a FSTENV or FNSTENV instruction.\n\n   The FPU operating environment consists of the FPU control word, status\n   word, tag word, instruction pointer, data pointer, and last opcode.\n   Figures 8-9 through 8-12 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, show the layout in memory of the\n   loaded environment, depending on the operating mode of the processor\n   (protected or real) and the current operand-size attribute (16-bit or\n   32-bit). In virtual-8086 mode, the real mode layouts are used.\n\n   The FLDENV instruction should be executed in the same operating mode as\n   the corresponding FSTENV/FNSTENV instruction.\n\n   If one or more unmasked exception flags are set in the new FPU status\n   word, a floating-point exception will be generated upon execution of the\n   next floating-point instruction (except for the no-wait floating-point\n   instructions, see the section titled \u201cSoftware Exception Handling\u201d in\n   Chapter 8 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1). To avoid generating exceptions when loading a new\n   environment, clear all the exception flags in the FPU status word that is\n   being loaded.\n\n   If a page or limit fault occurs during the execution of this instruction,\n   the state of the x87 FPU registers as seen by the fault handler may be\n   different than the state being loaded from memory. In such situations, the\n   fault handler should ignore the status of the x87 FPU registers, handle\n   the fault, and return. The FLDENV instruction will then complete the\n   loading of the x87 FPU registers with no resulting context inconsistency.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   The C0, C1, C2, C3 flags are loaded.\n"],
	["vrcp14ps", "      VRCP14PS \u2014 Compute Approximate Reciprocals of Packed Float32 Values\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Computes the approximate   \n   EVEX.128.66.0F38.W0 4C                          reciprocals of the packed  \n   /r VRCP14PS xmm1                       AVX512VL single-precision           \n   {k1}{z},               A     V/V       AVX512F  floating-point values in   \n   xmm2/m128/m32bcst                               xmm2/m128/m32bcst and      \n                                                   stores the results in      \n                                                   xmm1. Under writemask.     \n                                                   Computes the approximate   \n   EVEX.256.66.0F38.W0 4C                          reciprocals of the packed  \n   /r VRCP14PS ymm1                       AVX512VL single-precision           \n   {k1}{z},               A     V/V       AVX512F  floating-point values in   \n   ymm2/m256/m32bcst                               ymm2/m256/m32bcst and      \n                                                   stores the results in      \n                                                   ymm1. Under writemask.     \n                                                   Computes the approximate   \n   EVEX.512.66.0F38.W0 4C                          reciprocals of the packed  \n   /r VRCP14PS zmm1                                single-precision           \n   {k1}{z},               A     V/V       AVX512F  floating-point values in   \n   zmm2/m512/m32bcst                               zmm2/m512/m32bcst and      \n                                                   stores the results in      \n                                                   zmm1. Under writemask.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate\n   reciprocals of the packed single-precision floating-point values in the\n   source operand (the second operand) and stores the packed single-precision\n   floating-point results in the destination operand (the first operand). The\n   maximum relative error for this approximation is less than 2^-14.\n\n   The source operand can be a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a ZMM register conditionally updated according to the\n   writemask.\n\n   The VRCP14PS instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. A denormal source value will be treated as\n   zero only in case of DAZ bit set in MXCSR. Otherwise it is treated\n   correctly (i.e., not as a 0.0). Underflow results are flushed to zero only\n   in case of FTZ bit set in MXCSR. Otherwise it will be treated correctly\n   (i.e., correct underflow result is written) with the sign of the operand.\n   When a source value is a SNaN or QNaN, the SNaN is converted to a QNaN or\n   the source QNaN is returned.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n   Input value      Result value Comments                                  \n   _0 \u2264 X \u2264 2^-128  INF          Very small denormal                       \n   -2^-128 \u2264 X \u2264 -0 -INF         Very small denormal                       \n   X > 2^126        Underflow    Up to 18 bits of fractions are returned^1 \n   X < -2^126       -Underflow   Up to 18 bits of fractions are returned^1 \n   _X = 2-n         _2^n         \n   X = -2^-n        -2^n         \n\n   Table 5-27. VRCP14PS/VRCP14SS Special Cases\n\n     1. In this case, the mantissa is shifted right by one or two bits.\n\n   A numerically exact implementation of VRCP14xx can be found at:\n\n  https://software.intel.com/en-us/articles/reference-implementations-for-IA-approximation-instructions-vrcp14-\n  \u00b6\n\n  vrsqrt14-vrcp28-vrsqrt28-vexp2. \u00b6\n"],
	["vmclear", "               VMCLEAR \u2014 Clear Virtual-Machine Control Structure\n\n   Opcode/Instruction      Op/En Description                              \n   66 0F C7 /6 VMCLEAR m64 M     Copy VMCS data to VMCS region in memory. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) NA        NA        NA        \n\nDescription \u00b6\n\n   This instruction applies to the VMCS whose VMCS region resides at the\n   physical address contained in the instruction operand. The instruction\n   ensures that VMCS data for that VMCS (some of these data may be currently\n   maintained on the processor) are copied to the VMCS region in memory. It\n   also initializes parts of the VMCS region (for example, it sets the launch\n   state of that VMCS to clear). See Chapter 25, \u201cVirtual Machine Control\n   Structures.\u201d\n\n   The operand of this instruction is always 64 bits and is always in memory.\n   If the operand is the current-VMCS pointer, then that pointer is made\n   invalid (set to FFFFFFFF_FFFFFFFFH).\n\n   Note that the VMCLEAR instruction might not explicitly write any VMCS data\n   to memory; the data may be already resident in memory before the VMCLEAR\n   is executed.\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["vpdpbusds", "     VPDPBUSDS \u2014 Multiply and Add Unsigned and Signed Bytes With Saturation\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply groups of 4  \n                                                        pairs signed bytes in \n                                                        xmm3/m128 with        \n   VEX.128.66.0F38.W0 51                                corresponding         \n   /r VPDPBUSDS xmm1,     A     V/V       AVX-VNNI      unsigned bytes of     \n   xmm2, xmm3/m128                                      xmm2, summing those   \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result, with signed   \n                                                        saturation in xmm1.   \n                                                        Multiply groups of 4  \n                                                        pairs signed bytes in \n                                                        ymm3/m256 with        \n   VEX.256.66.0F38.W0 51                                corresponding         \n   /r VPDPBUSDS ymm1,     A     V/V       AVX-VNNI      unsigned bytes of     \n   ymm2, ymm3/m256                                      ymm2, summing those   \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result, with signed   \n                                                        saturation in ymm1.   \n                                                        Multiply groups of 4  \n                                                        pairs signed bytes in \n                                                        xmm3/m128/m32bcst     \n   EVEX.128.66.0F38.W0 51                               with corresponding    \n   /r VPDPBUSDS                           AVX512_VNNI   unsigned bytes of     \n   xmm1{k1}{z}, xmm2,     B     V/V       AVX512VL      xmm2, summing those   \n   xmm3/m128/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result, with signed   \n                                                        saturation in xmm1,   \n                                                        under writemask k1.   \n                                                        Multiply groups of 4  \n                                                        pairs signed bytes in \n                                                        ymm3/m256/m32bcst     \n   EVEX.256.66.0F38.W0 51                               with corresponding    \n   /r VPDPBUSDS                           AVX512_VNNI   unsigned bytes of     \n   ymm1{k1}{z}, ymm2,     B     V/V       AVX512VL      ymm2, summing those   \n   ymm3/m256/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result, with signed   \n                                                        saturation in ymm1,   \n                                                        under writemask k1.   \n                                                        Multiply groups of 4  \n                                                        pairs signed bytes in \n                                                        zmm3/m512/m32bcst     \n   EVEX.512.66.0F38.W0 51                               with corresponding    \n   /r VPDPBUSDS                                         unsigned bytes of     \n   zmm1{k1}{z}, zmm2,     B     V/V       AVX512_VNNI   zmm2, summing those   \n   zmm3/m512/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result, with signed   \n                                                        saturation in zmm1,   \n                                                        under writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A   ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full  ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Multiplies the individual unsigned bytes of the first source operand by\n   the corresponding signed bytes of the second source operand, producing\n   intermediate signed word results. The word results are then summed and\n   accumulated in the destination dword element size operand. If the\n   intermediate sum overflows a 32b signed number the result is saturated to\n   either 0x7FFF_FFFF for positive numbers of 0x8000_0000 for negative\n   numbers.\n\n   This instruction supports memory fault suppression.\n"],
	["vcvtudq2ps", "   VCVTUDQ2PS \u2014 Convert Packed Unsigned Doubleword Integers to Packed Single\n                         PrecisionFloating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert four packed      \n                                                     unsigned doubleword      \n   EVEX.128.F2.0F.W0 7A /r                  AVX512VL integers from            \n   VCVTUDQ2PS xmm1 {k1}{z}, A     V/V       AVX512F  xmm2/m128/m32bcst to     \n   xmm2/m128/m32bcst                                 packed single precision  \n                                                     floating-point values in \n                                                     xmm1 with writemask k1.  \n                                                     Convert eight packed     \n                                                     unsigned doubleword      \n   EVEX.256.F2.0F.W0 7A /r                  AVX512VL integers from            \n   VCVTUDQ2PS ymm1 {k1}{z}, A     V/V       AVX512F  ymm2/m256/m32bcst to     \n   ymm2/m256/m32bcst                                 packed single precision  \n                                                     floating-point values in \n                                                     zmm1 with writemask k1.  \n                                                     Convert sixteen packed   \n                                                     unsigned doubleword      \n   EVEX.512.F2.0F.W0 7A /r                           integers from            \n   VCVTUDQ2PS zmm1 {k1}{z}, A     V/V       AVX512F  zmm2/m512/m32bcst to     \n   zmm2/m512/m32bcst{er}                             sixteen packed single    \n                                                     precision floating-point \n                                                     values in zmm1 with      \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed unsigned doubleword integers in the source operand (second\n   operand) to single precision floating-point values in the destination\n   operand (first operand).\n\n   The source operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location or a 512/256/128-bit vector broadcasted from a 32-bit memory\n   location. The destination operand is a ZMM/YMM/XMM register conditionally\n   updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["invvpid", "                INVVPID \u2014 Invalidate Translations Based on VPID\n\n   Opcode/Instruction            Op/En Description                            \n                                       Invalidates entries in the TLBs and    \n   66 0F 38 81 INVVPID r64, m128 RM    paging-structure caches based on VPID  \n                                       (in 64-bit mode).                      \n                                       Invalidates entries in the TLBs and    \n   66 0F 38 81 INVVPID r32, m128 RM    paging-structure caches based on VPID  \n                                       (outside 64-bit mode).                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) NA        NA        \n\nDescription \u00b6\n\n   Invalidates mappings in the translation lookaside buffers (TLBs) and\n   paging-structure caches based on virtualprocessor identifier (VPID). (See\n   Chapter 29, \u201cVMX Support for Address Translation.\u201d) Invalidation is based\n   on the INVVPID type specified in the register operand and the INVVPID\n   descriptor specified in the memory operand.\n\n   Outside IA-32e mode, the register operand is always 32 bits, regardless of\n   the value of CS.D; in 64-bit mode, the register operand has 64 bits (the\n   instruction cannot be executed in compatibility mode).\n\n   The INVVPID types supported by a logical processors are reported in the\n   IA32_VMX_EPT_VPID_CAP MSR (see Appendix A, \u201cVMX Capability Reporting\n   Facility\u201d). There are four INVVPID types currently defined:\n\n     * Individual-address invalidation: If the INVVPID type is 0, the logical\n       processor invalidates mappings for the linear address and VPID\n       specified in the INVVPID descriptor. In some cases, it may invalidate\n       mappings for other linear addresses (or other VPIDs) as well.\n     * Single-context invalidation: If the INVVPID type is 1, the logical\n       processor invalidates all mappings tagged with the VPID specified in\n       the INVVPID descriptor. In some cases, it may invalidate mappings for\n       other VPIDs as well.\n     * All-contexts invalidation: If the INVVPID type is 2, the logical\n       processor invalidates all mappings tagged with all VPIDs except VPID\n       0000H. In some cases, it may invalidate translations with VPID 0000H\n       as well.\n     * Single-context invalidation, retaining global translations: If the\n       INVVPID type is 3, the logical processor invalidates all mappings\n       tagged with the VPID specified in the INVVPID descriptor except global\n       translations. In some cases, it may invalidate global translations\n       (and mappings with other VPIDs) as well. See the \u201cCaching Translation\n       Information\u201d section in Chapter 4 of the Intel^\u00ae 64 and IA-32\n       Architectures Software Developer\u2019s Manual, Volume 3A, for information\n       about global translations.\n\n   If an unsupported INVVPID type is specified, the instruction fails.\n\n   INVVPID invalidates all the specified mappings for the indicated VPID(s)\n   regardless of the EPTP and PCID values with which those mappings may be\n   associated.\n\n   The INVVPID descriptor comprises 128 bits and consists of a VPID and a\n   linear address as shown in Figure 31-2.\n\n   127 6463 1615 0 Linear Address Reserved (must be zero) VPID Figure 31-2.\n   INVVPID Descriptor\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["xresldtrk", "                   XRESLDTRK \u2014 Resume Tracking Load Addresses\n\n   Opcode/Instruction    Op/En 64/32 bit    CPUID        Description          \n                               Mode Support Feature Flag \n                                                         Specifies the end of \n   F2 0F 01 E9 XRESLDTRK ZO    V/V          TSXLDTRK     an Intel TSX suspend \n                                                         read address         \n                                                         tracking region.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\n  Description \u00b6\n\n   The instruction marks the end of an Intel TSX (RTM) suspend load address\n   tracking region. If the instruction is used inside a suspend load address\n   tracking region it will end the suspend region and all following load\n   addresses will be added to the transaction read set. If this instruction\n   is used inside an active transaction but not in a suspend region it will\n   cause transaction abort.\n\n   If the instruction is used outside of a transactional region it behaves\n   like a NOP.\n\n   Chapter 16, \u201cProgramming with Intel\u00ae Transactional Synchronization\n   Extensions\u201a\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1 provides additional information on Intel^\u00ae\n   TSX Suspend Load Address Tracking.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["movlps", "        MOVLPS \u2014 Move Low Packed Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Move two packed single      \n   NP 0F 12 /r MOVLPS      A    V/V       SSE     precision floating-point    \n   xmm1, m64                                      values from m64 to low      \n                                                  quadword of xmm1.           \n                                                  Merge two packed single     \n   VEX.128.0F.WIG 12 /r    B    V/V       AVX     precision floating-point    \n   VMOVLPS xmm2, xmm1, m64                        values from m64 and the     \n                                                  high quadword of xmm1.      \n                                                  Merge two packed single     \n   EVEX.128.0F.W0 12 /r    D    V/V       AVX512F precision floating-point    \n   VMOVLPS xmm2, xmm1, m64                        values from m64 and the     \n                                                  high quadword of xmm1.      \n                                                  Move two packed single      \n   0F 13/r MOVLPS m64,     C    V/V       SSE     precision floating-point    \n   xmm1                                           values from low quadword of \n                                                  xmm1 to m64.                \n                                                  Move two packed single      \n   VEX.128.0F.WIG 13/r     C    V/V       AVX     precision floating-point    \n   VMOVLPS m64, xmm1                              values from low quadword of \n                                                  xmm1 to m64.                \n                                                  Move two packed single      \n   EVEX.128.0F.W0 13/r     E    V/V       AVX512F precision floating-point    \n   VMOVLPS m64, xmm1                              values from low quadword of \n                                                  xmm1 to m64.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     N/A        ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n   D     Tuple2     ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   E     Tuple2     ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n\nDescription \u00b6\n\n   This instruction cannot be used for register to register or memory to\n   memory moves.\n\n   128-bit Legacy SSE load:\n\n   Moves two packed single precision floating-point values from the source\n   64-bit memory operand and stores them in the low 64-bits of the\n   destination XMM register. The upper 64bits of the XMM register are\n   preserved. Bits (MAXVL-1:128) of the corresponding destination register\n   are preserved.\n\n   VEX.128 & EVEX encoded load:\n\n   Loads two packed single precision floating-point values from the source\n   64-bit memory operand (the third operand), merges them with the upper\n   64-bits of the first source operand (the second operand), and stores them\n   in the low 128-bits of the destination register (the first operand). Bits\n   (MAXVL-1:128) of the corresponding destination register are zeroed.\n\n   128-bit store:\n\n   Loads two packed single precision floating-point values from the low\n   64-bits of the XMM register source (second operand) to the 64-bit memory\n   location (first operand).\n\n   Note: VMOVLPS (store) (VEX.128.0F 13 /r) is legal and has the same\n   behavior as the existing 0F 13 store. For VMOVLPS (store) VEX.vvvv and\n   EVEX.vvvv are reserved and must be 1111b otherwise instruction will #UD.\n\n   If VMOVLPS is encoded with VEX.L or EVEX.L\u2019L= 1, an attempt to execute the\n   instruction encoded with VEX.L or EVEX.L\u2019L= 1 will cause an #UD exception.\n"],
	["bndmov", "                              BNDMOV \u2014 Move Bounds\n\n                                  64/32 bit    CPUID                          \n   Opcode/Instruction       Op/En Mode Support Feature Description\n                                               Flag    \n   66 0F 1A /r BNDMOV bnd1,                            Move lower and upper   \n   bnd2/m64                 RM    N.E./V       MPX     bound from bnd2/m64 to \n                                                       bound register bnd1.   \n                                                       Move lower and upper   \n   66 0F 1A /r BNDMOV bnd1, RM    V/N.E.       MPX     bound from bnd2/m128   \n   bnd2/m128                                           to bound register      \n                                                       bnd1.                  \n   66 0F 1B /r BNDMOV                                  Move lower and upper   \n   bnd1/m64, bnd2           MR    N.E./V       MPX     bound from bnd2 to     \n                                                       bnd1/m64.              \n                                                       Move lower and upper   \n   66 0F 1B /r BNDMOV       MR    V/N.E.       MPX     bound from bnd2 to     \n   bnd1/m128, bnd2                                     bound register         \n                                                       bnd1/m128.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       \n\nDescription \u00b6\n\n   BNDMOV moves a pair of lower and upper bound values from the source\n   operand (the second operand) to the destination (the first operand). Each\n   operation is 128-bit move. The exceptions are same as the MOV instruction.\n   The memory format for loading/store bounds in 64-bit mode is shown in\n   Figure 3-5.\n\n   BNDMOV to memory in 64-bit mode Upper Bound (UB) Lower Bound (LB) 0\n   Byteoffset 16 8 BNDMOV to memory in 32-bit mode Upper Bound (UB) Lower\n   Bound (LB) 0 Byteoffset 16 8 4 Figure 3-5. Memory Layout of BNDMOV to/from\n   Memory\n\n   This instruction does not change flags.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vrsqrt14sd", "  VRSQRT14SD \u2014 Compute Approximate Reciprocal of Square Root of Scalar Float64\n                                     Value\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Computes the approximate   \n                                                   reciprocal square root of  \n                                                   the scalar double          \n   EVEX.LLIG.66.0F38.W1 4F                         precision floating-point   \n   /r VRSQRT14SD xmm1      A     V/V       AVX512F value in xmm3/m64 and      \n   {k1}{z}, xmm2, xmm3/m64                         stores the result in the   \n                                                   low quadword element of    \n                                                   xmm1 using writemask k1.   \n                                                   Bits[127:64] of xmm2 is    \n                                                   copied to xmm1[127:64].    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Computes the approximate reciprocal of the square roots of the scalar\n   double precision floating-point value in the low quadword element of the\n   source operand (the second operand) and stores the result in the low\n   quadword element of the destination operand (the first operand) according\n   to the writemask. The maximum relative error for this approximation is\n   less than 2^-14. The source operand can be an XMM register or a 32-bit\n   memory location. The destination operand is an XMM register.\n\n   Bits (127:64) of the XMM register destination are copied from\n   corresponding bits in the first source operand. Bits (MAXVL-1:128) of the\n   destination register are zeroed.\n\n   The VRSQRT14SD instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. When the source operand is an +\u221e then +ZERO\n   value is returned. A denormal source value is treated as zero only if DAZ\n   bit is set in MXCSR. Otherwise it is treated correctly and performs the\n   approximation with the specified masked response. When a source value is a\n   negative value (other than 0.0) a floating-point QNaN_indefinite is\n   returned. When a source value is an SNaN or QNaN, the SNaN is converted to\n   a QNaN or the source QNaN is returned.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n  A numerically exact implementation of VRSQRT14xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["fptan", "                            FPTAN \u2014 Partial Tangent\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Replace ST(0) with its      \n   D9 F2  FPTAN       Valid       Valid           approximate tangent and     \n                                                  push 1 onto the FPU stack.  \n\nDescription \u00b6\n\n   Computes the approximate tangent of the source operand in register ST(0),\n   stores the result in ST(0), and pushes a 1.0 onto the FPU register stack.\n   The source operand must be given in radians and must be less than \u00b12^63.\n   The following table shows the unmasked results obtained when computing the\n   partial tangent of various classes of numbers, assuming that underflow\n   does not occur.\n\n   ST(0) SRC ST(0) DEST \n   \u2212\u221e        *          \n   \u2212F        \u2212 F to + F \n   \u22120        -0         \n   +0        +0         \n   +F        \u2212 F to + F \n   +\u221e        *          \n   NaN       NaN        \n\n   Table 3-33. FPTAN Results\n\n     F Means finite floating-point value.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   If the source operand is outside the acceptable range, the C2 flag in the\n   FPU status word is set, and the value in register ST(0) remains unchanged.\n   The instruction does not raise an exception when the source operand is out\n   of range. It is up to the program to check the C2 flag for out-of-range\n   conditions. Source values outside the range \u2212 2^63 to +2^63 can be reduced\n   to the range of the instruction by subtracting an appropriate integer\n   multiple of 2\u03c0. However, even within the range -2^63 to +2^63, inaccurate\n   results can occur because the finite approximation of \u03c0 used internally\n   for argument reduction is not sufficient in all cases. Therefore, for\n   accurate results it is safe to apply FPTAN only to arguments reduced\n   accurately in software, to a value smaller in absolute value than 3\u03c0/8.\n   See the sections titled \u201cApproximation of Pi\u201d and \u201cTranscendental\n   Instruction Accuracy\u201d in Chapter 8 of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a discussion of\n   the proper value to use for \u03c0 in performing such reductions.\n\n   The value 1.0 is pushed onto the register stack after the tangent has been\n   computed to maintain compatibility with the Intel 8087 and Intel287 math\n   coprocessors. This operation also simplifies the calculation of other\n   trigonometric functions. For instance, the cotangent (which is the\n   reciprocal of the tangent) can be computed by executing a FDIVR\n   instruction after the FPTAN instruction.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n          Set to 0 if stack underflow occurred; set to 1 if stack overflow    \n          occurred.                                                           \n   C1     Set if result was rounded up; cleared otherwise.                    \n          Set to 1 if outside range (\u2212263 < source operand < +263);           \n          otherwise, set to 0.                                                \n   C2     \n   C0, C3 Undefined.                                                          \n"],
	["blsi", "                     BLSI \u2014 Extract Lowest Set Isolated Bit\n\n                              64/32-bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                                        Flag    \n   VEX.LZ.0F38.W0 F3 /3                         Extract lowest set bit from   \n   BLSI r32, r/m32      VM    V/V       BMI1    r/m32 and set that bit in     \n                                                r32.                          \n   VEX.LZ.0F38.W1 F3 /3                         Extract lowest set bit from   \n   BLSI r64, r/m64      VM    V/N.E.    BMI1    r/m64, and set that bit in    \n                                                r64.                          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1    Operand 2     Operand 3 Operand 4 \n   VM    VEX.vvvv (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Extracts the lowest set bit from the source operand and set the\n   corresponding bit in the destination register. All other bits in the\n   destination operand are zeroed. If no bits are set in the source operand,\n   BLSI sets all the bits in the destination to 0 and sets ZF and CF.\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   ZF and SF are updated based on the result. CF is set if the source is not\n   zero. OF flags are cleared. AF and PF flags are undefined.\n"],
	["wrssd:wrssq", "                      WRSSD/WRSSQ \u2014 Write to Shadow Stack\n\n                                        64/32 bit    CPUID                    \n   Opcode/Instruction             Op/En Mode Support Feature Description\n                                                     Flag    \n   0F 38 F6 !(11):rrr:bbb WRSSD   MR    V/V          CET_SS  Write 4 bytes to \n   m32, r32                                                  shadow stack.    \n   REX.W 0F 38 F6 !(11):rrr:bbb   MR    V/N.E.       CET_SS  Write 8 bytes to \n   WRSSQ m64, r64                                            shadow stack.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Writes bytes in register source to the shadow stack.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["tdpbssd:tdpbsud:tdpbusd:tdpbuud", "  TDPBSSD/TDPBSUD/TDPBUSD/TDPBUUD \u2014 Dot Product of Signed/Unsigned Bytes with\n                               DwordAccumulation\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Matrix multiply signed   \n   VEX.128.F2.0F38.W0 5E                             byte elements from tmm2  \n   11:rrr:bbb TDPBSSD tmm1, A     V/N.E.    AMX-INT8 by signed byte elements  \n   tmm2, tmm3                                        from tmm3 and accumulate \n                                                     the dword elements in    \n                                                     tmm1.                    \n                                                     Matrix multiply signed   \n   VEX.128.F3.0F38.W0 5E                             byte elements from tmm2  \n   11:rrr:bbb TDPBSUD tmm1, A     V/N.E.    AMX-INT8 by unsigned byte         \n   tmm2, tmm3                                        elements from tmm3 and   \n                                                     accumulate the dword     \n                                                     elements in tmm1.        \n                                                     Matrix multiply unsigned \n   VEX.128.66.0F38.W0 5E                             byte elements from tmm2  \n   11:rrr:bbb TDPBUSD tmm1, A     V/N.E.    AMX-INT8 by signed byte elements  \n   tmm2, tmm3                                        from tmm3 and accumulate \n                                                     the dword elements in    \n                                                     tmm1.                    \n                                                     Matrix multiply unsigned \n   VEX.128.NP.0F38.W0 5E                             byte elements from tmm2  \n   11:rrr:bbb TDPBUUD tmm1, A     V/N.E.    AMX-INT8 by unsigned byte         \n   tmm2, tmm3                                        elements from tmm3 and   \n                                                     accumulate the dword     \n                                                     elements in tmm1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3    Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) VEX.vvvv (r) N/A       \n\nDescription \u00b6\n\n   For each possible combination of (row of tmm2, column of tmm3), the\n   instruction performs a set of SIMD dot-products on all corresponding four\n   byte elements, one from tmm2 and one from tmm3, adds the results of those\n   dot-products, and then accumulates the result into the corresponding row\n   and column of tmm1. Each dword in input tiles tmm2 and tmm3 is interpreted\n   as four byte elements. These may be signed or unsigned. Each letter in the\n   two-letter pattern SU, US, SS, UU indicates the signed/unsigned nature of\n   the values in tmm2 and tmm3, respectively.\n\n   Any attempt to execute the TDPBSSD/TDPBSUD/TDPBUSD/TDPBUUD instructions\n   inside an Intel TSX transaction will result in a transaction abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vrcpph", "               VRCPPH \u2014 Compute Reciprocals of Packed FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En bit     \n   Mode Flag CPUID Feature        \n   Instruction En bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En bit Mode Flag   \n   CPUID Feature Instruction En   \n   bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Compute the           \n                                                        approximate           \n   EVEX.128.66.MAP6.W0 4C /r                            reciprocals of packed \n   VRCPPH xmm1{k1}{z},            A V/V     AVX512-FP16 FP16 values in        \n   xmm2/m128/m16bcst                        AVX512VL    xmm2/m128/m16bcst and \n                                                        store the result in   \n                                                        xmm1 subject to       \n                                                        writemask k1.         \n                                                        Compute the           \n                                                        approximate           \n   EVEX.256.66.MAP6.W0 4C /r                            reciprocals of packed \n   VRCPPH ymm1{k1}{z},            A V/V     AVX512-FP16 FP16 values in        \n   ymm2/m256/m16bcst                        AVX512VL    ymm2/m256/m16bcst and \n                                                        store the result in   \n                                                        ymm1 subject to       \n                                                        writemask k1.         \n                                                        Compute the           \n                                                        approximate           \n   EVEX.512.66.MAP6.W0 4C /r                            reciprocals of packed \n   VRCPPH zmm1{k1}{z},            A V/V     AVX512-FP16 FP16 values in        \n   zmm2/m512/m16bcst                                    zmm2/m512/m16bcst and \n                                                        store the result in   \n                                                        zmm1 subject to       \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate\n   reciprocals of 8/16/32 packed FP16 values in the source operand (the\n   second operand) and stores the packed FP16 results in the destination\n   operand. The maximum relative error for this approximation is less than\n   2^\u221211 + 2^\u221214.\n\n   For special cases, see Table 5-28.\n\n   Input Value     Result Value Comments            \n   0 \u2264 X \u2264 2^-16   INF          Very small denormal \n   \u22122^-16 \u2264 X \u2264 -0 \u2212INF         Very small denormal \n   X > +\u221e          +0           \n   X < \u2212\u221e          \u22120           \n   _X = 2-n        _2^n         \n   X = \u22122^-n       \u22122^n         \n\n   Table 5-28. VRCPPH/VRCPSH Special Cases\n"],
	["vfmsub132ss:vfmsub213ss:vfmsub231ss", "    VFMSUB132SS/VFMSUB213SS/VFMSUB231SS \u2014 Fused Multiply-Subtract of Scalar\n                     SinglePrecision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Multiply scalar single    \n   VEX.LIG.66.0F38.W0 9B /r                         precision floating-point  \n   VFMSUB132SS xmm1, xmm2,  A     V/V       FMA     value from xmm1 and       \n   xmm3/m32                                         xmm3/m32, subtract xmm2   \n                                                    and put result in xmm1.   \n                                                    Multiply scalar single    \n   VEX.LIG.66.0F38.W0 AB /r                         precision floating-point  \n   VFMSUB213SS xmm1, xmm2,  A     V/V       FMA     value from xmm1 and xmm2, \n   xmm3/m32                                         subtract xmm3/m32 and put \n                                                    result in xmm1.           \n                                                    Multiply scalar single    \n   VEX.LIG.66.0F38.W0 BB /r                         precision floating-point  \n   VFMSUB231SS xmm1, xmm2,  A     V/V       FMA     value from xmm2 and       \n   xmm3/m32                                         xmm3/m32, subtract xmm1   \n                                                    and put result in xmm1.   \n   EVEX.LLIG.66.0F38.W0 9B                          Multiply scalar single    \n   /r VFMSUB132SS xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm1 and       \n   xmm3/m32{er}                                     xmm3/m32, subtract xmm2   \n                                                    and put result in xmm1.   \n   EVEX.LLIG.66.0F38.W0 AB                          Multiply scalar single    \n   /r VFMSUB213SS xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm1 and xmm2, \n   xmm3/m32{er}                                     subtract xmm3/m32 and put \n                                                    result in xmm1.           \n   EVEX.LLIG.66.0F38.W0 BB                          Multiply scalar single    \n   /r VFMSUB231SS xmm1                              precision floating-point  \n   {k1}{z}, xmm2,           B     V/V       AVX512F value from xmm2 and       \n   xmm3/m32{er}                                     xmm3/m32, subtract xmm1   \n                                                    and put result in xmm1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a SIMD multiply-subtract computation on the low packed single\n   precision floating-point values using three source operands and writes the\n   multiply-subtract result in the destination operand. The destination\n   operand is also the first source operand. The second operand must be a XMM\n   register. The third source operand can be a XMM register or a 32-bit\n   memory location.\n\n   VFMSUB132SS: Multiplies the low packed single precision floating-point\n   value from the first source operand to the low packed single precision\n   floating-point value in the third source operand. From the infinite\n   precision intermediate result, subtracts the low packed single precision\n   floating-point values in the second source operand, performs rounding and\n   stores the resulting packed single precision floating-point value to the\n   destination operand (first source operand).\n\n   VFMSUB213SS: Multiplies the low packed single precision floating-point\n   value from the second source operand to the low packed single precision\n   floating-point value in the first source operand. From the infinite\n   precision intermediate result, subtracts the low packed single precision\n   floating-point value in the third source operand, performs rounding and\n   stores the resulting packed single precision floating-point value to the\n   destination operand (first source operand).\n\n   VFMSUB231SS: Multiplies the low packed single precision floating-point\n   value from the second source to the low packed single precision\n   floating-point value in the third source operand. From the infinite\n   precision intermediate result, subtracts the low packed single precision\n   floating-point value in the first source operand, performs rounding and\n   stores the resulting packed single precision floating-point value to the\n   destination operand (first source operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:32 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination is\n   updated according to the writemask.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["kortestw:kortestb:kortestq:kortestd", "          KORTESTW/KORTESTB/KORTESTQ/KORTESTD \u2014 OR Masks and Set Flags\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction    Op/E n Mode      Feature  Description\n                                Support   Flag     \n   VEX.L0.0F.W0 98 /r                              Bitwise OR 16 bits masks   \n   KORTESTW k1, k2       RR     V/V       AVX512F  k1 and k2 and update ZF    \n                                                   and CF accordingly.        \n   VEX.L0.66.0F.W0 98 /r                           Bitwise OR 8 bits masks k1 \n   KORTESTB k1, k2       RR     V/V       AVX512DQ and k2 and update ZF and   \n                                                   CF accordingly.            \n   VEX.L0.0F.W1 98 /r                              Bitwise OR 64 bits masks   \n   KORTESTQ k1, k2       RR     V/V       AVX512BW k1 and k2 and update ZF    \n                                                   and CF accordingly.        \n   VEX.L0.66.0F.W1 98 /r                           Bitwise OR 32 bits masks   \n   KORTESTD k1, k2       RR     V/V       AVX512BW k1 and k2 and update ZF    \n                                                   and CF accordingly.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2                              \n   RR    ModRM:reg (w) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise OR between the vector mask register k2, and the vector\n   mask register k1, and sets CF and ZF based on the operation result.\n\n   ZF flag is set if both sources are 0x0. CF is set if, after the OR\n   operation is done, the operation result is all 1\u2019s.\n\nFlags Affected \u00b6\n\n   The ZF flag is set if the result of OR-ing both sources is all 0s.\n\n   The CF flag is set if the result of OR-ing both sources is all 1s.\n\n   The OF, SF, AF, and PF flags are set to 0.\n"],
	["vdivph", "                       VDIVPH \u2014 Divide Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Divide packed FP16     \n                                                       values in xmm2 by      \n   EVEX.128.NP.MAP5.W0 5E /r               AVX512-FP16 packed FP16 values in  \n   VDIVPH xmm1{k1}{z}, xmm2,     A V/V     AVX512VL    xmm3/m128/m16bcst, and \n   xmm3/m128/m16bcst                                   store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Divide packed FP16     \n                                                       values in ymm2 by      \n   EVEX.256.NP.MAP5.W0 5E /r               AVX512-FP16 packed FP16 values in  \n   VDIVPH ymm1{k1}{z}, ymm2,     A V/V     AVX512VL    ymm3/m256/m16bcst, and \n   ymm3/m256/m16bcst                                   store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Divide packed FP16     \n                                                       values in zmm2 by      \n   EVEX.512.NP.MAP5.W0 5E /r                           packed FP16 values in  \n   VDIVPH zmm1{k1}{z}, zmm2,     A V/V     AVX512-FP16 zmm3/m512/m16bcst, and \n   zmm3/m512/m16bcst {er}                              store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction divides packed FP16 values from the first source operand\n   by the corresponding elements in the second source operand, storing the\n   packed FP16 result in the destination operand. The destination elements\n   are updated according to the writemask.\n"],
	["vcvtpd2uqq", "  VCVTPD2UQQ \u2014 Convert Packed Double Precision Floating-Point Values to Packed\n                           UnsignedQuadword Integers\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     double precision         \n   EVEX.128.66.0F.W1 79 /r                  AVX512VL floating-point values    \n   VCVTPD2UQQ xmm1 {k1}{z}, A     V/V       AVX512DQ from xmm2/mem to two     \n   xmm2/m128/m64bcst                                 packed unsigned quadword \n                                                     integers in xmm1 with    \n                                                     writemask k1.            \n                                                     Convert fourth packed    \n                                                     double precision         \n   EVEX.256.66.0F.W1 79 /r                  AVX512VL floating-point values    \n   VCVTPD2UQQ ymm1 {k1}{z}, A     V/V       AVX512DQ from ymm2/mem to four    \n   ymm2/m256/m64bcst                                 packed unsigned quadword \n                                                     integers in ymm1 with    \n                                                     writemask k1.            \n                                                     Convert eight packed     \n                                                     double precision         \n   EVEX.512.66.0F.W1 79 /r                           floating-point values    \n   VCVTPD2UQQ zmm1 {k1}{z}, A     V/V       AVX512DQ from zmm2/mem to eight   \n   zmm2/m512/m64bcst{er}                             packed unsigned quadword \n                                                     integers in zmm1 with    \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed double precision floating-point values in the source\n   operand (second operand) to packed unsigned quadword integers in the\n   destination operand (first operand).\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   The source operand is a ZMM/YMM/XMM register or a 512/256/128-bit memory\n   location. The destination operation is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["fbld", "                        FBLD \u2014 Load Binary Coded Decimal\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Convert BCD value to        \n   DF /4  FBLD m80bcd Valid       Valid           floating-point and push     \n                                                  onto the FPU stack.         \n\nDescription \u00b6\n\n   Converts the BCD source operand into double extended-precision\n   floating-point format and pushes the value onto the FPU stack. The source\n   operand is loaded without rounding errors. The sign of the source operand\n   is preserved, including that of \u22120.\n\n   The packed BCD digits are assumed to be in the range 0 through 9; the\n   instruction does not check for invalid digits (AH through FH). Attempting\n   to load an invalid encoding produces an undefined result.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 1 if stack overflow occurred; otherwise, set to 0. \n   C0, C2, C3 Undefined.                                                \n"],
	["vperm2i128", "                      VPERM2I128 \u2014 Permute Integer Values\n\n                                   64/32     CPUID                            \n   Opcode/Instruction        Op/En -bit Mode Feature Description\n                                             Flag    \n                                                     Permute 128-bit integer  \n   VEX.256.66.0F3A.W0 46 /r                          data in ymm2 and         \n   ib VPERM2I128 ymm1, ymm2, RVMI  V/V       AVX2    ymm3/mem using controls  \n   ymm3/m256, imm8                                   from imm8 and store      \n                                                     result in ymm1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVMI  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Permute 128 bit integer data from the first source operand (second\n   operand) and second source operand (third operand) using bits in the 8-bit\n   immediate and store results in the destination operand (first operand).\n   The first source operand is a YMM register, the second source operand is a\n   YMM register or a 256-bit memory location, and the destination operand is\n   a YMM register.\n\n   Y1 Y0 SRC2 X1 X0 SRC1 X0, X1, Y0, or Y1 DEST X0, X1, Y0, or Y1 Figure\n   5-22. VPERM2I128 Operation\n\n   Imm8[1:0] select the source for the first destination 128-bit field,\n   imm8[5:4] select the source for the second destination field. If imm8[3]\n   is set, the low 128-bit field is zeroed. If imm8[7] is set, the high\n   128-bit field is zeroed.\n\n   VEX.L must be 1, otherwise the instruction will #UD.\n"],
	["por", "                            POR \u2014 Bitwise Logical OR\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F EB /r^1 POR mm,   A     V/V       MMX      Bitwise OR of mm/m64 and  \n   mm/m64                                           mm.                       \n   66 0F EB /r POR xmm1,   A     V/V       SSE2     Bitwise OR of xmm2/m128   \n   xmm2/m128                                        and xmm1.                 \n   VEX.128.66.0F.WIG EB /r                          Bitwise OR of xmm2/m128   \n   VPOR xmm1, xmm2,        B     V/V       AVX      and xmm3.                 \n   xmm3/m128               \n   VEX.256.66.0F.WIG EB /r                          Bitwise OR of ymm2/m256   \n   VPOR ymm1, ymm2,        B     V/V       AVX2     and ymm3.                 \n   ymm3/m256               \n                                                    Bitwise OR of packed      \n   EVEX.128.66.0F.W0 EB /r                 AVX512VL doubleword integers in    \n   VPORD xmm1 {k1}{z},     C     V/V       AVX512F  xmm2 and                  \n   xmm2, xmm3/m128/m32bcst                          xmm3/m128/m32bcst using   \n                                                    writemask k1.             \n                                                    Bitwise OR of packed      \n   EVEX.256.66.0F.W0 EB /r                 AVX512VL doubleword integers in    \n   VPORD ymm1 {k1}{z},     C     V/V       AVX512F  ymm2 and                  \n   ymm2, ymm3/m256/m32bcst                          ymm3/m256/m32bcst using   \n                                                    writemask k1.             \n                                                    Bitwise OR of packed      \n   EVEX.512.66.0F.W0 EB /r                          doubleword integers in    \n   VPORD zmm1 {k1}{z},     C     V/V       AVX512F  zmm2 and                  \n   zmm2, zmm3/m512/m32bcst                          zmm3/m512/m32bcst using   \n                                                    writemask k1.             \n   EVEX.128.66.0F.W1 EB /r                          Bitwise OR of packed      \n   VPORQ xmm1 {k1}{z},     C     V/V       AVX512VL quadword integers in xmm2 \n   xmm2, xmm3/m128/m64bcst                 AVX512F  and xmm3/m128/m64bcst     \n                                                    using writemask k1.       \n   EVEX.256.66.0F.W1 EB /r                          Bitwise OR of packed      \n   VPORQ ymm1 {k1}{z},     C     V/V       AVX512VL quadword integers in ymm2 \n   ymm2, ymm3/m256/m64bcst                 AVX512F  and ymm3/m256/m64bcst     \n                                                    using writemask k1.       \n   EVEX.512.66.0F.W1 EB /r                          Bitwise OR of packed      \n   VPORQ zmm1 {k1}{z},     C     V/V       AVX512F  quadword integers in zmm2 \n   zmm2, zmm3/m512/m64bcst                          and zmm3/m512/m64bcst     \n                                                    using writemask k1.       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical OR operation on the source operand (second\n   operand) and the destination operand (first operand) and stores the result\n   in the destination operand. Each bit of the result is set to 1 if either\n   or both of the corresponding bits of the first and second operands are 1;\n   otherwise, it is set to 0.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version: The source operand can be an MMX technology register\n   or a 64-bit memory location. The destination operand is an MMX technology\n   register.\n\n   128-bit Legacy SSE version: The second source operand is an XMM register\n   or a 128-bit memory location. The first source and destination operands\n   can be XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand is an XMM register or a\n   128-bit memory location. The first source and destination operands can be\n   XMM registers. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: The second source operand is an YMM register or a\n   256-bit memory location. The first source and destination operands can be\n   YMM registers.\n\n   EVEX encoded version: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with write-mask k1 at 32/64-bit granularity.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vscalefss", "           VSCALEFSS \u2014 Scale Scalar Float32 Value With Float32 Value\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Scale the scalar           \n   EVEX.LLIG.66.0F38.W0 2D                         single-precision           \n   /r VSCALEFSS xmm1       A     V/V       AVX512F floating-point value in    \n   {k1}{z}, xmm2,                                  xmm2 using floating-point  \n   xmm3/m32{er}                                    value from xmm3/m32. Under \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a floating-point scale of the scalar single-precision\n   floating-point value in the first source operand by multiplying it by 2 to\n   the power of the float32 value in second source operand.\n\n   The equation of this operation is given by:\n\n   xmm1 := xmm2*2^floor(xmm3).\n\n   Floor(xmm3) means maximum integer value \u2264 xmm3.\n\n   If the result cannot be represented in single-precision, then the proper\n   overflow response (for positive scaling operand), or the proper underflow\n   response (for negative scaling operand) is issued. The overflow and\n   underflow responses are dependent on the rounding mode (for IEEE-compliant\n   rounding), as well as on other settings in MXCSR (exception mask bits, FTZ\n   bit), and on the SAE bit.\n\n   EVEX encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or a memory location. The\n   destination operand is an XMM register conditionally updated with\n   writemask k1.\n\n   Handling of special-case input values are listed in Table 5-39 and Table\n   5-43.\n"],
	["or", "                           OR \u2014 Logical Inclusive OR\n\n   Opcode   Instruction    Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   0C ib    OR AL, imm8    I     Valid  Valid      AL OR imm8.                \n   0D iw    OR AX, imm16   I     Valid  Valid      AX OR imm16.               \n   0D id    OR EAX, imm32  I     Valid  Valid      EAX OR imm32.              \n   REX.W +  OR RAX, imm32  I     Valid  N.E.       RAX OR imm32               \n   0D id                                           (sign-extended).           \n   80 /1 ib OR r/m8, imm8  MI    Valid  Valid      r/m8 OR imm8.              \n   REX + 80 OR r/m8^1,     MI    Valid  N.E.       r/m8 OR imm8.              \n   /1 ib    imm8           \n   81 /1 iw OR r/m16,      MI    Valid  Valid      r/m16 OR imm16.            \n            imm16          \n   81 /1 id OR r/m32,      MI    Valid  Valid      r/m32 OR imm32.            \n            imm32          \n   REX.W +  OR r/m64,      MI    Valid  N.E.       r/m64 OR imm32             \n   81 /1 id imm32                                  (sign-extended).           \n   83 /1 ib OR r/m16, imm8 MI    Valid  Valid      r/m16 OR imm8              \n                                                   (sign-extended).           \n   83 /1 ib OR r/m32, imm8 MI    Valid  Valid      r/m32 OR imm8              \n                                                   (sign-extended).           \n   REX.W +  OR r/m64, imm8 MI    Valid  N.E.       r/m64 OR imm8              \n   83 /1 ib                                        (sign-extended).           \n   08 /r    OR r/m8, r8    MR    Valid  Valid      r/m8 OR r8.                \n   REX + 08 OR r/m8^1,     MR    Valid  N.E.       r/m8 OR r8.                \n   /r       r8^1           \n   09 /r    OR r/m16, r16  MR    Valid  Valid      r/m16 OR r16.              \n   09 /r    OR r/m32, r32  MR    Valid  Valid      r/m32 OR r32.              \n   REX.W +  OR r/m64, r64  MR    Valid  N.E.       r/m64 OR r64.              \n   09 /r    \n   0A /r    OR r8, r/m8    RM    Valid  Valid      r8 OR r/m8.                \n   REX + 0A OR r8^1,       RM    Valid  N.E.       r8 OR r/m8.                \n   /r       r/m8^1         \n   0B /r    OR r16, r/m16  RM    Valid  Valid      r16 OR r/m16.              \n   0B /r    OR r32, r/m32  RM    Valid  Valid      r32 OR r/m32.              \n   REX.W +  OR r64, r/m64  RM    Valid  N.E.       r64 OR r/m64.              \n   0B /r    \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   I     AL/AX/EAX/RAX    imm8/16/32    N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8/16/32    N/A       N/A       \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs a bitwise inclusive OR operation between the destination (first)\n   and source (second) operands and stores the result in the destination\n   operand location. The source operand can be an immediate, a register, or a\n   memory location; the destination operand can be a register or a memory\n   location. (However, two memory operands cannot be used in one\n   instruction.) Each bit of the result of the OR instruction is set to 0 if\n   both corresponding bits of the first and second operands are 0; otherwise,\n   each bit is set to 1.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The OF and CF flags are cleared; the SF, ZF, and PF flags are set\n   according to the result. The state of the AF flag is undefined.\n"],
	["vpsravw:vpsravd:vpsravq", "         VPSRAVW/VPSRAVD/VPSRAVQ \u2014 Variable Bit Shift Right Arithmetic\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Shift doublewords in xmm2  \n   VEX.128.66.0F38.W0 46                           right by amount specified  \n   /r VPSRAVD xmm1, xmm2, A     V/V       AVX2     in the corresponding       \n   xmm3/m128                                       element of xmm3/m128 while \n                                                   shifting in sign bits.     \n                                                   Shift doublewords in ymm2  \n   VEX.256.66.0F38.W0 46                           right by amount specified  \n   /r VPSRAVD ymm1, ymm2, A     V/V       AVX2     in the corresponding       \n   ymm3/m256                                       element of ymm3/m256 while \n                                                   shifting in sign bits.     \n                                                   Shift words in xmm2 right  \n   EVEX.128.66.0F38.W1 11                          by amount specified in the \n   /r VPSRAVW xmm1        B     V/V       AVX512VL corresponding element of   \n   {k1}{z}, xmm2,                         AVX512BW xmm3/m128 while shifting   \n   xmm3/m128                                       in sign bits using         \n                                                   writemask k1.              \n                                                   Shift words in ymm2 right  \n   EVEX.256.66.0F38.W1 11                          by amount specified in the \n   /r VPSRAVW ymm1        B     V/V       AVX512VL corresponding element of   \n   {k1}{z}, ymm2,                         AVX512BW ymm3/m256 while shifting   \n   ymm3/m256                                       in sign bits using         \n                                                   writemask k1.              \n                                                   Shift words in zmm2 right  \n   EVEX.512.66.0F38.W1 11                          by amount specified in the \n   /r VPSRAVW zmm1        B     V/V       AVX512BW corresponding element of   \n   {k1}{z}, zmm2,                                  zmm3/m512 while shifting   \n   zmm3/m512                                       in sign bits using         \n                                                   writemask k1.              \n                                                   Shift doublewords in xmm2  \n   EVEX.128.66.0F38.W0 46                          right by amount specified  \n   /r VPSRAVD xmm1                        AVX512VL in the corresponding       \n   {k1}{z}, xmm2,         C     V/V       AVX512F  element of                 \n   xmm3/m128/m32bcst                               xmm3/m128/m32bcst while    \n                                                   shifting in sign bits      \n                                                   using writemask k1.        \n                                                   Shift doublewords in ymm2  \n   EVEX.256.66.0F38.W0 46                          right by amount specified  \n   /r VPSRAVD ymm1                        AVX512VL in the corresponding       \n   {k1}{z}, ymm2,         C     V/V       AVX512F  element of                 \n   ymm3/m256/m32bcst                               ymm3/m256/m32bcst while    \n                                                   shifting in sign bits      \n                                                   using writemask k1.        \n                                                   Shift doublewords in zmm2  \n   EVEX.512.66.0F38.W0 46                          right by amount specified  \n   /r VPSRAVD zmm1                                 in the corresponding       \n   {k1}{z}, zmm2,         C     V/V       AVX512F  element of                 \n   zmm3/m512/m32bcst                               zmm3/m512/m32bcst while    \n                                                   shifting in sign bits      \n                                                   using writemask k1.        \n                                                   Shift quadwords in xmm2    \n   EVEX.128.66.0F38.W1 46                          right by amount specified  \n   /r VPSRAVQ xmm1                        AVX512VL in the corresponding       \n   {k1}{z}, xmm2,         C     V/V       AVX512F  element of                 \n   xmm3/m128/m64bcst                               xmm3/m128/m64bcst while    \n                                                   shifting in sign bits      \n                                                   using writemask k1.        \n                                                   Shift quadwords in ymm2    \n   EVEX.256.66.0F38.W1 46                          right by amount specified  \n   /r VPSRAVQ ymm1                        AVX512VL in the corresponding       \n   {k1}{z}, ymm2,         C     V/V       AVX512F  element of                 \n   ymm3/m256/m64bcst                               ymm3/m256/m64bcst while    \n                                                   shifting in sign bits      \n                                                   using writemask k1.        \n                                                   Shift quadwords in zmm2    \n   EVEX.512.66.0F38.W1 46                          right by amount specified  \n   /r VPSRAVQ zmm1                                 in the corresponding       \n   {k1}{z}, zmm2,         C     V/V       AVX512F  element of                 \n   zmm3/m512/m64bcst                               zmm3/m512/m64bcst while    \n                                                   shifting in sign bits      \n                                                   using writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Shifts the bits in the individual data elements\n   (word/doublewords/quadword) in the first source operand (the second\n   operand) to the right by the number of bits specified in the count value\n   of respective data elements in the second source operand (the third\n   operand). As the bits in the data elements are shifted right, the empty\n   high-order bits are set to the MSB (sign extension).\n\n   The count values are specified individually in each data element of the\n   second source operand. If the unsigned integer value specified in the\n   respective data element of the second source operand is greater than 15\n   (for words), 31 (for doublewords), or 63 (for a quadword), then the\n   destination data element is filled with the corresponding sign bit of the\n   source element.\n\n   VEX.128 encoded version: The destination and first source operands are XMM\n   registers. The count operand can be either an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The destination and first source operands are YMM\n   registers. The count operand can be either an YMM register or a 256-bit\n   memory. Bits (MAXVL-1:256) of the corresponding destination register are\n   zeroed.\n\n   EVEX.512/256/128 encoded VPSRAVD/W: The destination and first source\n   operands are ZMM/YMM/XMM registers. The count operand can be either a\n   ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 32/64-bit memory location. The\n   destination is conditionally updated with writemask k1.\n\n   EVEX.512/256/128 encoded VPSRAVQ: The destination and first source\n   operands are ZMM/YMM/XMM registers. The count operand can be either a\n   ZMM/YMM/XMM register, a 512/256/128-bit memory location. The destination\n   is conditionally updated with writemask k1.\n"],
	["vpblendmd:vpblendmq", "    VPBLENDMD/VPBLENDMQ \u2014 Blend Int32/Int64 Vectors Using an OpMask Control\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n   EVEX.128.66.0F38.W0 64                          Blend doubleword integer   \n   /r VPBLENDMD xmm1                      AVX512VL vector xmm2 and doubleword \n   {k1}{z}, xmm2,         A     V/V       AVX512F  vector xmm3/m128/m32bcst   \n   xmm3/m128/m32bcst                               and store the result in    \n                                                   xmm1, under control mask.  \n   EVEX.256.66.0F38.W0 64                          Blend doubleword integer   \n   /r VPBLENDMD ymm1                      AVX512VL vector ymm2 and doubleword \n   {k1}{z}, ymm2,         A     V/V       AVX512F  vector ymm3/m256/m32bcst   \n   ymm3/m256/m32bcst                               and store the result in    \n                                                   ymm1, under control mask.  \n   EVEX.512.66.0F38.W0 64                          Blend doubleword integer   \n   /r VPBLENDMD zmm1                               vector zmm2 and doubleword \n   {k1}{z}, zmm2,         A     V/V       AVX512F  vector zmm3/m512/m32bcst   \n   zmm3/m512/m32bcst                               and store the result in    \n                                                   zmm1, under control mask.  \n   EVEX.128.66.0F38.W1 64                          Blend quadword integer     \n   /r VPBLENDMQ xmm1                      AVX512VL vector xmm2 and quadword   \n   {k1}{z}, xmm2,         A     V/V       AVX512F  vector xmm3/m128/m64bcst   \n   xmm3/m128/m64bcst                               and store the result in    \n                                                   xmm1, under control mask.  \n   EVEX.256.66.0F38.W1 64                          Blend quadword integer     \n   /r VPBLENDMQ ymm1                      AVX512VL vector ymm2 and quadword   \n   {k1}{z}, ymm2,         A     V/V       AVX512F  vector ymm3/m256/m64bcst   \n   ymm3/m256/m64bcst                               and store the result in    \n                                                   ymm1, under control mask.  \n   EVEX.512.66.0F38.W1 64                          Blend quadword integer     \n   /r VPBLENDMQ zmm1                               vector zmm2 and quadword   \n   {k1}{z}, zmm2,         A     V/V       AVX512F  vector zmm3/m512/m64bcst   \n   zmm3/m512/m64bcst                               and store the result in    \n                                                   zmm1, under control mask.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs an element-by-element blending of dword/qword elements between\n   the first source operand (the second operand) and the elements of the\n   second source operand (the third operand) using an opmask register as\n   select control. The blended result is written into the destination.\n\n   The destination and first source operands are ZMM registers. The second\n   source operand can be a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 32-bit memory location.\n\n   The opmask register is not used as a writemask for this instruction.\n   Instead, the mask is used as an element selector: every element of the\n   destination is conditionally selected between first source or second\n   source using the value of the related mask bit (0 for the first source\n   operand, 1 for the second source operand).\n\n   If EVEX.z is set, the elements with corresponding mask bit value of 0 in\n   the destination operand are zeroed.\n"],
	["eextend", "        EEXTEND \u2014 Extend Uninitialized Enclave Measurement by 256 Bytes\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n   EAX = 06H                                     This leaf function measures  \n   ENCLS[EEXTEND]     IR    V/V          SGX1    256 bytes of an              \n                                                 uninitialized enclave page.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX          EBX                      RCX                            \n                      Effective address of the Effective address of a         \n   IR    EEXTEND (In) SECS of the data chunk   256-byte chunk in the EPC (In) \n                      (In)                     \n\n  Description \u00b6\n\n   This leaf function updates the MRENCLAVE measurement register of an SECS\n   with the measurement of an EXTEND string compromising of \u201cEEXTEND\u201d ||\n   ENCLAVEOFFSET || PADDING || 256 bytes of the enclave page. This\n   instruction can only be executed when current privilege level is 0 and the\n   enclave is uninitialized.\n\n   RBX contains the effective address of the SECS of the region to be\n   measured. The address must be the same as the one used to add the page\n   into the enclave.\n\n   RCX contains the effective address of the 256 byte region of an EPC page\n   to be measured. The DS segment is used to create linear addresses. Segment\n   override is not supported.\n\nEEXTEND Memory Parameter Semantics \u00b6\n\n   EPC[RCX]               \n   Read access by Enclave \n\n   The instruction faults if any of the following:\n\nEEXTEND Faulting Conditions \u00b6\n\n   RBX points to an address not 4KBytes RBX does not resolve to an SECS.      \n   aligned.                             \n   RBX does not point to an SECS page.  RBX does not point to the SECS page   \n                                        of the data chunk.                    \n   RCX points to an address not 256B    RCX points to an unused page or a     \n   aligned.                             SECS.                                 \n   RCX does not resolve in an EPC page. If SECS is locked.                    \n   If the SECS is already initialized.  May page fault.                       \n   CPL > 0.                             \n\n  Concurrency Restrictions \u00b6\n\n                           Base Concurrency Restrictions\n   Leaf    Parameter       Access     On Conflict SGX_CONFLICT VM Exit        \n                                                  Qualification               \n   EEXTEND Target [DS:RCX] Shared     #GP         \n           SECS [DS:RBX]   Concurrent \n\n   Table 38-23. Base Concurrency Restrictions of EEXTEND\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT,                                       \n                     EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\n   Leaf    Parameter EMODPE, EMODPR,     EINIT\n                     EMODT      \n                     Access     On       Access     On       Access     On       \n                                Conflict            Conflict            Conflict \n           Target    Concurrent          Concurrent          Concurrent \n   EEXTEND [DS:RCX]  \n           SECS      Concurrent          Exclusive  #GP      Concurrent \n           [DS:RBX]  \n\n   Table 38-24. Additional Concurrency Restrictions of EEXTEND\n\n  Flags Affected \u00b6\n\n   None\n"],
	["andnps", "   ANDNPS \u2014 Bitwise Logical AND NOT of Packed Single Precision Floating-Point\n                                     Values\n\n                         Op / 64/32 bit CPUID                                 \n   Opcode/Instruction    En   Mode      Feature  Description\n                              Support   Flag     \n                                                 Return the bitwise logical   \n   NP 0F 55 /r ANDNPS    A    V/V       SSE      AND NOT of packed single     \n   xmm1, xmm2/m128                               precision floating-point     \n                                                 values in xmm1 and xmm2/mem. \n   VEX.128.0F 55 /r                              Return the bitwise logical   \n   VANDNPS xmm1, xmm2,   B    V/V       AVX      AND NOT of packed single     \n   xmm3/m128                                     precision floating-point     \n                                                 values in xmm2 and xmm3/mem. \n   VEX.256.0F 55 /r                              Return the bitwise logical   \n   VANDNPS ymm1, ymm2,   B    V/V       AVX      AND NOT of packed single     \n   ymm3/m256                                     precision floating-point     \n                                                 values in ymm2 and ymm3/mem. \n                                                 Return the bitwise logical   \n   EVEX.128.0F.W0 55 /r                          AND of packed single         \n   VANDNPS xmm1 {k1}{z}, C    V/V       AVX512VL precision floating-point     \n   xmm2,                                AVX512DQ values in xmm2 and           \n   xmm3/m128/m32bcst                             xmm3/m128/m32bcst subject to \n                                                 writemask k1.                \n                                                 Return the bitwise logical   \n   EVEX.256.0F.W0 55 /r                          AND of packed single         \n   VANDNPS ymm1 {k1}{z}, C    V/V       AVX512VL precision floating-point     \n   ymm2,                                AVX512DQ values in ymm2 and           \n   ymm3/m256/m32bcst                             ymm3/m256/m32bcst subject to \n                                                 writemask k1.                \n                                                 Return the bitwise logical   \n   EVEX.512.0F.W0 55 /r                          AND of packed single         \n   VANDNPS zmm1 {k1}{z}, C    V/V       AVX512DQ precision floating-point     \n   zmm2,                                         values in zmm2 and           \n   zmm3/m512/m32bcst                             zmm3/m512/m32bcst subject to \n                                                 writemask k1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical AND NOT of the four, eight or sixteen packed\n   single precision floating-point values from the first source operand and\n   the second source operand, and stores the result in the destination\n   operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["vcvtph2pd", "             VCVTPH2PD \u2014 Convert Packed FP16 Values to FP64 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert packed FP16  \n                                                         values in            \n   EVEX.128.NP.MAP5.W0 5A /r                 AVX512-FP16 xmm2/m32/m16bcst to  \n   VCVTPH2PD xmm1{k1}{z},          A V/V     AVX512VL    FP64 values, and     \n   xmm2/m32/m16bcst                                      store result in xmm1 \n                                                         subject to writemask \n                                                         k1.                  \n                                                         Convert packed FP16  \n                                                         values in            \n   EVEX.256.NP.MAP5.W0 5A /r                 AVX512-FP16 xmm2/m64/m16bcst to  \n   VCVTPH2PD ymm1{k1}{z},          A V/V     AVX512VL    FP64 values, and     \n   xmm2/m64/m16bcst                                      store result in ymm1 \n                                                         subject to writemask \n                                                         k1.                  \n                                                         Convert packed FP16  \n                                                         values in            \n   EVEX.512.NP.MAP5.W0 5A /r                             xmm2/m128/m16bcst to \n   VCVTPH2PD zmm1{k1}{z},          A V/V     AVX512-FP16 FP64 values, and     \n   xmm2/m128/m16bcst {sae}                               store result in zmm1 \n                                                         subject to writemask \n                                                         k1.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Quarter ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values to FP64 values in the\n   destination register. The destination elements are updated according to\n   the writemask.\n\n   This instruction handles both normal and denormal FP16 inputs.\n"],
	["pext", "                          PEXT \u2014 Parallel Bits Extract\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Parallel extract of bits   \n   VEX.LZ.F3.0F38.W0 F5 /r RVM   V/V       BMI2    from r32b using mask in    \n   PEXT r32a, r32b, r/m32                          r/m32, result is written   \n                                                   to r32a.                   \n                                                   Parallel extract of bits   \n   VEX.LZ.F3.0F38.W1 F5 /r RVM   V/N.E.    BMI2    from r64b using mask in    \n   PEXT r64a, r64b, r/m64                          r/m64, result is written   \n                                                   to r64a.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVM   ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   PEXT uses a mask in the second source operand (the third operand) to\n   transfer either contiguous or non-contiguous bits in the first source\n   operand (the second operand) to contiguous low order bit positions in the\n   destination (the first operand). For each bit set in the MASK, PEXT\n   extracts the corresponding bits from the first source operand and writes\n   them into contiguous lower bits of destination operand. The remaining\n   upper bits of destination are zeroed.\n\n   SRC1 S31S30 S29S28S27 S7 S6 S5 S4 S3 S2 S1 S0 SRC2 0 0 0 1 0 1 0 1 0 0 1 0\n   0 (mask) 0 0 0 0 S28 S7 S5 S2 DEST 0 0 0 0 0 bit 0 bit 31 Figure 4-9. PEXT\n   Example\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["maskmovdqu", "              MASKMOVDQU \u2014 Store Selected Bytes of Double Quadword\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                          Flag    \n                                                  Selectively write bytes     \n                                                  from xmm1 to memory         \n   66 0F F7 /r MASKMOVDQU RM    V/V       SSE2    location using the byte     \n   xmm1, xmm2                                     mask in xmm2. The default   \n                                                  memory location is          \n                                                  specified by DS:DI/EDI/RDI. \n                                                  Selectively write bytes     \n   VEX.128.66.0F.WIG F7                           from xmm1 to memory         \n   /r VMASKMOVDQU xmm1,   RM    V/V       AVX     location using the byte     \n   xmm2                                           mask in xmm2. The default   \n                                                  memory location is          \n                                                  specified by DS:DI/EDI/RDI. \n\nInstruction Operand Encoding^1 \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Stores selected bytes from the source operand (first operand) into an\n   128-bit memory location. The mask operand (second operand) selects which\n   bytes from the source operand are written to memory. The source and mask\n   operands are XMM registers. The memory location specified by the effective\n   address in the DI/EDI/RDI register (the default segment register is DS,\n   but this may be overridden with a segment-override prefix). The memory\n   location does not need to be aligned on a natural boundary. (The size of\n   the store address depends on the address-size attribute.)\n\n   The most significant bit in each byte of the mask operand determines\n   whether the corresponding byte in the source operand is written to the\n   corresponding byte location in memory: 0 indicates no write and 1\n   indicates write.\n\n   The MASKMOVDQU instruction generates a non-temporal hint to the processor\n   to minimize cache pollution. The non-temporal hint is implemented by using\n   a write combining (WC) memory type protocol (see \u201cCaching of Temporal vs.\n   Non-Temporal Data\u201d in Chapter 10, of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1). Because the WC\n   protocol uses a weakly-ordered memory consistency model, a fencing\n   operation implemented with the SFENCE or MFENCE instruction should be used\n   in conjunction with MASKMOVDQU instructions if multiple processors might\n   use different memory types to read/write the destination memory locations.\n\n     1.ModRM.MOD = 011B required\n\n   Behavior with a mask of all 0s is as follows:\n\n     * No data will be written to memory.\n     * Signaling of breakpoints (code or data) is not guaranteed; different\n       processor implementations may signal or not signal these breakpoints.\n     * Exceptions associated with addressing memory and page faults may still\n       be signaled (implementation dependent).\n     * If the destination memory region is mapped as UC or WP, enforcement of\n       associated semantics for these memory types is not guaranteed (that\n       is, is reserved) and is implementation-specific.\n\n   The MASKMOVDQU instruction can be used to improve performance of\n   algorithms that need to merge data on a byte-by-byte basis. MASKMOVDQU\n   should not cause a read for ownership; doing so generates unnecessary\n   bandwidth since data is to be written directly using the byte-mask without\n   allocating old data prior to the store.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b\n   otherwise instructions will #UD.\n\n   If VMASKMOVDQU is encoded with VEX.L= 1, an attempt to execute the\n   instruction encoded with VEX.L= 1 will cause an #UD exception.\n"],
	["cmppd", "         CMPPD \u2014 Compare Packed Double Precision Floating-Point Values\n\n                              Op / 64/32 bit CPUID                            \n   Opcode/Instruction         En   Mode      Feature  Description\n                                   Support   Flag     \n                                                      Compare packed double   \n                                                      precision               \n   66 0F C2 /r ib CMPPD xmm1,                         floating-point values   \n   xmm2/m128, imm8            A    V/V       SSE2     in xmm2/m128 and xmm1   \n                                                      using bits 2:0 of imm8  \n                                                      as a comparison         \n                                                      predicate.              \n                                                      Compare packed double   \n                                                      precision               \n   VEX.128.66.0F.WIG C2 /r ib                         floating-point values   \n   VCMPPD xmm1, xmm2,         B    V/V       AVX      in xmm3/m128 and xmm2   \n   xmm3/m128, imm8                                    using bits 4:0 of imm8  \n                                                      as a comparison         \n                                                      predicate.              \n                                                      Compare packed double   \n                                                      precision               \n   VEX.256.66.0F.WIG C2 /r ib                         floating-point values   \n   VCMPPD ymm1, ymm2,         B    V/V       AVX      in ymm3/m256 and ymm2   \n   ymm3/m256, imm8                                    using bits 4:0 of imm8  \n                                                      as a comparison         \n                                                      predicate.              \n                                                      Compare packed double   \n                                                      precision               \n                                                      floating-point values   \n   EVEX.128.66.0F.W1 C2 /r ib                         in xmm3/m128/m64bcst    \n   VCMPPD k1 {k2}, xmm2,      C    V/V       AVX512VL and xmm2 using bits 4:0 \n   xmm3/m128/m64bcst, imm8                   AVX512F  of imm8 as a comparison \n                                                      predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed double   \n                                                      precision               \n                                                      floating-point values   \n   EVEX.256.66.0F.W1 C2 /r ib                         in ymm3/m256/m64bcst    \n   VCMPPD k1 {k2}, ymm2,      C    V/V       AVX512VL and ymm2 using bits 4:0 \n   ymm3/m256/m64bcst, imm8                   AVX512F  of imm8 as a comparison \n                                                      predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed double   \n                                                      precision               \n                                                      floating-point values   \n   EVEX.512.66.0F.W1 C2 /r ib                         in zmm3/m512/m64bcst    \n   VCMPPD k1 {k2}, zmm2,      C    V/V       AVX512F  and zmm2 using bits 4:0 \n   zmm3/m512/m64bcst{sae},                            of imm8 as a comparison \n   imm8                                               predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed double precision floating-point\n   values in the second source operand and the first source operand and\n   returns the result of the comparison to the destination operand. The\n   comparison predicate operand (immediate byte) specifies the type of\n   comparison performed on each pair of packed values in the two source\n   operands.\n\n   EVEX encoded versions: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. The destination operand (first\n   operand) is an opmask register. Comparison results are written to the\n   destination operand under the writemask k2. Each comparison result is a\n   single mask bit of 1 (comparison true) or 0 (comparison false).\n\n   VEX.256 encoded version: The first source operand (second operand) is a\n   YMM register. The second source operand (third operand) can be a YMM\n   register or a 256-bit memory location. The destination operand (first\n   operand) is a YMM register. Four comparisons are performed with results\n   written to the destination operand. The result of each comparison is a\n   quadword mask of all 1s (comparison true) or all 0s (comparison false).\n\n   128-bit Legacy SSE version: The first source and destination operand\n   (first operand) is an XMM register. The second source operand (second\n   operand) can be an XMM register or 128-bit memory location. Bits\n   (MAXVL-1:128) of the corresponding ZMM destination register remain\n   unchanged. Two comparisons are performed with results written to bits\n   127:0 of the destination operand. The result of each comparison is a\n   quadword mask of all 1s (comparison true) or all 0s (comparison false).\n\n   VEX.128 encoded version: The first source operand (second operand) is an\n   XMM register. The second source operand (third operand) can be an XMM\n   register or a 128-bit memory location. Bits (MAXVL-1:128) of the\n   destination ZMM register are zeroed. Two comparisons are performed with\n   results written to bits 127:0 of the destination operand.\n\n   The comparison predicate operand is an 8-bit immediate:\n\n     * For instructions encoded using the VEX or EVEX prefix, bits 4:0 define\n       the type of comparison to be performed (see Table 3-1). Bits 5 through\n       7 of the immediate are reserved.\n     * For instruction encodings that do not use VEX prefix, bits 2:0 define\n       the type of comparison to be made (see the first 8 rows of Table 3-1).\n       Bits 3 through 7 of the immediate are reserved.\n\n                imm8                            Result: A Is 1st Operand, B   Signals \nPredicate       Value Description               Is 2nd Operand                #IA on  \n                                                A >B  A<B   A=B   Unordered^1 QNAN    \nEQ_OQ (EQ)      0H    Equal (ordered,           False False True  False       No      \n                      non-signaling)            \nLT_OS (LT)      1H    Less-than (ordered,       False True  False False       Yes     \n                      signaling)                \nLE_OS (LE)      2H    Less-than-or-equal        False True  True  False       Yes     \n                      (ordered, signaling)      \nUNORD_Q (UNORD) 3H    Unordered (non-signaling) False False False True        No      \nNEQ_UQ (NEQ)    4H    Not-equal (unordered,     True  True  False True        No      \n                      non-signaling)            \nNLT_US (NLT)    5H    Not-less-than (unordered, True  False True  True        Yes     \n                      signaling)                \nNLE_US (NLE)    6H    Not-less-than-or-equal    True  False False True        Yes     \n                      (unordered, signaling)    \nORD_Q (ORD)     7H    Ordered (non-signaling)   True  True  True  False       No      \nEQ_UQ           8H    Equal (unordered,         False False True  True        No      \n                      non-signaling)            \nNGE_US (NGE)    9H    Not-greater-than-or-equal False True  False True        Yes     \n                      (unordered, signaling)    \nNGT_US (NGT)    AH    Not-greater-than          False True  True  True        Yes     \n                      (unordered, signaling)    \nFALSE_OQ(FALSE) BH    False (ordered,           False False False False       No      \n                      non-signaling)            \nNEQ_OQ          CH    Not-equal (ordered,       True  True  False False       No      \n                      non-signaling)            \nGE_OS (GE)      DH    Greater-than-or-equal     True  False True  False       Yes     \n                      (ordered, signaling)      \nGT_OS (GT)      EH    Greater-than (ordered,    True  False False False       Yes     \n                      signaling)                \nTRUE_UQ(TRUE)   FH    True (unordered,          True  True  True  True        No      \n                      non-signaling)            \nEQ_OS           10H   Equal (ordered,           False False True  False       Yes     \n                      signaling)                \nLT_OQ           11H   Less-than (ordered,       False True  False False       No      \n                      nonsignaling)             \nLE_OQ           12H   Less-than-or-equal        False True  True  False       No      \n                      (ordered, nonsignaling)   \nUNORD_S         13H   Unordered (signaling)     False False False True        Yes     \nNEQ_US          14H   Not-equal (unordered,     True  True  False True        Yes     \n                      signaling)                \nNLT_UQ          15H   Not-less-than (unordered, True  False True  True        No      \n                      nonsignaling)             \nNLE_UQ          16H   Not-less-than-or-equal    True  False False True        No      \n                      (unordered, nonsignaling) \nORD_S           17H   Ordered (signaling)       True  True  True  False       Yes     \nEQ_US           18H   Equal (unordered,         False False True  True        Yes     \n                      signaling)                \n                      Not-greater-than-or-equal                                       \nNGE_UQ          19H   (unordered,               False True  False True        No\n                      non-signaling)            \nNGT_UQ          1AH   Not-greater-than          False True  True  True        No      \n                      (unordered, nonsignaling) \nFALSE_OS        1BH   False (ordered,           False False False False       Yes     \n                      signaling)                \nNEQ_OS          1CH   Not-equal (ordered,       True  True  False False       Yes     \n                      signaling)                \nGE_OQ           1DH   Greater-than-or-equal     True  False True  False       No      \n                      (ordered, nonsignaling)   \nGT_OQ           1EH   Greater-than (ordered,    True  False False False       No      \n                      nonsignaling)             \nTRUE_US         1FH   True (unordered,          True  True  True  True        Yes     \n                      signaling)                \n\n   Table 3-1. Comparison Predicate for CMPPD and CMPPS Instructions\n\n     1. If either operand A or B is a NAN.\n\n   The unordered relationship is true when at least one of the two source\n   operands being compared is a NaN; the ordered relationship is true when\n   neither source operand is a NaN.\n\n   A subsequent computational instruction that uses the mask result in the\n   destination operand as an input operand will not generate an exception,\n   because a mask of all 0s corresponds to a floating-point value of +0.0 and\n   a mask of all 1s corresponds to a QNaN.\n\n   Note that processors with \u201cCPUID.1H:ECX.AVX =0\u201d do not implement the\n   \u201cgreater-than\u201d, \u201cgreater-than-or-equal\u201d, \u201cnot-greater than\u201d, and\n   \u201cnot-greater-than-or-equal relations\u201d predicates. These comparisons can be\n   made either by using the inverse relationship (that is, use the\n   \u201cnot-less-than-or-equal\u201d to make a \u201cgreater-than\u201d comparison) or by using\n   software emulation. When using software emulation, the program must swap\n   the operands (copying registers when necessary to protect the data that\n   will now be in the destination), and then perform the compare using a\n   different predicate. The predicate to be used for these emulations is\n   listed in the first 8 rows of Table 3-7 (Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 2A) under the heading\n   Emulation.\n\n   Compilers and assemblers may implement the following two-operand\n   pseudo-ops in addition to the three-operand CMPPD instruction, for\n   processors with \u201cCPUID.1H:ECX.AVX =0\u201d. See Table 3-2. The compiler should\n   treat reserved imm8 values as illegal syntax.\n\n   Pseudo-Op             CMPPD Implementation \n   CMPEQPD xmm1, xmm2    CMPPD xmm1, xmm2, 0  \n   CMPLTPD xmm1, xmm2    CMPPD xmm1, xmm2, 1  \n   CMPLEPD xmm1, xmm2    CMPPD xmm1, xmm2, 2  \n   CMPUNORDPD xmm1, xmm2 CMPPD xmm1, xmm2, 3  \n   CMPNEQPD xmm1, xmm2   CMPPD xmm1, xmm2, 4  \n   CMPNLTPD xmm1, xmm2   CMPPD xmm1, xmm2, 5  \n   CMPNLEPD xmm1, xmm2   CMPPD xmm1, xmm2, 6  \n   CMPORDPD xmm1, xmm2   CMPPD xmm1, xmm2, 7  \n\n   Table 3-2. Pseudo-Op and CMPPD Implementation\n\n   The greater-than relations that the processor does not implement require\n   more than one instruction to emulate in software and therefore should not\n   be implemented as pseudo-ops. (For these, the programmer should reverse\n   the operands of the corresponding less than relations and use move\n   instructions to ensure that the mask is moved to the correct destination\n   register and that the source operand is left intact.)\n\n   Processors with \u201cCPUID.1H:ECX.AVX =1\u201d implement the full complement of 32\n   predicates shown in Table 3-3, software emulation is no longer needed.\n   Compilers and assemblers may implement the following three-operand\n   pseudo-ops in addition to the four-operand VCMPPD instruction. See Table\n   3-3, where the notations of reg1 reg2, and reg3 represent either XMM\n   registers or YMM registers. The compiler should treat reserved imm8 values\n   as\n\n   illegal syntax. Alternately, intrinsics can map the pseudo-ops to\n   pre-defined constants to support a simpler intrinsic interface. Compilers\n   and assemblers may implement three-operand pseudo-ops for EVEX encoded\n   VCMPPD instructions in a similar fashion by extending the syntax listed in\n   Table 3-3.\n\n   Pseudo-Op                       CMPPD Implementation         \n   VCMPEQPD reg1, reg2, reg3       VCMPPD reg1, reg2, reg3, 0   \n   VCMPLTPD reg1, reg2, reg3       VCMPPD reg1, reg2, reg3, 1   \n   VCMPLEPD reg1, reg2, reg3       VCMPPD reg1, reg2, reg3, 2   \n   VCMPUNORDPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 3   \n   VCMPNEQPD reg1, reg2, reg3      VCMPPD reg1, reg2, reg3, 4   \n   VCMPNLTPD reg1, reg2, reg3      VCMPPD reg1, reg2, reg3, 5   \n   VCMPNLEPD reg1, reg2, reg3      VCMPPD reg1, reg2, reg3, 6   \n   VCMPORDPD reg1, reg2, reg3      VCMPPD reg1, reg2, reg3, 7   \n   VCMPEQ_UQPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 8   \n   VCMPNGEPD reg1, reg2, reg3      VCMPPD reg1, reg2, reg3, 9   \n   VCMPNGTPD reg1, reg2, reg3      VCMPPD reg1, reg2, reg3, 0AH \n   VCMPFALSEPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 0BH \n   VCMPNEQ_OQPD reg1, reg2, reg3   VCMPPD reg1, reg2, reg3, 0CH \n   VCMPGEPD reg1, reg2, reg3       VCMPPD reg1, reg2, reg3, 0DH \n   VCMPGTPD reg1, reg2, reg3       VCMPPD reg1, reg2, reg3, 0EH \n   VCMPTRUEPD reg1, reg2, reg3     VCMPPD reg1, reg2, reg3, 0FH \n   VCMPEQ_OSPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 10H \n   VCMPLT_OQPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 11H \n   VCMPLE_OQPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 12H \n   VCMPUNORD_SPD reg1, reg2, reg3  VCMPPD reg1, reg2, reg3, 13H \n   VCMPNEQ_USPD reg1, reg2, reg3   VCMPPD reg1, reg2, reg3, 14H \n   VCMPNLT_UQPD reg1, reg2, reg3   VCMPPD reg1, reg2, reg3, 15H \n   VCMPNLE_UQPD reg1, reg2, reg3   VCMPPD reg1, reg2, reg3, 16H \n   VCMPORD_SPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 17H \n   VCMPEQ_USPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 18H \n   VCMPNGE_UQPD reg1, reg2, reg3   VCMPPD reg1, reg2, reg3, 19H \n   VCMPNGT_UQPD reg1, reg2, reg3   VCMPPD reg1, reg2, reg3, 1AH \n   VCMPFALSE_OSPD reg1, reg2, reg3 VCMPPD reg1, reg2, reg3, 1BH \n   VCMPNEQ_OSPD reg1, reg2, reg3   VCMPPD reg1, reg2, reg3, 1CH \n   VCMPGE_OQPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 1DH \n   VCMPGT_OQPD reg1, reg2, reg3    VCMPPD reg1, reg2, reg3, 1EH \n   VCMPTRUE_USPD reg1, reg2, reg3  VCMPPD reg1, reg2, reg3, 1FH \n\n   Table 3-3. Pseudo-Op and VCMPPD Implementation\n"],
	["cvtpd2pi", "CVTPD2PI \u2014 Convert Packed Double Precision Floating-Point Values to Packed Dword\n                                    Integers\n\n                              64/32 bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                              Support   Flag    \n                                                Convert two packed double     \n   66 0F 2D /r CVTPD2PI                         precision floating-point      \n   mm, xmm/m128         RM    V/V       SSE2    values from xmm/m128 to two   \n                                                packed signed doubleword      \n                                                integers in mm.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two packed double precision floating-point values in the source\n   operand (second operand) to two packed signed doubleword integers in the\n   destination operand (first operand).\n\n   The source operand can be an XMM register or a 128-bit memory location.\n   The destination operand is an MMX technology register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register. If a converted result is\n   larger than the maximum signed doubleword integer, the floating-point\n   invalid exception is raised, and if this exception is masked, the\n   indefinite integer value (80000000H) is returned.\n\n   This instruction causes a transition from x87 FPU to MMX technology\n   operation (that is, the x87 FPU top-of-stack pointer is set to 0 and the\n   x87 FPU tag word is set to all 0s [valid]). If this instruction is\n   executed while an x87 FPU floating-point exception is pending, the\n   exception is handled before the CVTPD2PI instruction is executed.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["cvtsd2si", " CVTSD2SI \u2014 Convert Scalar Double Precision Floating-Point Value to Doubleword\n                                    Integer\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature Description\n                               Support   Flag    \n                                                 Convert one double precision \n   F2 0F 2D /r CVTSD2SI   A    V/V       SSE2    floating-point value from    \n   r32, xmm1/m64                                 xmm1/m64 to one signed       \n                                                 doubleword integer r32.      \n                                                 Convert one double precision \n   F2 REX.W 0F 2D /r                             floating-point value from    \n   CVTSD2SI r64, xmm1/m64 A    V/N.E.    SSE2    xmm1/m64 to one signed       \n                                                 quadword integer             \n                                                 sign-extended into r64.      \n   VEX.LIG.F2.0F.W0 2D /r                        Convert one double precision \n   ^1 VCVTSD2SI r32,      A    V/V       AVX     floating-point value from    \n   xmm1/m64                                      xmm1/m64 to one signed       \n                                                 doubleword integer r32.      \n                                                 Convert one double precision \n   VEX.LIG.F2.0F.W1 2D /r                        floating-point value from    \n   ^1 VCVTSD2SI r64,      A    V/N.E.^2  AVX     xmm1/m64 to one signed       \n   xmm1/m64                                      quadword integer             \n                                                 sign-extended into r64.      \n   EVEX.LLIG.F2.0F.W0 2D                         Convert one double precision \n   /r VCVTSD2SI r32,      B    V/V       AVX512F floating-point value from    \n   xmm1/m64{er}                                  xmm1/m64 to one signed       \n                                                 doubleword integer r32.      \n                                                 Convert one double precision \n   EVEX.LLIG.F2.0F.W1 2D                         floating-point value from    \n   /r VCVTSD2SI r64,      B    V/N.E.^2  AVX512F xmm1/m64 to one signed       \n   xmm1/m64{er}                                  quadword integer             \n                                                 sign-extended into r64.      \n\n     1. Software should ensure VCVTSD2SI is encoded with VEX.L=0. Encoding\n     VCVTSD2SI with VEX.L=1 may encounter unpredictable behavior across\n     different processor generations.\n\n     2. VEX.W1/EVEX.W1 in non-64 bit is ignored; the instructions behaves as\n     if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A          ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts a double precision floating-point value in the source operand\n   (the second operand) to a signed double-word integer in the destination\n   operand (first operand). The source operand can be an XMM register or a\n   64-bit memory location. The destination operand is a general-purpose\n   register. When the source operand is an XMM register, the double precision\n   floating-point value is contained in the low quadword of the register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register.\n\n   If a converted result exceeds the range limits of signed doubleword\n   integer (in non-64-bit modes or 64-bit mode with REX.W/VEX.W/EVEX.W=0),\n   the floating-point invalid exception is raised, and if this exception is\n   masked, the indefinite integer value (80000000H) is returned.\n\n   If a converted result exceeds the range limits of signed quadword integer\n   (in 64-bit mode and REX.W/VEX.W/EVEX.W = 1), the floating-point invalid\n   exception is raised, and if this exception is masked, the indefinite\n   integer value (80000000_00000000H) is returned.\n\n   Legacy SSE instruction: Use of the REX.W prefix promotes the instruction\n   to produce 64-bit data in 64-bit mode. See the summary chart at the\n   beginning of this section for encoding data and limits.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCVTSD2SI is encoded with VEX.L=0. Encoding\n   VCVTSD2SI with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["cvtdq2pd", "    CVTDQ2PD \u2014 Convert Packed Doubleword Integers to Packed Double Precision\n                              Floating-PointValues\n\n                        Op / 64/32 bit CPUID                                  \n   Opcode/Instruction   En   Mode      Feature  Description\n                             Support   Flag     \n                                                Convert two packed signed     \n   F3 0F E6 /r CVTDQ2PD                         doubleword integers from      \n   xmm1, xmm2/m64       A    V/V       SSE2     xmm2/mem to two packed double \n                                                precision floating-point      \n                                                values in xmm1.               \n                                                Convert two packed signed     \n   VEX.128.F3.0F.WIG E6                         doubleword integers from      \n   /r VCVTDQ2PD xmm1,   A    V/V       AVX      xmm2/mem to two packed double \n   xmm2/m64                                     precision floating-point      \n                                                values in xmm1.               \n                                                Convert four packed signed    \n   VEX.256.F3.0F.WIG E6                         doubleword integers from      \n   /r VCVTDQ2PD ymm1,   A    V/V       AVX      xmm2/mem to four packed       \n   xmm2/m128                                    double precision              \n                                                floating-point values in      \n                                                ymm1.                         \n                                                Convert 2 packed signed       \n   EVEX.128.F3.0F.W0 E6                         doubleword integers from      \n   /r VCVTDQ2PD xmm1    B    V/V       AVX512VL xmm2/m64/m32bcst to eight     \n   {k1}{z},                            AVX512F  packed double precision       \n   xmm2/m64/m32bcst                             floating-point values in xmm1 \n                                                with writemask k1.            \n                                                Convert 4 packed signed       \n   EVEX.256.F3.0F.W0 E6                         doubleword integers from      \n   /r VCVTDQ2PD ymm1    B    V/V       AVX512VL xmm2/m128/m32bcst to 4 packed \n   {k1}{z},                            AVX512F  double precision              \n   xmm2/m128/m32bcst                            floating-point values in ymm1 \n                                                with writemask k1.            \n                                                Convert eight packed signed   \n   EVEX.512.F3.0F.W0 E6                         doubleword integers from      \n   /r VCVTDQ2PD zmm1    B    V/V       AVX512F  ymm2/m256/m32bcst to eight    \n   {k1}{z},                                     packed double precision       \n   ymm2/m256/m32bcst                            floating-point values in zmm1 \n                                                with writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two, four or eight packed signed doubleword integers in the\n   source operand (the second operand) to two, four or eight packed double\n   precision floating-point values in the destination operand (the first\n   operand).\n\n   EVEX encoded versions: The source operand can be a YMM/XMM/XMM (low 64\n   bits) register, a 256/128/64-bit memory location or a 256/128/64-bit\n   vector broadcasted from a 32-bit memory location. The destination operand\n   is a ZMM/YMM/XMM register conditionally updated with writemask k1. Attempt\n   to encode this instruction with EVEX embedded rounding is ignored.\n\n   VEX.256 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a YMM register.\n\n   VEX.128 encoded version: The source operand is an XMM register or 64- bit\n   memory location. The destination operand is a XMM register. The upper Bits\n   (MAXVL-1:128) of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 64-\n   bit memory location. The destination operand is an XMM register. The upper\n   Bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   X3 X2 X1 X0 SRC X3 X2 X1 X0 DEST Figure 3-11. CVTDQ2PD (VEX.256 encoded\n   version)\n"],
	["vcvtsh2si", "              VCVTSH2SI \u2014 Convert Low FP16 Value to Signed Integer\n\n   Instruction En Bit Mode Flag Support                                       \n   Instruction En Bit Mode Flag Support \n   64/32 CPUID Feature Instruction En   \n   Bit Mode Flag CPUID Feature          \n   Instruction En Bit Mode Flag Op/       Support             Description\n   64/32 CPUID Feature Instruction En   \n   Bit Mode Flag 64/32 CPUID Feature    \n   Instruction En Bit Mode Flag CPUID   \n   Feature Instruction En Bit Mode Flag \n   Op/ 64/32 CPUID Feature              \n                                                              Convert the low \n                                                              FP16 element in \n   EVEX.LLIG.F3.MAP5.W0 2D /r VCVTSH2SI A V/V^1   AVX512-FP16 xmm1/m16 to a   \n   r32, xmm1/m16 {er}                                         signed integer  \n                                                              and store the   \n                                                              result in r32.  \n                                                              Convert the low \n                                                              FP16 element in \n   EVEX.LLIG.F3.MAP5.W1 2D /r VCVTSH2SI A V/N.E.  AVX512-FP16 xmm1/m16 to a   \n   r64, xmm1/m16 {er}                                         signed integer  \n                                                              and store the   \n                                                              result in r64.  \n\n     1. Outside of 64b mode, the EVEX.W field is ignored. The instruction\n     behaves as if W=0 was used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP16 element in the source operand to a\n   signed integer in the destination general purpose register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer indefinite value is returned.\n"],
	["psubsb:psubsw", "     PSUBSB/PSUBSW \u2014 Subtract Packed Signed Integers With Signed Saturation\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Subtract signed packed   \n   NP 0F E8 /r^1 PSUBSB mm, A     V/V       MMX      bytes in mm/m64 from     \n   mm/m64                                            signed packed bytes in   \n                                                     mm and saturate results. \n                                                     Subtract packed signed   \n                                                     byte integers in         \n   66 0F E8 /r PSUBSB xmm1, A     V/V       SSE2     xmm2/m128 from packed    \n   xmm2/m128                                         signed byte integers in  \n                                                     xmm1 and saturate        \n                                                     results.                 \n                                                     Subtract signed packed   \n   NP 0F E9 /r^1 PSUBSW mm, A     V/V       MMX      words in mm/m64 from     \n   mm/m64                                            signed packed words in   \n                                                     mm and saturate results. \n                                                     Subtract packed signed   \n                                                     word integers in         \n   66 0F E9 /r PSUBSW xmm1, A     V/V       SSE2     xmm2/m128 from packed    \n   xmm2/m128                                         signed word integers in  \n                                                     xmm1 and saturate        \n                                                     results.                 \n                                                     Subtract packed signed   \n   VEX.128.66.0F.WIG E8 /r                           byte integers in         \n   VPSUBSB xmm1, xmm2,      B     V/V       AVX      xmm3/m128 from packed    \n   xmm3/m128                                         signed byte integers in  \n                                                     xmm2 and saturate        \n                                                     results.                 \n                                                     Subtract packed signed   \n   VEX.128.66.0F.WIG E9 /r                           word integers in         \n   VPSUBSW xmm1, xmm2,      B     V/V       AVX      xmm3/m128 from packed    \n   xmm3/m128                                         signed word integers in  \n                                                     xmm2 and saturate        \n                                                     results.                 \n                                                     Subtract packed signed   \n   VEX.256.66.0F.WIG E8 /r                           byte integers in         \n   VPSUBSB ymm1, ymm2,      B     V/V       AVX2     ymm3/m256 from packed    \n   ymm3/m256                                         signed byte integers in  \n                                                     ymm2 and saturate        \n                                                     results.                 \n                                                     Subtract packed signed   \n   VEX.256.66.0F.WIG E9 /r                           word integers in         \n   VPSUBSW ymm1, ymm2,      B     V/V       AVX2     ymm3/m256 from packed    \n   ymm3/m256                                         signed word integers in  \n                                                     ymm2 and saturate        \n                                                     results.                 \n                                                     Subtract packed signed   \n                                                     byte integers in         \n   EVEX.128.66.0F.WIG E8 /r                 AVX512VL xmm3/m128 from packed    \n   VPSUBSB xmm1 {k1}{z},    C     V/V       AVX512BW signed byte integers in  \n   xmm2, xmm3/m128                                   xmm2 and saturate        \n                                                     results and store in     \n                                                     xmm1 using writemask k1. \n                                                     Subtract packed signed   \n                                                     byte integers in         \n   EVEX.256.66.0F.WIG E8 /r                 AVX512VL ymm3/m256 from packed    \n   VPSUBSB ymm1 {k1}{z},    C     V/V       AVX512BW signed byte integers in  \n   ymm2, ymm3/m256                                   ymm2 and saturate        \n                                                     results and store in     \n                                                     ymm1 using writemask k1. \n                                                     Subtract packed signed   \n                                                     byte integers in         \n   EVEX.512.66.0F.WIG E8 /r                          zmm3/m512 from packed    \n   VPSUBSB zmm1 {k1}{z},    C     V/V       AVX512BW signed byte integers in  \n   zmm2, zmm3/m512                                   zmm2 and saturate        \n                                                     results and store in     \n                                                     zmm1 using writemask k1. \n                                                     Subtract packed signed   \n                                                     word integers in         \n   EVEX.128.66.0F.WIG E9 /r                 AVX512VL xmm3/m128 from packed    \n   VPSUBSW xmm1 {k1}{z},    C     V/V       AVX512BW signed word integers in  \n   xmm2, xmm3/m128                                   xmm2 and saturate        \n                                                     results and store in     \n                                                     xmm1 using writemask k1. \n                                                     Subtract packed signed   \n                                                     word integers in         \n   EVEX.256.66.0F.WIG E9 /r                 AVX512VL ymm3/m256 from packed    \n   VPSUBSW ymm1 {k1}{z},    C     V/V       AVX512BW signed word integers in  \n   ymm2, ymm3/m256                                   ymm2 and saturate        \n                                                     results and store in     \n                                                     ymm1 using writemask k1. \n                                                     Subtract packed signed   \n                                                     word integers in         \n   EVEX.512.66.0F.WIG E9 /r                          zmm3/m512 from packed    \n   VPSUBSW zmm1 {k1}{z},    C     V/V       AVX512BW signed word integers in  \n   zmm2, zmm3/m512                                   zmm2 and saturate        \n                                                     results and store in     \n                                                     zmm1 using writemask k1. \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD subtract of the packed signed integers of the source\n   operand (second operand) from the packed signed integers of the\n   destination operand (first operand), and stores the packed integer results\n   in the destination operand. See Figure 9-4 in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for an illustration\n   of a SIMD operation. Overflow is handled with signed saturation, as\n   described in the following paragraphs.\n\n   The (V)PSUBSB instruction subtracts packed signed byte integers. When an\n   individual byte result is beyond the range of a signed byte integer (that\n   is, greater than 7FH or less than 80H), the saturated value of 7FH or 80H,\n   respectively, is written to the destination operand.\n\n   The (V)PSUBSW instruction subtracts packed signed word integers. When an\n   individual word result is beyond the range of a signed word integer (that\n   is, greater than 7FFFH or less than 8000H), the saturated value of 7FFFH\n   or 8000H, respectively, is written to the destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The destination operand must be an MMX\n   technology register and the source operand can be either an MMX technology\n   register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The second source operand is an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand is an XMM register or a\n   128-bit memory location. The first source operand and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded versions: The second source operand is an YMM register or\n   an 256-bit memory location. The first source operand and destination\n   operands are YMM registers. Bits (MAXVL-1:256) of the corresponding ZMM\n   register are zeroed.\n\n   EVEX encoded version: The second source operand is an ZMM/YMM/XMM register\n   or an 512/256/128-bit memory location. The first source operand and\n   destination operands are ZMM/YMM/XMM registers. The destination is\n   conditionally updated with writemask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["eaccept", "                    EACCEPT \u2014 Accept Changes to an EPC Page\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n                                                 This leaf function accepts   \n   EAX = 05H          IR    V/V          SGX2    changes made by system       \n   ENCLU[EACCEPT]                                software to an EPC page in   \n                                                 the running enclave.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                       RBX          RCX                           \n   IR    EACCEPT (In) Return Error Address of a Address of the destination    \n                      Code (Out)   SECINFO (In) EPC page (In)                 \n\n  Description \u00b6\n\n   This leaf function accepts changes to a page in the running enclave by\n   verifying that the security attributes specified in the SECINFO match the\n   security attributes of the page in the EPCM. This instruction leaf can\n   only be executed when inside the enclave.\n\n   RBX contains the effective address of a SECINFO structure while RCX\n   contains the effective address of an EPC page. The table below provides\n   additional information on the memory parameter of the EACCEPT leaf\n   function.\n\nEACCEPT Memory Parameter Semantics \u00b6\n\n   SECINFO                              EPCPAGE (Destination)            \n   Read access permitted by Non Enclave Read access permitted by Enclave \n\n   The instruction faults if any of the following:\n\nEACCEPT Faulting Conditions \u00b6\n\n   The operands are not properly         RBX does not contain an effective    \n   aligned.                              address in an EPC page in the        \n                                         running enclave.                     \n   The EPC page is locked by another     RCX does not contain an effective    \n   thread.                               address of an EPC page in the        \n                                         running enclave.                     \n   The EPC page is not valid.            Page type is PT_REG and MODIFIED bit \n                                         is 0.                                \n                                         Page type is PT_TCS or PT_TRIM and   \n   SECINFO contains an invalid request.  PENDING bit is 0 and MODIFIED bit is \n                                         1.                                   \n   If security attributes of the SECINFO \n   page make the page inaccessible.      \n\n   The error codes are:\n\n   Error Code (see Table 38-4)  Description                                   \n   No Error                     EACCEPT successful.                           \n   SGX_PAGE_ATTRIBUTES_MISMATCH The attributes of the target EPC page do not  \n                                match the expected values.                    \n   SGX_NOT_TRACKED              The OS did not complete an ETRACK on the      \n                                target page.                                  \n\n   Table 38-54. EACCEPT Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                            Base Concurrency Restrictions\n   Leaf    Parameter        Access     On Conflict SGX_CONFLICT VM Exit       \n                                                   Qualification              \n   EACCEPT Target [DS:RCX]  Shared     #GP         \n           SECINFO [DS:RBX] Concurrent \n\n   Table 38-55. Base Concurrency Restrictions of EACCEPT\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT,                                       \n                     EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\n   Leaf    Parameter EMODPE, EMODPR,     EINIT\n                     EMODT      \n                     Access     On       Access     On       Access     On       \n                                Conflict            Conflict            Conflict \n           Target    Exclusive  #GP      Concurrent          Concurrent \n   EACCEPT [DS:RCX]  \n           SECINFO   Concurrent          Concurrent          Concurrent \n           [DS:RBX]  \n\n   Table 38-56. Additional Concurrency Restrictions of EACCEPT\n\n  Flags Affected \u00b6\n\n   Sets ZF if page cannot be accepted, otherwise cleared. Clears CF, PF, AF,\n   OF, SF\n"],
	["vfcmulcsh:vfmulcsh", "            VFCMULCSH/VFMULCSH \u2014 Complex Multiply Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Complex multiply a   \n                                                         pair of FP16 values  \n                                                         from xmm2 and        \n   EVEX.LLIG.F2.MAP6.W0 D7 /r                            complex conjugate of \n   VFCMULCSH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 xmm3/m32, and store  \n   xmm3/m32 {er}                                         the result in xmm1   \n                                                         subject to writemask \n                                                         k1. Bits 127:32 of   \n                                                         xmm2 are copied to   \n                                                         xmm1[127:32].        \n                                                         Complex multiply a   \n                                                         pair of FP16 values  \n                                                         from xmm2 and        \n   EVEX.LLIG.F3.MAP6.W0 D7 /r                            xmm3/m32, and store  \n   VFMULCSH xmm1{k1}{z}, xmm2,     A V/V     AVX512-FP16 the result in xmm1   \n   xmm3/m32 {er}                                         subject to writemask \n                                                         k1. Bits 127:32 of   \n                                                         xmm2 are copied to   \n                                                         xmm1[127:32].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a complex multiply operation. There are normal\n   and complex conjugate forms of the operation. The masking for this\n   operation is done on 32-bit quantities representing a pair of FP16 values.\n\n   Bits 127:32 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   Rounding is performed at every FMA (fused multiply and add) boundary.\n   Execution occurs as if all MXCSR exceptions are masked. MXCSR status bits\n   are updated to reflect exceptional conditions.\n"],
	["divpd", "          DIVPD \u2014 Divide Packed Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Divide packed double       \n                                                   precision floating-point   \n   66 0F 5E /r DIVPD xmm1, A    V/V       SSE2     values in xmm1 by packed   \n   xmm2/m128                                       double precision           \n                                                   floating-point values in   \n                                                   xmm2/mem.                  \n                                                   Divide packed double       \n   VEX.128.66.0F.WIG 5E /r                         precision floating-point   \n   VDIVPD xmm1, xmm2,      B    V/V       AVX      values in xmm2 by packed   \n   xmm3/m128                                       double precision           \n                                                   floating-point values in   \n                                                   xmm3/mem.                  \n                                                   Divide packed double       \n   VEX.256.66.0F.WIG 5E /r                         precision floating-point   \n   VDIVPD ymm1, ymm2,      B    V/V       AVX      values in ymm2 by packed   \n   ymm3/m256                                       double precision           \n                                                   floating-point values in   \n                                                   ymm3/mem.                  \n                                                   Divide packed double       \n                                                   precision floating-point   \n   EVEX.128.66.0F.W1 5E /r                         values in xmm2 by packed   \n   VDIVPD xmm1 {k1}{z},    C    V/V       AVX512VL double precision           \n   xmm2, xmm3/m128/m64bcst                AVX512F  floating-point values in   \n                                                   xmm3/m128/m64bcst and      \n                                                   write results to xmm1      \n                                                   subject to writemask k1.   \n                                                   Divide packed double       \n                                                   precision floating-point   \n   EVEX.256.66.0F.W1 5E /r                         values in ymm2 by packed   \n   VDIVPD ymm1 {k1}{z},    C    V/V       AVX512VL double precision           \n   ymm2, ymm3/m256/m64bcst                AVX512F  floating-point values in   \n                                                   ymm3/m256/m64bcst and      \n                                                   write results to ymm1      \n                                                   subject to writemask k1.   \n                                                   Divide packed double       \n                                                   precision floating-point   \n   EVEX.512.66.0F.W1 5E /r                         values in zmm2 by packed   \n   VDIVPD zmm1 {k1}{z},    C    V/V       AVX512F  double precision           \n   zmm2,                                           floating-point values in   \n   zmm3/m512/m64bcst{er}                           zmm3/m512/m64bcst and      \n                                                   write results to zmm1      \n                                                   subject to writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD divide of the double precision floating-point values in\n   the first source operand by the floating-point values in the second source\n   operand (the third operand). Results are written to the destination\n   operand (the first operand).\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand (the second operand) is\n   a YMM register. The second source operand can be a YMM register or a\n   256-bit memory location. The destination operand is a YMM register. The\n   upper bits (MAXVL-1:256) of the corresponding destination are zeroed.\n\n   VEX.128 encoded version: The first source operand (the second operand) is\n   a XMM register. The second source operand can be a XMM register or a\n   128-bit memory location. The destination operand is a XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding destination are zeroed.\n\n   128-bit Legacy SSE version: The second source operand (the second operand)\n   can be an XMM register or an 128-bit memory location. The destination is\n   the same as the first source operand. The upper bits (MAXVL-1:128) of the\n   corresponding destination are unmodified.\n"],
	["vfpclasspd", "               VFPCLASSPD \u2014 Tests Types of Packed Float64 Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Tests the input for the  \n                                                     following categories:    \n                                                     NaN, +0, -0, +Infinity,  \n   EVEX.128.66.0F3A.W1 66                            -Infinity, denormal,     \n   /r ib VFPCLASSPD k2                      AVX512VL finite negative. The     \n   {k1}, xmm2/m128/m64bcst, A     V/V       AVX512DQ immediate field provides \n   imm8                                              a mask bit for each of   \n                                                     these category tests.    \n                                                     The masked test results  \n                                                     are OR-ed together to    \n                                                     form a mask result.      \n                                                     Tests the input for the  \n                                                     following categories:    \n                                                     NaN, +0, -0, +Infinity,  \n   EVEX.256.66.0F3A.W1 66                            -Infinity, denormal,     \n   /r ib VFPCLASSPD k2                      AVX512VL finite negative. The     \n   {k1}, ymm2/m256/m64bcst, A     V/V       AVX512DQ immediate field provides \n   imm8                                              a mask bit for each of   \n                                                     these category tests.    \n                                                     The masked test results  \n                                                     are OR-ed together to    \n                                                     form a mask result.      \n                                                     Tests the input for the  \n                                                     following categories:    \n                                                     NaN, +0, -0, +Infinity,  \n   EVEX.512.66.0F3A.W1 66                            -Infinity, denormal,     \n   /r ib VFPCLASSPD k2                               finite negative. The     \n   {k1}, zmm2/m512/m64bcst, A     V/V       AVX512DQ immediate field provides \n   imm8                                              a mask bit for each of   \n                                                     these category tests.    \n                                                     The masked test results  \n                                                     are OR-ed together to    \n                                                     form a mask result.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   The FPCLASSPD instruction checks the packed double precision\n   floating-point values for special categories, specified by the set bits in\n   the imm8 byte. Each set bit in imm8 specifies a category of floating-point\n   values that the input data element is classified against. The classified\n   results of all specified categories of an input value are ORed together to\n   form the final boolean result for the input element. The result of each\n   element is written to the corresponding bit in a mask register k2\n   according to the writemask k1. Bits [MAX_KL-1:8/4/2] of the destination\n   are cleared.\n\n   The classification categories specified by imm8 are shown in Figure 5-13.\n   The classification test for each category is listed in Table 5-14.\n\n    76543210 \n    ^SNaN    Neg. Finite Denormal ^Neg. INF +INF Neg. 0 +0 QNaN \n\n   Figure 5-13. Imm8 Byte Specifier of Special Case Floating-Point Values for\n   VFPCLASSPD/SD/PS/SS Table 5-14. Classifier Operations for\n   VFPCLASSPD/SD/PS/SS\n\n   Bits Imm8[0] Imm8[1] Imm8[2] Imm8[3] Imm8[4] Imm8[5] Imm8[6] Imm8[7]\n\n   Category QNAN PosZero NegZero PosINF NegINF Denormal Negative SNAN\n\n   Classifier Checks for Checks for Checks for Checks for Checks for Checks\n   for Checks for Checks for QNaN +0 0 +INF INF Denormal Negative finite SNaN\n\n   The source operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location, or a 512/256/128-bit vector broadcasted from a 64-bit memory\n   location.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["vcvttps2udq", "  VCVTTPS2UDQ \u2014 Convert With Truncation Packed Single Precision Floating-Point\n               Values toPacked Unsigned Doubleword Integer Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Convert four packed     \n                                                      single precision        \n                                                      floating-point values   \n   EVEX.128.0F.W0 78 /r                      AVX512VL from xmm2/m128/m32bcst  \n   VCVTTPS2UDQ xmm1 {k1}{z}, A     V/V       AVX512F  to four packed unsigned \n   xmm2/m128/m32bcst                                  doubleword values in    \n                                                      xmm1 using truncation   \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Convert eight packed    \n                                                      single precision        \n                                                      floating-point values   \n   EVEX.256.0F.W0 78 /r                      AVX512VL from ymm2/m256/m32bcst  \n   VCVTTPS2UDQ ymm1 {k1}{z}, A     V/V       AVX512F  to eight packed         \n   ymm2/m256/m32bcst                                  unsigned doubleword     \n                                                      values in ymm1 using    \n                                                      truncation subject to   \n                                                      writemask k1.           \n                                                      Convert sixteen packed  \n                                                      single precision        \n                                                      floating-point values   \n   EVEX.512.0F.W0 78 /r                               from zmm2/m512/m32bcst  \n   VCVTTPS2UDQ zmm1 {k1}{z}, A     V/V       AVX512F  to sixteen packed       \n   zmm2/m512/m32bcst{sae}                             unsigned doubleword     \n                                                      values in zmm1 using    \n                                                      truncation subject to   \n                                                      writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation packed single precision floating-point values in\n   the source operand to sixteen unsigned doubleword integers in the\n   destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location or a 512/256/128-bit vector broadcasted\n   from a 32-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register conditionally updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n"],
	["vpdpwssds", "       VPDPWSSDS \u2014 Multiply and Add Signed Word Integers With Saturation\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply groups of 2  \n                                                        pairs of signed words \n                                                        in xmm3/m128 with     \n   VEX.128.66.0F38.W0 53                                corresponding signed  \n   /r VPDPWSSDS xmm1,     A     V/V       AVX-VNNI      words of xmm2,        \n   xmm2, xmm3/m128                                      summing those         \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result in xmm1, with  \n                                                        signed saturation.    \n                                                        Multiply groups of 2  \n                                                        pairs of signed words \n                                                        in ymm3/m256 with     \n   VEX.256.66.0F38.W0 53                                corresponding signed  \n   /r VPDPWSSDS ymm1,     A     V/V       AVX-VNNI      words of ymm2,        \n   ymm2, ymm3/m256                                      summing those         \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result in ymm1, with  \n                                                        signed saturation.    \n                                                        Multiply groups of 2  \n                                                        pairs of signed words \n                                                        in xmm3/m128/m32bcst  \n   EVEX.128.66.0F38.W0 53                               with corresponding    \n   /r VPDPWSSDS                           AVX512_VNNI   signed words of xmm2, \n   xmm1{k1}{z}, xmm2,     B     V/V       AVX512VL      summing those         \n   xmm3/m128/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in xmm1, with  \n                                                        signed saturation,    \n                                                        under writemask k1.   \n                                                        Multiply groups of 2  \n                                                        pairs of signed words \n                                                        in ymm3/m256/m32bcst  \n   EVEX.256.66.0F38.W0 53                               with corresponding    \n   /r VPDPWSSDS                           AVX512_VNNI   signed words of ymm2, \n   ymm1{k1}{z}, ymm2,     B     V/V       AVX512VL      summing those         \n   ymm3/m256/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in ymm1, with  \n                                                        signed saturation,    \n                                                        under writemask k1.   \n                                                        Multiply groups of 2  \n                                                        pairs of signed words \n                                                        in zmm3/m512/m32bcst  \n   EVEX.512.66.0F38.W0 53                               with corresponding    \n   /r VPDPWSSDS                                         signed words of zmm2, \n   zmm1{k1}{z}, zmm2,     B     V/V       AVX512_VNNI   summing those         \n   zmm3/m512/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in zmm1, with  \n                                                        signed saturation,    \n                                                        under writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A   ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full  ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Multiplies the individual signed words of the first source operand by the\n   corresponding signed words of the second source operand, producing\n   intermediate signed, doubleword results. The adjacent doubleword results\n   are then summed and accumulated in the destination operand. If the\n   intermediate sum overflows a 32b signed number, the result is saturated to\n   either 0x7FFF_FFFF for positive numbers of 0x8000_0000 for negative\n   numbers.\n\n   This instruction supports memory fault suppression.\n"],
	["vcvtps2ph", "        VCVTPS2PH \u2014 Convert Single-Precision FP Value to 16-bit FP Value\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Convert four packed       \n                                                    single-precision          \n   VEX.128.66.0F3A.W0 1D                            floating-point values in  \n   /r ib VCVTPS2PH         A     V/V       F16C     xmm2 to packed            \n   xmm1/m64, xmm2, imm8                             half-precision (16-bit)   \n                                                    floating-point values in  \n                                                    xmm1/m64. Imm8 provides   \n                                                    rounding controls.        \n                                                    Convert eight packed      \n                                                    single-precision          \n   VEX.256.66.0F3A.W0 1D                            floating-point values in  \n   /r ib VCVTPS2PH         A     V/V       F16C     ymm2 to packed            \n   xmm1/m128, ymm2, imm8                            half-precision (16-bit)   \n                                                    floating-point values in  \n                                                    xmm1/m128. Imm8 provides  \n                                                    rounding controls.        \n                                                    Convert four packed       \n                                                    single-precision          \n   EVEX.128.66.0F3A.W0 1D                           floating-point values in  \n   /r ib VCVTPS2PH         B     V/V       AVX512VL xmm2 to packed            \n   xmm1/m64 {k1}{z}, xmm2,                 AVX512F  half-precision (16-bit)   \n   imm8                                             floating-point values in  \n                                                    xmm1/m64. Imm8 provides   \n                                                    rounding controls.        \n                                                    Convert eight packed      \n                                                    single-precision          \n   EVEX.256.66.0F3A.W0 1D                           floating-point values in  \n   /r ib VCVTPS2PH         B     V/V       AVX512VL ymm2 to packed            \n   xmm1/m128 {k1}{z},                      AVX512F  half-precision (16-bit)   \n   ymm2, imm8                                       floating-point values in  \n                                                    xmm1/m128. Imm8 provides  \n                                                    rounding controls.        \n                                                    Convert sixteen packed    \n                                                    single-precision          \n   EVEX.512.66.0F3A.W0 1D                           floating-point values in  \n   /r ib VCVTPS2PH         B     V/V       AVX512F  zmm2 to packed            \n   ymm1/m256 {k1}{z},                               half-precision (16-bit)   \n   zmm2{sae}, imm8                                  floating-point values in  \n                                                    ymm1/m256. Imm8 provides  \n                                                    rounding controls.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   B     Half Mem   ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n\n  Description \u00b6\n\n   Convert packed single-precision floating values in the source operand to\n   half-precision (16-bit) floating-point values and store to the destination\n   operand. The rounding mode is specified using the immediate field (imm8).\n\n   Underflow results (i.e., tiny results) are converted to denormals.\n   MXCSR.FTZ is ignored. If a source element is denormal relative to the\n   input format with DM masked and at least one of PM or UM unmasked; a SIMD\n   exception will be raised with DE, UE and PE set.\n\n   VCVTPS2PHxmm1/mem64,xmm2, imm8 127 96 95 64 63 32 31 0 VS3 VS2 VS1 VS0\n   xmm2 convert convert convert convert 127 96 95 64 63 48 47 32 31 16 15 0\n   VH3 VH2 VH1 VH0 xmm1/mem64 Figure 5-7. VCVTPS2PH (128-bit Version)\n\n   The immediate byte defines several bit fields that control rounding\n   operation. The effect and encoding of the RC field are listed in Table\n   5-13.\n\n   Bits     Field Name/value Description               Comment         \n            RC=00B           Round to nearest even                     \n   Imm[1:0] RC=01B           Round down                If Imm[2] = 0\n            RC=10B           Round up                  \n            RC=11B           Truncate                  \n   Imm[2]   MS1=0            Use imm[1:0] for rounding Ignore MXCSR.RC \n            MS1=1            Use MXCSR.RC for rounding \n   Imm[7:3] Ignored          Ignored by processor      \n\n   Table 5-13. Immediate Byte Encoding for 16-bit Floating-Point Conversion\n   Instructions\n\n   VEX.128 version: The source operand is a XMM register. The destination\n   operand is a XMM register or 64-bit memory location. If the destination\n   operand is a register then the upper bits (MAXVL-1:64) of corresponding\n   register are zeroed.\n\n   VEX.256 version: The source operand is a YMM register. The destination\n   operand is a XMM register or 128-bit memory location. If the destination\n   operand is a register, the upper bits (MAXVL-1:128) of the corresponding\n   destination register are zeroed.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved (must be 1111b).\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register. The\n   destination operand is a YMM/XMM/XMM (low 64-bits) register or a\n   256/128/64-bit memory location, conditionally updated with writemask k1.\n   Bits (MAXVL-1:256/128/64) of the corresponding destination register are\n   zeroed.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["vpmadd52huq", "VPMADD52HUQ \u2014 Packed Multiply of Unsigned 52-Bit Unsigned Integers and Add High\n                     52-BitProducts to 64-Bit Accumulators\n\n                                64/32 Bit                                     \n   Opcode/Instruction     Op/En Mode      CPUID       Description\n                                Support   \n                                                      Multiply unsigned       \n                                                      52-bit integers in xmm2 \n   EVEX.128.66.0F38.W1 B5                             and xmm3/m128 and add   \n   /r VPMADD52HUQ xmm1    A     V/V       AVX512_IFMA the high 52 bits of the \n   {k1}{z}, xmm2,                         AVX512VL    104-bit product to the  \n   xmm3/m128/m64bcst                                  qword unsigned integers \n                                                      in xmm1 using writemask \n                                                      k1.                     \n                                                      Multiply unsigned       \n                                                      52-bit integers in ymm2 \n   EVEX.256.66.0F38.W1 B5                             and ymm3/m256 and add   \n   /r VPMADD52HUQ ymm1    A     V/V       AVX512_IFMA the high 52 bits of the \n   {k1}{z}, ymm2,                         AVX512VL    104-bit product to the  \n   ymm3/m256/m64bcst                                  qword unsigned integers \n                                                      in ymm1 using writemask \n                                                      k1.                     \n                                                      Multiply unsigned       \n                                                      52-bit integers in zmm2 \n   EVEX.512.66.0F38.W1 B5                             and zmm3/m512 and add   \n   /r VPMADD52HUQ zmm1    A     V/V       AVX512_IFMA the high 52 bits of the \n   {k1}{z}, zmm2,                                     104-bit product to the  \n   zmm3/m512/m64bcst                                  qword unsigned integers \n                                                      in zmm1 using writemask \n                                                      k1.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3    Operand 4 \n   A     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m(r) N/A       \n\n  Description \u00b6\n\n   Multiplies packed unsigned 52-bit integers in each qword element of the\n   first source operand (the second operand) with the packed unsigned 52-bit\n   integers in the corresponding elements of the second source operand (the\n   third operand) to form packed 104-bit intermediate results. The high\n   52-bit, unsigned integer of each 104-bit product is added to the\n   corresponding qword unsigned integer of the destination operand (the first\n   operand) under the writemask k1.\n\n   The first source operand is a ZMM/YMM/XMM register. The second source\n   operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location\n   or a 512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is a ZMM/YMM/XMM register conditionally updated with\n   writemask k1 at 64-bit granularity.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["mwait", "                              MWAIT \u2014 Monitor Wait\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                A hint that allows the        \n                                                processor to stop instruction \n                                                execution and enter an        \n   0F 01 C9 MWAIT       ZO    Valid  Valid      implementation-dependent      \n                                                optimized state until         \n                                                occurrence of a class of      \n                                                events.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   MWAIT instruction provides hints to allow the processor to enter an\n   implementation-dependent optimized state. There are two principal targeted\n   usages: address-range monitor and advanced power management. Both usages\n   of MWAIT require the use of the MONITOR instruction.\n\n   CPUID.01H:ECX.MONITOR[bit 3] indicates the availability of MONITOR and\n   MWAIT in the processor. When set, MWAIT may be executed only at privilege\n   level 0 (use at any other privilege level results in an invalid-opcode\n   exception). The operating system or system BIOS may disable this\n   instruction by using the IA32_MISC_ENABLE MSR; disabling MWAIT clears the\n   CPUID feature flag and causes execution to generate an invalid-opcode\n   exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\n   ECX specifies optional extensions for the MWAIT instruction. EAX may\n   contain hints such as the preferred optimized state the processor should\n   enter. The first processors to implement MWAIT supported only the zero\n   value for EAX and ECX. Later processors allowed setting ECX[0] to enable\n   masked interrupts as break events for MWAIT (see below). Software can use\n   the CPUID instruction to determine the extensions and hints supported by\n   the processor.\n\nMWAIT for Address Range Monitoring \u00b6\n\n   For address-range monitoring, the MWAIT instruction operates with the\n   MONITOR instruction. The two instructions allow the definition of an\n   address at which to wait (MONITOR) and a\n   implementation-dependent-optimized operation to commence at the wait\n   address (MWAIT). The execution of MWAIT is a hint to the processor that it\n   can enter an implementation-dependent-optimized state while waiting for an\n   event or a store operation to the address range armed by MONITOR.\n\n   The following cause the processor to exit the\n   implementation-dependent-optimized state: a store to the address range\n   armed by the MONITOR instruction, an NMI or SMI, a debug exception, a\n   machine check exception, the BINIT# signal, the INIT# signal, and the\n   RESET# signal. Other implementation-dependent events may also cause the\n   processor to exit the implementation-dependent-optimized state.\n\n   In addition, an external interrupt causes the processor to exit the\n   implementation-dependent-optimized state either (1) if the interrupt would\n   be delivered to software (e.g., as it would be if HLT had been executed\n   instead of MWAIT); or (2) if ECX[0] = 1. Software can execute MWAIT with\n   ECX[0] = 1 only if CPUID.05H:ECX[bit 1] = 1. (Implementation-specific\n   conditions may result in an interrupt causing the processor to exit the\n   implementation-dependent-optimized state even if interrupts are masked and\n   ECX[0] = 0.)\n\n   Following exit from the implementation-dependent-optimized state, control\n   passes to the instruction following the MWAIT instruction. A pending\n   interrupt that is not masked (including an NMI or an SMI) may be delivered\n   before execution of that instruction. Unlike the HLT instruction, the\n   MWAIT instruction does not support a restart at the MWAIT instruction\n   following the handling of an SMI.\n\n   If the preceding MONITOR instruction did not successfully arm an address\n   range or if the MONITOR instruction has not been executed prior to\n   executing MWAIT, then the processor will not enter the\n   implementation-dependent-optimized state. Execution will resume at the\n   instruction following the MWAIT.\n\nMWAIT for Power Management \u00b6\n\n   MWAIT accepts a hint and optional extension to the processor that it can\n   enter a specified target C state while waiting for an event or a store\n   operation to the address range armed by MONITOR. Support for MWAIT\n   extensions for power management is indicated by CPUID.05H:ECX[bit 0]\n   reporting 1.\n\n   EAX and ECX are used to communicate the additional information to the\n   MWAIT instruction, such as the kind of optimized state the processor\n   should enter. ECX specifies optional extensions for the MWAIT instruction.\n   EAX may contain hints such as the preferred optimized state the processor\n   should enter. Implementation-specific conditions may cause a processor to\n   ignore the hint and enter a different optimized state. Future processor\n   implementations may implement several optimized \u201cwaiting\u201d states and will\n   select among those states based on the hint argument.\n\n   Table 4-10 describes the meaning of ECX and EAX registers for MWAIT\n   extensions.\n\n   Bits  Description                                                          \n   0     Treat interrupts as break events even if masked (e.g., even if       \n         EFLAGS.IF=0). May be set only if CPUID.05H:ECX[bit 1] = 1.           \n   31: 1 Reserved                                                             \n\n   Table 4-10. MWAIT Extension Register (ECX)\n\n   Bits  Description                                                          \n   3:0   Sub C-state within a C-state, indicated by bits [7:4]                \n         Target C-state* Value of 0 means C1; 1 means C2 and so on Value of   \n   7:4   01111B means C0 Note: Target C states for MWAIT extensions are       \n         processor-specific C-states, not ACPI C-states                       \n   31: 8 Reserved                                                             \n\n   Table 4-11. MWAIT Hints Register (EAX)\n\n   Note that if MWAIT is used to enter any of the C-states that are\n   numerically higher than C1, a store to the address range armed by the\n   MONITOR instruction will cause the processor to exit MWAIT only if the\n   store was originated by other processor agents. A store from non-processor\n   agent might not cause the processor to exit MWAIT in such cases.\n\n   For additional details of MWAIT extensions, see Chapter 15, \u201cPower and\n   Thermal Management,\u201d of Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3A.\n\nExample \u00b6\n\n   MONITOR/MWAIT instruction pair must be coded in the same loop because\n   execution of the MWAIT instruction will trigger the monitor hardware. It\n   is not a proper usage to execute MONITOR once and then execute MWAIT in a\n   loop. Setting up MONITOR without executing MWAIT has no adverse effects.\n\n   Typically the MONITOR/MWAIT pair is used in a sequence, such as:\n\n   EAX = Logical Address(Trigger)\n\n   ECX = 0 (*Hints *)\n\n   EDX = 0 (* Hints *)\n\n   IF ( !trigger_store_happened) {\n\n   MONITOR EAX, ECX, EDX\n\n   IF ( !trigger_store_happened ) {\n\n   MWAIT EAX, ECX\n\n   }\n\n   }\n\n   The above code sequence makes sure that a triggering store does not happen\n   between the first check of the trigger and the execution of the monitor\n   instruction. Without the second check that triggering store would go\n   un-noticed. Typical usage of MONITOR and MWAIT would have the above code\n   sequence within a loop.\n"],
	["vfpclassph", "                 VFPCLASSPH \u2014 Test Types of Packed FP16 Values\n\n   Instruction En Bit                                                         \n   Mode Flag Support    \n   Instruction En Bit   \n   Mode Flag Support    \n   64/32 CPUID Feature  \n   Instruction En Bit   \n   Mode Flag CPUID      \n   Feature Instruction  \n   En Bit Mode Flag Op/   Support             Description\n   64/32 CPUID Feature  \n   Instruction En Bit   \n   Mode Flag 64/32      \n   CPUID Feature        \n   Instruction En Bit   \n   Mode Flag CPUID      \n   Feature Instruction  \n   En Bit Mode Flag Op/ \n   64/32 CPUID Feature  \n                                              Test the input for the          \n                                              following categories: NaN, +0,  \n   EVEX.128.NP.0F3A.W0                        -0, +Infinity, -Infinity,       \n   66 /r /ib VFPCLASSPH           AVX512-FP16 denormal, finite negative. The  \n   k1{k2},              A V/V     AVX512VL    immediate field provides a mask \n   xmm1/m128/m16bcst,                         bitforeachofthesecategorytests. \n   imm8                                       Themasked test results are      \n                                              OR-ed together to form a mask   \n                                              result.                         \n                                              Test the input for the          \n                                              following categories: NaN, +0,  \n   EVEX.256.NP.0F3A.W0                        -0, +Infinity, -Infinity,       \n   66 /r /ib VFPCLASSPH           AVX512-FP16 denormal, finite negative. The  \n   k1{k2},              A V/V     AVX512VL    immediate field provides a mask \n   ymm1/m256/m16bcst,                         bitforeachofthesecategorytests. \n   imm8                                       Themasked test results are      \n                                              OR-ed together to form a mask   \n                                              result.                         \n                                              Test the input for the          \n                                              following categories: NaN, +0,  \n   EVEX.512.NP.0F3A.W0                        -0, +Infinity, -Infinity,       \n   66 /r /ib VFPCLASSPH                       denormal, finite negative. The  \n   k1{k2},              A V/V     AVX512-FP16 immediate field provides a mask \n   zmm1/m512/m16bcst,                         bitforeachofthesecategorytests. \n   imm8                                       Themasked test results are      \n                                              OR-ed together to form a mask   \n                                              result.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) imm8 (r)  N/A       \n\n  Description \u00b6\n\n   This instruction checks the packed FP16 values in the source operand for\n   special categories, specified by the set bits in the imm8 byte. Each set\n   bit in imm8 specifies a category of floating-point values that the input\n   data element is classified against; see Table 5-9 for the categories. The\n   classified results of all specified categories of an input value are ORed\n   together to form the final boolean result for the input element. The\n   result is written to the corresponding bits in the destination mask\n   register according to the writemask.\n\n   Bits    Category Classifier                 \n   imm8[0] QNAN     Checks for QNAN            \n   imm8[1] PosZero  Checks +0                  \n   imm8[2] NegZero  Checks for -0              \n   imm8[3] PosINF   Checks for +\u221e              \n   imm8[4] NegINF   Checks for \u2212\u221e              \n   imm8[5] Denormal Checks for Denormal        \n   imm8[6] Negative Checks for Negative finite \n   imm8[7] SNAN     Checks for SNAN            \n\n   Table 5-9. Classifier Operations for VFPCLASSPH/VFPCLASSSH\n"],
	["vcvttph2w", "         VCVTTPH2W \u2014 Convert Packed FP16 Values to Signed Word Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert eight packed  \n                                                        FP16 values in        \n                                                        xmm2/m128/m16bcst to  \n   EVEX.128.66.MAP5.W0 7C /r                AVX512-FP16 eight signed word     \n   VCVTTPH2W xmm1{k1}{z},         A V/V     AVX512VL    integers, and store   \n   xmm2/m128/m16bcst                                    the result in xmm1    \n                                                        using truncation      \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert sixteen       \n                                                        packed FP16 values in \n                                                        ymm2/m256/m16bcst to  \n   EVEX.256.66.MAP5.W0 7C /r                AVX512-FP16 sixteen signed word   \n   VCVTTPH2W ymm1{k1}{z},         A V/V     AVX512VL    integers, and store   \n   ymm2/m256/m16bcst                                    the result in ymm1    \n                                                        using truncation      \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert thirty-two    \n                                                        packed FP16 values in \n                                                        zmm2/m512/m16bcst to  \n   EVEX.512.66.MAP5.W0 7C /r                            thirty-two signed     \n   VCVTTPH2W zmm1{k1}{z},         A V/V     AVX512-FP16 word integers, and    \n   zmm2/m512/m16bcst {sae}                              store the result in   \n                                                        zmm1 using truncation \n                                                        subject to writemask  \n                                                        k1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   signed word integers in the destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer indefinite value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["frndint", "                           FRNDINT \u2014 Round to Integer\n\n   Opcode  Mode Leg Mode Description                \n   D9 FC                 Round ST(0) to an integer. \n\nDescription \u00b6\n\n   Rounds the source value in the ST(0) register to the nearest integral\n   value, depending on the current rounding mode (setting of the RC field of\n   the FPU control word), and stores the result in ST(0).\n\n   If the source value is \u221e, the value is not changed. If the source value is\n   not an integral value, the floating-point inexact-result exception (#P) is\n   generated.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["fdiv:fdivp:fidiv", "                           FDIV/FDIVP/FIDIV \u2014 Divide\n\n   Opcode  Instruction  64-Bit Compat/Leg Mode Description                    \n                        Mode   \n   D8 /6   FDIV m32fp   Valid  Valid           Divide ST(0) by m32fp and      \n                                               store result in ST(0).         \n   DC /6   FDIV m64fp   Valid  Valid           Divide ST(0) by m64fp and      \n                                               store result in ST(0).         \n   D8 F0+i FDIV ST(0),  Valid  Valid           Divide ST(0) by ST(i) and      \n           ST(i)                               store result in ST(0).         \n   DC F8+i FDIV ST(i),  Valid  Valid           Divide ST(i) by ST(0) and      \n           ST(0)                               store result in ST(i).         \n           FDIVP ST(i),                        Divide ST(i) by ST(0), store   \n   DE F8+i ST(0)        Valid  Valid           result in ST(i), and pop the   \n                                               register stack.                \n                                               Divide ST(1) by ST(0), store   \n   DE F9   FDIVP        Valid  Valid           result in ST(1), and pop the   \n                                               register stack.                \n   DA /6   FIDIV m32int Valid  Valid           Divide ST(0) by m32int and     \n                                               store result in ST(0).         \n   DE /6   FIDIV m16int Valid  Valid           Divide ST(0) by m16int and     \n                                               store result in ST(0).         \n\nDescription \u00b6\n\n   Divides the destination operand by the source operand and stores the\n   result in the destination location. The destination operand (dividend) is\n   always in an FPU register; the source operand (divisor) can be a register\n   or a memory location. Source operands in memory can be in single precision\n   or double precision floating-point format, word or doubleword integer\n   format.\n\n   The no-operand version of the instruction divides the contents of the\n   ST(1) register by the contents of the ST(0) register. The one-operand\n   version divides the contents of the ST(0) register by the contents of a\n   memory location (either a floating-point or an integer value). The\n   two-operand version, divides the contents of the ST(0) register by the\n   contents of the ST(i) register or vice versa.\n\n   The FDIVP instructions perform the additional operation of popping the FPU\n   register stack after storing the result. To pop the register stack, the\n   processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1. The no-operand version of the floating-point divide\n   instructions always results in the register stack being popped. In some\n   assemblers, the mnemonic for this instruction is FDIV rather than FDIVP.\n\n   The FIDIV instructions convert an integer source operand to double\n   extended-precision floating-point format before performing the division.\n   When the source operand is an integer 0, it is treated as a +0.\n\n   If an unmasked divide-by-zero exception (#Z) is generated, no result is\n   stored; if the exception is masked, an \u221e of the appropriate sign is stored\n   in the destination operand.\n\n   The following table shows the results obtained when dividing various\n   classes of numbers, assuming that neither overflow nor underflow occurs.\n\n   DEST\n           \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n       \u2212\u221e  *   +0  +0  \u22120  \u22120  *   NaN \n       \u2212F  +\u221e  +F  +0  \u22120  \u2212F  \u2212\u221e  NaN \n       \u2212I  +\u221e  +F  +0  \u22120  \u2212F  \u2212\u221e  NaN \n   SRC \u22120  +\u221e  **  *   *   **  \u2212\u221e  NaN \n       +0  \u2212\u221e  **  *   *   **  +\u221e  NaN \n       +I  \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n       +F  \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n       +\u221e  *   \u22120  \u22120  +0  +0  *   NaN \n       NaN NaN NaN NaN NaN NaN NaN NaN \n\n   Table 3-24. FDIV/FDIVP/FIDIV Results\n\n     F Meansfinitefloating-pointvalue.\n\n     I Means integer.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n     ** Indicates floating-point zero-divide (#Z) exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["vpermps", "           VPERMPS \u2014 Permute Single Precision Floating-Point Elements\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Permute single-precision   \n   VEX.256.66.0F38.W0 16                           floating-point elements in \n   /r VPERMPS ymm1, ymm2, A     V/V       AVX2     ymm3/m256 using indices in \n   ymm3/m256                                       ymm2 and store the result  \n                                                   in ymm1.                   \n                                                   Permute single-precision   \n   EVEX.256.66.0F38.W0 16                          floating-point elements in \n   /r VPERMPS ymm1        B     V/V       AVX512VL ymm3/m256/m32bcst using    \n   {k1}{z}, ymm2,                         AVX512F  indexes in ymm2 and store  \n   ymm3/m256/m32bcst                               the result in ymm1 subject \n                                                   to write mask k1.          \n                                                   Permute single-precision   \n   EVEX.512.66.0F38.W0 16                          floating-point values in   \n   /r VPERMPS zmm1        B     V/V       AVX512F  zmm3/m512/m32bcst using    \n   {k1}{z}, zmm2,                                  indices in zmm2 and store  \n   zmm3/m512/m32bcst                               the result in zmm1 subject \n                                                   to write mask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Copies doubleword elements of single-precision floating-point values from\n   the second source operand (the third operand) to the destination operand\n   (the first operand) according to the indices in the first source operand\n   (the second operand). Note that this instruction permits a doubleword in\n   the source operand to be copied to more than one location in the\n   destination operand.\n\n   VEX.256 versions: The first and second operands are YMM registers, the\n   third operand can be a YMM register or memory location. Bits (MAXVL-1:256)\n   of the corresponding destination register are zeroed.\n\n   EVEX encoded version: The first and second operands are ZMM registers, the\n   third operand can be a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 32-bit memory location. The elements in\n   the destination are updated using the writemask k1.\n\n   If VPERMPS is encoded with VEX.L= 0, an attempt to execute the instruction\n   encoded with VEX.L= 0 will cause an #UD exception.\n"],
	["adc", "                              ADC \u2014 Add With Carry\n\n   Opcode     Instruction     Op/En 64-bit Compat/Leg Description             \n                                    Mode   Mode       \n   14 ib      ADC AL, imm8    I     Valid  Valid      Add with carry imm8 to  \n                                                      AL.                     \n   15 iw      ADC AX, imm16   I     Valid  Valid      Add with carry imm16 to \n                                                      AX.                     \n   15 id      ADC EAX, imm32  I     Valid  Valid      Add with carry imm32 to \n                                                      EAX.                    \n   REX.W + 15                                         Add with carry imm32    \n   id         ADC RAX, imm32  I     Valid  N.E.       sign extended to        \n                                                      64-bits to RAX.         \n   80 /2 ib   ADC r/m8, imm8  MI    Valid  Valid      Add with carry imm8 to  \n                                                      r/m8.                   \n   REX + 80   ADC r/m8^*,     MI    Valid  N.E.       Add with carry imm8 to  \n   /2 ib      imm8                                    r/m8.                   \n   81 /2 iw   ADC r/m16,      MI    Valid  Valid      Add with carry imm16 to \n              imm16                                   r/m16.                  \n   81 /2 id   ADC r/m32,      MI    Valid  Valid      Add with CF imm32 to    \n              imm32                                   r/m32.                  \n   REX.W + 81 ADC r/m64,                              Add with CF imm32 sign  \n   /2 id      imm32           MI    Valid  N.E.       extended to 64-bits to  \n                                                      r/m64.                  \n                                                      Add with CF             \n   83 /2 ib   ADC r/m16, imm8 MI    Valid  Valid      sign-extended imm8 to   \n                                                      r/m16.                  \n                                                      Add with CF             \n   83 /2 ib   ADC r/m32, imm8 MI    Valid  Valid      sign-extended imm8 into \n                                                      r/m32.                  \n   REX.W + 83                                         Add with CF             \n   /2 ib      ADC r/m64, imm8 MI    Valid  N.E.       sign-extended imm8 into \n                                                      r/m64.                  \n   10 /r      ADC r/m8, r8    MR    Valid  Valid      Add with carry byte     \n                                                      register to r/m8.       \n   REX + 10   ADC r/m8^*,     MR    Valid  N.E.       Add with carry byte     \n   /r         r8^*                                    register to r/m64.      \n   11 /r      ADC r/m16, r16  MR    Valid  Valid      Add with carry r16 to   \n                                                      r/m16.                  \n   11 /r      ADC r/m32, r32  MR    Valid  Valid      Add with CF r32 to      \n                                                      r/m32.                  \n   REX.W + 11 ADC r/m64, r64  MR    Valid  N.E.       Add with CF r64 to      \n   /r                                                 r/m64.                  \n   12 /r      ADC r8, r/m8    RM    Valid  Valid      Add with carry r/m8 to  \n                                                      byte register.          \n   REX + 12   ADC r8^*,       RM    Valid  N.E.       Add with carry r/m64 to \n   /r         r/m8^*                                  byte register.          \n   13 /r      ADC r16, r/m16  RM    Valid  Valid      Add with carry r/m16 to \n                                                      r16.                    \n   13 /r      ADC r32, r/m32  RM    Valid  Valid      Add with CF r/m32 to    \n                                                      r32.                    \n   REX.W + 13 ADC r64, r/m64  RM    Valid  N.E.       Add with CF r/m64 to    \n   /r                                                 r64.                    \n\n     *In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8/16/32    N/A       N/A       \n   I     AL/AX/EAX/RAX    imm8/16/32    N/A       N/A       \n\nDescription \u00b6\n\n   Adds the destination operand (first operand), the source operand (second\n   operand), and the carry (CF) flag and stores the result in the destination\n   operand. The destination operand can be a register or a memory location;\n   the source operand can be an immediate, a register, or a memory location.\n   (However, two memory operands cannot be used in one instruction.) The\n   state of the CF flag represents a carry from a previous addition. When an\n   immediate value is used as an operand, it is sign-extended to the length\n   of the destination operand format.\n\n   The ADC instruction does not distinguish between signed or unsigned\n   operands. Instead, the processor evaluates the result for both data types\n   and sets the OF and CF flags to indicate a carry in the signed or unsigned\n   result, respectively. The SF flag indicates the sign of the signed result.\n\n   The ADC instruction is usually executed as part of a multibyte or\n   multiword addition in which an ADD instruction is followed by an ADC\n   instruction.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The OF, SF, ZF, AF, CF, and PF flags are set according to the result.\n"],
	["exitac", "            GETSEC[EXITAC] \u2014 Exit Authenticated Code Execution Mode\n\n   Opcode           Instruction    Description                                \n                                   Exit authenticated code execution mode.    \n   NP 0F 37 (EAX=3) GETSEC[EXITAC] RBX holds the Near Absolute Indirect jump  \n                                   target and EDX hold the exit parameter     \n                                   flags.                                     \n\nDescription \u00b6\n\n   The GETSEC[EXITAC] leaf function exits the ILP out of authenticated code\n   execution mode established by GETSEC[ENTERACCS] or GETSEC[SENTER]. The\n   EXITAC leaf of GETSEC is selected with EAX set to 3 at entry. EBX (or RBX,\n   if in 64-bit mode) holds the near jump target offset for where the\n   processor execution resumes upon exiting authenticated code execution\n   mode. EDX contains additional parameter control information. Currently\n   only an input value of 0 in EDX is supported. All other EDX settings are\n   considered reserved and result in a general protection violation.\n\n   GETSEC[EXITAC] can only be executed if the processor is in protected mode\n   with CPL = 0 and EFLAGS.VM = 0. The processor must also be in\n   authenticated code execution mode. To avoid potential operability\n   conflicts between modes, the processor is not allowed to execute this\n   instruction if it is in SMM or in VMX operation. A violation of these\n   conditions results in a general protection violation.\n\n   Upon completion of the GETSEC[EXITAC] operation, the processor unmasks\n   responses to external event signals INIT#, NMI#, and SMI#. This unmasking\n   is performed conditionally, based on whether the authenticated code\n   execution mode was entered via execution of GETSEC[SENTER] or\n   GETSEC[ENTERACCS]. If the processor is in authenticated code execution\n   mode due to the execution of GETSEC[SENTER], then these external event\n   signals will remain masked. In this case, A20M is kept disabled in the\n   measured environment until the measured environment executes\n   GETSEC[SEXIT]. INIT# is unconditionally unmasked by EXITAC. Note that any\n   events that are pending, but have been blocked while in authenticated code\n   execution mode, will be recognized at the completion of the GETSEC[EXITAC]\n   instruction if the pin event is unmasked.\n\n   The intent of providing the ability to optionally leave the pin events\n   SMI#, and NMI# masked is to support the completion of a measured\n   environment bring-up that makes use of VMX. In this envisioned security\n   usage scenario, these events will remain masked until an appropriate\n   virtual machine has been established in order to field servicing of these\n   events in a safer manner. Details on when and how events are masked and\n   unmasked in VMX operation are described in Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3C. It should be\n   cautioned that if no VMX environment is to be activated following\n   GETSEC[EXITAC], that these events will remain masked until the measured\n   environment is exited with GETSEC[SEXIT]. If this is not desired then the\n   GETSEC function SMCTRL(0) can be used for unmasking SMI# in this context.\n   NMI# can be correspondingly unmasked by execution of IRET.\n\n   A successful exit of the authenticated code execution mode requires the\n   ILP to perform additional steps as outlined below:\n\n     * Invalidate the contents of the internal authenticated code execution\n       area.\n     * Invalidate processor TLBs.\n     * Clear the internal processor AC Mode indicator flag.\n     * Re-lock the TPM locality 3 space.\n     * Unlock the Intel^\u00ae TXT-capable chipset memory and I/O protections to\n       allow memory and I/O activity by other processor agents.\n     * Perform a near absolute indirect jump to the designated instruction\n       location.\n\n   The content of the authenticated code execution area is invalidated by\n   hardware in order to protect it from further use or visibility. This\n   internal processor storage area can no longer be used or relied upon after\n   GETSEC[EXITAC]. Data structures need to be re-established outside of the\n   authenticated code execution area if they are to be referenced after\n   EXITAC. Since addressed memory content formerly mapped to the\n   authenticated code execution area may no longer be coherent with external\n   system memory after EXITAC, processor TLBs in support of linear to\n   physical address translation are also invalidated.\n\n   Upon completion of GETSEC[EXITAC] a near absolute indirect transfer is\n   performed with EIP loaded with the contents of EBX (based on the current\n   operating mode size). In 64-bit mode, all 64 bits of RBX are loaded into\n   RIP if REX.W precedes GETSEC[EXITAC]. Otherwise RBX is treated as 32 bits\n   even while in 64-bit mode. Conventional CS limit checking is performed as\n   part of this control transfer. Any exception conditions generated as part\n   of this control transfer will be directed to the existing IDT; thus it is\n   recommended that an IDTR should also be established prior to execution of\n   the EXITAC function if there is a need for fault handling. In addition,\n   any segmentation related (and paging) data structures to be used after\n   EXITAC should be re-established or validated by the authenticated code\n   prior to EXITAC.\n\n   In addition, any segmentation related (and paging) data structures to be\n   used after EXITAC need to be re-established and mapped outside of the\n   authenticated RAM designated area by the authenticated code prior to\n   EXITAC. Any data structure held within the authenticated RAM allocated\n   area will no longer be accessible after completion by EXITAC.\n\nFlags Affected \u00b6\n\n   None.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX.W Sets 64-bit mode Operand size attribute.\n\nVM-Exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["crc32", "                         CRC32 \u2014 Accumulate CRC32 Value\n\n   Opcode/Instruction                Op/En 64-Bit Compat/Leg Description      \n                                           Mode   Mode       \n   F2 0F 38 F0 /r CRC32 r32, r/m8    RM    Valid  Valid      Accumulate CRC32 \n                                                             on r/m8.         \n   F2 REX 0F 38 F0 /r CRC32 r32,     RM    Valid  N.E.       Accumulate CRC32 \n   r/m8^1                                                    on r/m8.         \n   F2 0F 38 F1 /r CRC32 r32, r/m16   RM    Valid  Valid      Accumulate CRC32 \n                                                             on r/m16.        \n   F2 0F 38 F1 /r CRC32 r32, r/m32   RM    Valid  Valid      Accumulate CRC32 \n                                                             on r/m32.        \n   F2 REX.W 0F 38 F0 /r CRC32 r64,   RM    Valid  N.E.       Accumulate CRC32 \n   r/m8                                                      on r/m8.         \n   F2 REX.W 0F 38 F1 /r CRC32 r64,   RM    Valid  N.E.       Accumulate CRC32 \n   r/m64                                                     on r/m64.        \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Starting with an initial value in the first operand (destination operand),\n   accumulates a CRC32 (polynomial 11EDC6F41H) value for the second operand\n   (source operand) and stores the result in the destination operand. The\n   source operand can be a register or a memory location. The destination\n   operand must be an r32 or r64 register. If the destination is an r64\n   register, then the 32-bit result is stored in the least significant double\n   word and 00000000H is stored in the most significant double word of the\n   r64 register.\n\n   The initial value supplied in the destination operand is a double word\n   integer stored in the r32 register or the least significant double word of\n   the r64 register. To incrementally accumulate a CRC32 value, software\n   retains the result of the previous CRC32 operation in the destination\n   operand, then executes the CRC32 instruction again with new input data in\n   the source operand. Data contained in the source operand is processed in\n   reflected bit order. This means that the most significant bit of the\n   source operand is treated as the least significant bit of the quotient,\n   and so on, for all the bits of the source operand. Likewise, the result of\n   the CRC operation is stored in the destination operand in reflected bit\n   order. This means that the most significant bit of the resulting CRC (bit\n   31) is stored in the least significant bit of the destination operand (bit\n   0), and so on, for all the bits of the CRC.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pdep", "                          PDEP \u2014 Parallel Bits Deposit\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Parallel deposit of bits   \n   VEX.LZ.F2.0F38.W0 F5 /r RVM   V/V       BMI2    from r32b using mask in    \n   PDEP r32a, r32b, r/m32                          r/m32, result is written   \n                                                   to r32a.                   \n                                                   Parallel deposit of bits   \n   VEX.LZ.F2.0F38.W1 F5 /r RVM   V/N.E.    BMI2    from r64b using mask in    \n   PDEP r64a, r64b, r/m64                          r/m64, result is written   \n                                                   to r64a.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVM   ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   PDEP uses a mask in the second source operand (the third operand) to\n   transfer/scatter contiguous low order bits in the first source operand\n   (the second operand) into the destination (the first operand). PDEP takes\n   the low bits from the first source operand and deposit them in the\n   destination operand at the corresponding bit locations that are set in the\n   second source operand (mask). All other bits (bits not set in mask) in\n   destination are set to zero.\n\n   SRC1 S31S30 S29S28S27 S7 S6 S5 S4 S3 S2 S1 S0 SRC2 0 0 0 1 0 1 0 1 0 0 1 0\n   0 (mask) DEST 0 0 0 S3 0 S2 0 S1 0 0 S0 0 0 bit 0 bit 31 Figure 4-8. PDEP\n   Example\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vgetexpsh", "       VGETEXPSH \u2014 Convert Exponents of Scalar FP16 Values to FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert the exponent  \n                                                        of FP16 values in the \n                                                        low word of the       \n                                                        source operand to     \n                                                        FP16 results          \n                                                        representing unbiased \n   EVEX.LLIG.66.MAP6.W0 43 /r                           integer exponents,    \n   VGETEXPSH xmm1{k1}{z}, xmm2,   A V/V     AVX512-FP16 and stores the        \n   xmm3/m16 {sae}                                       results in the low    \n                                                        word of the           \n                                                        destination register  \n                                                        subject to writemask  \n                                                        k1. Bits 127:16 of    \n                                                        xmm2 are copied to    \n                                                        xmm1[127:16].         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction extracts the biased exponents from the normalized FP16\n   representation of the low word element of the source operand (the second\n   operand) as unbiased signed integer value, or convert the denormal\n   representation of input data to an unbiased negative integer value. The\n   integer value of the unbiased exponent is converted to an FP16 value and\n   written to the low word element of the destination operand (the first\n   operand) as an FP16 number.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   Each GETEXP operation converts the exponent value into a floating-point\n   number (permitting input value in denormal representation). Special cases\n   of input values are listed in Table 5-16.\n\n   The formula is:\n\n   GETEXP(x) = floor(log_2(|x|))\n\n   Notation floor(x) stands for maximal integer not exceeding real number x.\n\n   Software usage of VGETEXPxx and VGETMANTxx instructions generally involve\n   a combination of GETEXP operation and GETMANT operation (see VGETMANTSH).\n   Thus, the VGETEXPSH instruction does not require software to handle SIMD\n   floating-point exceptions.\n"],
	["xsaveopt", "              XSAVEOPT \u2014 Save Processor Extended States Optimized\n\n                              64/32 bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Flag Description\n                              Support   \n                                                     Save state components    \n   NP 0F AE /6 XSAVEOPT M     V/V       XSAVEOPT     specified by EDX:EAX to  \n   mem                                               mem, optimizing if       \n                                                     possible.                \n                                                     Save state components    \n   NP REX.W + 0F AE /6  M     V/V       XSAVEOPT     specified by EDX:EAX to  \n   XSAVEOPT64 mem                                    mem, optimizing if       \n                                                     possible.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a full or partial save of processor state components to the XSAVE\n   area located at the memory address specified by the destination operand.\n   The implicit EDX:EAX register pair specifies a 64-bit instruction mask.\n   The specific state components saved correspond to the bits set in the\n   requested-feature bitmap (RFBM), which is the logical-AND of EDX:EAX and\n   XCR0.\n\n   The format of the XSAVE area is detailed in Section 13.4, \u201cXSAVE Area,\u201d of\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n   Like FXRSTOR and FXSAVE, the memory format used for x87 state depends on a\n   REX.W prefix; see Section 13.5.1, \u201cx87 State\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1.\n\n   Section 13.9, \u201cOperation of XSAVEOPT,\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1 provides a detailed\n   description of the operation of the XSAVEOPT instruction. The following\n   items provide a highlevel outline:\n\n     * Execution of XSAVEOPT is similar to that of XSAVE. XSAVEOPT differs\n       from XSAVE in that it may use the init and modified optimizations. The\n       performance of XSAVEOPT will be equal to or better than that of XSAVE.\n     * XSAVEOPT saves state component i only if RFBM[i] = 1 and XINUSE[i] =\n       1.^1 (XINUSE is a bitmap by which the processor tracks the status of\n       various state components. See Section 13.6, \u201cProcessor Tracking of\n       XSAVEManaged State,\u201d of the Intel^\u00ae 64 and IA-32 Architectures\n       Software Developer\u2019s Manual, Volume 1.) Even if both bits are 1,\n       XSAVEOPT may optimize and not save state component i if (1) state\n       component i has not been modified since the last execution of XRSTOR\n       or XRSTORS; and (2) this execution of XSAVES corresponds to that last\n       execution of XRSTOR or XRSTORS as determined by the internal value\n       XRSTOR_INFO (see the Operation section below).\n     * XSAVEOPT does not modify bytes 511:464 of the legacy region of the\n       XSAVE area (see Section 13.4.1, \u201cLegacy Region of an XSAVE Area\u201d of\n       Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n       1).\n     * XSAVEOPT reads the XSTATE_BV field of the XSAVE header (see Section\n       13.4.2, \u201cXSAVE Header,\u201d of the Intel^\u00ae 64 and IA-32 Architectures\n       Software Developer\u2019s Manual, Volume 1) and writes a modified value\n       back to memory as follows. If RFBM[i] = 1, XSAVEOPT writes\n       XSTATE_BV[i] with the value of XINUSE[i]. If RFBM[i] = 0, XSAVEOPT\n       writes XSTATE_BV[i] with the value that it read from memory (it does\n       not modify the bit). XSAVEOPT does not write to any part of the XSAVE\n       header other than the XSTATE_BV field.\n     * XSAVEOPT always uses the standard format of the extended region of the\n       XSAVE area (see Section 13.4.3, \u201cExtended Region of an XSAVE Area\u201d of\n       Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n       1).\n\n     1. There is an exception made for MXCSR and MXCSR_MASK, which belong to\n     state component 1 \u2014 SSE. XSAVEOPT always saves these to memory if\n     RFBM[1] = 1 or RFBM[2] = 1, regardless of the value of XINUSE.\n\n   Use of a destination operand not aligned to 64-byte boundary (in either\n   64-bit or 32-bit modes) will result in a general-protection (#GP)\n   exception. In 64-bit mode, the upper 32 bits of RDX and RAX are ignored.\n\n   See Section 13.6, \u201cProcessor Tracking of XSAVE-Managed State,\u201d of Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1 for\n   discussion of the bitmap XMODIFIED and of the quantity XRSTOR_INFO.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vscatterpf0dps:vscatterpf0qps:vscatterpf0dpd:vscatterpf0qpd", "      VSCATTERPF0DPS/VSCATTERPF0QPS/VSCATTERPF0DPD/VSCATTERPF0QPD \u2014 Sparse\n PrefetchPacked SP/DP Data Values with Signed Dword, Signed Qword Indices Using\n                          T0 Hint With Intentto Write\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Using signed dword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W0 C6                           byte memory locations     \n   /5 /vsib VSCATTERPF0DPS A     V/V       AVX512PF containing                \n   vm32z {k1}                                       single-precision data     \n                                                    using writemask k1 and T0 \n                                                    hint with intent to       \n                                                    write.                    \n                                                    Using signed qword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W0 C7                           byte memory locations     \n   /5 /vsib VSCATTERPF0QPS A     V/V       AVX512PF containing                \n   vm64z {k1}                                       single-precision data     \n                                                    using writemask k1 and T0 \n                                                    hint with intent to       \n                                                    write.                    \n                                                    Using signed dword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W1 C6                           byte memory locations     \n   /5 /vsib VSCATTERPF0DPD A     V/V       AVX512PF containing double         \n   vm32y {k1}                                       precision data using      \n                                                    writemask k1 and T0 hint  \n                                                    with intent to write.     \n                                                    Using signed qword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W1 C7                           byte memory locations     \n   /5 /vsib VSCATTERPF0QPD A     V/V       AVX512PF containing double         \n   vm64z {k1}                                       precision data using      \n                                                    writemask k1 and T0 hint  \n                                                    with intent to write.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1                   Operand 2 Operand 3 Operand 4 \n   A     Tuple1     BaseReg (R): VSIB:base,     N/A       N/A       N/A       \n         Scalar     VectorReg(R): VSIB:index    \n\n  Description \u00b6\n\n   The instruction conditionally prefetches up to sixteen 32-bit or eight\n   64-bit integer byte data elements. The elements are specified via the VSIB\n   (i.e., the index register is an zmm, holding packed indices). Elements\n   will only be prefetched if their corresponding mask bit is one.\n\n   cache lines will be brought into exclusive state (RFO) specified by a\n   locality hint (T0):\n\n     * T0 (temporal data)\u2014prefetch data into the first level cache.\n\n   [PS data] For dword indices, the instruction will prefetch sixteen memory\n   locations. For qword indices, the instruction will prefetch eight values.\n\n   [PD data] For dword and qword indices, the instruction will prefetch eight\n   memory locations.\n\n   Note that:\n\n   (1) The prefetches may happen in any order (or not at all). The\n   instruction is a hint.\n\n   (2) The mask is left unchanged.\n\n   (3) Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n\n   (4) No FP nor memory faults may be produced by this instruction.\n\n   (5) Prefetches do not handle cache line splits\n\n   (6) A #UD is signaled if the memory operand is encoded without the SIB\n   byte.\n"],
	["erdinfo", "          ERDINFO \u2014 Read Type and Status Information About an EPC Page\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n   EAX = 10H                                     This leaf function returns   \n   ENCLS[ERDINFO]     IR    V/V          EAX[6]  type and status information  \n                                                 about an EPC page.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                       RBX                 RCX                    \n                      Return error Address of a RDINFO Address of the         \n   IR    ERDINFO (In) code (Out)   structure (In)      destination EPC page   \n                                                       (In)                   \n\n  Description \u00b6\n\n   This instruction reads type and status information about an EPC page and\n   returns it in a RDINFO structure. The STATUS field of the structure\n   describes the status of the page and determines the validity of the\n   remaining fields. The FLAGS field returns the EPCM permissions of the\n   page; the page type; and the BLOCKED, PENDING, MODIFIED, and PR status of\n   the page. For enclave pages, the ENCLAVECONTEXT field of the structure\n   returns the value of SECS.ENCLAVECONTEXT. For non-enclave pages (e.g., VA)\n   ENCLAVECONTEXT returns 0.\n\n   For invalid or non-EPC pages, the instruction returns an information code\n   indicating the page's status, in addition to populating the STATUS field.\n\n   ERDINFO returns an error code if the destination EPC page is being\n   modified by a concurrent SGX instruction.\n\n   RBX contains the effective address of a RDINFO structure while RCX\n   contains the effective address of an EPC page. The table below provides\n   additional information on the memory parameter of ERDINFO leaf function.\n\nERDINFO Memory Parameter Semantics \u00b6\n\n   RDINFO                                    EPCPAGE                          \n   Read/Write access permitted by Non        Read access permitted by Enclave \n   Enclave                                   \n\n   The instruction faults if any of the following:\n\nERDINFO Faulting Conditions \u00b6\n\n   A memory operand effective address is outside   A memory operand is not    \n   the DS segment limit (32b mode).                properly aligned.          \n   DS segment is unusable (32b mode).              A page fault occurs in     \n                                                   accessing memory operands. \n   A memory address is in a non-canonical form     \n   (64b mode).                                     \n\n   The error codes are:\n\n   Error Code            Value Description                                    \n   No Error              0     ERDINFO successful.                            \n   SGX_EPC_PAGE_CONFLICT       Failure due to concurrent operation of another \n                               SGX instruction.                               \n   SGX_PG_INVLD                Target page is not a valid EPC page.           \n   SGX_PG_NONEPC               Page is not an EPC page.                       \n\n   Table 38-39. ERDINFO Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                           Base Concurrency Restrictions\n   Leaf    Parameter       Access On Conflict   SGX_CONFLICT VM Exit          \n                                                Qualification                 \n   ERDINFO Target [DS:RCX] Shared SGX_EPC_PAGE_ \n                                  CONFLICT      \n\n   Table 38-40. Base Concurrency Restrictions of ERDINFO\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT, EACCEPTCOPY, vs. vs. EADD,                 \n                     EADD, EEXTEND, EINIT vs.      EEXTEND, EINIT            \n                     ETRACK, ETRACKC Access vs.    vs. EADD,      vs. ETRACK,\n                     ETRACK, ETRACKC Access On     EEXTEND, EINIT ETRACKC\n   Leaf    Parameter Conflict Access vs. ETRACK,   vs. ETRACK,  \n                     ETRACKC Access On Conflict    ETRACKC      \n                     EMODPE, EMODPR, EMODT      \n                     Access On Conflict Access  \n                     On Conflict Access Access  \n                     On Conflict Access On      \n                     Conflict                   \n   ERDINFO Target    Concurrent                    Concurrent     Concurrent \n           [DS:RCX]  \n\n   Table 38-41. Additional Concurrency Restrictions of ERDINFO\n\n  Flags Affected \u00b6\n\n   ZF is set if ERDINFO fails due to concurrent operation with another SGX\n   instruction; otherwise cleared.\n\n   CF is set if page is not a valid EPC page or not an EPC page; otherwise\n   cleared.\n\n   PF, AF, OF, and SF are cleared.\n"],
	["vcompresspd", " VCOMPRESSPD \u2014 Store Sparse Packed Double Precision Floating-Point Values Into\n                                  DenseMemory\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Compress packed double   \n   EVEX.128.66.0F38.W1 8A                   AVX512VL precision floating-point \n   /r VCOMPRESSPD xmm1/m128 A     V/V       AVX512F  values from xmm2 to      \n   {k1}{z}, xmm2                                     xmm1/m128 using          \n                                                     writemask k1.            \n                                                     Compress packed double   \n   EVEX.256.66.0F38.W1 8A                   AVX512VL precision floating-point \n   /r VCOMPRESSPD ymm1/m256 A     V/V       AVX512F  values from ymm2 to      \n   {k1}{z}, ymm2                                     ymm1/m256 using          \n                                                     writemask k1.            \n                                                     Compress packed double   \n   EVEX.512.66.0F38.W1 8A                            precision floating-point \n   /r VCOMPRESSPD zmm1/m512 A     V/V       AVX512F  values from zmm2 using   \n   {k1}{z}, zmm2                                     control mask k1 to       \n                                                     zmm1/m512.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   Compress (store) up to 8 double precision floating-point values from the\n   source operand (the second operand) as a contiguous vector to the\n   destination operand (the first operand) The source operand is a\n   ZMM/YMM/XMM register, the destination operand can be a ZMM/YMM/XMM\n   register or a 512/256/128-bit memory location.\n\n   The opmask register k1 selects the active elements (partial vector or\n   possibly non-contiguous if less than 8 active elements) from the source\n   operand to compress into a contiguous vector. The contiguous vector is\n   written to the destination starting from the low element of the\n   destination operand.\n\n   Memory destination version: Only the contiguous vector is written to the\n   destination memory location. EVEX.z must be zero.\n\n   Register destination version: If the vector length of the contiguous\n   vector is less than that of the input vector in the source operand, the\n   upper bits of the destination register are unmodified if EVEX.z is not\n   set, otherwise the upper bits are zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["vcvtpd2qq", "  VCVTPD2QQ \u2014 Convert Packed Double Precision Floating-Point Values to Packed\n                                QuadwordIntegers\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Convert two packed double \n                                                    precision floating-point  \n   EVEX.128.66.0F.W1 7B /r                 AVX512VL values from               \n   VCVTPD2QQ xmm1 {k1}{z}, A     V/V       AVX512DQ xmm2/m128/m64bcst to two  \n   xmm2/m128/m64bcst                                packed quadword integers  \n                                                    in xmm1 with writemask    \n                                                    k1.                       \n                                                    Convert four packed       \n                                                    double precision          \n   EVEX.256.66.0F.W1 7B /r                 AVX512VL floating-point values     \n   VCVTPD2QQ ymm1 {k1}{z}, A     V/V       AVX512DQ from ymm2/m256/m64bcst to \n   ymm2/m256/m64bcst                                four packed quadword      \n                                                    integers in ymm1 with     \n                                                    writemask k1.             \n                                                    Convert eight packed      \n                                                    double precision          \n   EVEX.512.66.0F.W1 7B /r                          floating-point values     \n   VCVTPD2QQ zmm1 {k1}{z}, A     V/V       AVX512DQ from zmm2/m512/m64bcst to \n   zmm2/m512/m64bcst{er}                            eight packed quadword     \n                                                    integers in zmm1 with     \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed double precision floating-point values in the source\n   operand (second operand) to packed quadword integers in the destination\n   operand (first operand).\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register or a\n   512/256/128-bit memory location. The destination operation is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (2^w-1, where w\n   represents the number of bits in the destination format) is returned.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["cvtps2pi", "CVTPS2PI \u2014 Convert Packed Single Precision Floating-Point Values to Packed Dword\n                                    Integers\n\n   Opcode/Instruction   Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                Convert two packed single     \n   NP 0F 2D /r CVTPS2PI                         precision floating-point      \n   mm, xmm/m64          RM    Valid  Valid      values from xmm/m64 to two    \n                                                packed signed doubleword      \n                                                integers in mm.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two packed single precision floating-point values in the source\n   operand (second operand) to two packed signed doubleword integers in the\n   destination operand (first operand).\n\n   The source operand can be an XMM register or a 128-bit memory location.\n   The destination operand is an MMX technology register. When the source\n   operand is an XMM register, the two single precision floating-point values\n   are contained in the low quadword of the register. When a conversion is\n   inexact, the value returned is rounded according to the rounding control\n   bits in the MXCSR register. If a converted result is larger than the\n   maximum signed doubleword integer, the floating-point invalid exception is\n   raised, and if this exception is masked, the indefinite integer value\n   (80000000H) is returned.\n\n   CVTPS2PI causes a transition from x87 FPU to MMX technology operation\n   (that is, the x87 FPU top-of-stack pointer is set to 0 and the x87 FPU tag\n   word is set to all 0s [valid]). If this instruction is executed while an\n   x87 FPU floating-point exception is pending, the exception is handled\n   before the CVTPS2PI instruction is executed.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["vreducesd", "    VREDUCESD \u2014 Perform a Reduction Transformation on a Scalar Float64 Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature   Description\n                                Support   Flag      \n                                                    Perform a reduction       \n                                                    transformation on a       \n                                                    scalar double precision   \n                                                    floating-point value in   \n   EVEX.LLIG.66.0F3A.W1 57                          xmm3/m64 by subtracting a \n   VREDUCESD xmm1 {k1}{z},                          number of fraction bits   \n   xmm2, xmm3/m64{sae},    A    V/V       AVX512D Q specified by the imm8     \n   imm8/r                                           field. Also, upper double \n                                                    precision floating-point  \n                                                    value (bits[127:64]) from \n                                                    xmm2 are copied to        \n                                                    xmm1[127:64]. Stores the  \n                                                    result in xmm1 register.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Perform a reduction transformation of the binary encoded double precision\n   floating-point value in the low qword element of the second source operand\n   (the third operand) and store the reduced result in binary floating-point\n   format to the low qword element of the destination operand (the first\n   operand) under the writemask k1. Bits 127:64 of the destination operand\n   are copied from respective qword elements of the first source operand (the\n   second operand).\n\n   The reduction transformation subtracts the integer part and the leading M\n   fractional bits from the binary floating-point source value, where M is a\n   unsigned integer specified by imm8[7:4], see Figure 5-28. Specifically,\n   the reduction transformation can be expressed as:\n\n   dest = src \u2013 (ROUND(2^M*src))*2^-M;\n\n   where \u201cRound()\u201d treats \u201csrc\u201d, \u201c2^M\u201d, and their product as binary\n   floating-point numbers with normalized significand and biased exponents.\n\n   The magnitude of the reduced result can be expressed by considering src=\n   2^p*man2,\n\n   where \u2018man2\u2019 is the normalized significand and \u2018p\u2019 is the unbiased\n   exponent\n\n   Then if RC = RNE: 0<=|Reduced Result|<=2^p-M-1\n\n   Then if RC =\u0338 RNE: 0<=|Reduced Result|<2^p-M\n\n   This instruction might end up with a precision exception set. However, in\n   case of SPE set (i.e., Suppress Precision Exception, which is imm8[3]=1),\n   no precision exception is reported.\n\n   The operation is write masked.\n\n   Handling of special case of input values are listed in Table 5-29.\n"],
	["outs:outsb:outsw:outsd", "                 OUTS/OUTSB/OUTSW/OUTSD \u2014 Output String to Port\n\n   Opcode^1\n\n      Instruction  Op/En 64-Bit Mode Compat/Leg Mode Description              \n                                                     Output byte from memory  \n   6E OUTS DX, m8  ZO    Valid       Valid           location specified in    \n                                                     DS:(E)SI or RSI to I/O   \n                                                     port specified in DX^2.  \n                                                     Output word from memory  \n   6F OUTS DX, m16 ZO    Valid       Valid           location specified in    \n                                                     DS:(E)SI or RSI to I/O   \n                                                     port specified in DX^2.  \n                                                     Output doubleword from   \n                                                     memory location          \n   6F OUTS DX, m32 ZO    Valid       Valid           specified in DS:(E)SI or \n                                                     RSI to I/O port          \n                                                     specified in DX^2.       \n                                                     Output byte from memory  \n   6E OUTSB        ZO    Valid       Valid           location specified in    \n                                                     DS:(E)SI or RSI to I/O   \n                                                     port specified in DX^2.  \n                                                     Output word from memory  \n   6F OUTSW        ZO    Valid       Valid           location specified in    \n                                                     DS:(E)SI or RSI to I/O   \n                                                     port specified in DX^2.  \n                                                     Output doubleword from   \n                                                     memory location          \n   6F OUTSD        ZO    Valid       Valid           specified in DS:(E)SI or \n                                                     RSI to I/O port          \n                                                     specified in DX^2.       \n\n     1. See the IA-32 Architecture Compatibility section below.\n\n     2. In 64-bit mode, only 64-bit (RSI) and 32-bit (ESI) address sizes are\n     supported. In non-64-bit mode, only 32-bit (ESI) and 16-bit (SI) address\n     sizes are supported.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Copies data from the source operand (second operand) to the I/O port\n   specified with the destination operand (first operand). The source operand\n   is a memory location, the address of which is read from either the DS:SI,\n   DS:ESI or the RSI registers (depending on the address-size attribute of\n   the instruction, 16, 32 or 64, respectively). (The DS segment may be\n   overridden with a segment override prefix.) The destination operand is an\n   I/O port address (from 0 to 65,535) that is read from the DX register. The\n   size of the I/O port being accessed (that is, the size of the source and\n   destination operands) is determined by the opcode for an 8-bit I/O port or\n   by the operand-size attribute of the instruction for a 16- or 32-bit I/O\n   port.\n\n   At the assembly-code level, two forms of this instruction are allowed: the\n   \u201cexplicit-operands\u201d form and the \u201cno-operands\u201d form. The explicit-operands\n   form (specified with the OUTS mnemonic) allows the source and destination\n   operands to be specified explicitly. Here, the source operand should be a\n   symbol that indicates the size of the I/O port and the source address, and\n   the destination operand must be DX. This explicit-operands form is\n   provided to allow documentation; however, note that the documentation\n   provided by this form can be misleading. That is, the source operand\n   symbol must specify the correct type (size) of the operand (byte, word, or\n   doubleword), but it does not have to specify the correct location. The\n   location is always specified by the DS:(E)SI or RSI registers, which must\n   be loaded correctly before the OUTS instruction is executed.\n\n   The no-operands form provides \u201cshort forms\u201d of the byte, word, and\n   doubleword versions of the OUTS instructions. Here also DS:(E)SI is\n   assumed to be the source operand and DX is assumed to be the destination\n   operand. The size of the I/O port is specified with the choice of\n   mnemonic: OUTSB (byte), OUTSW (word), or OUTSD (doubleword).\n\n   After the byte, word, or doubleword is transferred from the memory\n   location to the I/O port, the SI/ESI/RSI register is incremented or\n   decremented automatically according to the setting of the DF flag in the\n   EFLAGS register. (If the DF flag is 0, the (E)SI register is incremented;\n   if the DF flag is 1, the SI/ESI/RSI register is decremented.) The\n   SI/ESI/RSI register is incremented or decremented by 1 for byte\n   operations, by 2 for word operations, and by 4 for doubleword operations.\n\n   The OUTS, OUTSB, OUTSW, and OUTSD instructions can be preceded by the REP\n   prefix for block input of ECX bytes, words, or doublewords. See\n   \u201cREP/REPE/REPZ /REPNE/REPNZ\u2014Repeat String Operation Prefix\u201d in this\n   chapter for a\n\n   description of the REP prefix. This instruction is only useful for\n   accessing I/O ports located in the processor\u2019s I/O address space. See\n   Chapter 19, \u201cInput/Output,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, for more information on accessing\n   I/O ports in the I/O address space.\n\n   In 64-bit mode, the default operand size is 32 bits; operand size is not\n   promoted by the use of REX.W. In 64-bit mode, the default address size is\n   64 bits, and 64-bit address is specified using RSI by default. 32-bit\n   address using ESI is support using the prefix 67H, but 16-bit address is\n   not supported in 64-bit mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   After executing an OUTS, OUTSB, OUTSW, or OUTSD instruction, the Pentium\n   processor ensures that the EWBE# pin has been sampled active before it\n   begins to execute the next instruction. (Note that the instruction can be\n   prefetched if EWBE# is not active, but it will not be executed until the\n   EWBE# pin is sampled active.) Only the Pentium processor family has the\n   EWBE# pin.\n\n   For the Pentium 4, Intel^\u00ae Xeon^\u00ae, and P6 processor family, upon execution\n   of an OUTS, OUTSB, OUTSW, or OUTSD instruction, the processor will not\n   execute the next instruction until the data phase of the transaction is\n   complete.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pshufd", "                      PSHUFD \u2014 Shuffle Packed Doublewords\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Shuffle the doublewords   \n   66 0F 70 /r ib PSHUFD   A     V/V       SSE2     in xmm2/m128 based on the \n   xmm1, xmm2/m128, imm8                            encoding in imm8 and      \n                                                    store the result in xmm1. \n   VEX.128.66.0F.WIG 70 /r                          Shuffle the doublewords   \n   ib VPSHUFD xmm1,        A     V/V       AVX      in xmm2/m128 based on the \n   xmm2/m128, imm8                                  encoding in imm8 and      \n                                                    store the result in xmm1. \n   VEX.256.66.0F.WIG 70 /r                          Shuffle the doublewords   \n   ib VPSHUFD ymm1,        A     V/V       AVX2     in ymm2/m256 based on the \n   ymm2/m256, imm8                                  encoding in imm8 and      \n                                                    store the result in ymm1. \n                                                    Shuffle the doublewords   \n   EVEX.128.66.0F.W0 70 /r                          in xmm2/m128/m32bcst      \n   ib VPSHUFD xmm1         B     V/V       AVX512VL based on the encoding in  \n   {k1}{z},                                AVX512F  imm8 and store the result \n   xmm2/m128/m32bcst, imm8                          in xmm1 using writemask   \n                                                    k1.                       \n                                                    Shuffle the doublewords   \n   EVEX.256.66.0F.W0 70 /r                          in ymm2/m256/m32bcst      \n   ib VPSHUFD ymm1         B     V/V       AVX512VL based on the encoding in  \n   {k1}{z},                                AVX512F  imm8 and store the result \n   ymm2/m256/m32bcst, imm8                          in ymm1 using writemask   \n                                                    k1.                       \n                                                    Shuffle the doublewords   \n   EVEX.512.66.0F.W0 70 /r                          in zmm2/m512/m32bcst      \n   ib VPSHUFD zmm1         B     V/V       AVX512F  based on the encoding in  \n   {k1}{z},                                         imm8 and store the result \n   zmm2/m512/m32bcst, imm8                          in zmm1 using writemask   \n                                                    k1.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Copies doublewords from source operand (second operand) and inserts them\n   in the destination operand (first operand) at the locations selected with\n   the order operand (third operand). Figure 4-16 shows the operation of the\n   256-bit VPSHUFD instruction and the encoding of the order operand. Each\n   2-bit field in the order operand selects the contents of one doubleword\n   location within a 128-bit lane and copy to the target element in the\n   destination operand. For example, bits 0 and 1 of the order operand\n   targets the first doubleword element in the low and high 128-bit lane of\n   the destination operand for 256-bit VPSHUFD. The encoded value of bits 1:0\n   of the order operand (see the field encoding in Figure 4-16) determines\n   which doubleword element (from the respective 128-bit lane) of the source\n   operand will be copied to doubleword 0 of the destination operand.\n\n   For 128-bit operation, only the low 128-bit lane are operative. The source\n   operand can be an XMM register or a 128-bit memory location. The\n   destination operand is an XMM register. The order operand is an 8-bit\n   immediate. Note that this instruction permits a doubleword in the source\n   operand to be copied to more than one doubleword location in the\n   destination operand.\n\n   SRC X7 X6 X5 X4 X3 X2 X1 X0 DEST Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 00B - X4 Encoding\n   00B - X0 Encoding 01B - X5 of Fields in ORDER 01B - X1 of Fields in 10B -\n   X6 ORDER\n\n   10B - X2 ORDER 11B - X7 7 6 5 4 3 2 1 0 Operand 11B - X3 Operand\n\n   Figure 4-16. 256-bit VPSHUFD Instruction Operation\n\n   The source operand can be an XMM register or a 128-bit memory location.\n   The destination operand is an XMM register. The order operand is an 8-bit\n   immediate. Note that this instruction permits a doubleword in the source\n   operand to be copied to more than one doubleword location in the\n   destination operand.\n\n   In 64-bit mode and not encoded in VEX/EVEX, using REX.R permits this\n   instruction to access XMM8-XMM15.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The source operand can be an XMM register or a\n   128-bit memory location. The destination operand is an XMM register. Bits\n   (MAXVL-1:128) of the corresponding ZMM register are zeroed.\n\n   VEX.256 encoded version: The source operand can be an YMM register or a\n   256-bit memory location. The destination operand is an YMM register. Bits\n   (MAXVL-1:256) of the corresponding ZMM register are zeroed. Bits\n   (255-1:128) of the destination stores the shuffled results of the upper 16\n   bytes of the source operand using the immediate byte as the order operand.\n\n   EVEX encoded version: The source operand can be an ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 32-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register updated according to the writemask.\n\n   Each 128-bit lane of the destination stores the shuffled results of the\n   respective lane of the source operand using the immediate byte as the\n   order operand.\n\n   Note: EVEX.vvvv and VEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fstsw:fnstsw", "                    FSTSW/FNSTSW \u2014 Store x87 FPU Status Word\n\n   Opcode   Instruction     64-Bit Compat/Leg Description                     \n                            Mode   Mode       \n                                              Store FPU status word at m2byte \n   9B DD /7 FSTSW m2byte    Valid  Valid      after checking for pending      \n                                              unmasked floating-point         \n                                              exceptions.                     \n                                              Store FPU status word in AX     \n   9B DF E0 FSTSW AX        Valid  Valid      register after checking for     \n                                              pending unmasked floating-point \n                                              exceptions.                     \n                                              Store FPU status word at m2byte \n   DD /7    FNSTSW^1 m2byte Valid  Valid      without checking for pending    \n                                              unmasked floating-point         \n                                              exceptions.                     \n                                              Store FPU status word in AX     \n   DF E0    FNSTSW^1 AX     Valid  Valid      register without checking for   \n                                              pending unmasked floating-point \n                                              exceptions.                     \n\n     1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Stores the current value of the x87 FPU status word in the destination\n   location. The destination operand can be either a two-byte memory location\n   or the AX register. The FSTSW instruction checks for and handles pending\n   unmasked floating-point exceptions before storing the status word; the\n   FNSTSW instruction does not.\n\n   The FNSTSW AX form of the instruction is used primarily in conditional\n   branching (for instance, after an FPU comparison instruction or an FPREM,\n   FPREM1, or FXAM instruction), where the direction of the branch depends on\n   the state of the FPU condition code flags. (See the section titled\n   \u201cBranching and Conditional Moves on FPU Condition Codes\u201d in Chapter 8 of\n   the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n   1.) This instruction can also be used to invoke exception handlers (by\n   examining the exception flags) in environments that do not use interrupts.\n   When the FNSTSW AX instruction is executed, the AX register is updated\n   before the processor executes any further instructions. The status stored\n   in the AX register is thus guaranteed to be from the completion of the\n   prior FPU instruction.\n\n   The assembler issues two instructions for the FSTSW instruction (an FWAIT\n   instruction followed by an FNSTSW instruction), and the processor executes\n   each of these instructions separately. If an exception is generated for\n   either of these instructions, the save EIP points to the instruction that\n   caused the exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   When operating a Pentium or Intel486 processor in MS-DOS compatibility\n   mode, it is possible (under unusual circumstances) for an FNSTSW\n   instruction to be interrupted prior to being executed to handle a pending\n   FPU exception. See the section titled \u201cNo-Wait FPU Instructions Can Get\n   FPU Interrupt in Window\u201d in Appendix D of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a description of\n   these circumstances. An FNSTSW instruction cannot be interrupted in this\n   way on later Intel processors, except for the Intel Quark^TM X1000\n   processor.\n\nFPU Flags Affected \u00b6\n\n   The C0, C1, C2, and C3 are undefined.\n"],
	["edecvirtchild", "                 EDECVIRTCHILD \u2014 Decrement VIRTCHILDCNT in SECS\n\n                              64/32 bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                              Support   Flag    \n   EAX = 00H            IR    V/V       EAX[5]  This leaf function decrements \n   ENCLV[EDECVIRTCHILD]                         the SECS VIRTCHILDCNT field.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                             RBX                   RCX            \n   IR    EDECVIRTCHILD (In) Return error Address of an enclave Address of an  \n                            code (Out)   page (In)             SECS page (In) \n\n  Description \u00b6\n\n   This instruction decrements the SECS VIRTCHILDCNT field. This instruction\n   can only be executed when current privilege level is 0.\n\n   The content of RCX is an effective address of an EPC page. The DS segment\n   is used to create linear address. Segment override is not supported.\n\nEDECVIRTCHILD Memory Parameter Semantics \u00b6\n\n   EPCPAGE                                   SECS                             \n   Read/Write access permitted by Non        Read access permitted by Enclave \n   Enclave                                   \n\n   The instruction faults if any of the following:\n\nEDECVIRTCHILD Faulting Conditions \u00b6\n\n   A memory operand effective address is     A page fault occurs in accessing \n   outside the DS segment limit (32b mode).  memory operands.                 \n   DS segment is unusable (32b mode).        RBX does not refer to an enclave \n                                             page (REG, TCS, TRIM, SECS).     \n   A memory address is in a non-canonical    RCX does not refer to an SECS    \n   form (64b mode).                          page.                            \n                                             RBX does not refer to an enclave \n   A memory operand is not properly aligned. page associated with SECS        \n                                             referenced in RCX.               \n\n  Concurrency Restrictions \u00b6\n\n                               Base Concurrency Restrictions\n   Leaf          Parameter     Access     On Conflict   SGX_CONFLICT VM Exit  \n                                                        Qualification         \n                 Target        Shared     SGX_EPC_PAGE_ \n   EDECVIRTCHILD [DS:RBX]                 CONFLICT      \n                 SECS [DS:RCX] Concurrent \n\n   Table 38-76. Base Concurrency Restrictions of EDECVIRTCHILD\n\n                        Additional Concurrency Restrictions\n                        vs. EACCEPT,                                       \n                        EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\nLeaf          Parameter EMODPE, EMODPR,     EINIT\n                        EMODT      \n                        Access     On       Access     On       Access     On       \n                                   Conflict            Conflict            Conflict \n              Target    Concurrent          Concurrent          Concurrent \nEDECVIRTCHILD [DS:RBX]  \n              SECS      Concurrent          Concurrent          Concurrent \n              [DS:RCX]  \n\n   Table 38-77. Additional Concurrency Restrictions of EDECVIRTCHILD\n\n  Flags Affected \u00b6\n\n   ZF is set if EDECVIRTCHILD fails due to concurrent operation with another\n   SGX instruction, or if there is a VIRTCHILDCNT underflow. Otherwise\n   cleared.\n"],
	["insertps", "         INSERTPS \u2014 Insert Scalar Single Precision Floating-Point Value\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature Description\n                               Support   Flag    \n                                                 Insert a single precision    \n                                                 floating-point value         \n                                                 selected by imm8 from        \n   66 0F 3A 21 /r ib                             xmm2/m32 into xmm1 at the    \n   INSERTPS xmm1,         A    V/V       SSE4_1  specified destination        \n   xmm2/m32, imm8                                element specified by imm8    \n                                                 and zero out destination     \n                                                 elements in xmm1 as          \n                                                 indicated in imm8.           \n                                                 Insert a single precision    \n                                                 floating-point value         \n                                                 selected by imm8 from        \n                                                 xmm3/m32 and merge with      \n   VEX.128.66.0F3A.WIG 21                        values in xmm2 at the        \n   /r ib VINSERTPS xmm1,  B    V/V       AVX     specified destination        \n   xmm2, xmm3/m32, imm8                          element specified by imm8    \n                                                 and write out the result and \n                                                 zero out destination         \n                                                 elements in xmm1 as          \n                                                 indicated in imm8.           \n                                                 Insert a single precision    \n                                                 floating-point value         \n                                                 selected by imm8 from        \n                                                 xmm3/m32 and merge with      \n   EVEX.128.66.0F3A.W0 21                        values in xmm2 at the        \n   /r ib VINSERTPS xmm1,  C    V/V       AVX512F specified destination        \n   xmm2, xmm3/m32, imm8                          element specified by imm8    \n                                                 and write out the result and \n                                                 zero out destination         \n                                                 elements in xmm1 as          \n                                                 indicated in imm8.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   (register source form)\n\n   Copy a single precision scalar floating-point element into a 128-bit\n   vector register. The immediate operand has three fields, where the ZMask\n   bits specify which elements of the destination will be set to zero, the\n   Count_D bits specify which element of the destination will be overwritten\n   with the scalar value, and for vector register sources the Count_S bits\n   specify which element of the source will be copied. When the scalar source\n   is a memory operand the Count_S bits are ignored.\n\n   (memory source form)\n\n   Load a floating-point element from a 32-bit memory location and\n   destination operand it into the first source at the location indicated by\n   the Count_D bits of the immediate operand. Store in the destination and\n   zero out destination elements based on the ZMask bits of the immediate\n   operand.\n\n   128-bit Legacy SSE version: The first source register is an XMM register.\n   The second source operand is either an XMM register or a 32-bit memory\n   location. The destination is not distinct from the first source XMM\n   register and the upper bits (MAXVL-1:128) of the corresponding register\n   destination are unmodified.\n\n   VEX.128 and EVEX encoded version: The destination and first source\n   register is an XMM register. The second source operand is either an XMM\n   register or a 32-bit memory location. The upper bits (MAXVL-1:128) of the\n   corresponding register destination are zeroed.\n\n   If VINSERTPS is encoded with VEX.L= 1, an attempt to execute the\n   instruction encoded with VEX.L= 1 will cause an #UD exception.\n"],
	["vgetmantsd", "    VGETMANTSD \u2014 Extract Float64 of Normalized Mantissa From Float64 Scalar\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Extract the normalized     \n                                                   mantissa of the low        \n                                                   float64 element in         \n   EVEX.LLIG.66.0F3A.W1 27                         xmm3/m64 using imm8 for    \n   /r ib VGETMANTSD xmm1   A     V/V       AVX512F sign control and mantissa  \n   {k1}{z}, xmm2,                                  interval normalization.    \n   xmm3/m64{sae}, imm8                             Store the mantissa to xmm1 \n                                                   under the writemask k1 and \n                                                   merge with the other       \n                                                   elements of xmm2.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Convert the double precision floating values in the low quadword element\n   of the second source operand (the third operand) to double precision\n   floating-point value with the mantissa normalization and sign control\n   specified by the imm8 byte, see Figure 5-15. The converted result is\n   written to the low quadword element of the destination operand (the first\n   operand) using writemask k1. Bits (127:64) of the XMM register destination\n   are copied from corresponding bits in the first source operand. The\n   normalized mantissa is specified by interv (imm8[1:0]) and the sign\n   control (sc) is specified by bits 3:2 of the immediate byte.\n\n   The conversion operation is:\n\n   GetMant(x) = \u00b12^k|x.significand|\n\n   where:\n\n   1 <= |x.significand| < 2\n\n   Unbiased exponent k can be either 0 or -1, depending on the interval range\n   defined by interv, the range of the significand and whether the exponent\n   of the source is even or odd. The sign of the final result is determined\n   by sc and the source sign. The encoded value of imm8[1:0] and sign control\n   are shown in Figure 5-15.\n\n   The converted double precision floating-point result is encoded according\n   to the sign control, the unbiased exponent k (adding bias) and a mantissa\n   normalized to the range specified by interv.\n\n   The GetMant() function follows Table 5-18 when dealing with floating-point\n   special numbers.\n\n   If writemasking is used, the low quadword element of the destination\n   operand is conditionally updated depending on the value of writemask\n   register k1. If writemasking is not used, the low quadword element of the\n   destination operand is unconditionally updated.\n"],
	["sbb", "                     SBB \u2014 Integer Subtraction With Borrow\n\n   Opcode     Instruction    Op/En 64-Bit Compat/Leg Description              \n                                   Mode   Mode       \n   1C ib      SBB AL, imm8   I     Valid  Valid      Subtract with borrow     \n                                                     imm8 from AL.            \n   1D iw      SBB AX, imm16  I     Valid  Valid      Subtract with borrow     \n                                                     imm16 from AX.           \n   1D id      SBB EAX, imm32 I     Valid  Valid      Subtract with borrow     \n                                                     imm32 from EAX.          \n   REX.W + 1D                                        Subtract with borrow     \n   id         SBB RAX, imm32 I     Valid  N.E.       sign-extended imm.32 to  \n                                                     64-bits from RAX.        \n   80 /3 ib   SBB r/m8, imm8 MI    Valid  Valid      Subtract with borrow     \n                                                     imm8 from r/m8.          \n   REX + 80   SBB r/m8^1,    MI    Valid  N.E.       Subtract with borrow     \n   /3 ib      imm8                                   imm8 from r/m8.          \n   81 /3 iw   SBB r/m16,     MI    Valid  Valid      Subtract with borrow     \n              imm16                                  imm16 from r/m16.        \n   81 /3 id   SBB r/m32,     MI    Valid  Valid      Subtract with borrow     \n              imm32                                  imm32 from r/m32.        \n   REX.W + 81 SBB r/m64,                             Subtract with borrow     \n   /3 id      imm32          MI    Valid  N.E.       sign-extended imm32 to   \n                                                     64-bits from r/m64.      \n              SBB r/m16,                             Subtract with borrow     \n   83 /3 ib   imm8           MI    Valid  Valid      sign-extended imm8 from  \n                                                     r/m16.                   \n              SBB r/m32,                             Subtract with borrow     \n   83 /3 ib   imm8           MI    Valid  Valid      sign-extended imm8 from  \n                                                     r/m32.                   \n   REX.W + 83 SBB r/m64,                             Subtract with borrow     \n   /3 ib      imm8           MI    Valid  N.E.       sign-extended imm8 from  \n                                                     r/m64.                   \n   18 /r      SBB r/m8, r8   MR    Valid  Valid      Subtract with borrow r8  \n                                                     from r/m8.               \n   REX + 18   SBB r/m8^1, r8 MR    Valid  N.E.       Subtract with borrow r8  \n   /r                                                from r/m8.               \n   19 /r      SBB r/m16, r16 MR    Valid  Valid      Subtract with borrow r16 \n                                                     from r/m16.              \n   19 /r      SBB r/m32, r32 MR    Valid  Valid      Subtract with borrow r32 \n                                                     from r/m32.              \n   REX.W + 19 SBB r/m64, r64 MR    Valid  N.E.       Subtract with borrow r64 \n   /r                                                from r/m64.              \n   1A /r      SBB r8, r/m8   RM    Valid  Valid      Subtract with borrow     \n                                                     r/m8 from r8.            \n   REX + 1A   SBB r8^1,      RM    Valid  N.E.       Subtract with borrow     \n   /r         r/m8^1                                 r/m8 from r8.            \n   1B /r      SBB r16, r/m16 RM    Valid  Valid      Subtract with borrow     \n                                                     r/m16 from r16.          \n   1B /r      SBB r32, r/m32 RM    Valid  Valid      Subtract with borrow     \n                                                     r/m32 from r32.          \n   REX.W + 1B SBB r64, r/m64 RM    Valid  N.E.       Subtract with borrow     \n   /r                                                r/m64 from r64.          \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   I     AL/AX/EAX/RAX imm8/16/32    N/A       N/A       \n   MI    ModRM:r/m (w) imm8/16/32    N/A       N/A       \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Adds the source operand (second operand) and the carry (CF) flag, and\n   subtracts the result from the destination operand (first operand). The\n   result of the subtraction is stored in the destination operand. The\n   destination operand can be a register or a memory location; the source\n   operand can be an immediate, a register, or a memory location.\n\n   (However, two memory operands cannot be used in one instruction.) The\n   state of the CF flag represents a borrow from a previous subtraction.\n\n   When an immediate value is used as an operand, it is sign-extended to the\n   length of the destination operand format.\n\n   The SBB instruction does not distinguish between signed or unsigned\n   operands. Instead, the processor evaluates the result for both data types\n   and sets the OF and CF flags to indicate a borrow in the signed or\n   unsigned result, respectively. The SF flag indicates the sign of the\n   signed result.\n\n   The SBB instruction is usually executed as part of a multibyte or\n   multiword subtraction in which a SUB instruction is followed by a SBB\n   instruction.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The OF, SF, ZF, AF, PF, and CF flags are set according to the result.\n"],
	["mulpd", "         MULPD \u2014 Multiply Packed Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Multiply packed double     \n   66 0F 59 /r MULPD xmm1,                         precision floating-point   \n   xmm2/m128               A    V/V       SSE2     values in xmm2/m128 with   \n                                                   xmm1 and store result in   \n                                                   xmm1.                      \n                                                   Multiply packed double     \n   VEX.128.66.0F.WIG 59 /r                         precision floating-point   \n   VMULPD xmm1,xmm2,       B    V/V       AVX      values in xmm3/m128 with   \n   xmm3/m128                                       xmm2 and store result in   \n                                                   xmm1.                      \n                                                   Multiply packed double     \n   VEX.256.66.0F.WIG 59 /r                         precision floating-point   \n   VMULPD ymm1, ymm2,      B    V/V       AVX      values in ymm3/m256 with   \n   ymm3/m256                                       ymm2 and store result in   \n                                                   ymm1.                      \n                                                   Multiply packed double     \n   EVEX.128.66.0F.W1 59 /r                AVX512VL precision floating-point   \n   VMULPD xmm1 {k1}{z},    C    V/V       AVX512F  values from                \n   xmm2, xmm3/m128/m64bcst                         xmm3/m128/m64bcst to xmm2  \n                                                   and store result in xmm1.  \n                                                   Multiply packed double     \n   EVEX.256.66.0F.W1 59 /r                AVX512VL precision floating-point   \n   VMULPD ymm1 {k1}{z},    C    V/V       AVX512F  values from                \n   ymm2, ymm3/m256/m64bcst                         ymm3/m256/m64bcst to ymm2  \n                                                   and store result in ymm1.  \n                                                   Multiply packed double     \n   EVEX.512.66.0F.W1 59 /r                         precision floating-point   \n   VMULPD zmm1 {k1}{z},    C    V/V       AVX512F  values in                  \n   zmm2,                                           zmm3/m512/m64bcst with     \n   zmm3/m512/m64bcst{er}                           zmm2 and store result in   \n                                                   zmm1.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Multiply packed double precision floating-point values from the first\n   source operand with corresponding values in the second source operand, and\n   stores the packed double precision floating-point results in the\n   destination operand.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. Bits (MAXVL-1:256) of the\n   corresponding destination ZMM register are zeroed.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the destination YMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["clac", "                    CLAC \u2014 Clear AC Flag in EFLAGS Register\n\n   Opcode/Instruction Op / 64/32 bit Mode CPUID        Description            \n                      En   Support        Feature Flag \n   NP 0F 01 CA CLAC   ZO   V/V            SMAP         Clear the AC flag in   \n                                                       the EFLAGS register.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Clears the AC flag bit in EFLAGS register. This disables any alignment\n   checking of user-mode data accesses. Ifthe SMAP bit is set in the CR4\n   register, this disallows explicit supervisor-mode data accesses to\n   user-mode pages.\n\n   This instruction's operation is the same in non-64-bit modes and 64-bit\n   mode. Attempts to execute CLAC when CPL > 0 cause #UD.\n\nFlags Affected \u00b6\n\n   AC cleared. Other flags are unaffected.\n"],
	["vminsh", "                   VMINSH \u2014 Return Minimum Scalar FP16 Value\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode   \n   Flag Support 64/32 CPUID Feature  \n   Instruction En bit Mode Flag      \n   CPUID Feature Instruction En bit  \n   Mode Flag Op/ 64/32 CPUID Feature   Support             Description\n   Instruction En bit Mode Flag      \n   64/32 CPUID Feature Instruction   \n   En bit Mode Flag CPUID Feature    \n   Instruction En bit Mode Flag Op/  \n   64/32 CPUID Feature               \n                                                           Return the minimum \n                                                           low FP16 value     \n                                                           between xmm3/m16   \n                                                           and xmm2. Stores   \n   EVEX.LLIG.F3.MAP5.W0 5D /r VMINSH A V/V     AVX512-FP16 the result in xmm1 \n   xmm1{k1}{z}, xmm2, xmm3/m16 {sae}                       subject to         \n                                                           writemask k1. Bits \n                                                           127:16 of xmm2 are \n                                                           copied to          \n                                                           xmm1[127:16].      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a compare of the low packed FP16 values in the\n   first source operand and the second source operand and returns the minimum\n   value for the pair of values to the destination operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of VMINSH can be emulated using a sequence of\n   instructions, such as, a comparison followed by AND, ANDN, and OR.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcast from a 16-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n"],
	["cld", "                           CLD \u2014 Clear Direction Flag\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description    \n   FC     CLD         ZO    Valid       Valid           Clear DF flag. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Clears the DF flag in the EFLAGS register. When the DF flag is set to 0,\n   string operations increment the index registers (ESI and/or EDI).\n   Operation is the same in all modes.\n\nFlags Affected \u00b6\n\n   The DF flag is set to 0. The CF, OF, ZF, SF, AF, and PF flags are\n   unaffected.\n"],
	["vsubsh", "                      VSUBSH \u2014 Subtract Scalar FP16 Value\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode   \n   Flag Support 64/32 CPUID Feature  \n   Instruction En bit Mode Flag      \n   CPUID Feature Instruction En bit  \n   Mode Flag Op/ 64/32 CPUID Feature   Support             Description\n   Instruction En bit Mode Flag      \n   64/32 CPUID Feature Instruction   \n   En bit Mode Flag CPUID Feature    \n   Instruction En bit Mode Flag Op/  \n   64/32 CPUID Feature               \n                                                           Subtract the low   \n                                                           FP16 value in      \n                                                           xmm3/m16 from xmm2 \n                                                           and store the      \n   EVEX.LLIG.F3.MAP5.W0 5C /r VSUBSH A V/V     AVX512-FP16 result in xmm1     \n   xmm1{k1}{z}, xmm2, xmm3/m16 {er}                        subject to         \n                                                           writemask k1. Bits \n                                                           127:16 from xmm2   \n                                                           are copied to      \n                                                           xmm1[127:16].      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction subtracts the low FP16 value from the second source\n   operand from the corresponding value in the first source operand, storing\n   the FP16 result in the destination operand. Bits 127:16 of the destination\n   operand are copied from the corresponding bits of the first source\n   operand. Bits MAXVL-1:128 of the destination operand are zeroed. The low\n   FP16 element of the destination is updated according to the writemask.\n"],
	["saveprevssp", "                SAVEPREVSSP \u2014 Save Previous Shadow Stack Pointer\n\n                               64/32 bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                               Support   Flag    \n   F3 0F 01 EA (mod!=11,                         Save a restore-shadow-stack  \n   /5, RM=010)           ZO    V/V       CET_SS  token on previous shadow     \n   SAVEPREVSSP                                   stack.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Push a restore-shadow-stack token on the previous shadow stack at the next\n   8 byte aligned boundary. The previous SSP is obtained from the\n   previous-ssp token at the top of the current shadow stack.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcompressps", " VCOMPRESSPS \u2014 Store Sparse Packed Single Precision Floating-Point Values Into\n                                  Dense Memory\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Compress packed single   \n   EVEX.128.66.0F38.W0 8A                   AVX512VL precision floating-point \n   /r VCOMPRESSPS xmm1/m128 A     V/V       AVX512F  values from xmm2 to      \n   {k1}{z}, xmm2                                     xmm1/m128 using          \n                                                     writemask k1.            \n                                                     Compress packed single   \n   EVEX.256.66.0F38.W0 8A                   AVX512VL precision floating-point \n   /r VCOMPRESSPS ymm1/m256 A     V/V       AVX512F  values from ymm2 to      \n   {k1}{z}, ymm2                                     ymm1/m256 using          \n                                                     writemask k1.            \n                                                     Compress packed single   \n   EVEX.512.66.0F38.W0 8A                            precision floating-point \n   /r VCOMPRESSPS zmm1/m512 A     V/V       AVX512F  values from zmm2 using   \n   {k1}{z}, zmm2                                     control mask k1 to       \n                                                     zmm1/m512.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   Compress (stores) up to 16 single precision floating-point values from the\n   source operand (the second operand) to the destination operand (the first\n   operand). The source operand is a ZMM/YMM/XMM register, the destination\n   operand can be a ZMM/YMM/XMM register or a 512/256/128-bit memory\n   location.\n\n   The opmask register k1 selects the active elements (a partial vector or\n   possibly non-contiguous if less than 16 active elements) from the source\n   operand to compress into a contiguous vector. The contiguous vector is\n   written to the destination starting from the low element of the\n   destination operand.\n\n   Memory destination version: Only the contiguous vector is written to the\n   destination memory location. EVEX.z must be zero.\n\n   Register destination version: If the vector length of the contiguous\n   vector is less than that of the input vector in the source operand, the\n   upper bits of the destination register are unmodified if EVEX.z is not\n   set, otherwise the upper bits are zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["vpgatherdd:vpgatherqd", "  VPGATHERDD/VPGATHERQD \u2014 Gather Packed Dword Values Using Signed Dword/Qword\n                                    Indices\n\n                                  64/32     CPUID                             \n   Opcode/Instruction       Op/En -bit Mode Feature Description\n                                            Flag    \n                                                    Using dword indices       \n                                                    specified in vm32x,       \n   VEX.128.66.0F38.W0 90 /r                         gather dword values from  \n   VPGATHERDD xmm1, vm32x,  RMV   V/V       AVX2    memory conditioned on     \n   xmm2                                             mask specified by xmm2.   \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    xmm1.                     \n                                                    Using qword indices       \n                                                    specified in vm64x,       \n   VEX.128.66.0F38.W0 91 /r                         gather dword values from  \n   VPGATHERQD xmm1, vm64x,  RMV   V/V       AVX2    memory conditioned on     \n   xmm2                                             mask specified by xmm2.   \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    xmm1.                     \n                                                    Using dword indices       \n                                                    specified in vm32y,       \n   VEX.256.66.0F38.W0 90 /r                         gather dword from memory  \n   VPGATHERDD ymm1, vm32y,  RMV   V/V       AVX2    conditioned on mask       \n   ymm2                                             specified by ymm2.        \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    ymm1.                     \n                                                    Using qword indices       \n                                                    specified in vm64y,       \n   VEX.256.66.0F38.W0 91 /r                         gather dword values from  \n   VPGATHERQD xmm1, vm64y,  RMV   V/V       AVX2    memory conditioned on     \n   xmm2                                             mask specified by xmm2.   \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    xmm1.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1       Operand 2                  Operand 3       Operand 4 \n   RMV   ModRM:reg (r,w) BaseReg (R): VSIB:base,    VEX.vvvv (r, w) N/A       \n                         VectorReg(R): VSIB:index   \n\nDescription \u00b6\n\n   The instruction conditionally loads up to 4 or 8 dword values from memory\n   addresses specified by the memory operand (the second operand) and using\n   dword indices. The memory operand uses the VSIB form of the SIB byte to\n   specify a general purpose register operand as the common base, a vector\n   register for an array of indices relative to the base and a constant scale\n   factor.\n\n   The mask operand (the third operand) specifies the conditional load\n   operation from each memory address and the corresponding update of each\n   data element of the destination operand (the first operand).\n   Conditionality is specified by the most significant bit of each data\n   element of the mask register. If an element\u2019s mask bit is not set, the\n   corresponding element of the destination register is left unchanged. The\n   width of data element in the destination register and mask register are\n   identical. The entire mask register will be set to zero by this\n   instruction unless the instruction causes an exception.\n\n   Using qword indices, the instruction conditionally loads up to 2 or 4\n   qword values from the VSIB addressing memory operand, and updates the\n   lower half of the destination register. The upper 128 or 256 bits of the\n   destination register are zero\u2019ed with qword indices.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask operand are partially updated; those\n   elements that have been gathered are placed into the destination register\n   and have their mask bits set to zero. If any traps or interrupts are\n   pending from already gathered elements, they will be delivered in lieu of\n   the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data size and index size are different, part of the destination\n   register and part of the mask register do not correspond to any elements\n   being gathered. This instruction sets those parts to zero. It may do this\n   to one or both of those registers even if the instruction triggers an\n   exception, and even if the instruction triggers the exception before\n   gathering any elements.\n\n   VEX.128 version: For dword indices, the instruction will gather four dword\n   values. For qword indices, the instruction will gather two values and zero\n   the upper 64 bits of the destination.\n\n   VEX.256 version: For dword indices, the instruction will gather eight\n   dword values. For qword indices, the instruction will gather four values\n   and zero the upper 128 bits of the destination.\n\n   Note that:\n\n     * If any pair of the index, mask, or destination registers are the same,\n       this instruction results a UD fault.\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination will be completed (and non-faulting). Individual\n       elements closer to the MSB may or may not be completed. If a given\n       element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to-left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * This instruction will cause a #UD if the address size attribute is\n       16-bit.\n     * This instruction will cause a #UD if the memory operand is encoded\n       without the SIB byte.\n     * This instruction should not be used to access memory mapped I/O as the\n       ordering of the individual loads it does is implementation specific,\n       and some implementations may use loads larger than the data element\n       size or load elements an indeterminate number of times.\n     * The scaled index may require more bits to represent than the address\n       bits used by the processor (e.g., in 32-bit mode, if the scale is\n       greater than one). In this case, the most significant bits beyond the\n       number of address bits are ignored.\n"],
	["tilerelease", "                           TILERELEASE \u2014 Release Tile\n\n   Opcode/Instruction             Op/En 64/32 bit    CPUID        Description \n                                        Mode Support Feature Flag \n   VEX.128.NP.0F38.W0 49 C0                                       Initialize  \n   TILERELEASE                    A     V/N.E.       AMX-TILE     TILECFG and \n                                                                  TILEDATA.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   A     N/A   N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   This instruction returns TILECFG and TILEDATA to the INIT state.\n\n   Any attempt to execute the TILERELEASE instruction inside an Intel TSX\n   transaction will result in a transaction abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtudq2ph", " VCVTUDQ2PH \u2014 Convert Packed Unsigned Doubleword Integers to Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert four packed  \n                                                         unsigned doubleword  \n   EVEX.128.F2.MAP5.W0 7A /r                             integers from        \n   VCVTUDQ2PH xmm1{k1}{z},         A V/V     AVX512-FP16 xmm2/m128/m32bcst to \n   xmm2/m128/m32bcst                         AVX512VL    packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n                                                         Convert eight packed \n                                                         unsigned doubleword  \n   EVEX.256.F2.MAP5.W0 7A /r                             integers from        \n   VCVTUDQ2PH xmm1{k1}{z},         A V/V     AVX512-FP16 ymm2/m256/m32bcst to \n   ymm2/m256/m32bcst                         AVX512VL    packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n                                                         Convert sixteen      \n                                                         packed unsigned      \n                                                         doubleword integers  \n   EVEX.512.F2.MAP5.W0 7A /r                             from                 \n   VCVTUDQ2PH ymm1{k1}{z},         A V/V     AVX512-FP16 zmm2/m512/m32bcst to \n   zmm2/m512/m32bcst {er}                                packed FP16 values,  \n                                                         and store the result \n                                                         in ymm1 subject to   \n                                                         writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed unsigned doubleword integers in the\n   source operand to packed FP16 values in the destination operand. The\n   destination elements are updated according to the writemask.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   If the result of the convert operation is overflow and MXCSR.OM=0 then a\n   SIMD exception will be raised with OE=1, PE=1.\n"],
	["movbe", "                     MOVBE \u2014 Move Data After Swapping Bytes\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n   0F 38 F0 /r MOVBE r16,    RM    V/V       MOVBE   Reverse byte order in    \n   m16                                               m16 and move to r16.     \n   0F 38 F0 /r MOVBE r32,    RM    V/V       MOVBE   Reverse byte order in    \n   m32                                               m32 and move to r32.     \n   REX.W + 0F 38 F0 /r MOVBE RM    V/N.E.    MOVBE   Reverse byte order in    \n   r64, m64                                          m64 and move to r64.     \n   0F 38 F1 /r MOVBE m16,    MR    V/V       MOVBE   Reverse byte order in    \n   r16                                               r16 and move to m16.     \n   0F 38 F1 /r MOVBE m32,    MR    V/V       MOVBE   Reverse byte order in    \n   r32                                               r32 and move to m32.     \n   REX.W + 0F 38 F1 /r MOVBE MR    V/N.E.    MOVBE   Reverse byte order in    \n   m64, r64                                          r64 and move to m64.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs a byte swap operation on the data copied from the second operand\n   (source operand) and store the result in the first operand (destination\n   operand). The source operand can be a general-purpose register, or memory\n   location; the destination register can be a general-purpose register, or a\n   memory location; however, both operands can not be registers, and only one\n   operand can be a memory location. Both operands must be the same size,\n   which can be a word, a doubleword or quadword.\n\n   The MOVBE instruction is provided for swapping the bytes on a read from\n   memory or on a write to memory; thus providing support for converting\n   little-endian values to big-endian format and vice versa.\n\n   In 64-bit mode, the instruction's default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["gf2p8affineqb", "               GF2P8AFFINEQB \u2014 Galois Field Affine Transformation\n\n                                         64/32 bit CPUID                      \n   Opcode/Instruction              Op/En Mode      Feature  Description\n                                         Support   Flag     \n                                                            Computes affine   \n   66 0F3A CE /r /ib GF2P8AFFINEQB A     V/V       GFNI     transformation in \n   xmm1, xmm2/m128, imm8                                    the finite field  \n                                                            GF(2^8).          \n   VEX.128.66.0F3A.W1 CE /r /ib                             Computes affine   \n   VGF2P8AFFINEQB xmm1, xmm2,      B     V/V       AVX GFNI transformation in \n   xmm3/m128, imm8                                          the finite field  \n                                                            GF(2^8).          \n   VEX.256.66.0F3A.W1 CE /r /ib                             Computes affine   \n   VGF2P8AFFINEQB ymm1, ymm2,      B     V/V       AVX GFNI transformation in \n   ymm3/m256, imm8                                          the finite field  \n                                                            GF(2^8).          \n   EVEX.128.66.0F3A.W1 CE /r /ib                            Computes affine   \n   VGF2P8AFFINEQB xmm1{k1}{z},     C     V/V       AVX512VL transformation in \n   xmm2, xmm3/m128/m64bcst, imm8                   GFNI     the finite field  \n                                                            GF(2^8).          \n   EVEX.256.66.0F3A.W1 CE /r /ib                            Computes affine   \n   VGF2P8AFFINEQB ymm1{k1}{z},     C     V/V       AVX512VL transformation in \n   ymm2, ymm3/m256/m64bcst, imm8                   GFNI     the finite field  \n                                                            GF(2^8).          \n   EVEX.512.66.0F3A.W1 CE /r /ib                            Computes affine   \n   VGF2P8AFFINEQB zmm1{k1}{z},     C     V/V       AVX512F  transformation in \n   zmm2, zmm3/m512/m64bcst, imm8                   GFNI     the finite field  \n                                                            GF(2^8).          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) imm8 (r)      N/A       \n   B     N/A   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8 (r)  \n   C     Full  ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   The AFFINEB instruction computes an affine transformation in the Galois\n   Field 2^8. For this instruction, an affine transformation is defined by A\n   * x + b where \u201cA\u201d is an 8 by 8 bit matrix, and \u201cx\u201d and \u201cb\u201d are 8-bit\n   vectors. One SIMD register (operand 1) holds \u201cx\u201d as either 16, 32 or 64\n   8-bit vectors. A second SIMD (operand 2) register or memory operand\n   contains 2, 4, or 8 \u201cA\u201d values, which are operated upon by the\n   correspondingly aligned 8 \u201cx\u201d values in the first register. The \u201cb\u201d vector\n   is constant for all calculations and contained in the immediate byte.\n\n   The EVEX encoded form of this instruction does not support memory fault\n   suppression. The SSE encoded forms of the instruction require16B alignment\n   on their memory operations.\n"],
	["cvtps2dq", "   CVTPS2DQ \u2014 Convert Packed Single Precision Floating-Point Values to Packed\n                        SignedDoubleword Integer Values\n\n                             Op / 64/32 bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert four packed      \n                                                     single precision         \n   66 0F 5B /r CVTPS2DQ      A    V/V       SSE2     floating-point values    \n   xmm1, xmm2/m128                                   from xmm2/mem to four    \n                                                     packed signed doubleword \n                                                     values in xmm1.          \n                                                     Convert four packed      \n                                                     single precision         \n   VEX.128.66.0F.WIG 5B /r   A    V/V       AVX      floating-point values    \n   VCVTPS2DQ xmm1, xmm2/m128                         from xmm2/mem to four    \n                                                     packed signed doubleword \n                                                     values in xmm1.          \n                                                     Convert eight packed     \n                                                     single precision         \n   VEX.256.66.0F.WIG 5B /r   A    V/V       AVX      floating-point values    \n   VCVTPS2DQ ymm1, ymm2/m256                         from ymm2/mem to eight   \n                                                     packed signed doubleword \n                                                     values in ymm1.          \n                                                     Convert four packed      \n                                                     single precision         \n   EVEX.128.66.0F.W0 5B /r                           floating-point values    \n   VCVTPS2DQ xmm1 {k1}{z},   B    V/V       AVX512VL from xmm2/m128/m32bcst   \n   xmm2/m128/m32bcst                        AVX512F  to four packed signed    \n                                                     doubleword values in     \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Convert eight packed     \n                                                     single precision         \n   EVEX.256.66.0F.W0 5B /r                           floating-point values    \n   VCVTPS2DQ ymm1 {k1}{z},   B    V/V       AVX512VL from ymm2/m256/m32bcst   \n   ymm2/m256/m32bcst                        AVX512F  to eight packed signed   \n                                                     doubleword values in     \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Convert sixteen packed   \n                                                     single precision         \n   EVEX.512.66.0F.W0 5B /r                           floating-point values    \n   VCVTPS2DQ zmm1 {k1}{z},   B    V/V       AVX512F  from zmm2/m512/m32bcst   \n   zmm2/m512/m32bcst{er}                             to sixteen packed signed \n                                                     doubleword values in     \n                                                     zmm1 subject to          \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts four, eight or sixteen packed single precision floating-point\n   values in the source operand to four, eight or sixteen signed doubleword\n   integers in the destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (2^w-1, where w\n   represents the number of bits in the destination format) is returned.\n\n   EVEX encoded versions: The source operand is a ZMM register, a 512-bit\n   memory location or a 512-bit vector broadcasted from a 32-bit memory\n   location. The destination operand is a ZMM register conditionally updated\n   with writemask k1.\n\n   VEX.256 encoded version: The source operand is a YMM register or 256- bit\n   memory location. The destination operand is a YMM register. The upper bits\n   (MAXVL-1:256) of the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a XMM register. The upper bits\n   (MAXVL-1:128) of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 128-\n   bit memory location. The destination operand is an XMM register. The upper\n   bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["vscatterdps:vscatterdpd:vscatterqps:vscatterqpd", "    VSCATTERDPS/VSCATTERDPD/VSCATTERQPS/VSCATTERQPD \u2014 Scatter Packed Single,\n                PackedDouble with Signed Dword and Qword Indices\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction      Op/E n Mode      Feature  Description\n                                  Support   Flag     \n                                                     Using signed dword       \n   EVEX.128.66.0F38.W0 A2                            indices, scatter         \n   /vsib VSCATTERDPS vm32x A      V/V       AVX512VL single-precision         \n   {k1}, xmm1                               AVX512F  floating-point values to \n                                                     memory using writemask   \n                                                     k1.                      \n                                                     Using signed dword       \n   EVEX.256.66.0F38.W0 A2                            indices, scatter         \n   /vsib VSCATTERDPS vm32y A      V/V       AVX512VL single-precision         \n   {k1}, ymm1                               AVX512F  floating-point values to \n                                                     memory using writemask   \n                                                     k1.                      \n                                                     Using signed dword       \n   EVEX.512.66.0F38.W0 A2                            indices, scatter         \n   /vsib VSCATTERDPS vm32z A      V/V       AVX512F  single-precision         \n   {k1}, zmm1                                        floating-point values to \n                                                     memory using writemask   \n                                                     k1.                      \n                                                     Using signed dword       \n   EVEX.128.66.0F38.W1 A2                   AVX512VL indices, scatter double  \n   /vsib VSCATTERDPD vm32x A      V/V       AVX512F  precision floating-point \n   {k1}, xmm1                                        values to memory using   \n                                                     writemask k1.            \n                                                     Using signed dword       \n   EVEX.256.66.0F38.W1 A2                   AVX512VL indices, scatter double  \n   /vsib VSCATTERDPD vm32x A      V/V       AVX512F  precision floating-point \n   {k1}, ymm1                                        values to memory using   \n                                                     writemask k1.            \n                                                     Using signed dword       \n   EVEX.512.66.0F38.W1 A2                            indices, scatter double  \n   /vsib VSCATTERDPD vm32y A      V/V       AVX512F  precision floating-point \n   {k1}, zmm1                                        values to memory using   \n                                                     writemask k1.            \n                                                     Using signed qword       \n   EVEX.128.66.0F38.W0 A3                            indices, scatter         \n   /vsib VSCATTERQPS vm64x A      V/V       AVX512VL single-precision         \n   {k1}, xmm1                               AVX512F  floating-point values to \n                                                     memory using writemask   \n                                                     k1.                      \n                                                     Using signed qword       \n   EVEX.256.66.0F38.W0 A3                            indices, scatter         \n   /vsib VSCATTERQPS vm64y A      V/V       AVX512VL single-precision         \n   {k1}, xmm1                               AVX512F  floating-point values to \n                                                     memory using writemask   \n                                                     k1.                      \n                                                     Using signed qword       \n   EVEX.512.66.0F38.W0 A3                            indices, scatter         \n   /vsib VSCATTERQPS vm64z A      V/V       AVX512F  single-precision         \n   {k1}, ymm1                                        floating-point values to \n                                                     memory using writemask   \n                                                     k1.                      \n                                                     Using signed qword       \n   EVEX.128.66.0F38.W1 A3                   AVX512VL indices, scatter double  \n   /vsib VSCATTERQPD vm64x A      V/V       AVX512F  precision floating-point \n   {k1}, xmm1                                        values to memory using   \n                                                     writemask k1.            \n                                                     Using signed qword       \n   EVEX.256.66.0F38.W1 A3                   AVX512VL indices, scatter double  \n   /vsib VSCATTERQPD vm64y A      V/V       AVX512F  precision floating-point \n   {k1}, ymm1                                        values to memory using   \n                                                     writemask k1.            \n                                                     Using signed qword       \n   EVEX.512.66.0F38.W1 A3                            indices, scatter double  \n   /vsib VSCATTERQPD vm64z A      V/V       AVX512F  precision floating-point \n   {k1}, zmm1                                        values to memory using   \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1               Operand 2     Operand 3 Operand 4 \n         Tuple1     BaseReg (R): VSIB:base,                                   \n   A     Scalar     VectorReg(R):           ModRM:reg (r) N/A       N/A\n                    VSIB:index              \n\n  Description \u00b6\n\n   Stores up to 16 elements (or 8 elements) in doubleword/quadword vector\n   zmm1 to the memory locations pointed by base address BASE_ADDR and index\n   vector VINDEX, with scale SCALE. The elements are specified via the VSIB\n   (i.e., the index register is a vector register, holding packed indices).\n   Elements will only be stored if their corresponding mask bit is one. The\n   entire mask register will be set to zero by this instruction unless it\n   triggers an exception.\n\n   This instruction can be suspended by an exception if at least one element\n   is already scattered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask register (k1) are partially updated.\n   If any traps or interrupts are pending from already scattered elements,\n   they will be delivered in lieu of the exception; in this case, EFLAG.RF is\n   set to one so an instruction breakpoint is not re-triggered when the\n   instruction is continued.\n\n   Note that:\n\n     * Only writes to overlapping vector indices are guaranteed to be ordered\n       with respect to each other (from LSB to MSB of the source registers).\n       Note that this also include partially overlapping vector indices.\n       Writes that are not overlapped may happen in any order. Memory\n       ordering with other instructions follows the Intel-64 memory ordering\n       model. Note that this does not account for non-overlapping indices\n       that map into the same physical address locations.\n     * If two or more destination indices completely overlap, the \u201cearlier\u201d\n       write(s) may be skipped.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination zmm will be completed (and non-faulting).\n       Individual elements closer to the MSB may or may not be completed. If\n       a given element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be scattered in any order, but faults must be delivered\n       in a right-to left order; thus, elements to the left of a faulting one\n       may be scattered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be scattered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n     * If this instruction overwrites itself and then takes a fault, only a\n       subset of elements may be completed before the fault is delivered (as\n       described above). If the fault handler completes and attempts to\n       re-execute this instruction, the new instruction will be executed, and\n       the scatter will not complete.\n\n   Note that the presence of VSIB byte is enforced in this instruction.\n   Hence, the instruction will #UD fault if ModRM.rm is different than 100b.\n\n   This instruction has special disp8*N and alignment rules. N is considered\n   to be the size of a single vector element.\n\n   The scaled index may require more bits to represent than the address bits\n   used by the processor (e.g., in 32-bit mode, if the scale is greater than\n   one). In this case, the most significant bits beyond the number of address\n   bits are ignored.\n\n   The instruction will #UD fault if the k0 mask register is specified.\n"],
	["vmaxsh", "                 VMAXSH \u2014 Return Maximum of Scalar FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode   \n   Flag Support 64/32 CPUID Feature  \n   Instruction En bit Mode Flag      \n   CPUID Feature Instruction En bit  \n   Mode Flag Op/ 64/32 CPUID Feature   Support             Description\n   Instruction En bit Mode Flag      \n   64/32 CPUID Feature Instruction   \n   En bit Mode Flag CPUID Feature    \n   Instruction En bit Mode Flag Op/  \n   64/32 CPUID Feature               \n                                                           Return the maximum \n                                                           low FP16 value     \n                                                           between xmm3/m16   \n                                                           and xmm2 and store \n   EVEX.LLIG.F3.MAP5.W0 5F /r VMAXSH A V/V     AVX512-FP16 the result in xmm1 \n   xmm1{k1}{z}, xmm2, xmm3/m16 {sae}                       subject to         \n                                                           writemask k1. Bits \n                                                           127:16 of xmm2 are \n                                                           copied to          \n                                                           xmm1[127:16].      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a compare of the low packed FP16 values in the\n   first source operand and the second source operand and returns the maximum\n   value for the pair of values to the destination operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of VMAXSH can be emulated using a sequence of\n   instructions, such as, a comparison followed by AND, ANDN, and OR.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n"],
	["kmovw:kmovb:kmovq:kmovd", "           KMOVW/KMOVB/KMOVQ/KMOVD \u2014 Move From and to Mask Registers\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Flag Description\n                                  Support   \n                                                         Move 16 bits mask    \n   VEX.L0.0F.W0 90 /r KMOVW RM    V/V       AVX512F      from k2/m16 and      \n   k1, k2/m16                                            store the result in  \n                                                         k1.                  \n   VEX.L0.66.0F.W0 90 /r                                 Move 8 bits mask     \n   KMOVB k1, k2/m8          RM    V/V       AVX512DQ     from k2/m8 and store \n                                                         the result in k1.    \n                                                         Move 64 bits mask    \n   VEX.L0.0F.W1 90 /r KMOVQ RM    V/V       AVX512BW     from k2/m64 and      \n   k1, k2/m64                                            store the result in  \n                                                         k1.                  \n                                                         Move 32 bits mask    \n   VEX.L0.66.0F.W1 90 /r    RM    V/V       AVX512BW     from k2/m32 and      \n   KMOVD k1, k2/m32                                      store the result in  \n                                                         k1.                  \n   VEX.L0.0F.W0 91 /r KMOVW                              Move 16 bits mask    \n   m16, k1                  MR    V/V       AVX512F      from k1 and store    \n                                                         the result in m16.   \n   VEX.L0.66.0F.W0 91 /r                                 Move 8 bits mask     \n   KMOVB m8, k1             MR    V/V       AVX512DQ     from k1 and store    \n                                                         the result in m8.    \n   VEX.L0.0F.W1 91 /r KMOVQ                              Move 64 bits mask    \n   m64, k1                  MR    V/V       AVX512BW     from k1 and store    \n                                                         the result in m64.   \n   VEX.L0.66.0F.W1 91 /r                                 Move 32 bits mask    \n   KMOVD m32, k1            MR    V/V       AVX512BW     from k1 and store    \n                                                         the result in m32.   \n   VEX.L0.0F.W0 92 /r KMOVW RR    V/V       AVX512F      Move 16 bits mask    \n   k1, r32                                               from r32 to k1.      \n   VEX.L0.66.0F.W0 92 /r    RR    V/V       AVX512DQ     Move 8 bits mask     \n   KMOVB k1, r32                                         from r32 to k1.      \n   VEX.L0.F2.0F.W1 92 /r    RR    V/I       AVX512BW     Move 64 bits mask    \n   KMOVQ k1, r64                                         from r64 to k1.      \n   VEX.L0.F2.0F.W0 92 /r    RR    V/V       AVX512BW     Move 32 bits mask    \n   KMOVD k1, r32                                         from r32 to k1.      \n   VEX.L0.0F.W0 93 /r KMOVW RR    V/V       AVX512F      Move 16 bits mask    \n   r32, k1                                               from k1 to r32.      \n   VEX.L0.66.0F.W0 93 /r    RR    V/V       AVX512DQ     Move 8 bits mask     \n   KMOVB r32, k1                                         from k1 to r32.      \n   VEX.L0.F2.0F.W1 93 /r    RR    V/I       AVX512BW     Move 64 bits mask    \n   KMOVQ r64, k1                                         from k1 to r64.      \n   VEX.L0.F2.0F.W0 93 /r    RR    V/V       AVX512BW     Move 32 bits mask    \n   KMOVD r32, k1                                         from k1 to r32.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1                             Operand 2                      \n   RM    ModRM:reg (w)                         ModRM:r/m (r)                  \n   MR    ModRM:r/m (w, ModRM:[7:6] must not be ModRM:reg (r)                  \n         11b)                                  \n   RR    ModRM:reg (w)                         ModRM:r/m (r, ModRM:[7:6] must \n                                               be 11b)                        \n\nDescription \u00b6\n\n   Copies values from the source operand (second operand) to the destination\n   operand (first operand). The source and destination operands can be mask\n   registers, memory location or general purpose. The instruction cannot be\n   used to transfer data between general purpose registers and or memory\n   locations.\n\n   When moving to a mask register, the result is zero extended to MAX_KL size\n   (i.e., 64 bits currently). When moving to a general-purpose register\n   (GPR), the result is zero-extended to the size of the destination. In\n   32-bit mode, the default GPR destination\u2019s size is 32 bits. In 64-bit\n   mode, the default GPR destination\u2019s size is 64 bits. Note that VEX.W can\n   only be used to modify the size of the GPR operand in 64b mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["subpd", "         SUBPD \u2014 Subtract Packed Double Precision Floating-Point Values\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction      Op/E n Mode      Feature  Description\n                                  Support   Flag     \n                                                     Subtract packed double   \n   66 0F 5C /r SUBPD xmm1,                           precision floating-point \n   xmm2/m128               A      V/V       SSE2     values in xmm2/mem from  \n                                                     xmm1 and store result in \n                                                     xmm1.                    \n                                                     Subtract packed double   \n   VEX.128.66.0F.WIG 5C /r                           precision floating-point \n   VSUBPD xmm1,xmm2,       B      V/V       AVX      values in xmm3/mem from  \n   xmm3/m128                                         xmm2 and store result in \n                                                     xmm1.                    \n                                                     Subtract packed double   \n   VEX.256.66.0F.WIG 5C /r                           precision floating-point \n   VSUBPD ymm1, ymm2,      B      V/V       AVX      values in ymm3/mem from  \n   ymm3/m256                                         ymm2 and store result in \n                                                     ymm1.                    \n                                                     Subtract packed double   \n   EVEX.128.66.0F.W1 5C /r                           precision floating-point \n   VSUBPD xmm1 {k1}{z},    C      V/V       AVX512VL values from              \n   xmm2, xmm3/m128/m64bcst                  AVX512F  xmm3/m128/m64bcst to     \n                                                     xmm2 and store result in \n                                                     xmm1 with writemask k1.  \n                                                     Subtract packed double   \n   EVEX.256.66.0F.W1 5C /r                           precision floating-point \n   VSUBPD ymm1 {k1}{z},    C      V/V       AVX512VL values from              \n   ymm2, ymm3/m256/m64bcst                  AVX512F  ymm3/m256/m64bcst to     \n                                                     ymm2 and store result in \n                                                     ymm1 with writemask k1.  \n                                                     Subtract packed double   \n   EVEX.512.66.0F.W1 5C /r                           precision floating-point \n   VSUBPD zmm1 {k1}{z},    C      V/V       AVX512F  values from              \n   zmm2,                                             zmm3/m512/m64bcst to     \n   zmm3/m512/m64bcst{er}                             zmm2 and store result in \n                                                     zmm1 with writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD subtract of the two, four or eight packed double precision\n   floating-point values of the second Source operand from the first Source\n   operand, and stores the packed double precision floating-point results in\n   the destination operand.\n\n   VEX.128 and EVEX.128 encoded versions: The second source operand is an XMM\n   register or an 128-bit memory location. The first source operand and\n   destination operands are XMM registers. Bits (MAXVL-1:128) of the\n   corresponding destination register are zeroed.\n\n   VEX.256 and EVEX.256 encoded versions: The second source operand is an YMM\n   register or an 256-bit memory location. The first source operand and\n   destination operands are YMM registers. Bits (MAXVL-1:256) of the\n   corresponding destination register are zeroed.\n\n   EVEX.512 encoded version: The second source operand is a ZMM register, a\n   512-bit memory location or a 512-bit vector broadcasted from a 64-bit\n   memory location. The first source operand and destination operands are ZMM\n   registers. The destination operand is conditionally updated according to\n   the writemask.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper Bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["vmovw", "                               VMOVW \u2014 Move Word\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode     \n   Flag Support 64/32 CPUID Feature    \n   Instruction En bit Mode Flag CPUID  \n   Feature Instruction En bit Mode     \n   Flag Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En bit Mode Flag 64/32  \n   CPUID Feature Instruction En bit    \n   Mode Flag CPUID Feature Instruction \n   En bit Mode Flag Op/ 64/32 CPUID    \n   Feature                             \n   EVEX.128.66.MAP5.WIG 6E /r VMOVW    A V/V     AVX512-FP16 Copy word from   \n   xmm1, reg/m16                                             reg/m16 to xmm1. \n   EVEX.128.66.MAP5.WIG 7E /r VMOVW    B V/V     AVX512-FP16 Copy word from   \n   reg/m16, xmm1                                             xmm1 to reg/m16. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction either (a) copies one word element from an XMM register\n   to a general-purpose register or memory location or (b) copies one word\n   element from a general-purpose register or memory location to an XMM\n   register. When writing a general-purpose register, the lower 16-bits of\n   the register will contain the word value. The upper bits of the\n   general-purpose register are written with zeros.\n"],
	["pmovsx", "                     PMOVSX \u2014 Packed Move With Sign Extend\n\n                             Op / 64/32 bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Sign extend 8 packed     \n   66 0f 38 20 /r PMOVSXBW                           8-bit integers in the    \n   xmm1, xmm2/m64            A    V/V       SSE4_1   low 8 bytes of xmm2/m64  \n                                                     to 8 packed 16-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 4 packed     \n   66 0f 38 21 /r PMOVSXBD                           8-bit integers in the    \n   xmm1, xmm2/m32            A    V/V       SSE4_1   low 4 bytes of xmm2/m32  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 2 packed     \n   66 0f 38 22 /r PMOVSXBQ                           8-bit integers in the    \n   xmm1, xmm2/m16            A    V/V       SSE4_1   low 2 bytes of xmm2/m16  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 4 packed     \n   66 0f 38 23/r PMOVSXWD                            16-bit integers in the   \n   xmm1, xmm2/m64            A    V/V       SSE4_1   low 8 bytes of xmm2/m64  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 2 packed     \n   66 0f 38 24 /r PMOVSXWQ                           16-bit integers in the   \n   xmm1, xmm2/m32            A    V/V       SSE4_1   low 4 bytes of xmm2/m32  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 2 packed     \n   66 0f 38 25 /r PMOVSXDQ                           32-bit integers in the   \n   xmm1, xmm2/m64            A    V/V       SSE4_1   low 8 bytes of xmm2/m64  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 8 packed     \n   VEX.128.66.0F38.WIG 20 /r                         8-bit integers in the    \n   VPMOVSXBW xmm1, xmm2/m64  A    V/V       AVX      low 8 bytes of xmm2/m64  \n                                                     to 8 packed 16-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 4 packed     \n   VEX.128.66.0F38.WIG 21 /r                         8-bit integers in the    \n   VPMOVSXBD xmm1, xmm2/m32  A    V/V       AVX      low 4 bytes of xmm2/m32  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 2 packed     \n   VEX.128.66.0F38.WIG 22 /r                         8-bit integers in the    \n   VPMOVSXBQ xmm1, xmm2/m16  A    V/V       AVX      low 2 bytes of xmm2/m16  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 4 packed     \n   VEX.128.66.0F38.WIG 23 /r                         16-bit integers in the   \n   VPMOVSXWD xmm1, xmm2/m64  A    V/V       AVX      low 8 bytes of xmm2/m64  \n                                                     to 4 packed 32-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 2 packed     \n   VEX.128.66.0F38.WIG 24 /r                         16-bit integers in the   \n   VPMOVSXWQ xmm1, xmm2/m32  A    V/V       AVX      low 4 bytes of xmm2/m32  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 2 packed     \n   VEX.128.66.0F38.WIG 25 /r                         32-bit integers in the   \n   VPMOVSXDQ xmm1, xmm2/m64  A    V/V       AVX      low 8 bytes of xmm2/m64  \n                                                     to 2 packed 64-bit       \n                                                     integers in xmm1.        \n                                                     Sign extend 16 packed    \n   VEX.256.66.0F38.WIG 20 /r A    V/V       AVX2     8-bit integers in        \n   VPMOVSXBW ymm1, xmm2/m128                         xmm2/m128 to 16 packed   \n                                                     16-bit integers in ymm1. \n                                                     Sign extend 8 packed     \n   VEX.256.66.0F38.WIG 21 /r                         8-bit integers in the    \n   VPMOVSXBD ymm1, xmm2/m64  A    V/V       AVX2     low 8 bytes of xmm2/m64  \n                                                     to 8 packed 32-bit       \n                                                     integers in ymm1.        \n                                                     Sign extend 4 packed     \n   VEX.256.66.0F38.WIG 22 /r                         8-bit integers in the    \n   VPMOVSXBQ ymm1, xmm2/m32  A    V/V       AVX2     low 4 bytes of xmm2/m32  \n                                                     to 4 packed 64-bit       \n                                                     integers in ymm1.        \n                                                     Sign extend 8 packed     \n   VEX.256.66.0F38.WIG 23 /r                         16-bit integers in the   \n   VPMOVSXWD ymm1, xmm2/m128 A    V/V       AVX2     low 16 bytes of          \n                                                     xmm2/m128 to 8 packed    \n                                                     32-bit integers in ymm1. \n                                                     Sign extend 4 packed     \n   VEX.256.66.0F38.WIG 24 /r                         16-bit integers in the   \n   VPMOVSXWQ ymm1, xmm2/m64  A    V/V       AVX2     low 8 bytes of xmm2/m64  \n                                                     to 4 packed 64-bit       \n                                                     integers in ymm1.        \n                                                     Sign extend 4 packed     \n   VEX.256.66.0F38.WIG 25 /r                         32-bit integers in the   \n   VPMOVSXDQ ymm1, xmm2/m128 A    V/V       AVX2     low 16 bytes of          \n                                                     xmm2/m128 to 4 packed    \n                                                     64-bit integers in ymm1. \n   EVEX.128.66.0F38.WIG 20                           Sign extend 8 packed     \n   /r VPMOVSXBW xmm1         B    V/V       AVX512VL 8-bit integers in        \n   {k1}{z}, xmm2/m64                        AVX512BW xmm2/m64 to 8 packed     \n                                                     16-bit integers in zmm1. \n   EVEX.256.66.0F38.WIG 20                           Sign extend 16 packed    \n   /r VPMOVSXBW ymm1         B    V/V       AVX512VL 8-bit integers in        \n   {k1}{z}, xmm2/m128                       AVX512BW xmm2/m128 to 16 packed   \n                                                     16-bit integers in ymm1. \n   EVEX.512.66.0F38.WIG 20                           Sign extend 32 packed    \n   /r VPMOVSXBW zmm1         B    V/V       AVX512BW 8-bit integers in        \n   {k1}{z}, ymm2/m256                                ymm2/m256 to 32 packed   \n                                                     16-bit integers in zmm1. \n                                                     Sign extend 4 packed     \n   EVEX.128.66.0F38.WIG 21                           8-bit integers in the    \n   /r VPMOVSXBD xmm1         C    V/V       AVX512VL low 4 bytes of xmm2/m32  \n   {k1}{z}, xmm2/m32                        AVX512F  to 4 packed 32-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 8 packed     \n   EVEX.256.66.0F38.WIG 21                           8-bit integers in the    \n   /r VPMOVSXBD ymm1         C    V/V       AVX512VL low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                        AVX512F  to 8 packed 32-bit       \n                                                     integers in ymm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 16 packed    \n   EVEX.512.66.0F38.WIG 21                           8-bit integers in the    \n   /r VPMOVSXBD zmm1         C    V/V       AVX512F  low 16 bytes of          \n   {k1}{z}, xmm2/m128                                xmm2/m128 to 16 packed   \n                                                     32-bit integers in zmm1  \n                                                     subject to writemask k1. \n                                                     Sign extend 2 packed     \n   EVEX.128.66.0F38.WIG 22                           8-bit integers in the    \n   /r VPMOVSXBQ xmm1         D    V/V       AVX512VL low 2 bytes of xmm2/m16  \n   {k1}{z}, xmm2/m16                        AVX512F  to 2 packed 64-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 4 packed     \n   EVEX.256.66.0F38.WIG 22                           8-bit integers in the    \n   /r VPMOVSXBQ ymm1         D    V/V       AVX512VL low 4 bytes of xmm2/m32  \n   {k1}{z}, xmm2/m32                        AVX512F  to 4 packed 64-bit       \n                                                     integers in ymm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 8 packed     \n   EVEX.512.66.0F38.WIG 22                           8-bit integers in the    \n   /r VPMOVSXBQ zmm1         D    V/V       AVX512F  low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                                 to 8 packed 64-bit       \n                                                     integers in zmm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 4 packed     \n   EVEX.128.66.0F38.WIG 23                           16-bit integers in the   \n   /r VPMOVSXWD xmm1         B    V/V       AVX512VL low 8 bytes of ymm2/mem  \n   {k1}{z}, xmm2/m64                        AVX512F  to 4 packed 32-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 8 packed     \n   EVEX.256.66.0F38.WIG 23                           16-bit integers in the   \n   /r VPMOVSXWD ymm1         B    V/V       AVX512VL low 16 bytes of          \n   {k1}{z}, xmm2/m128                       AVX512F  ymm2/m128 to 8 packed    \n                                                     32-bit integers in ymm1  \n                                                     subject to writemask k1. \n                                                     Sign extend 16 packed    \n   EVEX.512.66.0F38.WIG 23                           16-bit integers in the   \n   /r VPMOVSXWD zmm1         B    V/V       AVX512F  low 32 bytes of          \n   {k1}{z}, ymm2/m256                                ymm2/m256 to 16 packed   \n                                                     32-bit integers in zmm1  \n                                                     subject to writemask k1. \n                                                     Sign extend 2 packed     \n   EVEX.128.66.0F38.WIG 24                           16-bit integers in the   \n   /r VPMOVSXWQ xmm1         C    V/V       AVX512VL low 4 bytes of xmm2/m32  \n   {k1}{z}, xmm2/m32                        AVX512F  to 2 packed 64-bit       \n                                                     integers in xmm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 4 packed     \n   EVEX.256.66.0F38.WIG 24                           16-bit integers in the   \n   /r VPMOVSXWQ ymm1         C    V/V       AVX512VL low 8 bytes of xmm2/m64  \n   {k1}{z}, xmm2/m64                        AVX512F  to 4 packed 64-bit       \n                                                     integers in ymm1 subject \n                                                     to writemask k1.         \n                                                     Sign extend 8 packed     \n   EVEX.512.66.0F38.WIG 24                           16-bit integers in the   \n   /r VPMOVSXWQ zmm1         C    V/V       AVX512F  low 16 bytes of          \n   {k1}{z}, xmm2/m128                                xmm2/m128 to 8 packed    \n                                                     64-bit integers in zmm1  \n                                                     subject to writemask k1. \n                                                     Sign extend 2 packed     \n   EVEX.128.66.0F38.W0 25 /r                         32-bit integers in the   \n   VPMOVSXDQ xmm1 {k1}{z},   B    V/V       AVX512VL low 8 bytes of xmm2/m64  \n   xmm2/m64                                 AVX512F  to 2 packed 64-bit       \n                                                     integers in zmm1 using   \n                                                     writemask k1.            \n                                                     Sign extend 4 packed     \n   EVEX.256.66.0F38.W0 25 /r                         32-bit integers in the   \n   VPMOVSXDQ ymm1 {k1}{z},   B    V/V       AVX512VL low 16 bytes of          \n   xmm2/m128                                AVX512F  xmm2/m128 to 4 packed    \n                                                     64-bit integers in zmm1  \n                                                     using writemask k1.      \n                                                     Sign extend 8 packed     \n   EVEX.512.66.0F38.W0 25 /r                         32-bit integers in the   \n   VPMOVSXDQ zmm1 {k1}{z},   B    V/V       AVX512F  low 32 bytes of          \n   ymm2/m256                                         ymm2/m256 to 8 packed    \n                                                     64-bit integers in zmm1  \n                                                     using writemask k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A         ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Half Mem    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   C     Quarter Mem ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Eighth Mem  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Legacy and VEX encoded versions: Packed byte, word, or dword integers in\n   the low bytes of the source operand (second operand) are sign extended to\n   word, dword, or quadword integers and stored in packed signed bytes the\n   destination operand.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   VEX.128 and EVEX.128 encoded versions: Bits (MAXVL-1:128) of the\n   corresponding destination register are zeroed.\n\n   VEX.256 and EVEX.256 encoded versions: Bits (MAXVL-1:256) of the\n   corresponding destination register are zeroed.\n\n   EVEX encoded versions: Packed byte, word or dword integers starting from\n   the low bytes of the source operand (second operand) are sign extended to\n   word, dword or quadword integers and stored to the destination operand\n   under the writemask. The destination register is XMM, YMM or ZMM Register.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["vfnmadd132pd:vfnmadd213pd:vfnmadd231pd", "    VFNMADD132PD/VFNMADD213PD/VFNMADD231PD \u2014 Fused Negative Multiply-Add of\n                  PackedDouble Precision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.128.66.0F38.W1 9C /r                          values from xmm1 and     \n   VFNMADD132PD xmm1, xmm2, A     V/V       FMA      xmm3/mem, negate the     \n   xmm3/m128                                         multiplication result    \n                                                     and add to xmm2 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.128.66.0F38.W1 AC /r                          values from xmm1 and     \n   VFNMADD213PD xmm1, xmm2, A     V/V       FMA      xmm2, negate the         \n   xmm3/m128                                         multiplication result    \n                                                     and add to xmm3/mem and  \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.128.66.0F38.W1 BC /r                          values from xmm2 and     \n   VFNMADD231PD xmm1, xmm2, A     V/V       FMA      xmm3/mem, negate the     \n   xmm3/m128                                         multiplication result    \n                                                     and add to xmm1 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.256.66.0F38.W1 9C /r                          values from ymm1 and     \n   VFNMADD132PD ymm1, ymm2, A     V/V       FMA      ymm3/mem, negate the     \n   ymm3/m256                                         multiplication result    \n                                                     and add to ymm2 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.256.66.0F38.W1 AC /r                          values from ymm1 and     \n   VFNMADD213PD ymm1, ymm2, A     V/V       FMA      ymm2, negate the         \n   ymm3/m256                                         multiplication result    \n                                                     and add to ymm3/mem and  \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   VEX.256.66.0F38.W1 BC /r                          values from ymm2 and     \n   VFNMADD231PD ymm1, ymm2, A     V/V       FMA      ymm3/mem, negate the     \n   ymm3/m256                                         multiplication result    \n                                                     and add to ymm1 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 9C                            values from xmm1 and     \n   /r VFNMADD132PD xmm0     B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm1,                           AVX512F  negate the               \n   xmm2/m128/m64bcst                                 multiplication result    \n                                                     and add to xmm2 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 AC                            values from xmm1 and     \n   /r VFNMADD213PD xmm1     B     V/V       AVX512VL xmm2, negate the         \n   {k1}{z}, xmm2,                           AVX512F  multiplication result    \n   xmm3/m128/m64bcst                                 and add to               \n                                                     xmm3/m128/m64bcst and    \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 BC                            values from xmm2 and     \n   /r VFNMADD231PD xmm1     B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm2,                           AVX512F  negate the               \n   xmm3/m128/m64bcst                                 multiplication result    \n                                                     and add to xmm1 and put  \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 9C                            values from ymm1 and     \n   /r VFNMADD132PD ymm1     B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  negate the               \n   ymm3/m256/m64bcst                                 multiplication result    \n                                                     and add to ymm2 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 AC                            values from ymm1 and     \n   /r VFNMADD213PD ymm1     B     V/V       AVX512VL ymm2, negate the         \n   {k1}{z}, ymm2,                           AVX512F  multiplication result    \n   ymm3/m256/m64bcst                                 and add to               \n                                                     ymm3/m256/m64bcst and    \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 BC                            values from ymm2 and     \n   /r VFNMADD231PD ymm1     B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  negate the               \n   ymm3/m256/m64bcst                                 multiplication result    \n                                                     and add to ymm1 and put  \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 9C                            values from zmm1 and     \n   /r VFNMADD132PD zmm1     B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    negate the               \n   zmm3/m512/m64bcst{er}                             multiplication result    \n                                                     and add to zmm2 and put  \n                                                     result in zmm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 AC                            values from zmm1 and     \n   /r VFNMADD213PD zmm1     B     V/V       AVX512F  zmm2, negate the         \n   {k1}{z}, zmm2,                                    multiplication result    \n   zmm3/m512/m64bcst{er}                             and add to               \n                                                     zmm3/m512/m64bcst and    \n                                                     put result in zmm1.      \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 BC                            values from zmm2 and     \n   /r VFNMADD231PD zmm1     B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    negate the               \n   zmm3/m512/m64bcst{er}                             multiplication result    \n                                                     and add to zmm1 and put  \n                                                     result in zmm1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMADD132PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the first source operand to the two, four or\n   eight packed double precision floating-point values in the third source\n   operand, adds the negated infinite precision intermediate result to the\n   two, four or eight packed double precision floating-point values in the\n   second source operand, performs rounding and stores the resulting two,\n   four or eight packed double precision floating-point values to the\n   destination operand (first source operand).\n\n   VFNMADD213PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source operand to the two, four or\n   eight packed double precision floating-point values in the first source\n   operand, adds the negated infinite precision intermediate result to the\n   two, four or eight packed double precision floating-point values in the\n   third source operand, performs rounding and stores the resulting two, four\n   or eight packed double precision floating-point values to the destination\n   operand (first source operand).\n\n   VFNMADD231PD: Multiplies the two, four or eight packed double precision\n   floating-point values from the second source to the two, four or eight\n   packed double precision floating-point values in the third source operand,\n   the negated infinite precision intermediate result to the two, four or\n   eight packed double precision floating-point values in the first source\n   operand, performs rounding and stores the resulting two, four or eight\n   packed double precision floating-point values to the destination operand\n   (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["fchs", "                               FCHS \u2014 Change Sign\n\n   Opcode  Mode Leg Mode Description                \n   D9 E0                 Complements sign of ST(0). \n\nDescription \u00b6\n\n   Complements the sign bit of ST(0). This operation changes a positive value\n   into a negative value of equal magnitude or vice versa. The following\n   table shows the results obtained when changing the sign of various classes\n   of numbers.\n\n   ST(0) SRC ST(0) DEST \n   \u2212\u221e        +\u221e         \n   \u2212F        +F         \n   \u22120        +0         \n   +0        \u22120         \n   +F        \u2212F         \n   +\u221e        \u2212\u221e         \n   NaN       NaN        \n\n   Table 3-20. FCHS Results\n\n     * Fmeansfinitefloating-pointvalue.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0.  \n   C0, C2, C3 Undefined. \n"],
	["comisd", " COMISD \u2014 Compare Scalar Ordered Double Precision Floating-Point Values and Set\n                                     EFLAGS\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Compare low double          \n   66 0F 2F /r COMISD                             precision floating-point    \n   xmm1, xmm2/m64          A    V/V       SSE2    values in xmm1 and          \n                                                  xmm2/mem64 and set the      \n                                                  EFLAGS flags accordingly.   \n                                                  Compare low double          \n   VEX.LIG.66.0F.WIG 2F /r                        precision floating-point    \n   VCOMISD xmm1, xmm2/m64  A    V/V       AVX     values in xmm1 and          \n                                                  xmm2/mem64 and set the      \n                                                  EFLAGS flags accordingly.   \n                                                  Compare low double          \n   EVEX.LLIG.66.0F.W1 2F                          precision floating-point    \n   /r VCOMISD xmm1,        B    V/V       AVX512F values in xmm1 and          \n   xmm2/m64{sae}                                  xmm2/mem64 and set the      \n                                                  EFLAGS flags accordingly.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Compares the double precision floating-point values in the low quadwords\n   of operand 1 (first operand) and operand 2 (second operand), and sets the\n   ZF, PF, and CF flags in the EFLAGS register according to the result\n   (unordered, greater than, less than, or equal). The OF, SF, and AF flags\n   in the EFLAGS register are set to 0. The unordered result is returned if\n   either source operand is a NaN (QNaN or SNaN).\n\n   Operand 1 is an XMM register; operand 2 can be an XMM register or a 64 bit\n   memory location. The COMISD instruction differs from the UCOMISD\n   instruction in that it signals a SIMD floating-point invalid operation\n   exception (#I) when a source operand is either a QNaN or SNaN. The UCOMISD\n   instruction signals an invalid operation exception only if a source\n   operand is an SNaN.\n\n   The EFLAGS register is not updated if an unmasked SIMD floating-point\n   exception is generated.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCOMISD is encoded with VEX.L=0. Encoding VCOMISD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["ldmxcsr", "                         LDMXCSR \u2014 Load MXCSR Register\n\n                                   64/32-bit     CPUID                        \n   Opcode/Instruction        Op/En Mode          Feature     Description\n                                                 Flag        \n                                                             Load MXCSR       \n   NP 0F AE /2 LDMXCSR m32   M     V/V           SSE         register from    \n                                                             m32.             \n   VEX.LZ.0F.WIG AE /2                                       Load MXCSR       \n   VLDMXCSR m32              M     V/V           AVX         register from    \n                                                             m32.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the source operand into the MXCSR control/status register. The\n   source operand is a 32-bit memory location. See \u201cMXCSR Control and Status\n   Register\u201d in Chapter 10, of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, for a description of the MXCSR\n   register and its contents.\n\n   The LDMXCSR instruction is typically used in conjunction with the\n   (V)STMXCSR instruction, which stores the contents of the MXCSR register in\n   memory.\n\n   The default MXCSR value at reset is 1F80H.\n\n   If a (V)LDMXCSR instruction clears a SIMD floating-point exception mask\n   bit and sets the corresponding exception flag bit, a SIMD floating-point\n   exception will not be immediately generated. The exception will be\n   generated only upon the execution of the next instruction that meets both\n   conditions below:\n\n     * the instruction must operate on an XMM or YMM register operand,\n     * the instruction causes that particular SIMD floating-point exception\n       to be reported.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\n   If VLDMXCSR is encoded with VEX.L= 1, an attempt to execute the\n   instruction encoded with VEX.L= 1 will cause an #UD exception.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["pshufhw", "                      PSHUFHW \u2014 Shuffle Packed High Words\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Shuffle the high words   \n   F3 0F 70 /r ib PSHUFHW                            in xmm2/m128 based on    \n   xmm1, xmm2/m128, imm8    A     V/V       SSE2     the encoding in imm8 and \n                                                     store the result in      \n                                                     xmm1.                    \n                                                     Shuffle the high words   \n   VEX.128.F3.0F.WIG 70 /r                           in xmm2/m128 based on    \n   ib VPSHUFHW xmm1,        A     V/V       AVX      the encoding in imm8 and \n   xmm2/m128, imm8                                   store the result in      \n                                                     xmm1.                    \n                                                     Shuffle the high words   \n   VEX.256.F3.0F.WIG 70 /r                           in ymm2/m256 based on    \n   ib VPSHUFHW ymm1,        A     V/V       AVX2     the encoding in imm8 and \n   ymm2/m256, imm8                                   store the result in      \n                                                     ymm1.                    \n                                                     Shuffle the high words   \n   EVEX.128.F3.0F.WIG 70 /r                 AVX512VL in xmm2/m128 based on    \n   ib VPSHUFHW xmm1         B     V/V       AVX512BW the encoding in imm8 and \n   {k1}{z}, xmm2/m128, imm8                          store the result in xmm1 \n                                                     under write mask k1.     \n                                                     Shuffle the high words   \n   EVEX.256.F3.0F.WIG 70 /r                 AVX512VL in ymm2/m256 based on    \n   ib VPSHUFHW ymm1         B     V/V       AVX512BW the encoding in imm8 and \n   {k1}{z}, ymm2/m256, imm8                          store the result in ymm1 \n                                                     under write mask k1.     \n                                                     Shuffle the high words   \n   EVEX.512.F3.0F.WIG 70 /r                          in zmm2/m512 based on    \n   ib VPSHUFHW zmm1         B     V/V       AVX512BW the encoding in imm8 and \n   {k1}{z}, zmm2/m512, imm8                          store the result in zmm1 \n                                                     under write mask k1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n   B     Full Mem   ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Copies words from the high quadword of a 128-bit lane of the source\n   operand and inserts them in the high quadword of the destination operand\n   at word locations (of the respective lane) selected with the immediate\n   operand. This 256-bit operation is similar to the in-lane operation used\n   by the 256-bit VPSHUFD instruction, which is illustrated in Figure 4-16.\n   For 128-bit operation, only the low 128-bit lane is operative. Each 2-bit\n   field in the immediate operand selects the contents of one word location\n   in the high quadword of the destination operand. The binary encodings of\n   the immediate operand fields select words (0, 1, 2 or 3, 4) from the high\n   quadword of the source operand to be copied to the destination operand.\n   The low quadword of the source operand is copied to the low quadword of\n   the destination operand, for each 128-bit lane.\n\n   Note that this instruction permits a word in the high quadword of the\n   source operand to be copied to more than one word location in the high\n   quadword of the destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The destination operand is an XMM register.\n   The source operand can be an XMM register or a 128-bit memory location.\n   Bits (MAXVL-1:128) of the corresponding YMM destination register remain\n   unchanged.\n\n   VEX.128 encoded version: The destination operand is an XMM register. The\n   source operand can be an XMM register or a 128-bit memory location. Bits\n   (MAXVL-1:128) of the destination YMM register are zeroed. VEX.vvvv is\n   reserved and must be 1111b, VEX.L must be 0, otherwise the instruction\n   will #UD.\n\n   VEX.256 encoded version: The destination operand is an YMM register. The\n   source operand can be an YMM register or a 256-bit memory location.\n\n   EVEX encoded version: The destination operand is a ZMM/YMM/XMM registers.\n   The source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location. The destination is updated according to the write-mask.\n\n   Note: In VEX encoded versions, VEX.vvvv is reserved and must be 1111b\n   otherwise instructions will #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["addsd", "           ADDSD \u2014 Add Scalar Double Precision Floating-Point Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Add the low double         \n   F2 0F 58 /r ADDSD xmm1,                         precision floating-point   \n   xmm2/m64                 A    V/V       SSE2    value from xmm2/mem to     \n                                                   xmm1 and store the result  \n                                                   in xmm1.                   \n                                                   Add the low double         \n   VEX.LIG.F2.0F.WIG 58 /r                         precision floating-point   \n   VADDSD xmm1, xmm2,       B    V/V       AVX     value from xmm3/mem to     \n   xmm3/m64                                        xmm2 and store the result  \n                                                   in xmm1.                   \n                                                   Add the low double         \n   EVEX.LLIG.F2.0F.W1 58 /r                        precision floating-point   \n   VADDSD xmm1 {k1}{z},     C    V/V       AVX512F value from xmm3/m64 to     \n   xmm2, xmm3/m64{er}                              xmm2 and store the result  \n                                                   in xmm1 with writemask k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds the low double precision floating-point values from the second source\n   operand and the first source operand and stores the double precision\n   floating-point result in the destination operand.\n\n   The second source operand can be an XMM register or a 64-bit memory\n   location. The first source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   the same. Bits (MAXVL-1:64) of the corresponding destination register\n   remain unchanged.\n\n   EVEX and VEX.128 encoded version: The first source operand is encoded by\n   EVEX.vvvv/VEX.vvvv. Bits (127:64) of the XMM register destination are\n   copied from corresponding bits in the first source operand. Bits\n   (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX version: The low quadword element of the destination is updated\n   according to the writemask.\n\n   Software should ensure VADDSD is encoded with VEX.L=0. Encoding VADDSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["andn", "                             ANDN \u2014 Logical AND NOT\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                          Flag    \n   VEX.LZ.0F38.W0 F2 /r                           Bitwise AND of inverted     \n   ANDN r32a, r32b, r/m32 RVM   V/V       BMI1    r32b with r/m32, store      \n                                                  result in r32a.             \n   VEX.LZ. 0F38.W1 F2 /r                          Bitwise AND of inverted     \n   ANDN r64a, r64b, r/m64 RVM   V/N.E.    BMI1    r64b with r/m64, store      \n                                                  result in r64a.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVM   ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical AND of inverted second operand (the first\n   source operand) with the third operand (the\n\n   second source operand). The result is stored in the first operand\n   (destination operand).\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   SF and ZF are updated based on result. OF and CF flags are cleared. AF and\n   PF flags are undefined.\n"],
	["vcvtusi2ss", "VCVTUSI2SS \u2014 Convert Unsigned Integer to Scalar Single Precision Floating-Point\n                                     Value\n\n                               64/32 Bit    CPUID                             \n   Opcode/Instruction    Op/En Mode Support Feature Description\n                                            Flag    \n                                                    Convert one signed        \n   EVEX.LLIG.F3.0F.W0 7B                            doubleword integer from   \n   /r VCVTUSI2SS xmm1,   A     V/V          AVX512F r/m32 to one single       \n   xmm2, r/m32{er}                                  precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   EVEX.LLIG.F3.0F.W1 7B                            quadword integer from     \n   /r VCVTUSI2SS xmm1,   A     V/N.E.^1     AVX512F r/m64 to one single       \n   xmm2, r/m64{er}                                  precision floating-point  \n                                                    value in xmm1.            \n\n     1. For this specific instruction, EVEX.W in non-64 bit is ignored; the\n     instruction behaves as if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Converts a unsigned doubleword integer (or unsigned quadword integer if\n   operand size is 64 bits) in the source operand (second operand) to a\n   single precision floating-point value in the destination operand (first\n   operand). The source operand can be a general-purpose register or a memory\n   location. The destination operand is an XMM register. The result is stored\n   in the low doubleword of the destination operand. When a conversion is\n   inexact, the value returned is rounded according to the rounding control\n   bits in the MXCSR register or the embedded rounding control bits.\n\n   The second source operand can be a general-purpose register or a 32/64-bit\n   memory location. The first source and destination operands are XMM\n   registers. Bits (127:32) of the XMM register destination are copied from\n   corresponding bits in the first source operand. Bits (MAXVL-1:128) of the\n   destination register are zeroed.\n\n   EVEX.W1 version: promotes the instruction to use 64-bit input value in\n   64-bit mode.\n"],
	["eldb:eldu:eldbc:elduc", "          ELDB/ELDU/ELDBC/ELDUC \u2014 Load an EPC Page and Mark its State\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                Support   Flag    \n                                                  This leaf function loads,   \n   EAX = 07H ENCLS[ELDB]  IR    V/V       SGX1    verifies an EPC page and    \n                                                  marks the page as blocked.  \n                                                  This leaf function loads,   \n   EAX = 08H ENCLS[ELDU]  IR    V/V       SGX1    verifies an EPC page and    \n                                                  marks the page as           \n                                                  unblocked.                  \n                                                  This leaf function behaves  \n   EAX = 12H ENCLS[ELDBC] IR    V/V       EAX[6]  lie ELDB but with improved  \n                                                  conflict handling for       \n                                                  oversubscription.           \n                                                  This leaf function behaves  \n   EAX = 13H ENCLS[ELDUC] IR    V/V       EAX[6]  like ELDU but with improved \n                                                  conflict handling for       \n                                                  oversubscription.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                   RBX            RCX          RDX                \n         (In) r (In) LDU       Address of the Address of   Address of the     \n   IR    Return error Return   PAGEINFO (In)  the EPC page version-array slot \n         error                                (In)         (In)               \n\n  Description \u00b6\n\n   This leaf function copies a page from regular main memory to the EPC. As\n   part of the copying process, the page is cryptographically authenticated\n   and decrypted. This instruction can only be executed when current\n   privilege level is 0.\n\n   The ELDB leaf function sets the BLOCK bit in the EPCM entry for the\n   destination page in the EPC after copying. The ELDU leaf function clears\n   the BLOCK bit in the EPCM entry for the destination page in the EPC after\n   copying.\n\n   RBX contains the effective address of a PAGEINFO structure; RCX contains\n   the effective address of the destination EPC page; RDX holds the effective\n   address of the version array slot that holds the version of the page.\n\n   The ELDBC/ELDUC leafs are very similar to ELDB and ELDU. They provide an\n   error code on the concurrency conflict for any of the pages which need to\n   acquire a lock. These include the destination, SECS, and VA slot.\n\n   The table below provides additional information on the memory parameter of\n   ELDB/ELDU leaf functions.\n\nELDB/ELDU/ELDBC/ELBUC Memory Parameter Semantics \u00b6\n\nPAGEINFO    PAGEINFO.SRCPGE PAGEINFO.PCMD PAGEINFO.SECS EPCPAGE    Version-Array \n                                                                   Slot          \n                                          Enclave       Read/Write Read/Write    \nNon-enclave Non-enclave     Non-enclave   read/write    access     access        \nread access read access     read access   access        permitted  permitted by  \n                                                        by Enclave Enclave       \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description             \n   No Error                    ELDB/ELDU successful.   \n   SGX_MAC_COMPARE_FAIL        If the MAC check fails. \n\n   Table 38-28. ELDB/ELDU/ELDBC/ELBUC Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                                  Base Concurrency Restrictions\nLeaf        Parameter             Access    On Conflict   SGX_CONFLICT VM Exit        \n                                                          Qualification               \n            Target [DS:RCX]       Exclusive #GP           EPC_PAGE_CONFLICT_EXCEPTION \nELDB/ELDU   VA [DS:RDX]           Shared    #GP           \n            SECS                  Shared    #GP           \n            [DS:RBX]PAGEINFO.SECS \n            Target [DS:RCX]       Exclusive SGX_EPC_PAGE_ EPC_PAGE_CONFLICT_ERROR     \n                                            CONFLICT      \nELDBC/ELBUC VA [DS:RDX]           Shared    SGX_EPC_PAGE_ \n                                            CONFLICT      \n            SECS                  Shared    SGX_EPC_PAGE_ \n            [DS:RBX]PAGEINFO.SECS           CONFLICT      \n\n   Table 38-29. Base Concurrency Restrictions of ELDB/ELDU/ELDBC/ELBUC\n\n                                  Additional Concurrency Restrictions\n                                  vs. EACCEPT,                                       \n                                  EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\nLeaf        Parameter             EMODPE, EMODPR,     EINIT\n                                  EMODT      \n                                  Access     On       Access     On       Access     On       \n                                             Conflict            Conflict            Conflict \n            Target [DS:RCX]       Concurrent          Concurrent          Concurrent \nELDB/ELDU   VA [DS:RDX]           Concurrent          Concurrent          Concurrent \n            SECS                  Concurrent          Concurrent          Concurrent \n            [DS:RBX]PAGEINFO.SECS \n            Target [DS:RCX]       Concurrent          Concurrent          Concurrent \nELDBC/ELBUC VA [DS:RDX]           Concurrent          Concurrent          Concurrent \n            SECS                  Concurrent          Concurrent          Concurrent \n            [DS:RBX]PAGEINFO.SECS \n\n   Table 38-30. Additional Concurrency Restrictions of ELDB/ELDU/ELDBC/ELBUC\n\n  Flags Affected \u00b6\n\n   Sets ZF if unsuccessful, otherwise cleared and RAX returns error code.\n   Clears CF, PF, AF, OF, SF.\n"],
	["vaddph", "                        VADDPH \u2014 Add Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Add packed FP16 value \n                                                        from                  \n   EVEX.128.NP.MAP5.W0 58 /r                AVX512-FP16 xmm3/m128/m16bcst to  \n   VADDPH xmm1{k1}{z}, xmm2,      A V/V     AVX512VL    xmm2, and store       \n   xmm3/m128/m16bcst                                    result in xmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Add packed FP16 value \n                                                        from                  \n   EVEX.256.NP.MAP5.W0 58 /r                AVX512-FP16 ymm3/m256/m16bcst to  \n   VADDPH ymm1{k1}{z}, ymm2,      A V/V     AVX512VL    ymm2, and store       \n   ymm3/m256/m16bcst                                    result in ymm1        \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Add packed FP16 value \n                                                        from                  \n   EVEX.512.NP.MAP5.W0 58 /r                            zmm3/m512/m16bcst to  \n   VADDPH zmm1{k1}{z}, zmm2,      A V/V     AVX512-FP16 zmm2, and store       \n   zmm3/m512/m16bcst {er}                               result in zmm1        \n                                                        subject to writemask  \n                                                        k1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction adds packed FP16 values from source operands and stores\n   the packed FP16 result in the destination operand. The destination\n   elements are updated according to the writemask.\n"],
	["xacquire:xrelease", "             XACQUIRE/XRELEASE \u2014 Hardware Lock Elision Prefix Hints\n\n                      64/32bit Mode CPUID                                     \n   Opcode/Instruction Support       Feature Description\n                                    Flag    \n                                            A hint used with an               \n                                            \u201cXACQUIRE-enabled\u201c instruction to \n   F2 XACQUIRE        V/V           HLE^1   start lock elision on the         \n                                            instruction memory operand        \n                                            address.                          \n                                            A hint used with an               \n                                            \u201cXRELEASE-enabled\u201c instruction to \n   F3 XRELEASE        V/V           HLE     end lock elision on the           \n                                            instruction memory operand        \n                                            address.                          \n\n     1. Software is not required to check the HLE feature flag to use\n     XACQUIRE or XRELEASE, as they are treated as regular prefix if HLE\n     feature flag reports 0.\n\nDescription \u00b6\n\n   The XACQUIRE prefix is a hint to start lock elision on the memory address\n   specified by the instruction and the XRELEASE prefix is a hint to end lock\n   elision on the memory address specified by the instruction.\n\n   The XACQUIRE prefix hint can only be used with the following instructions\n   (these instructions are also referred to as XACQUIRE-enabled when used\n   with the XACQUIRE prefix):\n\n     * Instructions with an explicit LOCK prefix (F0H) prepended to forms of\n       the instruction where the destination operand is a memory operand:\n       ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCHG8B, DEC, INC, NEG, NOT,\n       OR, SBB, SUB, XOR, XADD, and XCHG.\n     * The XCHG instruction either with or without the presence of the LOCK\n       prefix.\n\n   The XRELEASE prefix hint can only be used with the following instructions\n   (also referred to as XRELEASE-enabled when used with the XRELEASE prefix):\n\n     * Instructions with an explicit LOCK prefix (F0H) prepended to forms of\n       the instruction where the destination operand is a memory operand:\n       ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCHG8B, DEC, INC, NEG, NOT,\n       OR, SBB, SUB, XOR, XADD, and XCHG.\n     * The XCHG instruction either with or without the presence of the LOCK\n       prefix.\n     * The \u201cMOV mem, reg\u201d (Opcode 88H/89H) and \u201cMOV mem, imm\u201d (Opcode\n       C6H/C7H) instructions. In these cases, the XRELEASE is recognized\n       without the presence of the LOCK prefix.\n\n   The lock variables must satisfy the guidelines described in Intel^\u00ae 64 and\n   IA-32 Architectures Software Developer\u2019s Manual, Volume 1, Section 16.3.3,\n   for elision to be successful, otherwise an HLE abort may be signaled.\n\n   If an encoded byte sequence that meets XACQUIRE/XRELEASE requirements\n   includes both prefixes, then the HLE semantic is determined by the prefix\n   byte that is placed closest to the instruction opcode. For example, an\n   F3F2C6 will not be treated as a XRELEASE-enabled instruction since the F2H\n   (XACQUIRE) is closest to the instruction opcode C6. Similarly, an F2F3F0\n   prefixed instruction will be treated as a XRELEASE-enabled instruction\n   since F3H (XRELEASE) is closest to the instruction opcode.\n\n   Intel 64 and IA-32 Compatibility\n\n   The effect of the XACQUIRE/XRELEASE prefix hint is the same in non-64-bit\n   modes and in 64-bit mode.\n\n   For instructions that do not support the XACQUIRE hint, the presence of\n   the F2H prefix behaves the same way as prior hardware, according to\n\n     * REPNE/REPNZ semantics for string instructions,\n     * Serve as SIMD prefix for legacy SIMD instructions operating on XMM\n       register\n     * Cause #UD if prepending the VEX prefix.\n     * Undefined for non-string instructions or other situations.\n\n   For instructions that do not support the XRELEASE hint, the presence of\n   the F3H prefix behaves the same way as in prior hardware, according to\n\n     * REP/REPE/REPZ semantics for string instructions,\n     * Serve as SIMD prefix for legacy SIMD instructions operating on XMM\n       register\n     * Cause #UD if prepending the VEX prefix.\n     * Undefined for non-string instructions or other situations.\n"],
	["v4fmaddps:v4fnmaddps", "      V4FMADDPS/V4FNMADDPS \u2014 Packed Single Precision Floating-Point Fused\n                           Multiply-Add(4-Iterations)\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply packed       \n                                                        single-precision      \n   EVEX.512.F2.0F38.W0 9A                               floating-point values \n   /r V4FMADDPS           A     V/V       AVX512_4FMAPS from source register  \n   zmm1{k1}{z}, zmm2+3,                                 block indicated by    \n   m128                                                 zmm2 by values from   \n                                                        m128 and accumulate   \n                                                        the result in zmm1.   \n                                                        Multiply and negate   \n                                                        packed                \n   EVEX.512.F2.0F38.W0 AA                               single-precision      \n   /r V4FNMADDPS                                        floating-point values \n   zmm1{k1}{z}, zmm2+3,   A     V/V       AVX512_4FMAPS from source register  \n   m128                                                 block indicated by    \n                                                        zmm2 by values from   \n                                                        m128 and accumulate   \n                                                        the result in zmm1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4          \n   A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   This instruction computes 4 sequential packed fused single-precision\n   floating-point multiply-add instructions with a sequentially selected\n   memory operand in each of the four steps.\n\n   In the above box, the notation of \u201c+3\u201d is used to denote that the\n   instruction accesses 4 source registers based on that operand; sources are\n   consecutive, start in a multiple of 4 boundary, and contain the encoded\n   register operand.\n\n   This instruction supports memory fault suppression. The entire memory\n   operand is loaded if any of the 16 lowest significant mask bits is set to\n   1 or if a \u201cno masking\u201d encoding is used.\n\n   The tuple type Tuple1_4X implies that four 32-bit elements (16 bytes) are\n   referenced by the memory operation portion of this instruction.\n\n   Rounding is performed at every FMA (fused multiply and add) boundary.\n   Exceptions are also taken sequentially. Pre- and post-computational\n   exceptions of the first FMA take priority over the pre- and\n   post-computational exceptions of the second FMA, etc.\n"],
	["vcvtsh2ss", "                VCVTSH2SS \u2014 Convert Low FP16 Value to FP32 Value\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert the low FP16 \n                                                         element in xmm3/m16  \n                                                         to an FP32 value and \n   EVEX.LLIG.NP.MAP6.W0 13 /r                            store in the low     \n   VCVTSH2SS xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 element of xmm1      \n   xmm3/m16 {sae}                                        subject to writemask \n                                                         k1. Bits 127:32 of   \n                                                         xmm2 are copied to   \n                                                         xmm1[127:32].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP16 element in the second source\n   operand to the low FP32 element of the destination operand.\n\n   Bits 127:32 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n"],
	["vrsqrt28pd", "   VRSQRT28PD \u2014 Approximation to the Reciprocal Square Root of Packed Double\n       PrecisionFloating-Point Values With Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes approximations   \n                                                    to the Reciprocal square  \n   EVEX.512.66.0F38.W1 CC                           root (<2^-28 relative     \n   /r VRSQRT28PD zmm1                               error) of the packed      \n   {k1}{z},                A     V/V       AVX512ER double precision          \n   zmm2/m512/m64bcst {sae}                          floating-point values     \n                                                    from zmm2/m512/m64bcst    \n                                                    and stores result in      \n                                                    zmm1with writemask k1.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2  \n   Operand 3 Operand 4                   \n   A                                     Full ModRM:reg (w) ModRM:r/m (r) \n                                         N/A N/A                          \n\n  Description \u00b6\n\n   Computes the reciprocal square root of the float64 values in the source\n   operand (the second operand) and store the results to the destination\n   operand (the first operand). The approximate reciprocal is evaluated with\n   less than 2^-28 of maximum relative error.\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. Negative (non-zero) source numbers, as well as -\u221e,\n   return the canonical NaN and set the Invalid Flag (#I).\n\n   A value of -0 must return -\u221e and set the DivByZero flags (#Z). Negative\n   numbers should return NaN and set the Invalid flag (#I). Note however that\n   the instruction flush input denormals to zero of the same sign, so\n   negative denormals return -\u221e and set the DivByZero flag.\n\n   The source operand is a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n  A numerically exact implementation of VRSQRT28xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["movd:movq", "                   MOVD/MOVQ \u2014 Move Doubleword/Move Quadword\n\n                                   64/32-bit CPUID                            \n   Opcode/Instruction       Op/ En Mode      Feature Description\n                                             Flag    \n   NP 0F 6E /r MOVD mm,     A      V/V       MMX     Move doubleword from     \n   r/m32                                             r/m32 to mm.             \n   NP REX.W + 0F 6E /r MOVQ A      V/N.E.    MMX     Move quadword from r/m64 \n   mm, r/m64                                         to mm.                   \n   NP 0F 7E /r MOVD r/m32,  B      V/V       MMX     Move doubleword from mm  \n   mm                                                to r/m32.                \n   NP REX.W + 0F 7E /r MOVQ B      V/N.E.    MMX     Move quadword from mm to \n   r/m64, mm                                         r/m64.                   \n   66 0F 6E /r MOVD xmm,    A      V/V       SSE2    Move doubleword from     \n   r/m32                                             r/m32 to xmm.            \n   66 REX.W 0F 6E /r MOVQ   A      V/N.E.    SSE2    Move quadword from r/m64 \n   xmm, r/m64                                        to xmm.                  \n   66 0F 7E /r MOVD r/m32,  B      V/V       SSE2    Move doubleword from xmm \n   xmm                                               register to r/m32.       \n   66 REX.W 0F 7E /r MOVQ   B      V/N.E.    SSE2    Move quadword from xmm   \n   r/m64, xmm                                        register to r/m64.       \n   VEX.128.66.0F.W0 6E /    A      V/V       AVX     Move doubleword from     \n   VMOVD xmm1, r32/m32                               r/m32 to xmm1.           \n   VEX.128.66.0F.W1 6E /r   A      V/N.E^1.  AVX     Move quadword from r/m64 \n   VMOVQ xmm1, r64/m64                               to xmm1.                 \n   VEX.128.66.0F.W0 7E /r   B      V/V       AVX     Move doubleword from     \n   VMOVD r32/m32, xmm1                               xmm1 register to r/m32.  \n   VEX.128.66.0F.W1 7E /r   B      V/N.E^1.  AVX     Move quadword from xmm1  \n   VMOVQ r64/m64, xmm1                               register to r/m64.       \n   EVEX.128.66.0F.W0 6E /r  C      V/V       AVX512F Move doubleword from     \n   VMOVD xmm1, r32/m32                               r/m32 to xmm1.           \n   EVEX.128.66.0F.W1 6E /r  C      V/N.E.^1  AVX512F Move quadword from r/m64 \n   VMOVQ xmm1, r64/m64                               to xmm1.                 \n   EVEX.128.66.0F.W0 7E /r  D      V/V       AVX512F Move doubleword from     \n   VMOVD r32/m32, xmm1                               xmm1 register to r/m32.  \n   EVEX.128.66.0F.W1 7E /r  D      V/N.E.^1  AVX512F Move quadword from xmm1  \n   VMOVQ r64/m64, xmm1                               register to r/m64.       \n\n     1. For this specific instruction, VEX.W/EVEX.W in non-64 bit is ignored;\n     the instruction behaves as if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A           ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Copies a doubleword from the source operand (second operand) to the\n   destination operand (first operand). The source and destination operands\n   can be general-purpose registers, MMX technology registers, XMM registers,\n   or 32-bit memory locations. This instruction can be used to move a\n   doubleword to and from the low doubleword of an MMX technology register\n   and a general-purpose register or a 32-bit memory location, or to and from\n   the low doubleword of an XMM register and a general-purpose register or a\n   32-bit memory location. The instruction cannot be used to transfer data\n   between MMX technology registers, between XMM registers, between\n   general-purpose registers, or between memory locations.\n\n   When the destination operand is an MMX technology register, the source\n   operand is written to the low doubleword of the register, and the register\n   is zero-extended to 64 bits. When the destination operand is an XMM\n   register, the source operand is written to the low doubleword of the\n   register, and the register is zero-extended to 128 bits.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\n   MOVD/Q with XMM destination:\n\n   Moves a dword/qword integer from the source operand and stores it in the\n   low 32/64-bits of the destination XMM register. The upper bits of the\n   destination are zeroed. The source operand can be a 32/64-bit register or\n   32/64-bit memory location.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged. Qword operation requires the use of\n   REX.W=1.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed. Qword operation requires the use of VEX.W=1.\n\n   EVEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed. Qword operation requires the use of EVEX.W=1.\n\n   MOVD/Q with 32/64 reg/mem destination:\n\n   Stores the low dword/qword of the source XMM register to 32/64-bit memory\n   location or general-purpose register. Qword operation requires the use of\n   REX.W=1, VEX.W=1, or EVEX.W=1.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   If VMOVD or VMOVQ is encoded with VEX.L= 1, an attempt to execute the\n   instruction encoded with VEX.L= 1 will cause an #UD exception.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["orps", "   ORPS \u2014 Bitwise Logical OR of Packed Single Precision Floating-Point Values\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature  Description\n                               Support   Flag     \n                                                  Return the bitwise logical  \n   NP 0F 56 /r ORPS xmm1,                         OR of packed single         \n   xmm2/m128              A    V/V       SSE      precision floating-point    \n                                                  values in xmm1 and          \n                                                  xmm2/mem.                   \n                                                  Return the bitwise logical  \n   VEX.128.0F 56 /r VORPS                         OR of packed single         \n   xmm1,xmm2, xmm3/m128   B    V/V       AVX      precision floating-point    \n                                                  values in xmm2 and          \n                                                  xmm3/mem.                   \n                                                  Return the bitwise logical  \n   VEX.256.0F 56 /r VORPS                         OR of packed single         \n   ymm1, ymm2, ymm3/m256  B    V/V       AVX      precision floating-point    \n                                                  values in ymm2 and          \n                                                  ymm3/mem.                   \n                                                  Return the bitwise logical  \n   EVEX.128.0F.W0 56 /r                           OR of packed single         \n   VORPS xmm1 {k1}{z},    C    V/V       AVX512VL precision floating-point    \n   xmm2,                                 AVX512DQ values in xmm2 and          \n   xmm3/m128/m32bcst                              xmm3/m128/m32bcst subject   \n                                                  to writemask k1.            \n                                                  Return the bitwise logical  \n   EVEX.256.0F.W0 56 /r                           OR of packed single         \n   VORPS ymm1 {k1}{z},    C    V/V       AVX512VL precision floating-point    \n   ymm2,                                 AVX512DQ values in ymm2 and          \n   ymm3/m256/m32bcst                              ymm3/m256/m32bcst subject   \n                                                  to writemask k1.            \n                                                  Return the bitwise logical  \n   EVEX.512.0F.W0 56 /r                           OR of packed single         \n   VORPS zmm1 {k1}{z},    C    V/V       AVX512DQ precision floating-point    \n   zmm2,                                          values in zmm2 and          \n   zmm3/m512/m32bcst                              zmm3/m512/m32bcst subject   \n                                                  to writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical OR of the four, eight or sixteen packed single\n   precision floating-point values from the first source operand and the\n   second source operand, and stores the result in the destination operand\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with write-mask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["vpermi2w:vpermi2d:vpermi2q:vpermi2ps:vpermi2pd", " VPERMI2W/VPERMI2D/VPERMI2Q/VPERMI2PS/VPERMI2PD \u2014 Full Permute From Two Tables\n                             Overwriting the Index\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Permute word integers from \n   EVEX.128.66.0F38.W1 75                          two tables in xmm3/m128    \n   /r VPERMI2W xmm1       A     V/V       AVX512VL and xmm2 using indexes in  \n   {k1}{z}, xmm2,                         AVX512BW xmm1 and store the result  \n   xmm3/m128                                       in xmm1 using writemask    \n                                                   k1.                        \n                                                   Permute word integers from \n   EVEX.256.66.0F38.W1 75                          two tables in ymm3/m256    \n   /r VPERMI2W ymm1       A     V/V       AVX512VL and ymm2 using indexes in  \n   {k1}{z}, ymm2,                         AVX512BW ymm1 and store the result  \n   ymm3/m256                                       in ymm1 using writemask    \n                                                   k1.                        \n                                                   Permute word integers from \n   EVEX.512.66.0F38.W1 75                          two tables in zmm3/m512    \n   /r VPERMI2W zmm1       A     V/V       AVX512BW and zmm2 using indexes in  \n   {k1}{z}, zmm2,                                  zmm1 and store the result  \n   zmm3/m512                                       in zmm1 using writemask    \n                                                   k1.                        \n                                                   Permute double-words from  \n   EVEX.128.66.0F38.W0 76                          two tables in              \n   /r VPERMI2D xmm1       B     V/V       AVX512VL xmm3/m128/m32bcst and xmm2 \n   {k1}{z}, xmm2,                         AVX512F  using indexes in xmm1 and  \n   xmm3/m128/m32bcst                               store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute double-words from  \n   EVEX.256.66.0F38.W0 76                          two tables in              \n   /r VPERMI2D ymm1       B     V/V       AVX512VL ymm3/m256/m32bcst and ymm2 \n   {k1}{z}, ymm2,                         AVX512F  using indexes in ymm1 and  \n   ymm3/m256/m32bcst                               store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute double-words from  \n   EVEX.512.66.0F38.W0 76                          two tables in              \n   /r VPERMI2D zmm1       B     V/V       AVX512F  zmm3/m512/m32bcst and zmm2 \n   {k1}{z}, zmm2,                                  using indices in zmm1 and  \n   zmm3/m512/m32bcst                               store the result in zmm1   \n                                                   using writemask k1.        \n                                                   Permute quad-words from    \n   EVEX.128.66.0F38.W1 76                          two tables in              \n   /r VPERMI2Q xmm1       B     V/V       AVX512VL xmm3/m128/m64bcst and xmm2 \n   {k1}{z}, xmm2,                         AVX512F  using indexes in xmm1 and  \n   xmm3/m128/m64bcst                               store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute quad-words from    \n   EVEX.256.66.0F38.W1 76                          two tables in              \n   /r VPERMI2Q ymm1       B     V/V       AVX512VL ymm3/m256/m64bcst and ymm2 \n   {k1}{z}, ymm2,                         AVX512F  using indexes in ymm1 and  \n   ymm3/m256/m64bcst                               store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute quad-words from    \n   EVEX.512.66.0F38.W1 76                          two tables in              \n   /r VPERMI2Q zmm1       B     V/V       AVX512F  zmm3/m512/m64bcst and zmm2 \n   {k1}{z}, zmm2,                                  using indices in zmm1 and  \n   zmm3/m512/m64bcst                               store the result in zmm1   \n                                                   using writemask k1.        \n                                                   Permute single-precision   \n   EVEX.128.66.0F38.W0 77                          floating-point values from \n   /r VPERMI2PS xmm1                      AVX512VL two tables in              \n   {k1}{z}, xmm2,         B     V/V       AVX512F  xmm3/m128/m32bcst and xmm2 \n   xmm3/m128/m32bcst                               using indexes in xmm1 and  \n                                                   store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute single-precision   \n   EVEX.256.66.0F38.W0 77                          floating-point values from \n   /r VPERMI2PS ymm1                      AVX512VL two tables in              \n   {k1}{z}, ymm2,         B     V/V       AVX512F  ymm3/m256/m32bcst and ymm2 \n   ymm3/m256/m32bcst                               using indexes in ymm1 and  \n                                                   store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute single-precision   \n   EVEX.512.66.0F38.W0 77                          floating-point values from \n   /r VPERMI2PS zmm1                               two tables in              \n   {k1}{z}, zmm2,         B     V/V       AVX512F  zmm3/m512/m32bcst and zmm2 \n   zmm3/m512/m32bcst                               using indices in zmm1 and  \n                                                   store the result in zmm1   \n                                                   using writemask k1.        \n                                                   Permute double precision   \n   EVEX.128.66.0F38.W1 77                          floating-point values from \n   /r VPERMI2PD xmm1                      AVX512VL two tables in              \n   {k1}{z}, xmm2,         B     V/V       AVX512F  xmm3/m128/m64bcst and xmm2 \n   xmm3/m128/m64bcst                               using indexes in xmm1 and  \n                                                   store the result in xmm1   \n                                                   using writemask k1.        \n                                                   Permute double precision   \n   EVEX.256.66.0F38.W1 77                          floating-point values from \n   /r VPERMI2PD ymm1                      AVX512VL two tables in              \n   {k1}{z}, ymm2,         B     V/V       AVX512F  ymm3/m256/m64bcst and ymm2 \n   ymm3/m256/m64bcst                               using indexes in ymm1 and  \n                                                   store the result in ymm1   \n                                                   using writemask k1.        \n                                                   Permute double precision   \n   EVEX.512.66.0F38.W1 77                          floating-point values from \n   /r VPERMI2PD zmm1                               two tables in              \n   {k1}{z}, zmm2,         B     V/V       AVX512F  zmm3/m512/m64bcst and zmm2 \n   zmm3/m512/m64bcst                               using indices in zmm1 and  \n                                                   store the result in zmm1   \n                                                   using writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (r,w)  EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Permutes 16-bit/32-bit/64-bit values in the second operand (the first\n   source operand) and the third operand (the second source operand) using\n   indices in the first operand to select elements from the second and third\n   operands. The selected elements are written to the destination operand\n   (the first operand) according to the writemask k1.\n\n   The first and second operands are ZMM/YMM/XMM registers. The first operand\n   contains input indices to select elements from the two input tables in the\n   2nd and 3rd operands. The first operand is also the destination of the\n   result.\n\n   D/Q/PS/PD element versions: The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32/64-bit memory location. Broadcast from the low\n   32/64-bit memory location is performed if EVEX.b and the id bit for table\n   selection are set (selecting table_2).\n\n   Dword/PS versions: The id bit for table selection is bit 4/3/2, depending\n   on VL=512, 256, 128. Bits [3:0]/[2:0]/[1:0] of each element in the input\n   index vector select an element within the two source operands, If the id\n   bit is 0, table_1 (the first source) is selected; otherwise the second\n   source operand is selected.\n\n   Qword/PD versions: The id bit for table selection is bit 3/2/1, and bits\n   [2:0]/[1:0] /bit 0 selects element within each input table.\n\n   Word element versions: The second source operand can be a ZMM/YMM/XMM\n   register, or a 512/256/128-bit memory location. The id bit for table\n   selection is bit 5/4/3, and bits [4:0]/[3:0]/[2:0] selects element within\n   each input table.\n\n   Note that these instructions permit a 16-bit/32-bit/64-bit value in the\n   source operands to be copied to more than one location in the destination\n   operand. Note also that in this case, the same table can be reused for\n   example for a second iteration, while the index elements are overwritten.\n\n   Bits (MAXVL-1:256/128) of the destination are zeroed for VL=256,128.\n"],
	["etrackc", "                       ETRACKC \u2014 Activates EBLOCK Checks\n\n                                  64/32 bit    CPUID                          \n   Opcode/Instruction       Op/En Mode Support Feature Description\n                                               Flag    \n                                                       This leaf function     \n   EAX = 11H ENCLS[ETRACKC] IR    V/V          EAX[6]  activates EBLOCK       \n                                                       checks.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                      RCX                          \n                     Return error Address of the destination   Address of the \n   IR    ETRACK (In) code (Out)   EPC page (In, EA)            SECS page (In, \n                                                               EA)            \n\n  Description \u00b6\n\n   The ETRACKC instruction is thread safe variant of ETRACK leaf and can be\n   executed concurrently with other CPU threads operating on the same SECS.\n\n   This leaf function provides the mechanism for hardware to track that\n   software has completed the required TLB address clears successfully. The\n   instruction can only be executed when the current privilege level is 0.\n\n   The content of RCX is an effective address of an EPC page.\n\n   The table below provides additional information on the memory parameter of\n   ETRACK leaf function.\n\nETRACKC Memory Parameter Semantics \u00b6\n\n   EPCPAGE                                \n   Read/Write access permitted by Enclave \n\n   The error codes are:\n\n   Error Code             Value Description                                   \n   No Error               0     ETRACKC successful.                           \n   SGX_EPC_PAGE_CONFLICT  7     Failure due to concurrent operation of        \n                                another SGX instruction.                      \n   SGX_PG_INVLD           6     Target page is not a VALID EPC page.          \n   SGX_PREV_TRK_INCMPL    17    All processors did not complete the previous  \n                                tracking sequence.                            \n   SGX_TRACK_NOT_REQUIRED 27    Target page type does not require tracking.   \n\n   Table 38-48. ETRACKC Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                         Base Concurrency Restrictions\n   Leaf    Parameter     Access     On Conflict   SGX_CONFLICT VM Exit        \n                                                  Qualification               \n           Target        Shared     SGX_EPC_PAGE_ \n   ETRACKC [DS:RCX]                 CONFLICT      \n           SECS implicit Concurrent \n\n   Table 38-49. Base Concurrency Restrictions of ETRACKC\n\n                  Additional Concurrency Restrictions\n                  vs. EACCEPT,                                       \n                  EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\nLeaf    Parameter EMODPE, EMODPR,     EINIT\n                  EMODT      \n                  Access     On       Access     On       Access     On Conflict  \n                             Conflict            Conflict \n        Target    Concurrent          Concurrent          Concurrent \nETRACKC [DS:RCX]  \n        SECS      Concurrent          Concurrent          Exclusive  SGX_EPC_PAGE \n        implicit                                                     _CONFLICT    \n\n   Table 38-50. Additional Concurrency Restrictions of ETRACKC\n\n  Flags Affected \u00b6\n\n   ZF is set if ETRACKC fails due to concurrent operations with another SGX\n   instructions or target page is an invalid EPC page or tracking is not\n   completed on SECS page; otherwise cleared.\n\n   CF is set if target page is not of a type that requires tracking;\n   otherwise cleared.\n\n   PF, AF, OF, and SF are cleared.\n"],
	["sha1nexte", "         SHA1NEXTE \u2014 Calculate SHA1 State Variable E After Four Rounds\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Description\n                            Support   Flag    \n                                              Calculates SHA1 state variable  \n                                              E after four rounds of          \n                                              operation from the current SHA1 \n   NP 0F 38 C8 /r                             state variable A in xmm1. The   \n   SHA1NEXTE xmm1,    RM    V/V       SHA     calculated value of the SHA1    \n   xmm2/m128                                  state variable E is added to    \n                                              the scheduled dwords in         \n                                              xmm2/m128, and stored with some \n                                              of the scheduled dwords in      \n                                              xmm1.                           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   The SHA1NEXTE calculates the SHA1 state variable E after four rounds of\n   operation from the current SHA1 state variable A in the destination\n   operand. The calculated value of the SHA1 state variable E is added to the\n   source operand, which contains the scheduled dwords.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtuw2ph", "        VCVTUW2PH \u2014 Convert Packed Unsigned Word Integers to FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert eight packed \n                                                         unsigned word        \n   EVEX.128.F2.MAP5.W0 7D /r                             integers from        \n   VCVTUW2PH xmm1{k1}{z},          A V/V     AVX512-FP16 xmm2/m128/m16bcst to \n   xmm2/m128/m16bcst                         AVX512VL    FP16 values, and     \n                                                         store the result in  \n                                                         xmm1 subject to      \n                                                         writemask k1.        \n                                                         Convert sixteen      \n                                                         packed unsigned word \n   EVEX.256.F2.MAP5.W0 7D /r                             integers from        \n   VCVTUW2PH ymm1{k1}{z},          A V/V     AVX512-FP16 ymm2/m256/m16bcst to \n   ymm2/m256/m16bcst                         AVX512VL    FP16 values, and     \n                                                         store the result in  \n                                                         ymm1 subject to      \n                                                         writemask k1.        \n                                                         Convert thirty-two   \n                                                         packed unsigned word \n   EVEX.512.F2.MAP5.W0 7D /r                             integers from        \n   VCVTUW2PH zmm1{k1}{z},          A V/V     AVX512-FP16 zmm2/m512/m16bcst to \n   zmm2/m512/m16bcst {er}                                FP16 values, and     \n                                                         store the result in  \n                                                         zmm1 subject to      \n                                                         writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed unsigned word integers in the source\n   operand to FP16 values in the destination operand. When conversion is\n   inexact, the value returned is rounded according to the rounding control\n   bits in the MXCSR register or embedded rounding controls.\n\n   The destination elements are updated according to the writemask.\n\n   If the result of the convert operation is overflow and MXCSR.OM=0 then a\n   SIMD exception will be raised with OE=1, PE=1.\n"],
	["fist:fistp", "                           FIST/FISTP \u2014 Store Integer\n\n   Opcode Instruction  64-Bit Mode Compat/Leg Mode Description                \n   DF /2  FIST m16int  Valid       Valid           Store ST(0) in m16int.     \n   DB /2  FIST m32int  Valid       Valid           Store ST(0) in m32int.     \n   DF /3  FISTP m16int Valid       Valid           Store ST(0) in m16int and  \n                                                   pop register stack.        \n   DB /3  FISTP m32int Valid       Valid           Store ST(0) in m32int and  \n                                                   pop register stack.        \n   DF /7  FISTP m64int Valid       Valid           Store ST(0) in m64int and  \n                                                   pop register stack.        \n\nDescription \u00b6\n\n   The FIST instruction converts the value in the ST(0) register to a signed\n   integer and stores the result in the destination operand. Values can be\n   stored in word or doubleword integer format. The destination operand\n   specifies the address where the first byte of the destination value is to\n   be stored.\n\n   The FISTP instruction performs the same operation as the FIST instruction\n   and then pops the register stack. To pop the register stack, the processor\n   marks the ST(0) register as empty and increments the stack pointer (TOP)\n   by 1. The FISTP instruction also stores values in quadword integer format.\n\n   The following table shows the results obtained when storing various\n   classes of numbers in integer format.\n\n   ST(0)                                                     DEST             \n   \u2212 \u221e or Value Too Large for DEST Format                    *                \n   F \u2264 \u22121                                                    \u2212I               \n   \u22121 < F < \u22120                                               **               \n   \u22120                                                        0                \n   +0                                                        0                \n   +0<F<+1                                                   **               \n   F\u2265+1                                                      +I               \n   + \u221e or Value Too Large for DEST Format                    *                \n   NaN                                                       *                \n   NOTES: F Meansfinitefloating-pointvalue. I Means integer. *\n   Indicatesfloating-pointinvalid-operation(#IA)exception. ** 0 or \u00b11,\n   depending on the rounding mode.                           \n\n   Table 3-27. FIST/FISTP Results\n\n   If the source value is a non-integral value, it is rounded to an integer\n   value, according to the rounding mode specified by the RC field of the FPU\n   control word.\n\n   If the converted value is too large for the destination format, or if the\n   source operand is an \u221e, SNaN, QNAN, or is in an unsupported format, an\n   invalid-arithmetic-operand condition is signaled. If the invalid-operation\n   exception is not masked, an invalid-arithmetic-operand exception (#IA) is\n   generated and no value is stored in the destination operand. If the\n   invalid-operation exception is masked, the integer indefinite value is\n   stored in memory.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n              Set to 0 if stack underflow occurred.                           \n   C1         Indicates rounding direction of if the inexact exception (#P)   \n              is generated: 0 := not roundup; 1 := roundup.                   \n              Set to 0 otherwise.                                             \n   C0, C2, C3 Undefined.                                                      \n"],
	["vmfunc", "                          VMFUNC \u2014 Invoke VM function\n\n   Opcode/Instruction Op/En Description                          \n   NP 0F 01 D4 VMFUNC ZO    Invoke VM function specified in EAX. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    NA        NA        NA        NA        \n\nDescription \u00b6\n\n   This instruction allows software in VMX non-root operation to invoke a VM\n   function, which is processor functionality enabled and configured by\n   software in VMX root operation. The value of EAX selects the specific VM\n   function being invoked.\n\n   The behavior of each VM function (including any additional fault checking)\n   is specified in Section 26.5.6, \u201cVM Functions.\u201d\n\nFlags Affected \u00b6\n\n   Depends on the VM function specified in EAX. See Section 26.5.6, \u201cVM\n   Functions.\u201d\n\nProtected Mode Exceptions (not including those defined by specific VM functions)\n\u00b6\n\n   #UD If executed outside VMX non-root operation.\n\n   If \u201cenable VM functions\u201d VM-execution control is 0.\n\n   If EAX \u2265 64.\n"],
	["vpmovqw:vpmovsqw:vpmovusqw", "            VPMOVQW/VPMOVSQW/VPMOVUSQW \u2014 Down Convert QWord to Word\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature  Description\n                               Support   Flag     \n                                                  Converts 2 packed quad-word \n   EVEX.128.F3.0F38.W0 34                AVX512VL integers from xmm2 into 2   \n   /r VPMOVQW xmm1/m32    A    V/V       AVX512F  packed word integers in     \n   {k1}{z}, xmm2                                  xmm1/m32 with truncation    \n                                                  under writemask k1.         \n                                                  Converts 8 packed signed    \n   EVEX.128.F3.0F38.W0 24                         quad-word integers from     \n   /r VPMOVSQW xmm1/m32   A    V/V       AVX512VL zmm2 into 8 packed signed   \n   {k1}{z}, xmm2                         AVX512F  word integers in xmm1/m32   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 2 packed unsigned  \n   EVEX.128.F3.0F38.W0 14                         quad-word integers from     \n   /r VPMOVUSQW xmm1/m32  A    V/V       AVX512VL xmm2 into 2 packed unsigned \n   {k1}{z}, xmm2                         AVX512F  word integers in xmm1/m32   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 4 packed quad-word \n   EVEX.256.F3.0F38.W0 34                AVX512VL integers from ymm2 into 4   \n   /r VPMOVQW xmm1/m64    A    V/V       AVX512F  packed word integers in     \n   {k1}{z}, ymm2                                  xmm1/m64 with truncation    \n                                                  under writemask k1.         \n                                                  Converts 4 packed signed    \n   EVEX.256.F3.0F38.W0 24                         quad-word integers from     \n   /r VPMOVSQW xmm1/m64   A    V/V       AVX512VL ymm2 into 4 packed signed   \n   {k1}{z}, ymm2                         AVX512F  word integers in xmm1/m64   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 4 packed unsigned  \n   EVEX.256.F3.0F38.W0 14                         quad-word integers from     \n   /r VPMOVUSQW xmm1/m64  A    V/V       AVX512VL ymm2 into 4 packed unsigned \n   {k1}{z}, ymm2                         AVX512F  word integers in xmm1/m64   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 8 packed quad-word \n   EVEX.512.F3.0F38.W0 34                         integers from zmm2 into 8   \n   /r VPMOVQW xmm1/m128   A    V/V       AVX512F  packed word integers in     \n   {k1}{z}, zmm2                                  xmm1/m128 with truncation   \n                                                  under writemask k1.         \n                                                  Converts 8 packed signed    \n   EVEX.512.F3.0F38.W0 24                         quad-word integers from     \n   /r VPMOVSQW xmm1/m128  A    V/V       AVX512F  zmm2 into 8 packed signed   \n   {k1}{z}, zmm2                                  word integers in xmm1/m128  \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 8 packed unsigned  \n   EVEX.512.F3.0F38.W0 14                         quad-word integers from     \n   /r VPMOVUSQW xmm1/m128 A    V/V       AVX512F  zmm2 into 8 packed unsigned \n   {k1}{z}, zmm2                                  word integers in xmm1/m128  \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Quarter Mem ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   VPMOVQW down converts 64-bit integer elements in the source operand (the\n   second operand) into packed words using truncation. VPMOVSQW converts\n   signed 64-bit integers into packed signed words using signed saturation.\n   VPMOVUSQW convert unsigned quad-word values into unsigned word values\n   using unsigned saturation.\n\n   The source operand is a ZMM/YMM/XMM register. The destination operand is a\n   XMM register or a 128/64/32-bit memory location.\n\n   Down-converted word elements are written to the destination operand (the\n   first operand) from the least-significant word. Word elements of the\n   destination operand are updated according to the writemask. Bits\n   (MAXVL-1:128/64/32) of the register destination are zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["jcc", "                         Jcc \u2014 Jump if Condition Is Met\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n   77 cb    JA rel8     D     Valid  Valid      Jump short if above (CF=0 and \n                                                ZF=0).                        \n   73 cb    JAE rel8    D     Valid  Valid      Jump short if above or equal  \n                                                (CF=0).                       \n   72 cb    JB rel8     D     Valid  Valid      Jump short if below (CF=1).   \n   76 cb    JBE rel8    D     Valid  Valid      Jump short if below or equal  \n                                                (CF=1 or ZF=1).               \n   72 cb    JC rel8     D     Valid  Valid      Jump short if carry (CF=1).   \n   E3 cb    JCXZ rel8   D     N.E.   Valid      Jump short if CX register is  \n                                                0.                            \n   E3 cb    JECXZ rel8  D     Valid  Valid      Jump short if ECX register is \n                                                0.                            \n   E3 cb    JRCXZ rel8  D     Valid  N.E.       Jump short if RCX register is \n                                                0.                            \n   74 cb    JE rel8     D     Valid  Valid      Jump short if equal (ZF=1).   \n   7F cb    JG rel8     D     Valid  Valid      Jump short if greater (ZF=0   \n                                                and SF=OF).                   \n   7D cb    JGE rel8    D     Valid  Valid      Jump short if greater or      \n                                                equal (SF=OF).                \n   7C cb    JL rel8     D     Valid  Valid      Jump short if less (SF=\u0338 OF). \n   7E cb    JLE rel8    D     Valid  Valid      Jump short if less or equal   \n                                                (ZF=1 or SF=\u0338 OF).            \n   76 cb    JNA rel8    D     Valid  Valid      Jump short if not above (CF=1 \n                                                or ZF=1).                     \n   72 cb    JNAE rel8   D     Valid  Valid      Jump short if not above or    \n                                                equal (CF=1).                 \n   73 cb    JNB rel8    D     Valid  Valid      Jump short if not below       \n                                                (CF=0).                       \n   77 cb    JNBE rel8   D     Valid  Valid      Jump short if not below or    \n                                                equal (CF=0 and ZF=0).        \n   73 cb    JNC rel8    D     Valid  Valid      Jump short if not carry       \n                                                (CF=0).                       \n   75 cb    JNE rel8    D     Valid  Valid      Jump short if not equal       \n                                                (ZF=0).                       \n   7E cb    JNG rel8    D     Valid  Valid      Jump short if not greater     \n                                                (ZF=1 or SF=\u0338 OF).            \n   7C cb    JNGE rel8   D     Valid  Valid      Jump short if not greater or  \n                                                equal (SF=\u0338 OF).              \n   7D cb    JNL rel8    D     Valid  Valid      Jump short if not less        \n                                                (SF=OF).                      \n   7F cb    JNLE rel8   D     Valid  Valid      Jump short if not less or     \n                                                equal (ZF=0 and SF=OF).       \n   71 cb    JNO rel8    D     Valid  Valid      Jump short if not overflow    \n                                                (OF=0).                       \n   7B cb    JNP rel8    D     Valid  Valid      Jump short if not parity      \n                                                (PF=0).                       \n   79 cb    JNS rel8    D     Valid  Valid      Jump short if not sign        \n                                                (SF=0).                       \n   75 cb    JNZ rel8    D     Valid  Valid      Jump short if not zero        \n                                                (ZF=0).                       \n   70 cb    JO rel8     D     Valid  Valid      Jump short if overflow        \n                                                (OF=1).                       \n   7A cb    JP rel8     D     Valid  Valid      Jump short if parity (PF=1).  \n   7A cb    JPE rel8    D     Valid  Valid      Jump short if parity even     \n                                                (PF=1).                       \n   7B cb    JPO rel8    D     Valid  Valid      Jump short if parity odd      \n                                                (PF=0).                       \n   78 cb    JS rel8     D     Valid  Valid      Jump short if sign (SF=1).    \n   74 cb    JZ rel8     D     Valid  Valid      Jump short if zero (ZF = 1).  \n                                                Jump near if above (CF=0 and  \n   0F 87 cw JA rel16    D     N.S.   Valid      ZF=0). Not supported in       \n                                                64-bit mode.                  \n   0F 87 cd JA rel32    D     Valid  Valid      Jump near if above (CF=0 and  \n                                                ZF=0).                        \n                                                Jump near if above or equal   \n   0F 83 cw JAE rel16   D     N.S.   Valid      (CF=0). Not supported in      \n                                                64-bit mode.                  \n   0F 83 cd JAE rel32   D     Valid  Valid      Jump near if above or equal   \n                                                (CF=0).                       \n   0F 82 cw JB rel16    D     N.S.   Valid      Jump near if below (CF=1).    \n                                                Not supported in 64-bit mode. \n   0F 82 cd JB rel32    D     Valid  Valid      Jump near if below (CF=1).    \n                                                Jump near if below or equal   \n   0F 86 cw JBE rel16   D     N.S.   Valid      (CF=1 or ZF=1). Not supported \n                                                in 64-bit mode.               \n   0F 86 cd JBE rel32   D     Valid  Valid      Jump near if below or equal   \n                                                (CF=1 or ZF=1).               \n   0F 82 cw JC rel16    D     N.S.   Valid      Jump near if carry (CF=1).    \n                                                Not supported in 64-bit mode. \n   0F 82 cd JC rel32    D     Valid  Valid      Jump near if carry (CF=1).    \n   0F 84 cw JE rel16    D     N.S.   Valid      Jump near if equal (ZF=1).    \n                                                Not supported in 64-bit mode. \n   0F 84 cd JE rel32    D     Valid  Valid      Jump near if equal (ZF=1).    \n   0F 84 cw JZ rel16    D     N.S.   Valid      Jump near if 0 (ZF=1). Not    \n                                                supported in 64-bit mode.     \n   0F 84 cd JZ rel32    D     Valid  Valid      Jump near if 0 (ZF=1).        \n                                                Jump near if greater (ZF=0    \n   0F 8F cw JG rel16    D     N.S.   Valid      and SF=OF). Not supported in  \n                                                64-bit mode.                  \n   0F 8F cd JG rel32    D     Valid  Valid      Jump near if greater (ZF=0    \n                                                and SF=OF).                   \n                                                Jump near if greater or equal \n   0F 8D cw JGE rel16   D     N.S.   Valid      (SF=OF). Not supported in     \n                                                64-bit mode.                  \n   0F 8D cd JGE rel32   D     Valid  Valid      Jump near if greater or equal \n                                                (SF=OF).                      \n   0F 8C cw JL rel16    D     N.S.   Valid      Jump near if less (SF=\u0338 OF).  \n                                                Not supported in 64-bit mode. \n   0F 8C cd JL rel32    D     Valid  Valid      Jump near if less (SF=\u0338 OF).  \n                                                Jump near if less or equal    \n   0F 8E cw JLE rel16   D     N.S.   Valid      (ZF=1 or SF=\u0338 OF). Not        \n                                                supported in 64-bit mode.     \n   0F 8E cd JLE rel32   D     Valid  Valid      Jump near if less or equal    \n                                                (ZF=1 or SF=\u0338 OF).            \n                                                Jump near if not above (CF=1  \n   0F 86 cw JNA rel16   D     N.S.   Valid      or ZF=1). Not supported in    \n                                                64-bit mode.                  \n   0F 86 cd JNA rel32   D     Valid  Valid      Jump near if not above (CF=1  \n                                                or ZF=1).                     \n                                                Jump near if not above or     \n   0F 82 cw JNAE rel16  D     N.S.   Valid      equal (CF=1). Not supported   \n                                                in 64-bit mode.               \n   0F 82 cd JNAE rel32  D     Valid  Valid      Jump near if not above or     \n                                                equal (CF=1).                 \n                                                Jump near if not below        \n   0F 83 cw JNB rel16   D     N.S.   Valid      (CF=0). Not supported in      \n                                                64-bit mode.                  \n   0F 83 cd JNB rel32   D     Valid  Valid      Jump near if not below        \n                                                (CF=0).                       \n                                                Jump near if not below or     \n   0F 87 cw JNBE rel16  D     N.S.   Valid      equal (CF=0 and ZF=0). Not    \n                                                supported in 64-bit mode.     \n   0F 87 cd JNBE rel32  D     Valid  Valid      Jump near if not below or     \n                                                equal (CF=0 and ZF=0).        \n                                                Jump near if not carry        \n   0F 83 cw JNC rel16   D     N.S.   Valid      (CF=0). Not supported in      \n                                                64-bit mode.                  \n   0F 83 cd JNC rel32   D     Valid  Valid      Jump near if not carry        \n                                                (CF=0).                       \n                                                Jump near if not equal        \n   0F 85 cw JNE rel16   D     N.S.   Valid      (ZF=0). Not supported in      \n                                                64-bit mode.                  \n   0F 85 cd JNE rel32   D     Valid  Valid      Jump near if not equal        \n                                                (ZF=0).                       \n                                                Jump near if not greater      \n   0F 8E cw JNG rel16   D     N.S.   Valid      (ZF=1 or SF=\u0338 OF). Not        \n                                                supported in 64-bit mode.     \n   0F 8E cd JNG rel32   D     Valid  Valid      Jump near if not greater      \n                                                (ZF=1 or SF=\u0338 OF).            \n                                                Jump near if not greater or   \n   0F 8C cw JNGE rel16  D     N.S.   Valid      equal (SF=\u0338 OF). Not          \n                                                supported in 64-bit mode.     \n   0F 8C cd JNGE rel32  D     Valid  Valid      Jump near if not greater or   \n                                                equal (SF=\u0338 OF).              \n                                                Jump near if not less         \n   0F 8D cw JNL rel16   D     N.S.   Valid      (SF=OF). Not supported in     \n                                                64-bit mode.                  \n   0F 8D cd JNL rel32   D     Valid  Valid      Jump near if not less         \n                                                (SF=OF).                      \n                                                Jump near if not less or      \n   0F 8F cw JNLE rel16  D     N.S.   Valid      equal (ZF=0 and SF=OF). Not   \n                                                supported in 64-bit mode.     \n   0F 8F cd JNLE rel32  D     Valid  Valid      Jump near if not less or      \n                                                equal (ZF=0 and SF=OF).       \n                                                Jump near if not overflow     \n   0F 81 cw JNO rel16   D     N.S.   Valid      (OF=0). Not supported in      \n                                                64-bit mode.                  \n   0F 81 cd JNO rel32   D     Valid  Valid      Jump near if not overflow     \n                                                (OF=0).                       \n                                                Jump near if not parity       \n   0F 8B cw JNP rel16   D     N.S.   Valid      (PF=0). Not supported in      \n                                                64-bit mode.                  \n   0F 8B cd JNP rel32   D     Valid  Valid      Jump near if not parity       \n                                                (PF=0).                       \n   0F 89 cw JNS rel16   D     N.S.   Valid      Jump near if not sign (SF=0). \n                                                Not supported in 64-bit mode. \n   0F 89 cd JNS rel32   D     Valid  Valid      Jump near if not sign (SF=0). \n   0F 85 cw JNZ rel16   D     N.S.   Valid      Jump near if not zero (ZF=0). \n                                                Not supported in 64-bit mode. \n   0F 85 cd JNZ rel32   D     Valid  Valid      Jump near if not zero (ZF=0). \n   0F 80 cw JO rel16    D     N.S.   Valid      Jump near if overflow (OF=1). \n                                                Not supported in 64-bit mode. \n   0F 80 cd JO rel32    D     Valid  Valid      Jump near if overflow (OF=1). \n   0F 8A cw JP rel16    D     N.S.   Valid      Jump near if parity (PF=1).   \n                                                Not supported in 64-bit mode. \n   0F 8A cd JP rel32    D     Valid  Valid      Jump near if parity (PF=1).   \n                                                Jump near if parity even      \n   0F 8A cw JPE rel16   D     N.S.   Valid      (PF=1). Not supported in      \n                                                64-bit mode.                  \n   0F 8A cd JPE rel32   D     Valid  Valid      Jump near if parity even      \n                                                (PF=1).                       \n                                                Jump near if parity odd       \n   0F 8B cw JPO rel16   D     N.S.   Valid      (PF=0). Not supported in      \n                                                64-bit mode.                  \n   0F 8B cd JPO rel32   D     Valid  Valid      Jump near if parity odd       \n                                                (PF=0).                       \n   0F 88 cw JS rel16    D     N.S.   Valid      Jump near if sign (SF=1). Not \n                                                supported in 64-bit mode.     \n   0F 88 cd JS rel32    D     Valid  Valid      Jump near if sign (SF=1).     \n   0F 84 cw JZ rel16    D     N.S.   Valid      Jump near if 0 (ZF=1). Not    \n                                                supported in 64-bit mode.     \n   0F 84 cd JZ rel32    D     Valid  Valid      Jump near if 0 (ZF=1).        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   D     Offset    N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Checks the state of one or more of the status flags in the EFLAGS register\n   (CF, OF, PF, SF, and ZF) and, if the flags are in the specified state\n   (condition), performs a jump to the target instruction specified by the\n   destination operand. A condition code (cc) is associated with each\n   instruction to indicate the condition being tested for. If the condition\n   is not satisfied, the jump is not performed and execution continues with\n   the instruction following the Jcc instruction.\n\n   The target instruction is specified with a relative offset (a signed\n   offset relative to the current value of the instruction pointer in the EIP\n   register). A relative offset (rel8, rel16, or rel32) is generally\n   specified as a label in assembly code, but at the machine code level, it\n   is encoded as a signed, 8-bit or 32-bit immediate value, which is added to\n   the instruction pointer. Instruction coding is most efficient for offsets\n   of \u2013128 to +127. If the operand-size attribute is 16, the upper two bytes\n   of the EIP register are cleared, resulting in a maximum instruction\n   pointer size of 16 bits.\n\n   The conditions for each Jcc mnemonic are given in the \u201cDescription\u201d column\n   of the table on the preceding page. The terms \u201cless\u201d and \u201cgreater\u201d are\n   used for comparisons of signed integers and the terms \u201cabove\u201d and \u201cbelow\u201d\n   are used for unsigned integers.\n\n   Because a particular state of the status flags can sometimes be\n   interpreted in two ways, two mnemonics are defined for some opcodes. For\n   example, the JA (jump if above) instruction and the JNBE (jump if not\n   below or equal) instruction are alternate mnemonics for the opcode 77H.\n\n   The Jcc instruction does not support far jumps (jumps to other code\n   segments). When the target for the conditional jump is in a different\n   segment, use the opposite condition from the condition being tested for\n   the Jcc instruction, and then access the target with an unconditional far\n   jump (JMP instruction) to the other segment. For example, the following\n   conditional far jump is illegal:\n\n   JZ FARLABEL;\n\n   To accomplish this far jump, use the following two instructions:\n\n   JNZ BEYOND;\n\n   JMP FARLABEL;\n\n   BEYOND:\n\n   The JRCXZ, JECXZ, and JCXZ instructions differ from other Jcc instructions\n   because they do not check status flags. Instead, they check RCX, ECX or CX\n   for 0. The register checked is determined by the address-size attribute.\n   These instructions are useful when used at the beginning of a loop that\n   terminates with a conditional loop instruction (such as LOOPNE). They can\n   be used to prevent an instruction sequence from entering a loop when RCX,\n   ECX or CX is 0. This would cause the loop to execute 2^64, 2^32 or 64K\n   times (not zero times).\n\n   All conditional jumps are converted to code fetches of one or two cache\n   lines, regardless of jump address or cache-ability.\n\n   In 64-bit mode, operand size is fixed at 64 bits. JMP Short is RIP = RIP +\n   8-bit offset sign extended to 64 bits. JMP Near is RIP = RIP + 32-bit\n   offset sign extended to 64 bits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["phaddsw", "                  PHADDSW \u2014 Packed Horizontal Add and Saturate\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n                                                     Add 16-bit signed        \n   NP 0F 38 03 /r^1 PHADDSW  RM    V/V       SSSE3   integers horizontally,   \n   mm1, mm2/m64                                      pack saturated integers  \n                                                     to mm1.                  \n                                                     Add 16-bit signed        \n   66 0F 38 03 /r PHADDSW    RM    V/V       SSSE3   integers horizontally,   \n   xmm1, xmm2/m128                                   pack saturated integers  \n                                                     to xmm1.                 \n   VEX.128.66.0F38.WIG 03 /r                         Add 16-bit signed        \n   VPHADDSW xmm1, xmm2,      RVM   V/V       AVX     integers horizontally,   \n   xmm3/m128                                         pack saturated integers  \n                                                     to xmm1.                 \n   VEX.256.66.0F38.WIG 03 /r                         Add 16-bit signed        \n   VPHADDSW ymm1, ymm2,      RVM   V/V       AVX2    integers horizontally,   \n   ymm3/m256                                         pack saturated integers  \n                                                     to ymm1.                 \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   (V)PHADDSW adds two adjacent signed 16-bit integers horizontally from the\n   source and destination operands and saturates the signed results; packs\n   the signed, saturated 16-bit results to the destination operand (first\n   operand) When the source operand is a 128-bit memory operand, the operand\n   must be aligned on a 16-byte boundary or a general-protection exception\n   (#GP) will be generated.\n\n   Legacy SSE version: Both operands can be MMX registers. The second source\n   operand can be an MMX register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   In 64-bit mode, use the REX prefix to access additional registers.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: The first source and destination operands are YMM\n   registers. The second source operand can be an YMM register or a 256-bit\n   memory location.\n"],
	["vpblendd", "                         VPBLENDD \u2014 Blend Packed Dwords\n\n                                  64/32     CPUID                             \n   Opcode/Instruction       Op/En -bit Mode Feature Description\n                                            Flag    \n                                                    Select dwords from xmm2   \n   VEX.128.66.0F3A.W0 02 /r                         and xmm3/m128 from mask   \n   ib VPBLENDD xmm1, xmm2,  RVMI  V/V       AVX2    specified in imm8 and     \n   xmm3/m128, imm8                                  store the values into     \n                                                    xmm1.                     \n                                                    Select dwords from ymm2   \n   VEX.256.66.0F3A.W0 02 /r                         and ymm3/m256 from mask   \n   ib VPBLENDD ymm1, ymm2,  RVMI  V/V       AVX2    specified in imm8 and     \n   ymm3/m256, imm8                                  store the values into     \n                                                    ymm1.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3     Operand 4 \n   RVMI  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Dword elements from the source operand (second operand) are conditionally\n   written to the destination operand (first operand) depending on bits in\n   the immediate operand (third operand). The immediate bits (bits 7:0) form\n   a mask that determines whether the corresponding dword in the destination\n   is copied from the source. If a bit in the mask, corresponding to a dword,\n   is \u201c1\", then the dword is copied, else the dword is unchanged.\n\n   VEX.128 encoded version: The second source operand can be an XMM register\n   or a 128-bit memory location. The first source and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM register\n   are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n"],
	["mulss", "         MULSS \u2014 Multiply Scalar Single Precision Floating-Point Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Multiply the low single    \n                                                   precision floating-point   \n   F3 0F 59 /r MULSS        A    V/V       SSE     value in xmm2/m32 by the   \n   xmm1,xmm2/m32                                   low single precision       \n                                                   floating-point value in    \n                                                   xmm1.                      \n                                                   Multiply the low single    \n   VEX.LIG.F3.0F.WIG 59 /r                         precision floating-point   \n   VMULSS xmm1,xmm2,        B    V/V       AVX     value in xmm3/m32 by the   \n   xmm3/m32                                        low single precision       \n                                                   floating-point value in    \n                                                   xmm2.                      \n                                                   Multiply the low single    \n   EVEX.LLIG.F3.0F.W0 59 /r                        precision floating-point   \n   VMULSS xmm1 {k1}{z},     C    V/V       AVX512F value in xmm3/m32 by the   \n   xmm2, xmm3/m32 {er}                             low single precision       \n                                                   floating-point value in    \n                                                   xmm2.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Multiplies the low single precision floating-point value from the second\n   source operand by the low single precision floating-point value in the\n   first source operand, and stores the single precision floating-point\n   result in the destination operand. The second source operand can be an XMM\n   register or a 32-bit memory location. The first source operand and the\n   destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:32) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 and EVEX encoded version: The first source operand is an xmm\n   register encoded by VEX.vvvv. The three high-order doublewords of the\n   destination operand are copied from the first source operand. Bits\n   (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination\n   operand is updated according to the write-mask.\n\n   Software should ensure VMULSS is encoded with VEX.L=0. Encoding VMULSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["kandnw:kandnb:kandnq:kandnd", "          KANDNW/KANDNB/KANDNQ/KANDND \u2014 Bitwise Logical AND NOT Masks\n\n                               64/32 bit    CPUID                             \n   Opcode/Instruction    Op/En Mode Support Feature  Description\n                                            Flag     \n   VEX.L1.0F.W0 42 /r                                Bitwise AND NOT 16 bits  \n   KANDNW k1, k2, k3     RVR   V/V          AVX512F  masks k2 and k3 and      \n                                                     place result in k1.      \n   VEX.L1.66.0F.W0 42 /r                             Bitwise AND NOT 8 bits   \n   KANDNB k1, k2, k3     RVR   V/V          AVX512DQ masks k1 and k2 and      \n                                                     place result in k1.      \n   VEX.L1.0F.W1 42 /r                                Bitwise AND NOT 64 bits  \n   KANDNQ k1, k2, k3     RVR   V/V          AVX512BW masks k2 and k3 and      \n                                                     place result in k1.      \n   VEX.L1.66.0F.W1 42 /r                             Bitwise AND NOT 32 bits  \n   KANDND k1, k2, k3     RVR   V/V          AVX512BW masks k2 and k3 and      \n                                                     place result in k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3                              \n   RVR   ModRM:reg (w) VEX.1vvv (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise AND NOT between the vector mask k2 and the vector mask\n   k3, and writes the result into vector mask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vscalefps", "          VSCALEFPS \u2014 Scale Packed Float32 Values With Float32 Values\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Scale the packed           \n   EVEX.128.66.0F38.W0 2C                          single-precision           \n   /r VSCALEFPS xmm1      A     V/V       AVX512VL floating-point values in   \n   {k1}{z}, xmm2,                         AVX512F  xmm2 using values from     \n   xmm3/m128/m32bcst                               xmm3/m128/m32bcst. Under   \n                                                   writemask k1.              \n                                                   Scale the packed           \n   EVEX.256.66.0F38.W0 2C                          single-precision values in \n   /r VSCALEFPS ymm1      A     V/V       AVX512VL ymm2 using floating-point  \n   {k1}{z}, ymm2,                         AVX512F  values from                \n   ymm3/m256/m32bcst                               ymm3/m256/m32bcst. Under   \n                                                   writemask k1.              \n                                                   Scale the packed           \n   EVEX.512.66.0F38.W0 2C                          single-precision           \n   /r VSCALEFPS zmm1                               floating-point values in   \n   {k1}{z}, zmm2,         A     V/V       AVX512F  zmm2 using floating-point  \n   zmm3/m512/m32bcst{er}                           values from                \n                                                   zmm3/m512/m32bcst. Under   \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a floating-point scale of the packed single-precision\n   floating-point values in the first source operand by multiplying them by 2\n   to the power of the float32 values in second source operand.\n\n   The equation of this operation is given by:\n\n   zmm1 := zmm2*2^floor(zmm3).\n\n   Floor(zmm3) means maximum integer value \u2264 zmm3.\n\n   If the result cannot be represented in single-precision, then the proper\n   overflow response (for positive scaling operand), or the proper underflow\n   response (for negative scaling operand) is issued. The overflow and\n   underflow responses are dependent on the rounding mode (for IEEE-compliant\n   rounding), as well as on other settings in MXCSR (exception mask bits, FTZ\n   bit), and on the SAE bit.\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand is a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a ZMM register conditionally updated with writemask k1.\n\n   EVEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register, a 256-bit memory location, or a\n   256-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a YMM register, conditionally updated using writemask k1.\n\n   EVEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is a XMM register, a 128-bit memory location, or a\n   128-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a XMM register, conditionally updated using writemask k1.\n\n   Handling of special-case input values are listed in Table 5-39 and Table\n   5-43.\n\n   Special Case      Returned value                              Faults    \n   |result| < 2^-149 \u00b10 or \u00b1Min-Denormal (Src1 sign)             Underflow \n   |result| \u2265 2^128  \u00b1INF (Src1 sign) or \u00b1Max-normal (Src1 sign) Overflow  \n\n   Table 5-43. Additional VSCALEFPS/SS Special Cases\n"],
	["sha256msg2", "SHA256MSG2 \u2014 Perform a Final Calculation for the Next Four SHA256 Message Dwords\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Description\n                            Support   Flag    \n                                              Performs the final calculation  \n   NP 0F 38 CD /r                             for the next four SHA256        \n   SHA256MSG2 xmm1,   RM    V/V       SHA     message dwords using previous   \n   xmm2/m128                                  message dwords from xmm1 and    \n                                              xmm2/m128, storing the result   \n                                              in xmm1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   The SHA256MSG2 instruction is one of two SHA2 message scheduling\n   instructions. The instruction performs the final calculation for the next\n   four SHA256 message dwords.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["emodpr", "                EMODPR \u2014 Restrict the Permissions of an EPC Page\n\n                                 64/32 bit    CPUID                           \n   Opcode/Instruction      Op/En Mode Support Feature Description\n                                              Flag    \n                                                      This leaf function      \n                                                      restricts the access    \n   EAX = 0EH ENCLS[EMODPR] IR    V/V          SGX2    rights associated with  \n                                                      a EPC page in an        \n                                                      initialized enclave.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                      RBX          RCX                            \n   IR    EMODPR (In) Return Error Address of a Address of the destination EPC \n                     Code (Out)   SECINFO (In) page (In)                      \n\n  Description \u00b6\n\n   This leaf function restricts the access rights associated with an EPC page\n   in an initialized enclave. THE RWX bits of the SECINFO parameter are\n   treated as a permissions mask; supplying a value that does not restrict\n   the page permissions will have no effect. This instruction can only be\n   executed when current privilege level is 0.\n\n   RBX contains the effective address of a SECINFO structure while RCX\n   contains the effective address of an EPC page. The table below provides\n   additional information on the memory parameter of the EMODPR leaf\n   function.\n\nEMODPR Memory Parameter Semantics \u00b6\n\n   SECINFO                              EPCPAGE                               \n   Read access permitted by Non Enclave Read/Write access permitted by        \n                                        Enclave                               \n\n   The instruction faults if any of the following:\n\nEMODPR Faulting Conditions \u00b6\n\n   The operands are not properly   If unsupported security attributes are     \n   aligned.                        set.                                       \n   The Enclave is not initialized. SECS is locked by another thread.          \n   The EPC page is locked by       RCX does not contain an effective address  \n   another thread.                 of an EPC page in the running enclave.     \n   The EPC page is not valid.      \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EMODPR successful.                             \n   SGX_PAGE_NOT_MODIFIABLE     The EPC page cannot be modified because it is  \n                               in the PENDING or MODIFIED state.              \n   SGX_EPC_PAGE_CONFLICT       Page is being written by EADD, EAUG, ECREATE,  \n                               ELDU/B, EMODT, or EWB.                         \n\n   Table 38-31. EMODPR Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                         Parameter       Base Concurrency Restrictions\n                                                       On Conflict      \n   EMODPR EMODPR Target                         \n   [DS:RCX] Shared EMODPR       Target [DS:RCX]\n   Target [DS:RCX]              \n\n   Table 38-32. Base Concurrency Restrictions of EMODPR\n\n                  Additional Concurrency Restrictions\n                  vs. EACCEPT,           vs. EADD, EEXTEND,             \n Leaf   Parameter EACCEPTCOPY, EMODPE,   EINIT               vs. ETRACK, ETRACKC\n                  EMODPR, EMODT\n                  Access    On Conflict  Access     On       Access     On       \n                                                    Conflict            Conflict \n EMODPR Target    Exclusive SGX_EPC_PAGE Concurrent          Concurrent \n        [DS:RCX]            _CONFLICT    \n\n   Table 38-33. Additional Concurrency Restrictions of EMODPR\n\n  Flags Affected \u00b6\n\n   Sets ZF if page is not modifiable or if other SGX2 instructions are\n   executing concurrently, otherwise cleared. Clears CF, PF, AF, OF, SF.\n"],
	["pandn", "                            PANDN \u2014 Logical AND NOT\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F DF /r^1 PANDN mm, A     V/V       MMX      Bitwise AND NOT of mm/m64 \n   mm/m64                                           and mm.                   \n   66 0F DF /r PANDN xmm1, A     V/V       SSE2     Bitwise AND NOT of        \n   xmm2/m128                                        xmm2/m128 and xmm1.       \n   VEX.128.66.0F.WIG DF /r                          Bitwise AND NOT of        \n   VPANDN xmm1, xmm2,      B     V/V       AVX      xmm3/m128 and xmm2.       \n   xmm3/m128               \n   VEX.256.66.0F.WIG DF /r                          Bitwise AND NOT of ymm2,  \n   VPANDN ymm1, ymm2,      B     V/V       AVX2     and ymm3/m256 and store   \n   ymm3/m256                                        result in ymm1.           \n                                                    Bitwise AND NOT of packed \n   EVEX.128.66.0F.W0 DF /r                          doubleword integers in    \n   VPANDND xmm1 {k1}{z},   C     V/V       AVX512VL xmm2 and                  \n   xmm2, xmm3/m128/m32bcst                 AVX512F  xmm3/m128/m32bcst and     \n                                                    store result in xmm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND NOT of packed \n   EVEX.256.66.0F.W0 DF /r                          doubleword integers in    \n   VPANDND ymm1 {k1}{z},   C     V/V       AVX512VL ymm2 and                  \n   ymm2, ymm3/m256/m32bcst                 AVX512F  ymm3/m256/m32bcst and     \n                                                    store result in ymm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND NOT of packed \n   EVEX.512.66.0F.W0 DF /r                          doubleword integers in    \n   VPANDND zmm1 {k1}{z},   C     V/V       AVX512F  zmm2 and                  \n   zmm2, zmm3/m512/m32bcst                          zmm3/m512/m32bcst and     \n                                                    store result in zmm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND NOT of packed \n   EVEX.128.66.0F.W1 DF /r                 AVX512VL quadword integers in xmm2 \n   VPANDNQ xmm1 {k1}{z},   C     V/V       AVX512F  and xmm3/m128/m64bcst and \n   xmm2, xmm3/m128/m64bcst                          store result in xmm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND NOT of packed \n   EVEX.256.66.0F.W1 DF /r                 AVX512VL quadword integers in ymm2 \n   VPANDNQ ymm1 {k1}{z},   C     V/V       AVX512F  and ymm3/m256/m64bcst and \n   ymm2, ymm3/m256/m64bcst                          store result in ymm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND NOT of packed \n   EVEX.512.66.0F.W1 DF /r                          quadword integers in zmm2 \n   VPANDNQ zmm1 {k1}{z},   C     V/V       AVX512F  and zmm3/m512/m64bcst and \n   zmm2, zmm3/m512/m64bcst                          store result in zmm1      \n                                                    using writemask k1.       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical NOT operation on the first source operand, then\n   performs bitwise AND with second source operand and stores the result in\n   the destination operand. Each bit of the result is set to 1 if the\n   corresponding bit in the first operand is 0 and the corresponding bit in\n   the second operand is 1, otherwise it is set to 0.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with write-mask k1 at 32/64-bit granularity.\n\n   VEX.256 encoded versions: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded versions: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vextracti128:vextracti32x4:vextracti64x2:vextracti32x8:vextracti64x4", "     VEXTRACTI128/VEXTRACTI32x4/VEXTRACTI64x2/VEXTRACTI32x8/VEXTRACTI64x4 \u2014\n                          ExtractPacked Integer Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n   VEX.256.66.0F3A.W0 39 /r                           Extract 128 bits of     \n   ib VEXTRACTI128           A     V/V       AVX2     integer data from ymm2  \n   xmm1/m128, ymm2, imm8                              and store results in    \n                                                      xmm1/m128.              \n                                                      Extract 128 bits of     \n   EVEX.256.66.0F3A.W0 39 /r                          double-word integer     \n   ib VEXTRACTI32X4          C     V/V       AVX512VL values from ymm2 and    \n   xmm1/m128 {k1}{z}, ymm2,                  AVX512F  store results in        \n   imm8                                               xmm1/m128 subject to    \n                                                      writemask k1.           \n                                                      Extract 128 bits of     \n   EVEX.512.66.0F3A.W0 39 /r                          double-word integer     \n   ib VEXTRACTI32x4          C     V/V       AVX512F  values from zmm2 and    \n   xmm1/m128 {k1}{z}, zmm2,                           store results in        \n   imm8                                               xmm1/m128 subject to    \n                                                      writemask k1.           \n                                                      Extract 128 bits of     \n   EVEX.256.66.0F3A.W1 39 /r                          quad-word integer       \n   ib VEXTRACTI64X2          B     V/V       AVX512VL values from ymm2 and    \n   xmm1/m128 {k1}{z}, ymm2,                  AVX512DQ store results in        \n   imm8                                               xmm1/m128 subject to    \n                                                      writemask k1.           \n                                                      Extract 128 bits of     \n   EVEX.512.66.0F3A.W1 39 /r                          quad-word integer       \n   ib VEXTRACTI64X2          B     V/V       AVX512DQ values from zmm2 and    \n   xmm1/m128 {k1}{z}, zmm2,                           store results in        \n   imm8                                               xmm1/m128 subject to    \n                                                      writemask k1.           \n                                                      Extract 256 bits of     \n   EVEX.512.66.0F3A.W0 3B /r                          double-word integer     \n   ib VEXTRACTI32X8          D     V/V       AVX512DQ values from zmm2 and    \n   ymm1/m256 {k1}{z}, zmm2,                           store results in        \n   imm8                                               ymm1/m256 subject to    \n                                                      writemask k1.           \n                                                      Extract 256 bits of     \n   EVEX.512.66.0F3A.W1 3B /r                          quad-word integer       \n   ib VEXTRACTI64x4          C     V/V       AVX512F  values from zmm2 and    \n   ymm1/m256 {k1}{z}, zmm2,                           store results in        \n   imm8                                               ymm1/m256 subject to    \n                                                      writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   B     Tuple2     ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   C     Tuple4     ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   D     Tuple8     ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n\n  Description \u00b6\n\n   VEXTRACTI128/VEXTRACTI32x4 and VEXTRACTI64x2 extract 128-bits of\n   doubleword integer values from the source operand (the second operand) and\n   store to the low 128-bit of the destination operand (the first operand).\n   The 128-bit data extraction occurs at an 128-bit granular offset specified\n   by imm8[0] (256-bit) or imm8[1:0] as the multiply factor. The destination\n   may be either a vector register or an 128-bit memory location.\n\n   VEXTRACTI32x4: The low 128-bit of the destination operand is updated at\n   32-bit granularity according to the writemask.\n\n   VEXTRACTI64x2: The low 128-bit of the destination operand is updated at\n   64-bit granularity according to the writemask.\n\n   VEXTRACTI32x8 and VEXTRACTI64x4 extract 256-bits of quadword integer\n   values from the source operand (the second operand) and store to the low\n   256-bit of the destination operand (the first operand). The 256-bit data\n   extraction occurs at an 256-bit granular offset specified by imm8[0]\n   (256-bit) or imm8[0] as the multiply factor The destination may be either\n   a vector register or a 256-bit memory location.\n\n   VEXTRACTI32x8: The low 256-bit of the destination operand is updated at\n   32-bit granularity according to the writemask.\n\n   VEXTRACTI64x4: The low 256-bit of the destination operand is updated at\n   64-bit granularity according to the writemask.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   The high 7 bits (6 bits in EVEX.512) of the immediate are ignored.\n\n   If VEXTRACTI128 is encoded with VEX.L= 0, an attempt to execute the\n   instruction encoded with VEX.L= 0 will cause an #UD exception.\n"],
	["fsin", "                                  FSIN \u2014 Sine\n\n   Opcode  Mode Leg Mode Description                                     \n   D9 FE                 Replace ST(0) with the approximate of its sine. \n\nDescription \u00b6\n\n   Computes an approximation of the sine of the source operand in register\n   ST(0) and stores the result in ST(0). The source operand must be given in\n   radians and must be within the range \u22122^63 to +2^63. The following table\n   shows the results obtained when taking the sine of various classes of\n   numbers, assuming that underflow does not occur.\n\n   SRC (ST(0)) DEST (ST(0)) \n   \u2212\u221e          *            \n   \u2212F          \u2212 1 to + 1   \n   \u22120          \u22120           \n   +0          +0           \n   +F          \u2212 1 to +1    \n   +\u221e          *            \n   NaN         NaN          \n\n   Table 3-35. FSIN Results\n\n     F Means finite floating-point value.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   If the source operand is outside the acceptable range, the C2 flag in the\n   FPU status word is set, and the value in register ST(0) remains unchanged.\n   The instruction does not raise an exception when the source operand is out\n   of range. It is up to the program to check the C2 flag for out-of-range\n   conditions. Source values outside the range \u2212 2^63 to +2^63 can be reduced\n   to the range of the instruction by subtracting an appropriate integer\n   multiple of 2\u03c0. However, even within the range -2^63 to +2^63, inaccurate\n   results can occur because the finite approximation of \u03c0 used internally\n   for argument reduction is not sufficient in all cases. Therefore, for\n   accurate results it is safe to apply FSIN only to arguments reduced\n   accurately in software, to a value smaller in absolute value than 3\u03c0/4.\n   See the sections titled \u201cApproximation of Pi\u201d and \u201cTranscendental\n   Instruction Accuracy\u201d in Chapter 8 of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a discussion of\n   the proper value to use for \u03c0 in performing such reductions.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n          Set to 0 if stack underflow occurred.                               \n   C1     Set if result was rounded up; cleared otherwise.                    \n          Set to 1 if outside range (\u2212263 < source operand < +263);           \n          otherwise, set to 0.                                                \n   C2     \n   C0, C3 Undefined.                                                          \n"],
	["movaps", "      MOVAPS \u2014 Move Aligned Packed Single Precision Floating-Point Values\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Move aligned packed       \n   NP 0F 28 /r MOVAPS      A     V/V       SSE      single precision          \n   xmm1, xmm2/m128                                  floating-point values     \n                                                    from xmm2/mem to xmm1.    \n                                                    Move aligned packed       \n   NP 0F 29 /r MOVAPS      B     V/V       SSE      single precision          \n   xmm2/m128, xmm1                                  floating-point values     \n                                                    from xmm1 to xmm2/mem.    \n                                                    Move aligned packed       \n   VEX.128.0F.WIG 28 /r    A     V/V       AVX      single precision          \n   VMOVAPS xmm1, xmm2/m128                          floating-point values     \n                                                    from xmm2/mem to xmm1.    \n                                                    Move aligned packed       \n   VEX.128.0F.WIG 29 /r    B     V/V       AVX      single precision          \n   VMOVAPS xmm2/m128, xmm1                          floating-point values     \n                                                    from xmm1 to xmm2/mem.    \n                                                    Move aligned packed       \n   VEX.256.0F.WIG 28 /r    A     V/V       AVX      single precision          \n   VMOVAPS ymm1, ymm2/m256                          floating-point values     \n                                                    from ymm2/mem to ymm1.    \n                                                    Move aligned packed       \n   VEX.256.0F.WIG 29 /r    B     V/V       AVX      single precision          \n   VMOVAPS ymm2/m256, ymm1                          floating-point values     \n                                                    from ymm1 to ymm2/mem.    \n                                                    Move aligned packed       \n   EVEX.128.0F.W0 28 /r                    AVX512VL single precision          \n   VMOVAPS xmm1 {k1}{z},   C     V/V       AVX512F  floating-point values     \n   xmm2/m128                                        from xmm2/m128 to xmm1    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.256.0F.W0 28 /r                    AVX512VL single precision          \n   VMOVAPS ymm1 {k1}{z},   C     V/V       AVX512F  floating-point values     \n   ymm2/m256                                        from ymm2/m256 to ymm1    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.512.0F.W0 28 /r                             single precision          \n   VMOVAPS zmm1 {k1}{z},   C     V/V       AVX512F  floating-point values     \n   zmm2/m512                                        from zmm2/m512 to zmm1    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.128.0F.W0 29 /r                    AVX512VL single precision          \n   VMOVAPS xmm2/m128       D     V/V       AVX512F  floating-point values     \n   {k1}{z}, xmm1                                    from xmm1 to xmm2/m128    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.256.0F.W0 29 /r                    AVX512VL single precision          \n   VMOVAPS ymm2/m256       D     V/V       AVX512F  floating-point values     \n   {k1}{z}, ymm1                                    from ymm1 to ymm2/m256    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.512.0F.W0 29 /r                             single precision          \n   VMOVAPS zmm2/m512       D     V/V       AVX512F  floating-point values     \n   {k1}{z}, zmm1                                    from zmm1 to zmm2/m512    \n                                                    using writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves 4, 8 or 16 single precision floating-point values from the source\n   operand (second operand) to the destination operand (first operand). This\n   instruction can be used to load an XMM, YMM or ZMM register from an\n   128-bit, 256-bit or 512-bit memory location, to store the contents of an\n   XMM, YMM or ZMM register into a 128-bit, 256-bit or 512-bit memory\n   location, or to move data between two XMM, two YMM or two ZMM registers.\n\n   When the source or destination operand is a memory operand, the operand\n   must be aligned on a 16-byte (128-bit version), 32-byte (VEX.256 encoded\n   version) or 64-byte (EVEX.512 encoded version) boundary or a\n   general-protection exception (#GP) will be generated. For EVEX.512 encoded\n   versions, the operand must be aligned to the size of the memory operand.\n   To move single precision floating-point values to and from unaligned\n   memory locations, use the VMOVUPS instruction.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   EVEX.512 encoded version:\n\n   Moves 512 bits of packed single precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a ZMM register from a\n   512-bit float32 memory location, to store the contents of a ZMM register\n   into a float32 memory location, or to move data between two ZMM registers.\n   When the source or destination operand is a memory operand, the operand\n   must be aligned on a 64-byte boundary or a general-protection exception\n   (#GP) will be generated. To move single precision floating-point values to\n   and from unaligned memory locations, use the VMOVUPS instruction.\n\n   VEX.256 and EVEX.256 encoded version:\n\n   Moves 256 bits of packed single precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a YMM register from a\n   256-bit memory location, to store the contents of a YMM register into a\n   256-bit memory location, or to move data between two YMM registers. When\n   the source or destination operand is a memory operand, the operand must be\n   aligned on a 32-byte boundary or a general-protection exception (#GP) will\n   be generated.\n\n   128-bit versions:\n\n   Moves 128 bits of packed single precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load an XMM register from a\n   128-bit memory location, to store the contents of an XMM register into a\n   128-bit memory location, or to move data between two XMM registers. When\n   the source or destination operand is a memory operand, the operand must be\n   aligned on a 16-byte boundary or a general-protection exception (#GP) will\n   be generated. To move single precision floating-point values to and from\n   unaligned memory locations, use the VMOVUPS instruction.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding ZMM\n   destination register remain unchanged.\n\n   (E)VEX.128 encoded version: Bits (MAXVL-1:128) of the destination ZMM\n   register are zeroed.\n"],
	["enqcmds", "                      ENQCMDS \u2014 Enqueue Command Supervisor\n\n                               64/32 bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                               Support   Flag    \n                                                 Atomically enqueue 64-byte   \n                                                 command with PASID from      \n   F3 0F 38 F8                                   source memory operand to     \n   !(11):rrr:bbb ENQCMDS A     V/V       ENQCMD  destination offset in ES     \n   r32/r64, m512                                 segment specified in         \n                                                 register operand as offset   \n                                                 in ES segment.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   The ENQCMDS instruction allows system software to write commands to\n   enqueue registers, which are special device registers accessed using\n   memory-mapped I/O (MMIO).\n\n   Enqueue registers expect writes to have the format given in Figure 3-16\n   and explained in the section on \u201cENQCMD\u2014Enqueue Command.\u201d\n\n   The ENQCMDS instruction begins by reading 64 bytes of command data from\n   its source memory operand. This is an ordinary load with cacheability and\n   memory ordering implied normally by the memory type. The source operand\n   need not be aligned, and there is no guarantee that all 64 bytes are\n   loaded atomically. Bits 30:20 of the source operand must be zero.\n\n   ENQCMDS formats its source data differently from ENQCMD. Specifically, it\n   formats them into command data as follows:\n\n     * Command[19:0] get bits 19:0 of the source operand that was read from\n       memory. These 20 bits communicate a process address-space identifier\n       (PASID).\n     * Command[30:20] are zero.\n     * Command[511:31] get bits 511:31 of the source operand that was read\n       from memory. Bit 31 communicates a privilege identification (0 = user;\n       1 = supervisor).\n\n   The ENQCMDS instruction then uses an enqueue store (defined below) to\n   write this command data to the destination operand. The address of the\n   destination operand is specified in a general-purpose register as an\n   offset into the ES segment (the segment cannot be overridden).^1 The\n   destination linear address must be 64-byte aligned. The operation of an\n   enqueue store disregards the memory type of the destination memory\n   address.\n\n     1.\n     In64-bitmode,thewidthoftheregisteroperandis64bits(32bitswitha67Hprefix).Outside64-bitmodewhenCS.D=\n     1, the width is 32 bits (16 bits with a 67H prefix). Outside 64-bit mode\n     when CS.D=0, the width is 16 bits (32 bits with a 67H prefix).\n\n   An enqueue store is not ordered relative to older stores to WB or WC\n   memory (including non-temporal stores) or to executions of the CLFLUSHOPT\n   or CLWB (when applied to addresses other than that of the enqueue store).\n   Software can enforce such ordering by executing a fencing instruction such\n   as SFENCE or MFENCE before the enqueue store.\n\n   An enqueue store does not write the data into the cache hierarchy, nor\n   does it fetch any data into the cache hierarchy. An enqueue store\u2019s\n   command data is never combined with that of any other store to the same\n   address.\n\n   Unlike other stores, an enqueue store returns a status, which the ENQCMDS\n   instruction loads into the ZF flag in the RFLAGS register:\n\n     * ZF = 0 (success) reports that the 64-byte command data was written\n       atomically to a device\u2019s enqueue register and has been accepted by the\n       device. (It does not guarantee that the device has acted on the\n       command; it may have queued it for later execution.)\n     * ZF = 1 (retry) reports that the command data was not accepted. This\n       status is returned if the destination address is an enqueue register\n       but the command was not accepted due to capacity or other temporal\n       reasons.\n\n   This status is also returned if the destination address was not an enqueue\n   register (including the case of a memory address); in these cases, the\n   store is dropped and is written neither to MMIO nor to memory.\n\n   The ENQCMDS instruction may be executed only if CPL = 0. Availability of\n   the ENQCMDS instruction is indicated by the presence of the CPUID feature\n   flag ENQCMD (CPUID.(EAX=07H, ECX=0H):ECX[bit 29]).\n\n  Flags Affected \u00b6\n\n   The ZF flag is set if the enqueue-store completion returns the retry\n   status; otherwise it is cleared. All other flags are cleared.\n"],
	["smsw", "                        SMSW \u2014 Store Machine Status Word\n\n   Opcode*    Instruction  Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   0F 01 /4   SMSW r/m16   M     Valid  Valid      Store machine status word  \n                                                   to r/m16.                  \n                                                   Store machine status word  \n   0F 01 /4   SMSW r32/m16 M     Valid  Valid      in low-order 16 bits of    \n                                                   r32/m16; high-order 16     \n                                                   bits of r32 are undefined. \n                                                   Store machine status word  \n   REX.W + 0F SMSW r64/m16 M     Valid  Valid      in low-order 16 bits of    \n   01 /4                                           r64/m16; high-order 16     \n                                                   bits of r32 are undefined. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Stores the machine status word (bits 0 through 15 of control register CR0)\n   into the destination operand. The destination operand can be a\n   general-purpose register or a memory location.\n\n   In non-64-bit modes, when the destination operand is a 32-bit register,\n   the low-order 16 bits of register CR0 are copied into the low-order 16\n   bits of the register and the high-order 16 bits are undefined. When the\n   destination operand is a memory location, the low-order 16 bits of\n   register CR0 are written to memory as a 16-bit quantity, regardless of the\n   operand size.\n\n   In 64-bit mode, the behavior of the SMSW instruction is defined by the\n   following examples:\n\n     * SMSW r16 operand size 16, store CR0[15:0] in r16\n     * SMSW r32 operand size 32, zero-extend CR0[31:0], and store in r32\n     * SMSW r64 operand size 64, zero-extend CR0[63:0], and store in r64\n     * SMSW m16 operand size 16, store CR0[15:0] in m16\n     * SMSW m16 operand size 32, store CR0[15:0] in m16 (not m32)\n     * SMSW m16 operands size 64, store CR0[15:0] in m16 (not m64)\n\n   SMSW is only useful in operating-system software. However, it is not a\n   privileged instruction and can be used in application programs if CR4.UMIP\n   = 0. It is provided for compatibility with the Intel 286 processor.\n   Programs and procedures intended to run on IA-32 and Intel 64 processors\n   beginning with the Intel386 processors should use the MOV CR instruction\n   to load the machine status word.\n\n   See \u201cChanges to Instruction Behavior in VMX Non-Root Operation\u201d in Chapter\n   26 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3C, for more information about the behavior of this instruction in\n   VMX non-root operation.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["unpckhpd", "  UNPCKHPD \u2014 Unpack and Interleave High Packed Double Precision Floating-Point\n                                     Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Unpacks and Interleaves    \n   66 0F 15 /r UNPCKHPD                            double precision           \n   xmm1, xmm2/m128         A    V/V       SSE2     floating-point values from \n                                                   high quadwords of xmm1 and \n                                                   xmm2/m128.                 \n                                                   Unpacks and Interleaves    \n   VEX.128.66.0F.WIG 15 /r                         double precision           \n   VUNPCKHPD xmm1,xmm2,    B    V/V       AVX      floating-point values from \n   xmm3/m128                                       high quadwords of xmm2 and \n                                                   xmm3/m128.                 \n                                                   Unpacks and Interleaves    \n   VEX.256.66.0F.WIG 15 /r                         double precision           \n   VUNPCKHPD ymm1,ymm2,    B    V/V       AVX      floating-point values from \n   ymm3/m256                                       high quadwords of ymm2 and \n                                                   ymm3/m256.                 \n                                                   Unpacks and Interleaves    \n   EVEX.128.66.0F.W1 15 /r                         double precision           \n   VUNPCKHPD xmm1 {k1}{z}, C    V/V       AVX512VL floating-point values from \n   xmm2, xmm3/m128/m64bcst                AVX512F  high quadwords of xmm2 and \n                                                   xmm3/m128/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Unpacks and Interleaves    \n   EVEX.256.66.0F.W1 15 /r                         double precision           \n   VUNPCKHPD ymm1 {k1}{z}, C    V/V       AVX512VL floating-point values from \n   ymm2, ymm3/m256/m64bcst                AVX512F  high quadwords of ymm2 and \n                                                   ymm3/m256/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Unpacks and Interleaves    \n   EVEX.512.66.0F.W1 15 /r                         double precision           \n   VUNPCKHPD zmm1 {k1}{z}, C    V/V       AVX512F  floating-point values from \n   zmm2, zmm3/m512/m64bcst                         high quadwords of zmm2 and \n                                                   zmm3/m512/m64bcst subject  \n                                                   to writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs an interleaved unpack of the high double precision floating-point\n   values from the first source operand and the second source operand. See\n   Figure 4-15 in the Intel\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 2B.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified. When unpacking from a memory\n   operand, an implementation may fetch only the appropriate 64 bits;\n   however, alignment to 16-byte boundary and normal segment checking will\n   still be enforced.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand is a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register, a 256-bit memory location, or a\n   256-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a YMM register, conditionally updated using writemask k1.\n\n   EVEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand is a XMM register, a 128-bit memory location, or a\n   128-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a XMM register, conditionally updated using writemask k1.\n"],
	["vpmovwb:vpmovswb:vpmovuswb", "             VPMOVWB/VPMOVSWB/VPMOVUSWB \u2014 Down Convert Word to Byte\n\n                             Op / 64/32 bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Converts 8 packed word   \n   EVEX.128.F3.0F38.W0 30 /r                AVX512VL integers from xmm2 into  \n   VPMOVWB xmm1/m64 {k1}{z}, A    V/V       AVX512BW 8 packed bytes in        \n   xmm2                                              xmm1/m64 with truncation \n                                                     under writemask k1.      \n                                                     Converts 8 packed signed \n   EVEX.128.F3.0F38.W0 20 /r                         word integers from xmm2  \n   VPMOVSWB xmm1/m64         A    V/V       AVX512VL into 8 packed signed     \n   {k1}{z}, xmm2                            AVX512BW bytes in xmm1/m64 using  \n                                                     signed saturation under  \n                                                     writemask k1.            \n                                                     Converts 8 packed        \n                                                     unsigned word integers   \n   EVEX.128.F3.0F38.W0 10 /r                AVX512VL from xmm2 into 8 packed  \n   VPMOVUSWB xmm1/m64        A    V/V       AVX512BW unsigned bytes in        \n   {k1}{z}, xmm2                                     8mm1/m64 using unsigned  \n                                                     saturation under         \n                                                     writemask k1.            \n                                                     Converts 16 packed word  \n   EVEX.256.F3.0F38.W0 30 /r                         integers from ymm2 into  \n   VPMOVWB xmm1/m128         A    V/V       AVX512VL 16 packed bytes in       \n   {k1}{z}, ymm2                            AVX512BW xmm1/m128 with           \n                                                     truncation under         \n                                                     writemask k1.            \n                                                     Converts 16 packed       \n                                                     signed word integers     \n   EVEX.256.F3.0F38.W0 20 /r                AVX512VL from ymm2 into 16 packed \n   VPMOVSWB xmm1/m128        A    V/V       AVX512BW signed bytes in          \n   {k1}{z}, ymm2                                     xmm1/m128 using signed   \n                                                     saturation under         \n                                                     writemask k1.            \n                                                     Converts 16 packed       \n                                                     unsigned word integers   \n   EVEX.256.F3.0F38.W0 10 /r                AVX512VL from ymm2 into 16 packed \n   VPMOVUSWB xmm1/m128       A    V/V       AVX512BW unsigned bytes in        \n   {k1}{z}, ymm2                                     xmm1/m128 using unsigned \n                                                     saturation under         \n                                                     writemask k1.            \n                                                     Converts 32 packed word  \n   EVEX.512.F3.0F38.W0 30 /r                         integers from zmm2 into  \n   VPMOVWB ymm1/m256         A    V/V       AVX512BW 32 packed bytes in       \n   {k1}{z}, zmm2                                     ymm1/m256 with           \n                                                     truncation under         \n                                                     writemask k1.            \n                                                     Converts 32 packed       \n                                                     signed word integers     \n   EVEX.512.F3.0F38.W0 20 /r                         from zmm2 into 32 packed \n   VPMOVSWB ymm1/m256        A    V/V       AVX512BW signed bytes in          \n   {k1}{z}, zmm2                                     ymm1/m256 using signed   \n                                                     saturation under         \n                                                     writemask k1.            \n                                                     Converts 32 packed       \n                                                     unsigned word integers   \n   EVEX.512.F3.0F38.W0 10 /r                         from zmm2 into 32 packed \n   VPMOVUSWB ymm1/m256       A    V/V       AVX512BW unsigned bytes in        \n   {k1}{z}, zmm2                                     ymm1/m256 using unsigned \n                                                     saturation under         \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   VPMOVWB down converts 16-bit integers into packed bytes using truncation.\n   VPMOVSWB converts signed 16-bit integers into packed signed bytes using\n   signed saturation. VPMOVUSWB convert unsigned word values into unsigned\n   byte values using unsigned saturation.\n\n   The source operand is a ZMM/YMM/XMM register. The destination operand is a\n   YMM/XMM/XMM register or a 256/128/64-bit memory location.\n\n   Down-converted byte elements are written to the destination operand (the\n   first operand) from the least-significant byte. Byte elements of the\n   destination operand are updated according to the writemask. Bits\n   (MAXVL-1:256/128/64) of the register destination are zeroed.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n"],
	["fxch", "                       FXCH \u2014 Exchange Register Contents\n\n   Opcode  Instruction 64-Bit Mode Compat/Leg Mode Description                \n   D9 C8+i FXCH ST(i)  Valid       Valid           Exchange the contents of   \n                                                   ST(0) and ST(i).           \n   D9 C9   FXCH        Valid       Valid           Exchange the contents of   \n                                                   ST(0) and ST(1).           \n\nDescription \u00b6\n\n   Exchanges the contents of registers ST(0) and ST(i). If no source operand\n   is specified, the contents of ST(0) and ST(1) are exchanged.\n\n   This instruction provides a simple means of moving values in the FPU\n   register stack to the top of the stack [ST(0)], so that they can be\n   operated on by those floating-point instructions that can only operate on\n   values in ST(0). For example, the following instruction sequence takes the\n   square root of the third register from the top of the register stack:\n\n   FXCH ST(3);\n\n   FSQRT;\n\n   FXCH ST(3);\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0.  \n   C0, C2, C3 Undefined. \n"],
	["push", "            PUSH \u2014 Push Word, Doubleword, or Quadword Onto the Stack\n\n   Opcode^1\n\n         Instruction Op/En 64-Bit Mode Compat/Leg Mode Description \n   FF /6 PUSH r/m16  M     Valid       Valid           Push r/m16. \n   FF /6 PUSH r/m32  M     N.E.        Valid           Push r/m32. \n   FF /6 PUSH r/m64  M     Valid       N.E.            Push r/m64. \n   50+rw PUSH r16    O     Valid       Valid           Push r16.   \n   50+rd PUSH r32    O     N.E.        Valid           Push r32.   \n   50+rd PUSH r64    O     Valid       N.E.            Push r64.   \n   6A ib PUSH imm8   I     Valid       Valid           Push imm8.  \n   68 iw PUSH imm16  I     Valid       Valid           Push imm16. \n   68 id PUSH imm32  I     Valid       Valid           Push imm32. \n   0E    PUSH CS     ZO    Invalid     Valid           Push CS.    \n   16    PUSH SS     ZO    Invalid     Valid           Push SS.    \n   1E    PUSH DS     ZO    Invalid     Valid           Push DS.    \n   06    PUSH ES     ZO    Invalid     Valid           Push ES.    \n   0F A0 PUSH FS     ZO    Valid       Valid           Push FS.    \n   0F A8 PUSH GS     ZO    Valid       Valid           Push GS.    \n\n     1. See the IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1       Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r)   N/A       N/A       N/A       \n   O     opcode + rd (r) N/A       N/A       N/A       \n   I     imm8/16/32      N/A       N/A       N/A       \n   ZO    N/A             N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Decrements the stack pointer and then stores the source operand on the top\n   of the stack. Address and operand sizes are determined and used as\n   follows:\n\n     * Address size. The D flag in the current code-segment descriptor\n       determines the default address size; it may be overridden by an\n       instruction prefix (67H).\n\n   The address size is used only when referencing a source operand in memory.\n\n     * Operand size. The D flag in the current code-segment descriptor\n       determines the default operand size; it may be overridden by\n       instruction prefixes (66H or REX.W).\n\n   The operand size (16, 32, or 64 bits) determines the amount by which the\n   stack pointer is decremented (2, 4 or 8).\n\n   If the source operand is an immediate of size less than the operand size,\n   a sign-extended value is pushed on the stack. If the source operand is a\n   segment register (16 bits) and the operand size is 64-bits, a\n   zero-extended value is pushed on the stack; if the operand size is\n   32-bits, either a zero-extended value is pushed on the stack or the\n   segment selector is written on the stack using a 16-bit move. For the last\n   case, all recent Intel Core and Intel Atom processors perform a 16-bit\n   move, leaving the upper portion of the stack location unmodified.\n\n     * Stack-address size. Outside of 64-bit mode, the B flag in the current\n       stack-segment descriptor determines the size of the stack pointer (16\n       or 32 bits); in 64-bit mode, the size of the stack pointer is always\n       64 bits.\n\n   The stack-address size determines the width of the stack pointer when\n   writing to the stack in memory and when decrementing the stack pointer.\n   (As stated above, the amount by which the stack pointer is decremented is\n   determined by the operand size.)\n\n   If the operand size is less than the stack-address size, the PUSH\n   instruction may result in a misaligned stack pointer (a stack pointer that\n   is not aligned on a doubleword or quadword boundary).\n\n   The PUSH ESP instruction pushes the value of the ESP register as it\n   existed before the instruction was executed. If a PUSH instruction uses a\n   memory operand in which the ESP register is used for computing the operand\n   address, the address of the operand is computed before the ESP register is\n   decremented.\n\n   If the ESP or SP register is 1 when the PUSH instruction is executed in\n   real-address mode, a stack-fault exception (#SS) is generated (because the\n   limit of the stack segment is violated). Its delivery encounters a second\n   stack-fault exception (for the same reason), causing generation of a\n   double-fault exception (#DF). Delivery of the double-fault exception\n   encounters a third stack-fault exception, and the logical processor enters\n   shutdown mode. See the discussion of the double-fault exception in Chapter\n   6 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3A.\n\nIA-32 Architecture Compatibility \u00b6\n\n   For IA-32 processors from the Intel 286 on, the PUSH ESP instruction\n   pushes the value of the ESP register as it existed before the instruction\n   was executed. (This is also true for Intel 64 architecture, real-address\n   and virtual-8086 modes of IA-32 architecture.) For the Intel^\u00ae 8086\n   processor, the PUSH SP instruction pushes the new value of the SP register\n   (that is the value after it has been decremented by 2).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vprold:vprolvd:vprolq:vprolvq", "                VPROLD/VPROLVD/VPROLQ/VPROLVQ \u2014 Bit Rotate Left\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Rotate doublewords in xmm2 \n   EVEX.128.66.0F38.W0 15                          left by count in the       \n   /r VPROLVD xmm1         B    V/V       AVX512VL corresponding element of   \n   {k1}{z}, xmm2,                         AVX512F  xmm3/m128/m32bcst. Result  \n   xmm3/m128/m32bcst                               written to xmm1 under      \n                                                   writemask k1.              \n   EVEX.128.66.0F.W0 72 /1                         Rotate doublewords in      \n   ib VPROLD xmm1 {k1}{z}, A    V/V       AVX512VL xmm2/m128/m32bcst left by  \n   xmm2/m128/m32bcst, imm8                AVX512F  imm8. Result written to    \n                                                   xmm1 using writemask k1.   \n                                                   Rotate quadwords in xmm2   \n   EVEX.128.66.0F38.W1 15                          left by count in the       \n   /r VPROLVQ xmm1         B    V/V       AVX512VL corresponding element of   \n   {k1}{z}, xmm2,                         AVX512F  xmm3/m128/m64bcst. Result  \n   xmm3/m128/m64bcst                               written to xmm1 under      \n                                                   writemask k1.              \n   EVEX.128.66.0F.W1 72 /1                         Rotate quadwords in        \n   ib VPROLQ xmm1 {k1}{z}, A    V/V       AVX512VL xmm2/m128/m64bcst left by  \n   xmm2/m128/m64bcst, imm8                AVX512F  imm8. Result written to    \n                                                   xmm1 using writemask k1.   \n                                                   Rotate doublewords in ymm2 \n   EVEX.256.66.0F38.W0 15                          left by count in the       \n   /r VPROLVD ymm1         B    V/V       AVX512VL corresponding element of   \n   {k1}{z}, ymm2,                         AVX512F  ymm3/m256/m32bcst. Result  \n   ymm3/m256/m32bcst                               written to ymm1 under      \n                                                   writemask k1.              \n   EVEX.256.66.0F.W0 72 /1                         Rotate doublewords in      \n   ib VPROLD ymm1 {k1}{z}, A    V/V       AVX512VL ymm2/m256/m32bcst left by  \n   ymm2/m256/m32bcst, imm8                AVX512F  imm8. Result written to    \n                                                   ymm1 using writemask k1.   \n                                                   Rotate quadwords in ymm2   \n   EVEX.256.66.0F38.W1 15                          left by count in the       \n   /r VPROLVQ ymm1         B    V/V       AVX512VL corresponding element of   \n   {k1}{z}, ymm2,                         AVX512F  ymm3/m256/m64bcst. Result  \n   ymm3/m256/m64bcst                               written to ymm1 under      \n                                                   writemask k1.              \n   EVEX.256.66.0F.W1 72 /1                         Rotate quadwords in        \n   ib VPROLQ ymm1 {k1}{z}, A    V/V       AVX512VL ymm2/m256/m64bcst left by  \n   ymm2/m256/m64bcst, imm8                AVX512F  imm8. Result written to    \n                                                   ymm1 using writemask k1.   \n                                                   Rotate left of doublewords \n   EVEX.512.66.0F38.W0 15                          in zmm2 by count in the    \n   /r VPROLVD zmm1         B    V/V       AVX512F  corresponding element of   \n   {k1}{z}, zmm2,                                  zmm3/m512/m32bcst. Result  \n   zmm3/m512/m32bcst                               written to zmm1 using      \n                                                   writemask k1.              \n   EVEX.512.66.0F.W0 72 /1                         Rotate left of doublewords \n   ib VPROLD zmm1 {k1}{z}, A    V/V       AVX512F  in zmm3/m512/m32bcst by    \n   zmm2/m512/m32bcst, imm8                         imm8. Result written to    \n                                                   zmm1 using writemask k1.   \n                                                   Rotate quadwords in zmm2   \n   EVEX.512.66.0F38.W1 15                          left by count in the       \n   /r VPROLVQ zmm1         B    V/V       AVX512F  corresponding element of   \n   {k1}{z}, zmm2,                                  zmm3/m512/m64bcst. Result  \n   zmm3/m512/m64bcst                               written to zmm1under       \n                                                   writemask k1.              \n   EVEX.512.66.0F.W1 72 /1                         Rotate quadwords in        \n   ib VPROLQ zmm1 {k1}{z}, A    V/V       AVX512F  zmm2/m512/m64bcst left by  \n   zmm2/m512/m64bcst, imm8                         imm8. Result written to    \n                                                   zmm1 using writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       VEX.vvvv (w)  ModRM:r/m (R) imm8          N/A       \n   B     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Rotates the bits in the individual data elements (doublewords, or\n   quadword) in the first source operand to the left by the number of bits\n   specified in the count operand. If the value specified by the count\n   operand is greater than 31 (for doublewords), or 63 (for a quadword), then\n   the count operand modulo the data size (32 or 64) is used.\n\n   EVEX.128 encoded version: The destination operand is a XMM register. The\n   source operand is a XMM register or a memory location (for immediate\n   form). The count operand can come either from an XMM register or a memory\n   location or an 8-bit immediate. Bits (MAXVL-1:128) of the corresponding\n   ZMM register are zeroed.\n\n   EVEX.256 encoded version: The destination operand is a YMM register. The\n   source operand is a YMM register or a memory location (for immediate\n   form). The count operand can come either from an XMM register or a memory\n   location or an 8-bit immediate. Bits (MAXVL-1:256) of the corresponding\n   ZMM register are zeroed.\n\n   EVEX.512 encoded version: The destination operand is a ZMM register\n   updated according to the writemask. For the count operand in immediate\n   form, the source operand can be a ZMM register, a 512-bit memory location\n   or a 512-bit vector broadcasted from a 32/64-bit memory location, the\n   count operand is an 8-bit immediate. For the count operand in variable\n   form, the first source operand (the second operand) is a ZMM register and\n   the counter operand (the third operand) is a ZMM register, a 512-bit\n   memory location or a 512-bit vector broadcasted from a 32/64-bit memory\n   location.\n"],
	["vcvttsd2usi", "  VCVTTSD2USI \u2014 Convert With Truncation Scalar Double Precision Floating-Point\n                            Value toUnsigned Integer\n\n                               64/32 Bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                               Support   Flag    \n                                                 Convert one double precision \n   EVEX.LLIG.F2.0F.W0 78                         floating-point value from    \n   /r VCVTTSD2USI r32,   A     V/V       AVX512F xmm1/m64 to one unsigned     \n   xmm1/m64{sae}                                 doubleword integer r32 using \n                                                 truncation.                  \n                                                 Convert one double precision \n   EVEX.LLIG.F2.0F.W1 78                         floating-point value from    \n   /r VCVTTSD2USI r64,   A     V/N.E.^1  AVX512F xmm1/m64 to one unsigned     \n   xmm1/m64{sae}                                 quadword integer             \n                                                 zero-extended into r64 using \n                                                 truncation.                  \n\n     1. For this specific instruction, EVEX.W in non-64 bit is ignored; the\n     instruction behaves as if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation a double precision floating-point value in the\n   source operand (the second operand) to an unsigned doubleword integer (or\n   unsigned quadword integer if operand size is 64 bits) in the destination\n   operand (the first operand). The source operand can be an XMM register or\n   a 64-bit memory location. The destination operand is a general-purpose\n   register. When the source operand is an XMM register, the double precision\n   floating-point value is contained in the low quadword of the register.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   EVEX.W1 version: promotes the instruction to produce 64-bit data in 64-bit\n   mode.\n"],
	["sub", "                                 SUB \u2014 Subtract\n\n   Opcode     Instruction     Op/En 64-Bit Compat/Leg Description             \n                                    Mode   Mode       \n   2C ib      SUB AL, imm8    I     Valid  Valid      Subtract imm8 from AL.  \n   2D iw      SUB AX, imm16   I     Valid  Valid      Subtract imm16 from AX. \n   2D id      SUB EAX, imm32  I     Valid  Valid      Subtract imm32 from     \n                                                      EAX.                    \n   REX.W + 2D                                         Subtract imm32          \n   id         SUB RAX, imm32  I     Valid  N.E.       sign-extended to        \n                                                      64-bits from RAX.       \n   80 /5 ib   SUB r/m8, imm8  MI    Valid  Valid      Subtract imm8 from      \n                                                      r/m8.                   \n   REX + 80   SUB r/m8^1,     MI    Valid  N.E.       Subtract imm8 from      \n   /5 ib      imm8                                    r/m8.                   \n   81 /5 iw   SUB r/m16,      MI    Valid  Valid      Subtract imm16 from     \n              imm16                                   r/m16.                  \n   81 /5 id   SUB r/m32,      MI    Valid  Valid      Subtract imm32 from     \n              imm32                                   r/m32.                  \n   REX.W + 81 SUB r/m64,                              Subtract imm32          \n   /5 id      imm32           MI    Valid  N.E.       sign-extended to        \n                                                      64-bits from r/m64.     \n   83 /5 ib   SUB r/m16, imm8 MI    Valid  Valid      Subtract sign-extended  \n                                                      imm8 from r/m16.        \n   83 /5 ib   SUB r/m32, imm8 MI    Valid  Valid      Subtract sign-extended  \n                                                      imm8 from r/m32.        \n   REX.W + 83 SUB r/m64, imm8 MI    Valid  N.E.       Subtract sign-extended  \n   /5 ib                                              imm8 from r/m64.        \n   28 /r      SUB r/m8, r8    MR    Valid  Valid      Subtract r8 from r/m8.  \n   REX + 28   SUB r/m8^1,     MR    Valid  N.E.       Subtract r8 from r/m8.  \n   /r         r8^1            \n   29 /r      SUB r/m16, r16  MR    Valid  Valid      Subtract r16 from       \n                                                      r/m16.                  \n   29 /r      SUB r/m32, r32  MR    Valid  Valid      Subtract r32 from       \n                                                      r/m32.                  \n   REX.W + 29 SUB r/m64, r64  MR    Valid  N.E.       Subtract r64 from       \n   /r                                                 r/m64.                  \n   2A /r      SUB r8, r/m8    RM    Valid  Valid      Subtract r/m8 from r8.  \n   REX + 2A   SUB r8^1,       RM    Valid  N.E.       Subtract r/m8 from r8.  \n   /r         r/m8^1          \n   2B /r      SUB r16, r/m16  RM    Valid  Valid      Subtract r/m16 from     \n                                                      r16.                    \n   2B /r      SUB r32, r/m32  RM    Valid  Valid      Subtract r/m32 from     \n                                                      r32.                    \n   REX.W + 2B SUB r64, r/m64  RM    Valid  N.E.       Subtract r/m64 from     \n   /r                                                 r64.                    \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   I     AL/AX/EAX/RAX    imm8/16/32    N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8/16/32    N/A       N/A       \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Subtracts the second operand (source operand) from the first operand\n   (destination operand) and stores the result in the destination operand.\n   The destination operand can be a register or a memory location; the source\n   operand can be an immediate, register, or memory location. (However, two\n   memory operands cannot be used in one instruction.) When an immediate\n   value is used as an operand, it is sign-extended to the length of the\n   destination operand format.\n\n   The SUB instruction performs integer subtraction. It evaluates the result\n   for both signed and unsigned integer operands and sets the OF and CF flags\n   to indicate an overflow in the signed or unsigned result, respectively.\n   The SF flag indicates the sign of the signed result.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\nFlags Affected \u00b6\n\n   The OF, SF, ZF, AF, PF, and CF flags are set according to the result.\n"],
	["vucomish", "         VUCOMISH \u2014 Unordered Compare Scalar FP16 Values and Set EFLAGS\n\n   Instruction En bit Mode Flag Support                                       \n   Instruction En bit Mode Flag Support 64/32  \n   CPUID Feature Instruction En bit Mode Flag  \n   CPUID Feature Instruction En bit Mode Flag  \n   Op/ 64/32 CPUID Feature Instruction En bit  \n   Mode Flag 64/32 CPUID Feature Instruction   \n   En bit Mode Flag CPUID Feature Instruction  \n   En bit Mode Flag p/ 64/32 CPUID Feature     \n   Instruction En bit Mode Flag Support         Support  Description\n   Description EVEX.LLIG.NP.MAP5.W0 2E /r A    \n   V/V AVX512-FP16 Description                 \n   EVEX.LLIG.NP.MAP5.W0 2E /r A V/V            \n   AVX512-FP16 VUCOMISH xmm1, xmm2/m16 {sae}   \n   Description EVEX.LLIG.NP.MAP5.W0 2E /r A    \n   V/V AVX512-FP16 Description                 \n   EVEX.LLIG.NP.MAP5.W0 2E /r A V/V            \n   AVX512-FP16 Op/ 64/32 CPUID Feature         \n                                                         Compare low FP16     \n                                                         values in xmm1 and   \n   VUCOMISH xmm1, xmm2/m16 {sae}                         xmm2/m16 and set the \n                                                         EFLAGS flags         \n                                                         accordingly.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction compares the FP16 values in the low word of operand 1\n   (first operand) and operand 2 (second operand), and sets the ZF, PF, and\n   CF flags in the EFLAGS register according to the result (unordered,\n   greater than, less than, or equal). The OF, SF and AF flags in the EFLAGS\n   register are set to 0. The unordered result is returned if either source\n   operand is a NaN (QNaN or SNaN).\n\n   Operand 1 is an XMM register; operand 2 can be an XMM register or a 16-bit\n   memory location.\n\n   The VUCOMISH instruction differs from the VCOMISH instruction in that it\n   signals a SIMD floating-point invalid operation exception (#I) only if a\n   source operand is an SNaN. The COMISS instruction signals an invalid\n   numeric exception when a source operand is either a QNaN or SNaN.\n\n   The EFLAGS register is not updated if an unmasked SIMD floating-point\n   exception is generated. EVEX.vvvv are reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["movs:movsb:movsw:movsd:movsq", "         MOVS/MOVSB/MOVSW/MOVSD/MOVSQ \u2014 Move Data From String to String\n\n   \\\n\n   Opcode  Instruction   Op/En 64-Bit Compat/Leg Description                  \n                               Mode   Mode       \n                                                 For legacy mode, Move byte   \n                                                 from address DS:(E)SI to     \n   A4      MOVS m8, m8   ZO    Valid  Valid      ES:(E)DI. For 64-bit mode    \n                                                 move byte from address       \n                                                 (R|E)SI to (R|E)DI.          \n                                                 For legacy mode, move word   \n                                                 from address DS:(E)SI to     \n   A5      MOVS m16, m16 ZO    Valid  Valid      ES:(E)DI. For 64-bit mode    \n                                                 move word at address (R|E)SI \n                                                 to (R|E)DI.                  \n                                                 For legacy mode, move dword  \n                                                 from address DS:(E)SI to     \n   A5      MOVS m32, m32 ZO    Valid  Valid      ES:(E)DI. For 64-bit mode    \n                                                 move dword from address      \n                                                 (R|E)SI to (R|E)DI.          \n   REX.W + MOVS m64, m64 ZO    Valid  N.E.       Move qword from address      \n   A5                                            (R|E)SI to (R|E)DI.          \n                                                 For legacy mode, Move byte   \n                                                 from address DS:(E)SI to     \n   A4      MOVSB         ZO    Valid  Valid      ES:(E)DI. For 64-bit mode    \n                                                 move byte from address       \n                                                 (R|E)SI to (R|E)DI.          \n                                                 For legacy mode, move word   \n                                                 from address DS:(E)SI to     \n   A5      MOVSW         ZO    Valid  Valid      ES:(E)DI. For 64-bit mode    \n                                                 move word at address (R|E)SI \n                                                 to (R|E)DI.                  \n                                                 For legacy mode, move dword  \n                                                 from address DS:(E)SI to     \n   A5      MOVSD         ZO    Valid  Valid      ES:(E)DI. For 64-bit mode    \n                                                 move dword from address      \n                                                 (R|E)SI to (R|E)DI.          \n   REX.W + MOVSQ         ZO    Valid  N.E.       Move qword from address      \n   A5                                            (R|E)SI to (R|E)DI.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Moves the byte, word, or doubleword specified with the second operand\n   (source operand) to the location specified with the first operand\n   (destination operand). Both the source and destination operands are\n   located in memory. The address of the source operand is read from the\n   DS:ESI or the DS:SI registers (depending on the address-size attribute of\n   the instruction, 32 or 16, respectively). The address of the destination\n   operand is read from the ES:EDI or the ES:DI registers (again depending on\n   the address-size attribute of the instruction). The DS segment may be\n   overridden with a segment override prefix, but the ES segment cannot be\n   overridden.\n\n   At the assembly-code level, two forms of this instruction are allowed: the\n   \u201cexplicit-operands\u201d form and the \u201cno-operands\u201d form. The explicit-operands\n   form (specified with the MOVS mnemonic) allows the source and destination\n   operands to be specified explicitly. Here, the source and destination\n   operands should be symbols that indicate the size and location of the\n   source value and the destination, respectively. This explicit-operands\n   form is provided to allow documentation; however, note that the\n   documentation provided by this form can be misleading. That is, the source\n   and destination operand symbols must specify the correct type (size) of\n   the operands (bytes, words, or doublewords), but they do not have to\n   specify the correct location. The locations of the source and destination\n   operands are always specified by the DS:(E)SI and ES:(E)DI registers,\n   which must be loaded correctly before the move string instruction is\n   executed.\n\n   The no-operands form provides \u201cshort forms\u201d of the byte, word, and\n   doubleword versions of the MOVS instructions. Here also DS:(E)SI and\n   ES:(E)DI are assumed to be the source and destination operands,\n   respectively. The size of the source and destination operands is selected\n   with the mnemonic: MOVSB (byte move), MOVSW (word move), or MOVSD\n   (doubleword move).\n\n   After the move operation, the (E)SI and (E)DI registers are incremented or\n   decremented automatically according to the setting of the DF flag in the\n   EFLAGS register. (If the DF flag is 0, the (E)SI and (E)DI register are\n   incre-\n\n   mented; if the DF flag is 1, the (E)SI and (E)DI registers are\n   decremented.) The registers are incremented or decremented by 1 for byte\n   operations, by 2 for word operations, or by 4 for doubleword operations.\n\n     To improve performance, more recent processors support modifications to\n     the processor\u2019s operation during the string store operations initiated\n     with MOVS and MOVSB. See Section 7.3.9.3 in the Intel^\u00ae 64 and IA-32\n     Architectures Software Developer\u2019s Manual, Volume 1, for additional\n     information on fast-string operation.\n\n     The MOVS, MOVSB, MOVSW, and MOVSD instructions can be preceded by the\n     REP prefix (see \u201cREP/REPE/REPZ /REPNE/REPNZ\u2014Repeat String Operation\n     Prefix\u201d for a description of the REP prefix) for block moves of ECX\n     bytes, words, or doublewords.\n\n     In 64-bit mode, the instruction\u2019s default address size is 64 bits,\n     32-bit address size is supported using the prefix 67H. The 64-bit\n     addresses are specified by RSI and RDI; 32-bit address are specified by\n     ESI and EDI. Use of the REX.W prefix promotes doubleword operation to 64\n     bits. See the summary chart at the beginning of this section for\n     encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["movntdq", "            MOVNTDQ \u2014 Store Packed Integers Using Non-Temporal Hint\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n   66 0F E7 /r MOVNTDQ                             Move packed integer values \n   m128, xmm1              A    V/V       SSE2     in xmm1 to m128 using      \n                                                   non-temporal hint.         \n   VEX.128.66.0F.WIG E7 /r                         Move packed integer values \n   VMOVNTDQ m128, xmm1     A    V/V       AVX      in xmm1 to m128 using      \n                                                   non-temporal hint.         \n   VEX.256.66.0F.WIG E7 /r                         Move packed integer values \n   VMOVNTDQ m256, ymm1     A    V/V       AVX      in ymm1 to m256 using      \n                                                   non-temporal hint.         \n   EVEX.128.66.0F.W0 E7 /r                AVX512VL Move packed integer values \n   VMOVNTDQ m128, xmm1     B    V/V       AVX512F  in xmm1 to m128 using      \n                                                   non-temporal hint.         \n   EVEX.256.66.0F.W0 E7 /r                AVX512VL Move packed integer values \n   VMOVNTDQ m256, ymm1     B    V/V       AVX512F  in zmm1 to m256 using      \n                                                   non-temporal hint.         \n   EVEX.512.66.0F.W0 E7 /r                         Move packed integer values \n   VMOVNTDQ m512, zmm1     B    V/V       AVX512F  in zmm1 to m512 using      \n                                                   non-temporal hint.         \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. ModRM.MOD != 011B\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   B     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the packed integers in the source operand (second operand) to the\n   destination operand (first operand) using a non-temporal hint to prevent\n   caching of the data during the write to memory. The source operand is an\n   XMM register, YMM register or ZMM register, which is assumed to contain\n   integer data (packed bytes, words, double-words, or quadwords). The\n   destination operand is a 128-bit, 256-bit or 512-bit memory location. The\n   memory operand must be aligned on a 16-byte (128-bit version), 32-byte\n   (VEX.256 encoded version) or 64-byte (512-bit version) boundary otherwise\n   a general-protection exception (#GP) will be generated.\n\n   The non-temporal hint is implemented by using a write combining (WC)\n   memory type protocol when writing the data to memory. Using this protocol,\n   the processor does not write the data into the cache hierarchy, nor does\n   it fetch the corresponding cache line from memory into the cache\n   hierarchy. The memory type of the region being written to can override the\n   non-temporal hint, if the memory address specified for the non-temporal\n   store is in an uncacheable (UC) or write protected (WP) memory region. For\n   more information on non-temporal stores, see \u201cCaching of Temporal vs.\n   Non-Temporal Data\u201d in Chapter 10 in the IA-32 Intel Architecture Software\n   Developer\u2019s Manual, Volume 1.\n\n   Because the WC protocol uses a weakly-ordered memory consistency model, a\n   fencing operation implemented with the SFENCE or MFENCE instruction should\n   be used in conjunction with VMOVNTDQ instructions if multiple processors\n   might use different memory types to read/write the destination memory\n   locations.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, VEX.L must be\n   0; otherwise instructions will #UD.\n"],
	["bndcu:bndcn", "                        BNDCU/BNDCN \u2014 Check Upper Bound\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                Support   Flag    \n                                                  Generate a #BR if the       \n   F2 0F 1A /r BNDCU bnd,                         address in r/m32 is higher  \n   r/m32                  RM    N.E./V    MPX     than the upper bound in     \n                                                  bnd.UB (bnb.UB in 1's       \n                                                  complement form).           \n                                                  Generate a #BR if the       \n   F2 0F 1A /r BNDCU bnd,                         address in r/m64 is higher  \n   r/m64                  RM    V/N.E.    MPX     than the upper bound in     \n                                                  bnd.UB (bnb.UB in 1's       \n                                                  complement form).           \n                                                  Generate a #BR if the       \n   F2 0F 1B /r BNDCN bnd,                         address in r/m32 is higher  \n   r/m32                  RM    N.E./V    MPX     than the upper bound in     \n                                                  bnd.UB (bnb.UB not in 1's   \n                                                  complement form).           \n                                                  Generate a #BR if the       \n   F2 0F 1B /r BNDCN bnd,                         address in r/m64 is higher  \n   r/m64                  RM    V/N.E.    MPX     than the upper bound in     \n                                                  bnd.UB (bnb.UB not in 1's   \n                                                  complement form).           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Compare the address in the second operand with the upper bound in bnd. The\n   second operand can be either a register or a memory operand. If the\n   address is higher than the upper bound in bnd.UB, it will set BNDSTATUS to\n   01H and signal a #BR exception.\n\n   BNDCU perform 1\u2019s complement operation on the upper bound of bnd first\n   before proceeding with address comparison. BNDCN perform address\n   comparison directly using the upper bound in bnd that is already reverted\n   out of 1\u2019s complement form.\n\n   This instruction does not cause any memory access, and does not read or\n   write any flags.\n\n   Effective address computation of m32/64 has identical behavior to LEA\n\nFlags Affected \u00b6\n\n   None\n"],
	["rdtsc", "                        RDTSC \u2014 Read Time-Stamp Counter\n\n   Opcode* Instruction Op/En 64-Bit Mode Compat/Leg Mode Description          \n                                                         Read time-stamp      \n   0F 31   RDTSC       ZO    Valid       Valid           counter into         \n                                                         EDX:EAX.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reads the current value of the processor\u2019s time-stamp counter (a 64-bit\n   MSR) into the EDX:EAX registers. The EDX register is loaded with the\n   high-order 32 bits of the MSR and the EAX register is loaded with the\n   low-order 32 bits. (On processors that support the Intel 64 architecture,\n   the high-order 32 bits of each of RAX and RDX are cleared.)\n\n   The processor monotonically increments the time-stamp counter MSR every\n   clock cycle and resets it to 0 whenever the processor is reset. See \u201cTime\n   Stamp Counter\u201d in Chapter 18 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3B, for specific details of the time\n   stamp counter behavior.\n\n   The time stamp disable (TSD) flag in register CR4 restricts the use of the\n   RDTSC instruction as follows. When the flag is clear, the RDTSC\n   instruction can be executed at any privilege level; when the flag is set,\n   the instruction can only be executed at privilege level 0.\n\n   The time-stamp counter can also be read with the RDMSR instruction, when\n   executing at privilege level 0.\n\n   The RDTSC instruction is not a serializing instruction. It does not\n   necessarily wait until all previous instructions have been executed before\n   reading the counter. Similarly, subsequent instructions may begin\n   execution before the read operation is performed. The following items may\n   guide software seeking to order executions of RDTSC:\n\n     * If software requires RDTSC to be executed only after all previous\n       instructions have executed and all previous loads are globally\n       visible,^1 it can execute LFENCE immediately before RDTSC.\n     * If software requires RDTSC to be executed only after all previous\n       instructions have executed and all previous loads and stores are\n       globally visible, it can execute the sequence MFENCE;LFENCE\n       immediately before RDTSC.\n     * If software requires RDTSC to be executed prior to execution of any\n       subsequent instruction (including any memory accesses), it can execute\n       the sequence LFENCE immediately after RDTSC.\n\n   This instruction was introduced by the Pentium processor.\n\n   See \u201cChanges to Instruction Behavior in VMX Non-Root Operation\u201d in Chapter\n   26 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3C, for more information about the behavior of this instruction in\n   VMX non-root operation.\n\n     1. A load is considered to become globally visible when the value to be\n     loaded is determined.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vgetexppd", " VGETEXPPD \u2014 Convert Exponents of Packed Double Precision Floating-Point Values\n                    to DoublePrecision Floating-Point Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Convert the exponent of \n                                                      packed double precision \n                                                      floating-point values   \n                                                      in the source operand   \n   EVEX.128.66.0F38.W1 42 /r                 AVX512VL to double precision     \n   VGETEXPPD xmm1 {k1}{z},   A     V/V       AVX512F  floating-point results  \n   xmm2/m128/m64bcst                                  representing unbiased   \n                                                      integer exponents and   \n                                                      stores the results in   \n                                                      the destination         \n                                                      register.               \n                                                      Convert the exponent of \n                                                      packed double precision \n                                                      floating-point values   \n                                                      in the source operand   \n   EVEX.256.66.0F38.W1 42 /r                 AVX512VL to double precision     \n   VGETEXPPD ymm1 {k1}{z},   A     V/V       AVX512F  floating-point results  \n   ymm2/m256/m64bcst                                  representing unbiased   \n                                                      integer exponents and   \n                                                      stores the results in   \n                                                      the destination         \n                                                      register.               \n                                                      Convert the exponent of \n                                                      packed double precision \n                                                      floating-point values   \n                                                      in the source operand   \n   EVEX.512.66.0F38.W1 42 /r                          to double precision     \n   VGETEXPPD zmm1 {k1}{z},   A     V/V       AVX512F  floating-point results  \n   zmm2/m512/m64bcst{sae}                             representing unbiased   \n                                                      integer exponents and   \n                                                      stores the results in   \n                                                      the destination under   \n                                                      writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Extracts the biased exponents from the normalized double precision\n   floating-point representation of each qword data element of the source\n   operand (the second operand) as unbiased signed integer value, or convert\n   the denormal representation of input data to unbiased negative integer\n   values. Each integer value of the unbiased exponent is converted to double\n   precision floating-point value and written to the corresponding qword\n   elements of the destination operand (the first operand) as double\n   precision floating-point numbers.\n\n   The destination operand is a ZMM/YMM/XMM register and updated under the\n   writemask. The source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 64-bit memory location.\n\n   EVEX.vvvv is reserved and must be 1111b, otherwise instructions will #UD.\n\n   Each GETEXP operation converts the exponent value into a floating-point\n   number (permitting input value in denormal representation). Special cases\n   of input values are listed in Table 5-15.\n\n   The formula is:\n\n   GETEXP(x) = floor(log_2(|x|))\n\n   Notation floor(x) stands for the greatest integer not exceeding real\n   number x.\n\n   Input Operand    Result               Comments                             \n   src1 = NaN       QNaN(src1)                                                \n   0 < |src1| < INF floor(log_2(|src1|)) If (SRC = SNaN) then #IE If (SRC =   \n   | src1| = +INF   +INF                 denormal) then #DE\n   | src1| = 0      -INF                 \n\n   Table 5-15. VGETEXPPD/SD Special Cases\n"],
	["extractps", "                EXTRACTPS \u2014 Extract Packed Floating-Point Values\n\n                             Op / 64/32 bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature Description\n                                  Support   Flag    \n                                                    Extract one single        \n                                                    precision floating-point  \n   66 0F 3A 17 /r ib                                value from xmm1 at the    \n   EXTRACTPS reg/m32, xmm1,  A    VV        SSE4_1  offset specified by imm8  \n   imm8                                             and store the result in   \n                                                    reg or m32. Zero extend   \n                                                    the results in 64-bit     \n                                                    register if applicable.   \n                                                    Extract one single        \n                                                    precision floating-point  \n   VEX.128.66.0F3A.WIG 17 /r                        value from xmm1 at the    \n   ib VEXTRACTPS reg/m32,    A    V/V       AVX     offset specified by imm8  \n   xmm1, imm8                                       and store the result in   \n                                                    reg or m32. Zero extend   \n                                                    the results in 64-bit     \n                                                    register if applicable.   \n                                                    Extract one single        \n                                                    precision floating-point  \n   EVEX.128.66.0F3A.WIG 17                          value from xmm1 at the    \n   /r ib VEXTRACTPS reg/m32, B    V/V       AVX512F offset specified by imm8  \n   xmm1, imm8                                       and store the result in   \n                                                    reg or m32. Zero extend   \n                                                    the results in 64-bit     \n                                                    register if applicable.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   B     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n\nDescription \u00b6\n\n   Extracts a single precision floating-point value from the source operand\n   (second operand) at the 32-bit offset specified from imm8. Immediate bits\n   higher than the most significant offset for the vector length are ignored.\n\n   The extracted single precision floating-point value is stored in the low\n   32-bits of the destination operand\n\n   In 64-bit mode, destination register operand has default operand size of\n   64 bits. The upper 32-bits of the register are filled with zero. REX.W is\n   ignored.\n\n   VEX.128 and EVEX encoded version: When VEX.W1 or EVEX.W1 form is used in\n   64-bit mode with a general purpose register (GPR) as a destination\n   operand, the packed single quantity is zero extended to 64 bits.\n\n   VEX.vvvv/EVEX.vvvv is reserved and must be 1111b otherwise instructions\n   will #UD.\n\n   128-bit Legacy SSE version: When a REX.W prefix is used in 64-bit mode\n   with a general purpose register (GPR) as a destination operand, the packed\n   single quantity is zero extended to 64 bits.\n\n   The source register is an XMM register. Imm8[1:0] determine the starting\n   DWORD offset from which to extract the 32-bit floating-point value.\n\n   If VEXTRACTPS is encoded with VEX.L= 1, an attempt to execute the\n   instruction encoded with VEX.L= 1 will cause an #UD exception.\n"],
	["movmskps", "      MOVMSKPS \u2014 Extract Packed Single Precision Floating-Point Sign Mask\n\n                              64/32-bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                                        Flag    \n                                                Extract 4-bit sign mask from  \n   NP 0F 50 /r MOVMSKPS RM    V/V       SSE     xmm and store in reg. The     \n   reg, xmm                                     upper bits of r32 or r64 are  \n                                                filled with zeros.            \n                                                Extract 4-bit sign mask from  \n   VEX.128.0F.WIG 50 /r RM    V/V       AVX     xmm2 and store in reg. The    \n   VMOVMSKPS reg, xmm2                          upper bits of r32 or r64 are  \n                                                zeroed.                       \n                                                Extract 8-bit sign mask from  \n   VEX.256.0F.WIG 50 /r RM    V/V       AVX     ymm2 and store in reg. The    \n   VMOVMSKPS reg, ymm2                          upper bits of r32 or r64 are  \n                                                zeroed.                       \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. ModRM.MOD = 011B required\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Extracts the sign bits from the packed single precision floating-point\n   values in the source operand (second operand), formats them into a 4- or\n   8-bit mask, and stores the mask in the destination operand (first\n   operand). The source operand is an XMM or YMM register, and the\n   destination operand is a general-purpose register. The mask is stored in\n   the 4 or 8 low-order bits of the destination operand. The upper bits of\n   the destination operand beyond the mask are filled with zeros.\n\n   In 64-bit mode, the instruction can access additional registers\n   (XMM8-XMM15, R8-R15) when used with a REX.R prefix. The default operand\n   size is 64-bit in 64-bit mode.\n\n   128-bit versions: The source operand is a YMM register. The destination\n   operand is a general purpose register.\n\n   VEX.256 encoded version: The source operand is a YMM register. The\n   destination operand is a general purpose register.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["fucom:fucomp:fucompp", "         FUCOM/FUCOMP/FUCOMPP \u2014 Unordered Compare Floating-Point Values\n\n   Opcode  Instruction  64-Bit Mode Compat/Leg Mode Description               \n   DD E0+i FUCOM ST(i)  Valid       Valid           Compare ST(0) with ST(i). \n   DD E1   FUCOM        Valid       Valid           Compare ST(0) with ST(1). \n   DD E8+i FUCOMP ST(i) Valid       Valid           Compare ST(0) with ST(i)  \n                                                    and pop register stack.   \n   DD E9   FUCOMP       Valid       Valid           Compare ST(0) with ST(1)  \n                                                    and pop register stack.   \n                                                    Compare ST(0) with ST(1)  \n   DA E9   FUCOMPP      Valid       Valid           and pop register stack    \n                                                    twice.                    \n\nDescription \u00b6\n\n   Performs an unordered comparison of the contents of register ST(0) and\n   ST(i) and sets condition code flags C0, C2, and C3 in the FPU status word\n   according to the results (see the table below). If no operand is\n   specified, the contents of registers ST(0) and ST(1) are compared. The\n   sign of zero is ignored, so that \u20130.0 is equal to +0.0.\n\n   Comparison Results* C3 C2 C0 \n   ST0 > ST(i)         0  0  0  \n   ST0 < ST(i)         0  0  1  \n   ST0 = ST(i)         1  0  0  \n   Unordered           1  1  1  \n\n   Table 3-41. FUCOM/FUCOMP/FUCOMPP Results\n\n     *\n     Flagsnotsetifunmaskedinvalid-arithmetic-operand(#IA)exceptionisgenerated.\n\n   An unordered comparison checks the class of the numbers being compared\n   (see \u201cFXAM\u2014Examine Floating-Point\u201d in this chapter). The\n   FUCOM/FUCOMP/FUCOMPP instructions perform the same operations as the\n   FCOM/FCOMP/FCOMPP instructions. The only difference is that the\n   FUCOM/FUCOMP/FUCOMPP instructions raise the invalid-arithmetic-operand\n   exception (#IA) only when either or both operands are an SNaN or are in an\n   unsupported format; QNaNs cause the condition code flags to be set to\n   unordered, but do not cause an exception to be generated. The\n   FCOM/FCOMP/FCOMPP instructions raise an invalid-operation exception when\n   either or both of the operands are a NaN value of any kind or are in an\n   unsupported format.\n\n   As with the FCOM/FCOMP/FCOMPP instructions, if the operation results in an\n   invalid-arithmetic-operand exception being raised, the condition code\n   flags are set only if the exception is masked.\n\n   The FUCOMP instruction pops the register stack following the comparison\n   operation and the FUCOMPP instruction pops the register stack twice\n   following the comparison operation. To pop the register stack, the\n   processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred. \n   C0, C2, C3 See Table 3-41.                       \n"],
	["cmp", "                           CMP \u2014 Compare Two Operands\n\n   Opcode     Instruction     Op/En 64-Bit Compat/Leg Description             \n                                    Mode   Mode       \n   3C ib      CMP AL, imm8    I     Valid  Valid      Compare imm8 with AL.   \n   3D iw      CMP AX, imm16   I     Valid  Valid      Compare imm16 with AX.  \n   3D id      CMP EAX, imm32  I     Valid  Valid      Compare imm32 with EAX. \n   REX.W + 3D                                         Compare imm32           \n   id         CMP RAX, imm32  I     Valid  N.E.       sign-extended to        \n                                                      64-bits with RAX.       \n   80 /7 ib   CMP r/m8, imm8  MI    Valid  Valid      Compare imm8 with r/m8. \n   REX + 80   CMP r/m8^*,     MI    Valid  N.E.       Compare imm8 with r/m8. \n   /7 ib      imm8            \n   81 /7 iw   CMP r/m16,      MI    Valid  Valid      Compare imm16 with      \n              imm16                                   r/m16.                  \n   81 /7 id   CMP r/m32,      MI    Valid  Valid      Compare imm32 with      \n              imm32                                   r/m32.                  \n   REX.W + 81 CMP r/m64,                              Compare imm32           \n   /7 id      imm32           MI    Valid  N.E.       sign-extended to        \n                                                      64-bits with r/m64.     \n   83 /7 ib   CMP r/m16, imm8 MI    Valid  Valid      Compare imm8 with       \n                                                      r/m16.                  \n   83 /7 ib   CMP r/m32, imm8 MI    Valid  Valid      Compare imm8 with       \n                                                      r/m32.                  \n   REX.W + 83 CMP r/m64, imm8 MI    Valid  N.E.       Compare imm8 with       \n   /7 ib                                              r/m64.                  \n   38 /r      CMP r/m8, r8    MR    Valid  Valid      Compare r8 with r/m8.   \n   REX + 38   CMP r/m8^*,     MR    Valid  N.E.       Compare r8 with r/m8.   \n   /r         r8^*            \n   39 /r      CMP r/m16, r16  MR    Valid  Valid      Compare r16 with r/m16. \n   39 /r      CMP r/m32, r32  MR    Valid  Valid      Compare r32 with r/m32. \n   REX.W + 39 CMP r/m64,r64   MR    Valid  N.E.       Compare r64 with r/m64. \n   /r         \n   3A /r      CMP r8, r/m8    RM    Valid  Valid      Compare r/m8 with r8.   \n   REX + 3A   CMP r8^*,       RM    Valid  N.E.       Compare r/m8 with r8.   \n   /r         r/m8^*          \n   3B /r      CMP r16, r/m16  RM    Valid  Valid      Compare r/m16 with r16. \n   3B /r      CMP r32, r/m32  RM    Valid  Valid      Compare r/m32 with r32. \n   REX.W + 3B CMP r64, r/m64  RM    Valid  N.E.       Compare r/m64 with r64. \n   /r         \n\n     *\n     In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1         Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r)     ModRM:r/m (r) N/A       N/A       \n   MR    ModRM:r/m (r)     ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r)     imm8/16/32    N/A       N/A       \n   I     AL/AX/EAX/RAX (r) imm8/16/32    N/A       N/A       \n\nDescription \u00b6\n\n   Compares the first source operand with the second source operand and sets\n   the status flags in the EFLAGS register according to the results. The\n   comparison is performed by subtracting the second operand from the first\n   operand and then setting the status flags in the same manner as the SUB\n   instruction. When an immediate value is used as an operand, it is\n   sign-extended to the length of the first operand.\n\n   The condition codes used by the Jcc, CMOVcc, and SETcc instructions are\n   based on the results of a CMP instruction. Appendix B, \u201cEFLAGS Condition\n   Codes,\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1, shows the relationship of the status flags and the\n   condition codes.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   The CF, OF, SF, ZF, AF, and PF flags are set according to the result.\n"],
	["inc", "                              INC \u2014 Increment by 1\n\n   Opcode      Instruction Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   FE /0       INC r/m8    M     Valid  Valid      Increment r/m byte by 1.   \n   REX + FE /0 INC r/m8^1  M     Valid  N.E.       Increment r/m byte by 1.   \n   FF /0       INC r/m16   M     Valid  Valid      Increment r/m word by 1.   \n   FF /0       INC r/m32   M     Valid  Valid      Increment r/m doubleword   \n                                                   by 1.                      \n   REX.W + FF  INC r/m64   M     Valid  N.E.       Increment r/m quadword by  \n   /0                                              1.                         \n   40+ rw^2    INC r16     O     N.E.   Valid      Increment word register by \n                                                   1.                         \n   40+ rd      INC r32     O     N.E.   Valid      Increment doubleword       \n                                                   register by 1.             \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\n     2. 40H through 47H are REX prefixes in 64-bit mode.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1          Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r, w)   N/A       N/A       N/A       \n   O     opcode + rd (r, w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Adds 1 to the destination operand, while preserving the state of the CF\n   flag. The destination operand can be a register or a memory location. This\n   instruction allows a loop counter to be updated without disturbing the CF\n   flag. (Use a ADD instruction with an immediate operand of 1 to perform an\n   increment operation that does updates the CF flag.)\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, INC r16 and INC r32 are not encodable (because opcodes 40H\n   through 47H are REX prefixes). Otherwise, the instruction\u2019s 64-bit mode\n   default operation size is 32 bits. Use of the REX.R prefix permits access\n   to additional registers (R8-R15). Use of the REX.W prefix promotes\n   operation to 64 bits.\n\nFlags Affected \u00b6\n\n   The CF flag is not affected. The OF, SF, ZF, AF, and PF flags are set\n   according to the result.\n"],
	["aeskeygenassist", "               AESKEYGENASSIST \u2014 AES Round Key Generation Assist\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                          Flag     \n                                                   Assist in AES round key    \n                                                   generation using an 8 bits \n   66 0F 3A DF /r ib                               Round Constant (RCON)      \n   AESKEYGENASSIST xmm1,  RMI   V/V       AES      specified in the immediate \n   xmm2/m128, imm8                                 byte, operating on 128     \n                                                   bits of data specified in  \n                                                   xmm2/m128 and stores the   \n                                                   result in xmm1.            \n                                                   Assist in AES round key    \n                                                   generation using 8 bits    \n   VEX.128.66.0F3A.WIG DF                 Both AES Round Constant (RCON)      \n   /r ib VAESKEYGENASSIST RMI   V/V       and AVX  specified in the immediate \n   xmm1, xmm2/m128, imm8                  flags    byte, operating on 128     \n                                                   bits of data specified in  \n                                                   xmm2/m128 and stores the   \n                                                   result in xmm1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RMI   ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Assist in expanding the AES cipher key, by computing steps towards\n   generating a round key for encryption, using 128-bit data specified in the\n   source operand and an 8-bit round constant specified as an immediate,\n   store the result in the destination operand.\n\n   The destination operand is an XMM register. The source operand can be an\n   XMM register or a 128-bit memory location.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["lar", "                         LAR \u2014 Load Access Rights Byte\n\n   Opcode   Instruction      Op/En 64-Bit Compat/Leg Description              \n                                   Mode   Mode       \n   0F 02 /r LAR r16, r16/m16 RM    Valid  Valid      r16 := access rights     \n                                                     referenced by r16/m16    \n   0F 02 /r LAR reg,         RM    Valid  Valid      reg := access rights     \n            r32/m16^1                                referenced by r32/m16    \n\n     1. For all loads (regardless of source or destination sizing) only bits\n     16-0 are used. Other bits are ignored.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Loads the access rights from the segment descriptor specified by the\n   second operand (source operand) into the first operand (destination\n   operand) and sets the ZF flag in the flag register. The source operand\n   (which can be a register or a memory location) contains the segment\n   selector for the segment descriptor being accessed. If the source operand\n   is a memory address, only 16 bits of data are accessed. The destination\n   operand is a general-purpose register.\n\n   The processor performs access checks as part of the loading process. Once\n   loaded in the destination register, software can perform additional checks\n   on the access rights information.\n\n   The access rights for a segment descriptor include fields located in the\n   second doubleword (bytes 4\u20137) of the segment descriptor. The following\n   fields are loaded by the LAR instruction:\n\n     * Bits 7:0 are returned as 0\n     * Bits 11:8 return the segment type.\n     * Bit 12 returns the S flag.\n     * Bits 14:13 return the DPL.\n     * Bit 15 returns the P flag.\n     * The following fields are returned only if the operand size is greater\n       than 16 bits:\n          * Bits 19:16 are undefined.\n          * Bits 19:16 are undefined.\n          * Bit 20 returns the software-available bit in the descriptor.\n          * Bit 20 returns the software-available bit in the descriptor.\n          * Bit 21 returns the L flag.\n          * Bit 21 returns the L flag.\n          * Bit 22 returns the D/B flag.\n          * Bit 22 returns the D/B flag.\n          * Bit 23 returns the G flag.\n          * Bit 23 returns the G flag.\n          * Bits 31:24 are returned as 0.\n          * Bits 31:24 are returned as 0.\n\n   This instruction performs the following checks before it loads the access\n   rights in the destination register:\n\n     * Checks that the segment selector is not NULL.\n     * Checks that the segment selector points to a descriptor that is within\n       the limits of the GDT or LDT being accessed\n     * Checks that the descriptor type is valid for this instruction. All\n       code and data segment descriptors are valid for (can be accessed with)\n       the LAR instruction. The valid system segment and gate descriptor\n       types are given in Table 3-53.\n     * If the segment is not a conforming code segment, it checks that the\n       specified segment descriptor is visible at the CPL (that is, if the\n       CPL and the RPL of the segment selector are less than or equal to the\n       DPL of the segment selector).\n\n   If the segment descriptor cannot be accessed or is an invalid type for the\n   instruction, the ZF flag is cleared and no access rights are loaded in the\n   destination operand.\n\n   The LAR instruction can only be executed in protected mode and IA-32e\n   mode.\n\n   Type      Protected Mode                      IA-32e Mode       \n             Name                     Valid      Name              Valid      \n             Reserved Available                  Reserved Reserved            \n             16-bit TSS LDT Busy                 LDT Reserved                 \n             16-bit TSS 16-bit call              Reserved Reserved            \n             gate 16-bit/32-bit task  No Yes Yes Reserved Reserved No No Yes  \n   0 1 2 3 4 gate 16-bit interrupt    Yes Yes    Reserved          No No No   \n   5 6 7 8 9 gate 16-bit trap gate    Yes No No  Available 64-bit  No No No   \n   A B C D E Reserved Available       No Yes No  TSS Reserved Busy Yes No Yes\n   F         32-bit TSS Reserved Busy Yes Yes No 64-bit TSS 64-bit Yes No No\n             32-bit TSS 32-bit call   No No      call gate         No\n             gate Reserved 32-bit                Reserved 64-bit   \n             interrupt gate 32-bit               interrupt gate    \n             trap gate                           64-bit trap gate  \n\n   Table 3-53. Segment and Gate Types\n\nFlags Affected \u00b6\n\n   The ZF flag is set to 1 if the access rights are loaded successfully;\n   otherwise, it is cleared to 0.\n"],
	["blendvps", "    BLENDVPS \u2014 Variable Blend Packed Single Precision Floating-Point Values\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Select packed single       \n                                                   precision floating-point   \n   66 0F 38 14 /r BLENDVPS                         values from xmm1 and       \n   xmm1, xmm2/m128, <XMM0> RM0   V/V       SSE4_1  xmm2/m128 from mask        \n                                                   specified in XMM0 and      \n                                                   store the values into      \n                                                   xmm1.                      \n                                                   Conditionally copy single  \n                                                   precision floating-point   \n   VEX.128.66.0F3A.W0 4A                           values from xmm2 or        \n   /r /is4 VBLENDVPS xmm1, RVMR  V/V       AVX     xmm3/m128 to xmm1, based   \n   xmm2, xmm3/m128, xmm4                           on mask bits in the        \n                                                   specified mask operand,    \n                                                   xmm4.                      \n                                                   Conditionally copy single  \n                                                   precision floating-point   \n   VEX.256.66.0F3A.W0 4A                           values from ymm2 or        \n   /r /is4 VBLENDVPS ymm1, RVMR  V/V       AVX     ymm3/m256 to ymm1, based   \n   ymm2, ymm3/m256, ymm4                           on mask bits in the        \n                                                   specified mask register,   \n                                                   ymm4.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM0   ModRM:reg (r, w) ModRM:r/m (r) implicit XMM0 N/A       \n   RVMR  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8[7:4] \n\nDescription \u00b6\n\n   Conditionally copy each dword data element of single precision\n   floating-point value from the second source operand and the first source\n   operand depending on mask bits defined in the mask register operand. The\n   mask bits are the most significant bit in each dword element of the mask\n   register.\n\n   Each quadword element of the destination operand is copied from:\n\n     * the corresponding dword element in the second source operand, if a\n       mask bit is \u201c1\u201d; or\n     * the corresponding dword element in the first source operand, if a mask\n       bit is \u201c0\u201d.\n\n   The register assignment of the implicit mask operand for BLENDVPS is\n   defined to be the architectural register XMM0.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand is the same. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged. The mask register operand is\n   implicitly defined to be the architectural register XMM0. An attempt to\n   execute BLENDVPS with a VEX prefix will cause #UD.\n\n   VEX.128 encoded version: The first source operand and the destination\n   operand are XMM registers. The second source operand is an XMM register or\n   128-bit memory location. The mask operand is the third source register,\n   and encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of\n   imm8 are ignored. In 32-bit mode, imm8[7] is ignored. The upper bits\n   (MAXVL-1:128) of the corresponding YMM register (destination register) are\n   zeroed. VEX.W must be 0, otherwise, the instruction will #UD.\n\n   VEX.256 encoded version: The first source operand and destination operand\n   are YMM registers. The second source operand can be a YMM register or a\n   256-bit memory location. The mask operand is the third source register,\n   and encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of\n   imm8 are ignored. In 32-bit mode, imm8[7] is ignored. VEX.W must be 0,\n   otherwise, the instruction will #UD.\n\n   VBLENDVPS permits the mask to be any XMM or YMM register. In contrast,\n   BLENDVPS treats XMM0 implicitly as the mask and do not support\n   non-destructive destination operation.\n"],
	["vrcp28sd", "     VRCP28SD \u2014 Approximation to the Reciprocal of Scalar Double Precision\n            Floating-Point ValueWith Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes the approximate  \n                                                    reciprocal ( < 2^-28      \n                                                    relative error) of the    \n                                                    scalar double precision   \n   EVEX.LLIG.66.0F38.W1 CB                          floating-point value in   \n   /r VRCP28SD xmm1                                 xmm3/m64 and stores the   \n   {k1}{z}, xmm2, xmm3/m64 A     V/V       AVX512ER results in xmm1. Under    \n   {sae}                                            writemask. Also, upper    \n                                                    double precision          \n                                                    floating-point value      \n                                                    (bits[127:64]) from xmm2  \n                                                    is copied to              \n                                                    xmm1[127:64].             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4      \n   A Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   Computes the reciprocal approximation of the low float64 value in the\n   second source operand (the third operand) and store the result to the\n   destination operand (the first operand). The approximate reciprocal is\n   evaluated with less than 2^-28 of maximum relative error. The result is\n   written into the low float64 element of the destination operand according\n   to the writemask k1. Bits 127:64 of the destination is copied from the\n   corresponding bits of the first source operand (the second operand).\n\n   A denormal input value is treated as zero and does not signal #DE,\n   irrespective of MXCSR.DAZ. A denormal result is flushed to zero and does\n   not signal #UE, irrespective of MXCSR.FTZ.\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. If any source element is \u00b1\u221e, \u00b10.0 is returned for that\n   element. Also, if any source element is \u00b10.0, \u00b1\u221e is returned for that\n   element.\n\n   The first source operand is an XMM register. The second source operand is\n   an XMM register or a 64-bit memory location. The destination operand is a\n   XMM register, conditionally updated using writemask k1.\n\n  A numerically exact implementation of VRCP28xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["vfmadd132sh:vfnmadd132sh:vfmadd213sh:vfnmadd213sh:vfmadd231sh:vfnmadd231sh", "  VFMADD132SH/VFNMADD132SH/VFMADD213SH/VFNMADD213SH/VFMADD231SH/VFNMADD231SH \u2014\n                    Fused Multiply-Add of Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode    \n   Flag Support 64/32 CPUID Feature   \n   Instruction En Bit Mode Flag CPUID \n   Feature Instruction En Bit Mode    \n   Flag Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag 64/32 \n   CPUID Feature Instruction En Bit   \n   Mode Flag CPUID Feature            \n   Instruction En Bit Mode Flag Op/   \n   64/32 CPUID Feature                \n                                                            Multiply FP16     \n   EVEX.LLIG.66.MAP6.W0 99 /r                               values from xmm1  \n   VFMADD132SH xmm1{k1}{z}, xmm2,     A V/V     AVX512-FP16 and xmm3/m16, add \n   xmm3/m16 {er}                                            to xmm2, and      \n                                                            store the result  \n                                                            in xmm1.          \n                                                            Multiply FP16     \n   EVEX.LLIG.66.MAP6.W0 A9 /r                               values from xmm1  \n   VFMADD213SH xmm1{k1}{z}, xmm2,     A V/V     AVX512-FP16 and xmm2, add to  \n   xmm3/m16 {er}                                            xmm3/m16, and     \n                                                            store the result  \n                                                            in xmm1.          \n                                                            Multiply FP16     \n   EVEX.LLIG.66.MAP6.W0 B9 /r                               values from xmm2  \n   VFMADD231SH xmm1{k1}{z}, xmm2,     A V/V     AVX512-FP16 and xmm3/m16, add \n   xmm3/m16 {er}                                            to xmm1, and      \n                                                            store the result  \n                                                            in xmm1.          \n                                                            Multiply FP16     \n                                                            values from xmm1  \n   EVEX.LLIG.66.MAP6.W0 9D /r                               and xmm3/m16, and \n   VFNMADD132SH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 negate the value. \n   xmm3/m16 {er}                                            Add this value to \n                                                            xmm2, and store   \n                                                            the result in     \n                                                            xmm1.             \n                                                            Multiply FP16     \n                                                            values from xmm1  \n   EVEX.LLIG.66.MAP6.W0 AD /r                               and xmm2, and     \n   VFNMADD213SH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 negate the value. \n   xmm3/m16 {er}                                            Add this value to \n                                                            xmm3/m16, and     \n                                                            store the result  \n                                                            in xmm1.          \n                                                            Multiply FP16     \n                                                            values from xmm2  \n   EVEX.LLIG.66.MAP6.W0 BD /r                               and xmm3/m16, and \n   VFNMADD231SH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 negate the value. \n   xmm3/m16 {er}                                            Add this value to \n                                                            xmm1, and store   \n                                                            the result in     \n                                                            xmm1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a scalar multiply-add or negated multiply-add computation on the\n   low FP16 values using three source operands and writes the result in the\n   destination operand. The destination operand is also the first source\n   operand. The \u201cN\u201d (negated) forms of this instruction add the negated\n   infinite precision intermediate product to the corresponding remaining\n   operand. The notation\u2019 \u201c132\u201d, \u201c213\u201d and \u201c231\u201d indicate the use of the\n   operands in \u00b1A * B + C, where each digit corresponds to the operand\n   number, with the destination being operand 1; see Table 5-4.\n\n   Bits 127:16 of the destination operand are preserved. Bits MAXVL-1:128 of\n   the destination operand are zeroed. The low FP16 element of the\n   destination is updated according to the writemask.\n\n   Notation Operands                \n   132      dest = \u00b1 dest*src3+src2 \n   231      dest = \u00b1 src2*src3+dest \n   213      dest = \u00b1 src2*dest+src3 \n\n   Table 5-4. VF[,N]MADD[132,213,231]SH Notation for Operands\n"],
	["serialize", "                  SERIALIZE \u2014 Serialize Instruction Execution\n\n   Opcode/Instruction    Op/En 64/32 bit    CPUID Feature Description         \n                               Mode Support Flag          \n                                                          Serialize           \n   NP 0F 01 E8 SERIALIZE ZO    V/V          SERIALIZE     instruction fetch   \n                                                          and execution.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Serializes instruction execution. Before the next instruction is fetched\n   and executed, the SERIALIZE instruction ensures that all modifications to\n   flags, registers, and memory by previous instructions are completed,\n   draining all buffered writes to memory. This instruction is also a\n   serializing instruction as defined in the section \u201cSerializing\n   Instructions\u201d in Chapter 9 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3A.\n\n   SERIALIZE does not modify registers, arithmetic flags, or memory.\n"],
	["stmxcsr", "                      STMXCSR \u2014 Store MXCSR Register State\n\n                                 64/32 bit    CPUID                           \n   Opcode*/Instruction     Op/En Mode Support Feature Description\n                                              Flag    \n   NP 0F AE /3 STMXCSR m32 M     V/V          SSE     Store contents of MXCSR \n                                                      register to m32.        \n   VEX.LZ.0F.WIG AE /3     M     V/V          AVX     Store contents of MXCSR \n   VSTMXCSR m32                                       register to m32.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Stores the contents of the MXCSR control and status register to the\n   destination operand. The destination operand is a 32-bit memory location.\n   The reserved bits in the MXCSR register are stored as 0s.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\n   VEX.L must be 0, otherwise instructions will #UD.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["mov-2", "                       MOV \u2014 Move to/from Debug Registers\n\n   Opcode/Instruction       Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   0F 21/r MOV r32, DR0\u2013DR7 MR    N.E.   Valid      Move debug register to    \n                                                    r32.                      \n   0F 21/r MOV r64, DR0\u2013DR7 MR    Valid  N.E.       Move extended debug       \n                                                    register to r64.          \n   0F 23 /r MOV DR0\u2013DR7,    RM    N.E.   Valid      Move r32 to debug         \n   r32                                              register.                 \n   0F 23 /r MOV DR0\u2013DR7,    RM    Valid  N.E.       Move r64 to extended      \n   r64                                              debug register.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the contents of a debug register (DR0, DR1, DR2, DR3, DR4, DR5, DR6,\n   or DR7) to a general-purpose register or vice versa. The operand size for\n   these instructions is always 32 bits in non-64-bit modes, regardless of\n   the operand-size attribute. (See Section 18.2, \u201cDebug Registers\u201d, of the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A,\n   for a detailed description of the flags and fields in the debug\n   registers.)\n\n   The instructions must be executed at privilege level 0 or in real-address\n   mode.\n\n   When the debug extension (DE) flag in register CR4 is clear, these\n   instructions operate on debug registers in a manner that is compatible\n   with Intel386 and Intel486 processors. In this mode, references to DR4 and\n   DR5 refer to DR6 and DR7, respectively. When the DE flag in CR4 is set,\n   attempts to reference DR4 and DR5 result in an undefined opcode (#UD)\n   exception. (The CR4 register was added to the IA-32 Architecture beginning\n   with the Pentium processor.)\n\n   At the opcode level, the reg field within the ModR/M byte specifies which\n   of the debug registers is loaded or read. The two bits in the mod field\n   are ignored. The r/m field specifies the general-purpose register loaded\n   or read.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 64 bits. Use\n   of the REX.B prefix permits access to additional registers (R8\u2013R15). Use\n   of the REX.W or 66H prefix is ignored. Use of the REX.R prefix causes an\n   invalid-opcode exception. See the summary chart at the beginning of this\n   section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   The OF, SF, ZF, AF, PF, and CF flags are undefined.\n"],
	["test", "                             TEST \u2014 Logical Compare\n\n   Opcode   Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n                                                    AND imm8 with AL; set SF, \n   A8 ib    TEST AL, imm8   I     Valid  Valid      ZF, PF according to       \n                                                    result.                   \n                                                    AND imm16 with AX; set    \n   A9 iw    TEST AX, imm16  I     Valid  Valid      SF, ZF, PF according to   \n                                                    result.                   \n                                                    AND imm32 with EAX; set   \n   A9 id    TEST EAX, imm32 I     Valid  Valid      SF, ZF, PF according to   \n                                                    result.                   \n                                                    AND imm32 sign-extended   \n   REX.W +  TEST RAX, imm32 I     Valid  N.E.       to 64-bits with RAX; set  \n   A9 id                                            SF, ZF, PF according to   \n                                                    result.                   \n                                                    AND imm8 with r/m8; set   \n   F6 /0 ib TEST r/m8, imm8 MI    Valid  Valid      SF, ZF, PF according to   \n                                                    result.                   \n   REX + F6 TEST r/m8^1,                            AND imm8 with r/m8; set   \n   /0 ib    imm8            MI    Valid  N.E.       SF, ZF, PF according to   \n                                                    result.                   \n            TEST r/m16,                             AND imm16 with r/m16; set \n   F7 /0 iw imm16           MI    Valid  Valid      SF, ZF, PF according to   \n                                                    result.                   \n            TEST r/m32,                             AND imm32 with r/m32; set \n   F7 /0 id imm32           MI    Valid  Valid      SF, ZF, PF according to   \n                                                    result.                   \n                                                    AND imm32 sign-extended   \n   REX.W +  TEST r/m64,     MI    Valid  N.E.       to 64-bits with r/m64;    \n   F7 /0 id imm32                                   set SF, ZF, PF according  \n                                                    to result.                \n                                                    AND r8 with r/m8; set SF, \n   84 /r    TEST r/m8, r8   MR    Valid  Valid      ZF, PF according to       \n                                                    result.                   \n   REX + 84 TEST r/m8^1,                            AND r8 with r/m8; set SF, \n   /r       r8^1            MR    Valid  N.E.       ZF, PF according to       \n                                                    result.                   \n                                                    AND r16 with r/m16; set   \n   85 /r    TEST r/m16, r16 MR    Valid  Valid      SF, ZF, PF according to   \n                                                    result.                   \n                                                    AND r32 with r/m32; set   \n   85 /r    TEST r/m32, r32 MR    Valid  Valid      SF, ZF, PF according to   \n                                                    result.                   \n   REX.W +                                          AND r64 with r/m64; set   \n   85 /r    TEST r/m64, r64 MR    Valid  N.E.       SF, ZF, PF according to   \n                                                    result.                   \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   I     AL/AX/EAX/RAX imm8/16/32    N/A       N/A       \n   MI    ModRM:r/m (r) imm8/16/32    N/A       N/A       \n   MR    ModRM:r/m (r) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Computes the bit-wise logical AND of first operand (source 1 operand) and\n   the second operand (source 2 operand) and sets the SF, ZF, and PF status\n   flags according to the result. The result is then discarded.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits access to\n   additional registers (R8-R15). Using a REX prefix in the form of REX.W\n   promotes operation to 64 bits. See the summary chart at the beginning of\n   this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   The OF and CF flags are set to 0. The SF, ZF, and PF flags are set\n   according to the result (see the \u201cOperation\u201d section above). The state of\n   the AF flag is undefined.\n"],
	["vscalefsh", "             VSCALEFSH \u2014 Scale Scalar FP16 Values with FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En bit Mode Flag     \n   CPUID Feature Instruction En bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En bit Mode Flag     \n   CPUID Feature Instruction En bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Scale the FP16      \n                                                          values in xmm2      \n                                                          using the value     \n   EVEX.LLIG.66.MAP6.W0 2D /r                             from xmm3/m16 and   \n   VSCALEFSH xmm1{k1}{z}, xmm2,     A V/V     AVX512-FP16 store the result in \n   xmm3/m16 {er}                                          xmm1 subject to     \n                                                          writemask k1. Bits  \n                                                          127:16 from xmm2    \n                                                          are copied to       \n                                                          xmm1[127:16].       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a floating-point scale of the low FP16 element\n   in the first source operand by multiplying it by 2 to the power of the low\n   FP16 element in second source operand, storing the result in the low\n   element of the destination operand.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   The equation of this operation is given by:\n\n   xmm1 := xmm2 * 2^floor(xmm3).\n\n   Floor(xmm3) means maximum integer value \u2264 xmm3.\n\n   If the result cannot be represented in FP16, then the proper overflow\n   response (for positive scaling operand), or the proper underflow response\n   (for negative scaling operand), is issued. The overflow and underflow\n   responses are dependent on the rounding mode (for IEEE-compliant\n   rounding), as well as on other settings in MXCSR (exception mask bits, FTZ\n   bit), and on the SAE bit.\n\n   Handling of special-case input values are listed in Table 5-41 and Table\n   5-42.\n"],
	["vpbroadcast", "                    VPBROADCAST \u2014 Load Integer and Broadcast\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n   VEX.128.66.0F38.W0 78 /r                           Broadcast a byte        \n   VPBROADCASTB xmm1,        A     V/V       AVX2     integer in the source   \n   xmm2/m8                                            operand to sixteen      \n                                                      locations in xmm1.      \n   VEX.256.66.0F38.W0 78 /r                           Broadcast a byte        \n   VPBROADCASTB ymm1,        A     V/V       AVX2     integer in the source   \n   xmm2/m8                                            operand to thirty-two   \n                                                      locations in ymm1.      \n                                                      Broadcast a byte        \n   EVEX.128.66.0F38.W0 78 /r                 AVX512VL integer in the source   \n   VPBROADCASTB xmm1{k1}{z}, B     V/V       AVX512BW operand to locations in \n   xmm2/m8                                            xmm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a byte        \n   EVEX.256.66.0F38.W0 78 /r                 AVX512VL integer in the source   \n   VPBROADCASTB ymm1{k1}{z}, B     V/V       AVX512BW operand to locations in \n   xmm2/m8                                            ymm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a byte        \n   EVEX.512.66.0F38.W0 78 /r                          integer in the source   \n   VPBROADCASTB zmm1{k1}{z}, B     V/V       AVX512BW operand to 64 locations \n   xmm2/m8                                            in zmm1 subject to      \n                                                      writemask k1.           \n   VEX.128.66.0F38.W0 79 /r                           Broadcast a word        \n   VPBROADCASTW xmm1,        A     V/V       AVX2     integer in the source   \n   xmm2/m16                                           operand to eight        \n                                                      locations in xmm1.      \n   VEX.256.66.0F38.W0 79 /r                           Broadcast a word        \n   VPBROADCASTW ymm1,        A     V/V       AVX2     integer in the source   \n   xmm2/m16                                           operand to sixteen      \n                                                      locations in ymm1.      \n                                                      Broadcast a word        \n   EVEX.128.66.0F38.W0 79 /r                 AVX512VL integer in the source   \n   VPBROADCASTW xmm1{k1}{z}, B     V/V       AVX512BW operand to locations in \n   xmm2/m16                                           xmm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a word        \n   EVEX.256.66.0F38.W0 79 /r                 AVX512VL integer in the source   \n   VPBROADCASTW ymm1{k1}{z}, B     V/V       AVX512BW operand to locations in \n   xmm2/m16                                           ymm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a word        \n   EVEX.512.66.0F38.W0 79 /r                          integer in the source   \n   VPBROADCASTW zmm1{k1}{z}, B     V/V       AVX512BW operand to 32 locations \n   xmm2/m16                                           in zmm1 subject to      \n                                                      writemask k1.           \n   VEX.128.66.0F38.W0 58 /r                           Broadcast a dword       \n   VPBROADCASTD xmm1,        A     V/V       AVX2     integer in the source   \n   xmm2/m32                                           operand to four         \n                                                      locations in xmm1.      \n   VEX.256.66.0F38.W0 58 /r                           Broadcast a dword       \n   VPBROADCASTD ymm1,        A     V/V       AVX2     integer in the source   \n   xmm2/m32                                           operand to eight        \n                                                      locations in ymm1.      \n                                                      Broadcast a dword       \n   EVEX.128.66.0F38.W0 58 /r                 AVX512VL integer in the source   \n   VPBROADCASTD xmm1         B     V/V       AVX512F  operand to locations in \n   {k1}{z}, xmm2/m32                                  xmm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a dword       \n   EVEX.256.66.0F38.W0 58 /r                 AVX512VL integer in the source   \n   VPBROADCASTD ymm1         B     V/V       AVX512F  operand to locations in \n   {k1}{z}, xmm2/m32                                  ymm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a dword       \n   EVEX.512.66.0F38.W0 58 /r                          integer in the source   \n   VPBROADCASTD zmm1         B     V/V       AVX512F  operand to locations in \n   {k1}{z}, xmm2/m32                                  zmm1 subject to         \n                                                      writemask k1.           \n   VEX.128.66.0F38.W0 59 /r                           Broadcast a qword       \n   VPBROADCASTQ xmm1,        A     V/V       AVX2     element in source       \n   xmm2/m64                                           operand to two          \n                                                      locations in xmm1.      \n   VEX.256.66.0F38.W0 59 /r                           Broadcast a qword       \n   VPBROADCASTQ ymm1,        A     V/V       AVX2     element in source       \n   xmm2/m64                                           operand to four         \n                                                      locations in ymm1.      \n                                                      Broadcast a qword       \n   EVEX.128.66.0F38.W1 59 /r                 AVX512VL element in source       \n   VPBROADCASTQ xmm1         B     V/V       AVX512F  operand to locations in \n   {k1}{z}, xmm2/m64                                  xmm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a qword       \n   EVEX.256.66.0F38.W1 59 /r                 AVX512VL element in source       \n   VPBROADCASTQ ymm1         B     V/V       AVX512F  operand to locations in \n   {k1}{z}, xmm2/m64                                  ymm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast a qword       \n   EVEX.512.66.0F38.W1 59 /r                          element in source       \n   VPBROADCASTQ zmm1         B     V/V       AVX512F  operand to locations in \n   {k1}{z}, xmm2/m64                                  zmm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast two dword     \n   EVEX.128.66.0F38.W0 59 /r                 AVX512VL elements in source      \n   VBROADCASTI32x2 xmm1      C     V/V       AVX512DQ operand to locations in \n   {k1}{z}, xmm2/m64                                  xmm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast two dword     \n   EVEX.256.66.0F38.W0 59 /r                 AVX512VL elements in source      \n   VBROADCASTI32x2 ymm1      C     V/V       AVX512DQ operand to locations in \n   {k1}{z}, xmm2/m64                                  ymm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast two dword     \n   EVEX.512.66.0F38.W0 59 /r                          elements in source      \n   VBROADCASTI32x2 zmm1      C     V/V       AVX512DQ operand to locations in \n   {k1}{z}, xmm2/m64                                  zmm1 subject to         \n                                                      writemask k1.           \n                                                      Broadcast 128 bits of   \n   VEX.256.66.0F38.W0 5A /r  A     V/V       AVX2     integer data in mem to  \n   VBROADCASTI128 ymm1, m128                          low and high 128-bits   \n                                                      in ymm1.                \n                                                      Broadcast 128 bits of 4 \n   EVEX.256.66.0F38.W0 5A /r                 AVX512VL doubleword integer data \n   VBROADCASTI32X4 ymm1      D     V/V       AVX512F  in mem to locations in  \n   {k1}{z}, m128                                      ymm1 using writemask    \n                                                      k1.                     \n                                                      Broadcast 128 bits of 4 \n   EVEX.512.66.0F38.W0 5A /r                          doubleword integer data \n   VBROADCASTI32X4 zmm1      D     V/V       AVX512F  in mem to locations in  \n   {k1}{z}, m128                                      zmm1 using writemask    \n                                                      k1.                     \n                                                      Broadcast 128 bits of 2 \n   EVEX.256.66.0F38.W1 5A /r                 AVX512VL quadword integer data   \n   VBROADCASTI64X2 ymm1      C     V/V       AVX512DQ in mem to locations in  \n   {k1}{z}, m128                                      ymm1 using writemask    \n                                                      k1.                     \n                                                      Broadcast 128 bits of 2 \n   EVEX.512.66.0F38.W1 5A /r                          quadword integer data   \n   VBROADCASTI64X2 zmm1      C     V/V       AVX512DQ in mem to locations in  \n   {k1}{z}, m128                                      zmm1 using writemask    \n                                                      k1.                     \n                                                      Broadcast 256 bits of 8 \n   EVEX.512.66.0F38.W0 5B /r                          doubleword integer data \n   VBROADCASTI32X8 zmm1      E     V/V       AVX512DQ in mem to locations in  \n   {k1}{z}, m256                                      zmm1 using writemask    \n                                                      k1.                     \n                                                      Broadcast 256 bits of 4 \n   EVEX.512.66.0F38.W1 5B /r                          quadword integer data   \n   VBROADCASTI64X4 zmm1      D     V/V       AVX512F  in mem to locations in  \n   {k1}{z}, m256                                      zmm1 using writemask    \n                                                      k1.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   C     Tuple2        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Tuple4        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   E     Tuple8        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Load integer data from the source operand (the second operand) and\n   broadcast to all elements of the destination operand (the first operand).\n\n   VEX256-encoded VPBROADCASTB/W/D/Q: The source operand is 8-bit, 16-bit,\n   32-bit, 64-bit memory location or the low 8-bit, 16-bit 32-bit, 64-bit\n   data in an XMM register. The destination operand is a YMM register.\n   VPBROAD-CASTI128 support the source operand of 128-bit memory location.\n   Register source encodings for VPBROADCAS-TI128 is reserved and will #UD.\n   Bits (MAXVL-1:256) of the destination register are zeroed.\n\n   EVEX-encoded VPBROADCASTD/Q: The source operand is a 32-bit, 64-bit memory\n   location or the low 32-bit, 64-bit data in an XMM register. The\n   destination operand is a ZMM/YMM/XMM register and updated according to the\n   writemask k1.\n\n   VPBROADCASTI32X4 and VPBROADCASTI64X4: The destination operand is a ZMM\n   register and updated according to the writemask k1. The source operand is\n   128-bit or 256-bit memory location. Register source encodings for\n   VBROADCASTI32X4 and VBROADCASTI64X4 are reserved and will #UD.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   If VPBROADCASTI128 is encoded with VEX.L= 0, an attempt to execute the\n   instruction encoded with VEX.L= 0 will cause an #UD exception.\n\n   X0 m32 DEST X0 X0 X0 X0 X0 X0 X0 X0 Figure 5-16. VPBROADCASTD Operation\n   (VEX.256 encoded version) X0 m32 DEST 0 0 0 0 X0 X0 X0 X0 Figure 5-17.\n   VPBROADCASTD Operation (128-bit version) m64 X0 DEST X0 X0 X0 X0 Figure\n   5-18. VPBROADCASTQ Operation (256-bit version) m128 X0 DEST X0 X0 Figure\n   5-19. VBROADCASTI128 Operation (256-bit version) m256 X0 DEST X0 X0 Figure\n   5-20. VBROADCASTI256 Operation (512-bit version)\n"],
	["vpcmpd:vpcmpud", "            VPCMPD/VPCMPUD \u2014 Compare Packed Integer Values Into Mask\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Compare packed signed     \n                                                    doubleword integer values \n   EVEX.128.66.0F3A.W0 1F                           in xmm3/m128/m32bcst and  \n   /r ib VPCMPD k1 {k2},   A     V/V       AVX512VL xmm2 using bits 2:0 of    \n   xmm2,                                   AVX512F  imm8 as a comparison      \n   xmm3/m128/m32bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed signed     \n                                                    doubleword integer values \n   EVEX.256.66.0F3A.W0 1F                           in ymm3/m256/m32bcst and  \n   /r ib VPCMPD k1 {k2},   A     V/V       AVX512VL ymm2 using bits 2:0 of    \n   ymm2,                                   AVX512F  imm8 as a comparison      \n   ymm3/m256/m32bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed signed     \n                                                    doubleword integer values \n                                                    in zmm2 and               \n   EVEX.512.66.0F3A.W0 1F                           zmm3/m512/m32bcst using   \n   /r ib VPCMPD k1 {k2},   A     V/V       AVX512F  bits 2:0 of imm8 as a     \n   zmm2,                                            comparison predicate. The \n   zmm3/m512/m32bcst, imm8                          comparison results are    \n                                                    written to the            \n                                                    destination k1 under      \n                                                    writemask k2.             \n                                                    Compare packed unsigned   \n                                                    doubleword integer values \n   EVEX.128.66.0F3A.W0 1E                           in xmm3/m128/m32bcst and  \n   /r ib VPCMPUD k1 {k2},  A     V/V       AVX512VL xmm2 using bits 2:0 of    \n   xmm2,                                   AVX512F  imm8 as a comparison      \n   xmm3/m128/m32bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed unsigned   \n                                                    doubleword integer values \n   EVEX.256.66.0F3A.W0 1E                           in ymm3/m256/m32bcst and  \n   /r ib VPCMPUD k1 {k2},  A     V/V       AVX512VL ymm2 using bits 2:0 of    \n   ymm2,                                   AVX512F  imm8 as a comparison      \n   ymm3/m256/m32bcst, imm8                          predicate with writemask  \n                                                    k2 and leave the result   \n                                                    in mask register k1.      \n                                                    Compare packed unsigned   \n                                                    doubleword integer values \n                                                    in zmm2 and               \n   EVEX.512.66.0F3A.W0 1E                           zmm3/m512/m32bcst using   \n   /r ib VPCMPUD k1 {k2},  A     V/V       AVX512F  bits 2:0 of imm8 as a     \n   zmm2,                                            comparison predicate. The \n   zmm3/m512/m32bcst, imm8                          comparison results are    \n                                                    written to the            \n                                                    destination k1 under      \n                                                    writemask k2.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   Performs a SIMD compare of the packed integer values in the second source\n   operand and the first source operand and returns the results of the\n   comparison to the mask destination operand. The comparison predicate\n   operand (immediate byte) specifies the type of comparison performed on\n   each pair of packed values in the two source operands. The result of each\n   comparison is a single mask bit result of 1 (comparison true) or 0\n   (comparison false).\n\n   VPCMPD/VPCMPUD performs a comparison between pairs of signed/unsigned\n   doubleword integer values.\n\n   The first source operand (second operand) is a ZMM/YMM/XMM register. The\n   second source operand can be a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location or a 512-bit vector broadcasted from a 32-bit memory\n   location. The destination operand (first operand) is a mask register k1.\n   Up to 16/8/4 comparisons are performed with results written to the\n   destination operand under the writemask k2.\n\n   The comparison predicate operand is an 8-bit immediate: bits 2:0 define\n   the type of comparison to be performed. Bits 3 through 7 of the immediate\n   are reserved. Compiler can implement the pseudo-op mnemonic listed in\n   Table 5-21.\n"],
	["vfmadd132ph:vfnmadd132ph:vfmadd213ph:vfnmadd213ph:vfmadd231ph:vfnmadd231ph", "  VFMADD132PH/VFNMADD132PH/VFMADD213PH/VFNMADD213PH/VFMADD231PH/VFNMADD231PH \u2014\n                    Fused Multiply-Add of Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Multiply packed FP16   \n   EVEX.128.66.MAP6.W0 98 /r               AVX512-FP16 values from xmm1 and   \n   VFMADD132PH xmm1{k1}{z},      A V/V     AVX512VL    xmm3/m128/m16bcst, add \n   xmm2, xmm3/m128/m16bcst                             to xmm2, and store the \n                                                       result in xmm1.        \n                                                       Multiply packed FP16   \n   EVEX.256.66.MAP6.W0 98 /r               AVX512-FP16 values from ymm1 and   \n   VFMADD132PH ymm1{k1}{z},      A V/V     AVX512VL    ymm3/m256/m16bcst, add \n   ymm2, ymm3/m256/m16bcst                             to ymm2, and store the \n                                                       result in ymm1.        \n                                                       Multiply packed FP16   \n   EVEX.512.66.MAP6.W0 98 /r                           values from zmm1 and   \n   VFMADD132PH zmm1{k1}{z},      A V/V     AVX512-FP16 zmm3/m512/m16bcst, add \n   zmm2, zmm3/m512/m16bcst {er}                        to zmm2, and store the \n                                                       result in zmm1.        \n                                                       Multiply packed FP16   \n   EVEX.128.66.MAP6.W0 A8 /r                           values from xmm1 and   \n   VFMADD213PH xmm1{k1}{z},      A V/V     AVX512-FP16 xmm2, add to           \n   xmm2, xmm3/m128/m16bcst                 AVX512VL    xmm3/m128/m16bcst, and \n                                                       store the result in    \n                                                       xmm1.                  \n                                                       Multiply packed FP16   \n   EVEX.256.66.MAP6.W0 A8 /r                           values from ymm1 and   \n   VFMADD213PH ymm1{k1}{z},      A V/V     AVX512-FP16 ymm2, add to           \n   ymm2, ymm3/m256/m16bcst                 AVX512VL    ymm3/m256/m16bcst, and \n                                                       store the result in    \n                                                       ymm1.                  \n                                                       Multiply packed FP16   \n   EVEX.512.66.MAP6.W0 A8 /r                           values from zmm1 and   \n   VFMADD213PH zmm1{k1}{z},      A V/V     AVX512-FP16 zmm2, add to           \n   zmm2, zmm3/m512/m16bcst {er}                        zmm3/m512/m16bcst, and \n                                                       store the result in    \n                                                       zmm1.                  \n                                                       Multiply packed FP16   \n   EVEX.128.66.MAP6.W0 B8 /r               AVX512-FP16 values from xmm2 and   \n   VFMADD231PH xmm1{k1}{z},      A V/V     AVX512VL    xmm3/m128/m16bcst, add \n   xmm2, xmm3/m128/m16bcst                             to xmm1, and store the \n                                                       result in xmm1.        \n                                                       Multiply packed FP16   \n   EVEX.256.66.MAP6.W0 B8 /r               AVX512-FP16 values from ymm2 and   \n   VFMADD231PH ymm1{k1}{z},      A V/V     AVX512VL    ymm3/m256/m16bcst, add \n   ymm2, ymm3/m256/m16bcst                             to ymm1, and store the \n                                                       result in ymm1.        \n                                                       Multiply packed FP16   \n   EVEX.512.66.MAP6.W0 B8 /r                           values from zmm2 and   \n   VFMADD231PH zmm1{k1}{z},      A V/V     AVX512-FP16 zmm3/m512/m16bcst, add \n   zmm2, zmm3/m512/m16bcst {er}                        to zmm1, and store the \n                                                       result in zmm1.        \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 9C /r               AVX512-FP16 xmm3/m128/m16bcst, and \n   VFNMADD132PH xmm1{k1}{z},     A V/V     AVX512VL    negate the value. Add  \n   xmm2, xmm3/m128/m16bcst                             this value to xmm2,    \n                                                       and store the result   \n                                                       in xmm1.               \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 9C /r               AVX512-FP16 ymm3/m256/m16bcst, and \n   VFNMADD132PH ymm1{k1}{z},     A V/V     AVX512VL    negate the value. Add  \n   ymm2, ymm3/m256/m16bcst                             this value to ymm2,    \n                                                       and store the result   \n                                                       in ymm1.               \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 9C /r                           zmm3/m512/m16bcst, and \n   VFNMADD132PH zmm1{k1}{z},     A V/V     AVX512-FP16 negate the value. Add  \n   zmm2, zmm3/m512/m16bcst {er}                        this value to zmm2,    \n                                                       and store the result   \n                                                       in zmm1.               \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 AC /r               AVX512-FP16 xmm2, and negate the   \n   VFNMADD213PH xmm1{k1}{z},     A V/V     AVX512VL    value. Add this value  \n   xmm2, xmm3/m128/m16bcst                             to xmm3/m128/m16bcst,  \n                                                       and store the result   \n                                                       in xmm1.               \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 AC /r               AVX512-FP16 ymm2, and negate the   \n   VFNMADD213PH ymm1{k1}{z},     A V/V     AVX512VL    value. Add this value  \n   ymm2, ymm3/m256/m16bcst                             to ymm3/m256/m16bcst,  \n                                                       and store the result   \n                                                       in ymm1.               \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 AC /r                           zmm2, and negate the   \n   VFNMADD213PH zmm1{k1}{z},     A V/V     AVX512-FP16 value. Add this value  \n   zmm2, zmm3/m512/m16bcst {er}                        to zmm3/m512/m16bcst,  \n                                                       and store the result   \n                                                       in zmm1.               \n                                                       Multiply packed FP16   \n                                                       values from xmm2 and   \n   EVEX.128.66.MAP6.W0 BC /r               AVX512-FP16 xmm3/m128/m16bcst, and \n   VFNMADD231PH xmm1{k1}{z},     A V/V     AVX512VL    negate the value. Add  \n   xmm2, xmm3/m128/m16bcst                             this value to xmm1,    \n                                                       and store the result   \n                                                       in xmm1.               \n                                                       Multiply packed FP16   \n                                                       values from ymm2 and   \n   EVEX.256.66.MAP6.W0 BC /r               AVX512-FP16 ymm3/m256/m16bcst, and \n   VFNMADD231PH ymm1{k1}{z},     A V/V     AVX512VL    negate the value. Add  \n   ymm2, ymm3/m256/m16bcst                             this value to ymm1,    \n                                                       and store the result   \n                                                       in ymm1.               \n                                                       Multiply packed FP16   \n                                                       values from zmm2 and   \n   EVEX.512.66.MAP6.W0 BC /r                           zmm3/m512/m16bcst, and \n   VFNMADD231PH zmm1{k1}{z},     A V/V     AVX512-FP16 negate the value. Add  \n   zmm2, zmm3/m512/m16bcst {er}                        this value to zmm1,    \n                                                       and store the result   \n                                                       in zmm1.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a packed multiply-add or negated multiply-add\n   computation on FP16 values using three source operands and writes the\n   results in the destination operand. The destination operand is also the\n   first source operand. The \u201cN\u201d (negated) forms of this instruction add the\n   negated infinite precision intermediate product to the corresponding\n   remaining operand. The notation\u2019 \u201c132\u201d, \u201c213\u201d and \u201c231\u201d indicate the use\n   of the operands in \u00b1A * B + C, where each digit corresponds to the operand\n   number, with the destination being operand 1; see Table 5-2.\n\n   The destination elements are updated according to the writemask.\n\n   Notation Operands                \n   132      dest = \u00b1 dest*src3+src2 \n   231      dest = \u00b1 src2*src3+dest \n   213      dest = \u00b1 src2*dest+src3 \n\n   Table 5-2. VF[,N]MADD[132,213,231]PH Notation for Operands\n"],
	["lmsw", "                        LMSW \u2014 Load Machine Status Word\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Mode Description              \n                              Mode   \n   0F 01 /6 LMSW r/m16  M     Valid  Valid           Loads r/m16 in machine   \n                                                     status word of CR0.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the source operand into the machine status word, bits 0 through 15\n   of register CR0. The source operand can be a 16-bit general-purpose\n   register or a memory location. Only the low-order 4 bits of the source\n   operand (which contains the PE, MP, EM, and TS flags) are loaded into CR0.\n   The PG, CD, NW, AM, WP, NE, and ET flags of CR0 are not affected. The\n   operand-size attribute has no effect on this instruction.\n\n   If the PE flag of the source operand (bit 0) is set to 1, the instruction\n   causes the processor to switch to protected mode. While in protected mode,\n   the LMSW instruction cannot be used to clear the PE flag and force a\n   switch back to real-address mode.\n\n   The LMSW instruction is provided for use in operating-system software; it\n   should not be used in application programs. In protected or virtual-8086\n   mode, it can only be executed at CPL 0.\n\n   This instruction is provided for compatibility with the Intel 286\n   processor; programs and procedures intended to run on IA-32 and Intel 64\n   processors beginning with Intel386 processors should use the MOV (control\n   registers) instruction to load the whole CR0 register. The MOV CR0\n   instruction can be used to set and clear the PE flag in CR0, allowing a\n   procedure or program to switch between protected and real-address modes.\n\n   This instruction is a serializing instruction.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode. Note that the operand size is fixed at 16 bits.\n\n   See \u201cChanges to Instruction Behavior in VMX Non-Root Operation\u201d in Chapter\n   26 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3C, for more information about the behavior of this instruction in\n   VMX non-root operation.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["wait:fwait", "                               WAIT/FWAIT \u2014 Wait\n\n   Opcode Instruction Op/En 64-Bit Compat/Leg Mode Description                \n                            Mode   \n   9B     WAIT        ZO    Valid  Valid           Check pending unmasked     \n                                                   floating-point exceptions. \n   9B     FWAIT       ZO    Valid  Valid           Check pending unmasked     \n                                                   floating-point exceptions. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Causes the processor to check for and handle pending, unmasked,\n   floating-point exceptions before proceeding. (FWAIT is an alternate\n   mnemonic for WAIT.)\n\n   This instruction is useful for synchronizing exceptions in critical\n   sections of code. Coding a WAIT instruction after a floating-point\n   instruction ensures that any unmasked floating-point exceptions the\n   instruction may raise are handled before the processor can modify the\n   instruction\u2019s results. See the section titled \u201cFloating-Point Exception\n   Synchronization\u201d in Chapter 8 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, for more information on using the\n   WAIT/FWAIT instruction.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   The C0, C1, C2, and C3 flags are undefined.\n"],
	["fxsave", "              FXSAVE \u2014 Save x87 FPU, MMX Technology, and SSE State\n\n   Opcode/Instruction  Op/En 64-Bit Compat/Leg Description                    \n                             Mode   Mode       \n   NP 0F AE /0 FXSAVE                          Save the x87 FPU, MMX, XMM,    \n   m512byte            M     Valid  Valid      and MXCSR register state to    \n                                               m512byte.                      \n   NP REX.W + 0F AE /0                         Save the x87 FPU, MMX, XMM,    \n   FXSAVE64 m512byte   M     Valid  N.E.       and MXCSR register state to    \n                                               m512byte.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Saves the current state of the x87 FPU, MMX technology, XMM, and MXCSR\n   registers to a 512-byte memory location specified in the destination\n   operand. The content layout of the 512 byte region depends on whether the\n   processor is operating in non-64-bit operating modes or 64-bit sub-mode of\n   IA-32e mode.\n\n   Bytes 464:511 are available to software use. The processor does not write\n   to bytes 464:511 of an FXSAVE area.\n\n   The operation of FXSAVE in non-64-bit modes is described first.\n\nNon-64-Bit Mode Operation \u00b6\n\n   Table 3-43 shows the layout of the state information in memory when the\n   processor is operating in legacy modes.\n\n   15 14 13 12 1110  98  7654                                   3210  \n   Rsvd  FCS   FIP[31:0] FOP                           Rsvd FTW FSW   FCW 0   \n   MXCSR_MASK  MXCSR     R FDS s FDS r FDS v FDS d FDS FDS      FDP[31:0] 16  \n   Reserved          ST0/MM0                                              32  \n   Reserved          ST1/MM1                                              48  \n   Reserved          ST2/MM2                                              64  \n   Reserved          ST3/MM3                                              80  \n   Reserved          ST4/MM4                                              96  \n   Reserved          ST5/MM5                                              112 \n   Reserved          ST6/MM6                                              128 \n   Reserved          ST7/MM7                                              144 \n   XMM0                                                                   160 \n   XMM1                                                                   176 \n   XMM2                                                                   192 \n   XMM3                                                                   208 \n   XMM4                                                                   224 \n   XMM5                                                                   240 \n   XMM6                                                                   256 \n   XMM7                                                                   272 \n   Reserved                                                               288 \n\n   Table 3-43. Non-64-Bit-Mode Layout of FXSAVE and FXRSTOR Memory Region\n\n   15 14 13 12 11 10 9 8 7 6 5 4 3 2 1 0 \n   Reserved                              304 \n   Reserved                              320 \n   Reserved                              336 \n   Reserved                              352 \n   Reserved                              368 \n   Reserved                              384 \n   Reserved                              400 \n   Reserved                              416 \n   Reserved                              432 \n   Reserved                              448 \n   Available                             464 \n   Available                             480 \n   Available                             496 \n\n   Table 3-43. Non-64-Bit-Mode Layout of FXSAVE and FXRSTOR Memory Region\n   (Contd.)\n\n   The destination operand contains the first byte of the memory image, and\n   it must be aligned on a 16-byte boundary. A misaligned destination operand\n   will result in a general-protection (#GP) exception being generated (or in\n   some cases, an alignment check exception [#AC]).\n\n   The FXSAVE instruction is used when an operating system needs to perform a\n   context switch or when an exception handler needs to save and examine the\n   current state of the x87 FPU, MMX technology, and/or XMM and MXCSR\n   registers.\n\n   The fields in Table 3-43 are defined in Table 3-44.\n\n   Field             Definition                                               \n                     x87 FPU Control Word (16 bits). See Figure 8-6 in the    \n   FCW               Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s  \n                     Manual, Volume 1, for the layout of the x87 FPU control  \n                     word.                                                    \n                     x87 FPU Status Word (16 bits). See Figure 8-4 in the     \n   FSW               Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s  \n                     Manual, Volume 1, for the layout of the x87 FPU status   \n                     word.                                                    \n                     x87 FPU Tag Word (8 bits). The tag information saved     \n   Abridged FTW      here is abridged, as described in the following          \n                     paragraphs.                                              \n                     x87 FPU Opcode (16 bits). The lower 11 bits of this      \n                     field contain the opcode, upper 5 bits are reserved. See \n   FOP               Figure 8-8 in the Intel^\u00ae 64 and IA-32 Architectures     \n                     Software Developer\u2019s Manual, Volume 1, for the layout of \n                     the x87 FPU opcode field.                                \n                     x87 FPU Instruction Pointer Offset (64 bits). The        \n                     contents of this field differ depending on the current   \n                     addressing mode (32-bit, 16-bit, or 64-bit) of the       \n                     processor when the FXSAVE instruction was executed:      \n                     32-bit mode \u2014 32-bit IP offset. 16-bit mode \u2014 low 16     \n   FIP               bits are IP offset; high 16 bits are reserved. 64-bit    \n                     mode with REX.W \u2014 64-bit IP offset. 64-bit mode without  \n                     REX.W \u2014 32-bit IP offset. See \u201cx87 FPU Instruction and   \n                     Operand (Data) Pointers\u201d in Chapter 8 of the Intel^\u00ae 64  \n                     and IA-32 Architectures Software Developer\u2019s Manual,     \n                     Volume 1, for a description of the x87 FPU instruction   \n                     pointer.                                                 \n                     x87 FPU Instruction Pointer Selector (16 bits). If       \n   FCS               CPUID.(EAX=07H,ECX=0H):EBX[bit 13] = 1, the processor    \n                     deprecates FCS and FDS, and this field is saved as       \n                     0000H.                                                   \n                     x87 FPU Instruction Operand (Data) Pointer Offset (64    \n                     bits). The contents of this field differ depending on    \n                     the current addressing mode (32-bit, 16-bit, or 64-bit)  \n                     of the processor when the FXSAVE instruction was         \n                     executed: 32-bit mode \u2014 32-bit DP offset. 16-bit mode \u2014  \n   FDP               low 16 bits are DP offset; high 16 bits are reserved.    \n                     64-bit mode with REX.W \u2014 64-bit DP offset. 64-bit mode   \n                     without REX.W \u2014 32-bit DP offset. See \u201cx87 FPU           \n                     Instruction and Operand (Data) Pointers\u201d in Chapter 8 of \n                     the Intel^\u00ae 64 and IA-32 Architectures Software          \n                     Developer\u2019s Manual, Volume 1, for a description of the   \n                     x87 FPU operand pointer.                                 \n                     x87 FPU Instruction Operand (Data) Pointer Selector (16  \n   FDS               bits). If CPUID.(EAX=07H,ECX=0H):EBX[bit 13] = 1, the    \n                     processor deprecates FCS and FDS, and this field is      \n                     saved as 0000H.                                          \n                     MXCSR Register State (32 bits). See Figure 10-3 in the   \n                     Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s  \n   MXCSR             Manual, Volume 1, for the layout of the MXCSR register.  \n                     If the OSFXSR bit in control register CR4 is not set,    \n                     the FXSAVE instruction may not save this register. This  \n                     behavior is implementation dependent.                    \n                     MXCSR_MASK (32 bits). This mask can be used to adjust    \n                     values written to the MXCSR register, ensuring that      \n                     reserved bits are set to 0. Set the mask bits and flags  \n                     in MXCSR to the mode of operation desired for SSE and    \n   MXCSR_ MASK       SSE2 SIMD floating-point instructions. See \u201cGuidelines   \n                     for Writing to the MXCSR Register\u201d in Chapter 11 of the  \n                     Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s  \n                     Manual, Volume 1, for instructions for how to determine  \n                     and use the MXCSR_MASK value.                            \n                     x87 FPU or MMX technology registers. These 80-bit fields \n                     contain the x87 FPU data registers or the MMX technology \n                     registers, depending on the state of the processor prior \n                     to the execution of the FXSAVE instruction. If the       \n   ST0/MM0 through   processor had been executing x87 FPU instruction prior   \n   ST7/MM7           to the FXSAVE instruction, the x87 FPU data registers    \n                     are saved; if it had been executing MMX instructions (or \n                     SSE or SSE2 instructions that operated on the MMX        \n                     technology registers), the MMX technology registers are  \n                     saved. When the MMX technology registers are saved, the  \n                     high 16 bits of the field are reserved.                  \n                     XMM registers (128 bits per field). If the OSFXSR bit in \n   XMM0 through XMM7 control register CR4 is not set, the FXSAVE instruction  \n                     may not save these registers. This behavior is           \n                     implementation dependent.                                \n\n   Table 3-44. Field Definitions\n\n   The FXSAVE instruction saves an abridged version of the x87 FPU tag word\n   in the FTW field (unlike the FSAVE instruction, which saves the complete\n   tag word). The tag information is saved in physical register order (R0\n   through R7), rather than in top-of-stack (TOS) order. With the FXSAVE\n   instruction, however, only a single bit (1 for valid or 0 for empty) is\n   saved for each tag. For example, assume that the tag word is currently set\n   as follows:\n\n   R7 R6 R5 R4 R3 R2 R1 R0\n\n   11 xx xx xx 11 11 11 11\n\n   Here, 11B indicates empty stack elements and \u201cxx\u201d indicates valid (00B),\n   zero (01B), or special (10B).\n\n   For this example, the FXSAVE instruction saves only the following 8 bits\n   of information:\n\n   R7 R6 R5 R4 R3 R2 R1 R0\n\n   01110000\n\n   Here, a 1 is saved for any valid, zero, or special tag, and a 0 is saved\n   for any empty tag.\n\n   The operation of the FXSAVE instruction differs from that of the FSAVE\n   instruction, the as follows:\n\n     * FXSAVE instruction does not check for pending unmasked floating-point\n       exceptions. (The FXSAVE operation in this regard is similar to the\n       operation of the FNSAVE instruction).\n     * After the FXSAVE instruction has saved the state of the x87 FPU, MMX\n       technology, XMM, and MXCSR registers, the processor retains the\n       contents of the registers. Because of this behavior, the FXSAVE\n       instruction cannot be used by an application program to pass a \u201cclean\u201d\n       x87 FPU state to a procedure, since it retains the current state. To\n       clean the x87 FPU state, an application must explicitly execute an\n       FINIT instruction after an FXSAVE instruction to reinitialize the x87\n       FPU state.\n     * The format of the memory image saved with the FXSAVE instruction is\n       the same regardless of the current addressing mode (32-bit or 16-bit)\n       and operating mode (protected, real address, or system management).\n       This behavior differs from the FSAVE instructions, where the memory\n       image format is different depending on the addressing mode and\n       operating mode. Because of the different image formats, the memory\n       image saved with the FXSAVE instruction cannot be restored correctly\n       with the FRSTOR instruction, and likewise the state saved with the\n       FSAVE instruction cannot be restored correctly with the FXRSTOR\n       instruction.\n\n   The FSAVE format for FTW can be recreated from the FTW valid bits and the\n   stored 80-bit floating-point data (assuming the stored data was not the\n   contents of MMX technology registers) using Table 3-45.\n\n   Exponent all Exponent all Fraction all J and M FTW valid x87 FTW           \n   1\u2019s          0\u2019s          0\u2019s          bits    bit       \n   0 0          0 0          0 0          0x 1x   1 1       Special 10 Valid  \n                                                            00                \n   0 0          0 0          1 1          00 10   1 1       Special 10 Valid  \n                                                            00                \n   0 0          1 1          0 0          0x 1x   1 1       Special 10        \n                                                            Special 10        \n   0 0          1 1          1 1          00 10   1 1       Zero 01 Special   \n                                                            10                \n   1 1          0 0          0 0          1x 1x   1 1       Special 10        \n                                                            Special 10        \n   1 1          0 0          1 1          00 10   1 1       Special 10        \n                                                            Special 10        \n   For all legal combinations above.              0         Empty 11          \n\n   Table 3-45. Recreating FSAVE Format\n\n   The J-bit is defined to be the 1-bit binary integer to the left of the\n   decimal place in the significand. The M-bit is defined to be the most\n   significant bit of the fractional portion of the significand (i.e., the\n   bit immediately to the right of the decimal place).\n\n   When the M-bit is the most significant bit of the fractional portion of\n   the significand, it must be 0 if the fraction is all 0\u2019s.\n\nIA-32e Mode Operation \u00b6\n\n   In compatibility sub-mode of IA-32e mode, legacy SSE registers, XMM0\n   through XMM7, are saved according to the legacy FXSAVE map. In 64-bit\n   mode, all of the SSE registers, XMM0 through XMM15, are saved.\n   Additionally, there are two different layouts of the FXSAVE map in 64-bit\n   mode, corresponding to FXSAVE64 (which requires REX.W=1) and FXSAVE\n   (REX.W=0). In the FXSAVE64 map (Table 3-46), the FPU IP and FPU DP\n   pointers are 64-bit wide. In the FXSAVE map for 64-bit mode (Table 3-47),\n   the FPU IP and FPU DP pointers are 32-bits.\n\n   15 14 13 12 11 10 9 8 76543210 \n   FIP                   FOP      Reserved FTW FSW FCW 0   \n   MXCSR_MASK  MXCSR     FDP                           16  \n   Reserved          ST0/MM0                           32  \n   Reserved          ST1/MM1                           48  \n   Reserved          ST2/MM2                           64  \n   Reserved          ST3/MM3                           80  \n   Reserved          ST4/MM4                           96  \n   Reserved          ST5/MM5                           112 \n   Reserved          ST6/MM6                           128 \n   Reserved          ST7/MM7                           144 \n   XMM0                                                160 \n   XMM1                                                176 \n   XMM2                                                192 \n   XMM3                                                208 \n   XMM4                                                224 \n   XMM5                                                240 \n   XMM6                                                256 \n   XMM7                                                272 \n   XMM8                                                288 \n   XMM9                                                304 \n   XMM10                                               320 \n   XMM11                                               336 \n   XMM12                                               352 \n   XMM13                                               368 \n   XMM14                                               384 \n   XMM15                                               400 \n   Reserved                                            416 \n   Reserved                                            432 \n   Reserved                                            448 \n   Available                                           464 \n   Available                                           480 \n   Available                                           496 \n\n   Table 3-46. Layout of the 64-Bit Mode FXSAVE64 Map (Requires REX.W = 1)\n\n   15 14    13 12 1110  98  76       54           32   10   \n   Reserved FCS   FIP[31:0] FOP      Reserved FTW FSW  FCW  0   \n   MXCSR_MASK     MXCSR     Reserved FDS          FDP[31:0] 16  \n   Reserved             ST0/MM0                             32  \n   Reserved             ST1/MM1                             48  \n   Reserved             ST2/MM2                             64  \n   Reserved             ST3/MM3                             80  \n   Reserved             ST4/MM4                             96  \n   Reserved             ST5/MM5                             112 \n   Reserved             ST6/MM6                             128 \n   Reserved             ST7/MM7                             144 \n   XMM0                                                     160 \n   XMM1                                                     176 \n   XMM2                                                     192 \n   XMM3                                                     208 \n   XMM4                                                     224 \n   XMM5                                                     240 \n   XMM6                                                     256 \n   XMM7                                                     272 \n   XMM8                                                     288 \n   XMM9                                                     304 \n   XMM10                                                    320 \n   XMM11                                                    336 \n   XMM12                                                    352 \n   XMM13                                                    368 \n   XMM14                                                    384 \n   XMM15                                                    400 \n   Reserved                                                 416 \n   Reserved                                                 432 \n   Reserved                                                 448 \n   Available                                                464 \n   Available                                                480 \n   Available                                                496 \n\n   Table 3-47. Layout of the 64-Bit Mode FXSAVE Map (REX.W = 0)\n\nImplementation Note \u00b6\n\n   The order in which the processor signals general-protection (#GP) and\n   page-fault (#PF) exceptions when they both occur on an instruction\n   boundary is given in Table 5-2 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3B. This order vary for FXSAVE for\n   different processor implementations.\n"],
	["enqcmd", "                            ENQCMD \u2014 Enqueue Command\n\n                              64/32 bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                              Support   Flag    \n                                                Atomically enqueue 64-byte    \n   F2 0F 38 F8                                  user command from source      \n   !(11):rrr:bbb ENQCMD A     V/V       ENQCMD  memory operand to destination \n   r32/r64, m512                                offset in ES segment          \n                                                specified in register operand \n                                                as offset in ES segment.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   The ENQCMD instruction allows software to write commands to enqueue\n   registers, which are special device registers accessed using memory-mapped\n   I/O (MMIO).\n\n   Enqueue registers expect writes to have the following format:\n\n   511 32 31 30 20 19                          \n   DEVICE SPECIFIC COMMAND PRIV RESERVED PASID \n\n   Figure 3-16. 64-Byte Data Written to Enqueue Registers\n\n   Bits 19:0 convey the process address space identifier (PASID), a value\n   which system software may assign to individual software threads. Bit 31\n   contains privilege identification (0 = user; 1 = supervisor). Devices\n   implementing enqueue registers may use these two values along with a\n   device-specific command in the upper 60 bytes.\n\n   The ENQCMD instruction begins by reading 64 bytes of command data from its\n   source memory operand. This is an ordinary load with cacheability and\n   memory ordering implied normally by the memory type. The source operand\n   need not be aligned, and there is no guarantee that all 64 bytes are\n   loaded atomically. Bits 31:0 of the source operand must be zero.\n\n   The instruction then formats those 64 bytes into command data with a\n   format consistent with that given in Figure 3-16:\n\n     * Command[19:0] get IA32_PASID[19:0].^1\n     * Command[30:20] are zero.\n     * Command[31] is 0 (indicating user; this value is used regardless of\n       CPL).\n     * Command[511:32] get bits 511:32 of the source operand that was read\n       from memory.\n\n   The ENQCMD instruction uses an enqueue store (defined below) to write this\n   command data to the destination operand. The address of the destination\n   operand is specified in a general-purpose register as an offset into the\n   ES segment (the segment cannot be overridden).^2 The destination linear\n   address must be 64-byte aligned. The operation of an enqueue store\n   disregards the memory type of the destination memory address.\n\n     1.\n     ItisexpectedthatsystemsoftwarewillloadtheIA32_PASIDMSRsothatbits19:0containthePASIDofthecurrentsoft-ware\n     thread. The MSR\u2019s valid bit, IA32_PASID[31], must be 1. For additional\n     details on the IA32_PASID MSR, see the Intel^\u00ae 64 and IA-32\n     Architectures Software Developer\u2019s Manual, Volume 4.\n\n     2.\n     In64-bitmode,thewidthoftheregisteroperandis64bits(32bitswitha67Hprefix).Outside64-bitmodewhenCS.D=\n     1, the width is 32 bits (16 bits with a 67H prefix). Outside 64-bit mode\n     when CS.D=0, the width is 16 bits (32 bits with a 67H prefix).\n\n   An enqueue store is not ordered relative to older stores to WB or WC\n   memory (including non-temporal stores) or to executions of the CLFLUSHOPT\n   or CLWB (when applied to addresses other than that of the enqueue store).\n   Software can enforce such ordering by executing a fencing instruction such\n   as SFENCE or MFENCE before the enqueue store.\n\n   An enqueue store does not write the data into the cache hierarchy, nor\n   does it fetch any data into the cache hierarchy. An enqueue store\u2019s\n   command data is never combined with that of any other store to the same\n   address.\n\n   Unlike other stores, an enqueue store returns a status, which the ENQCMD\n   instruction loads into the ZF flag in the RFLAGS register:\n\n     * ZF = 0 (success) reports that the 64-byte command data was written\n       atomically to a device\u2019s enqueue register and has been accepted by the\n       device. (It does not guarantee that the device has acted on the\n       command; it may have queued it for later execution.)\n     * ZF = 1 (retry) reports that the command data was not accepted. This\n       status is returned if the destination address is an enqueue register\n       but the command was not accepted due to capacity or other temporal\n       reasons. This status is also returned if the destination address was\n       not an enqueue register (including the case of a memory address); in\n       these cases, the store is dropped and is written neither to MMIO nor\n       to memory.\n\n   Availability of the ENQCMD instruction is indicated by the presence of the\n   CPUID feature flag ENQCMD (CPUID.(EAX=07H, ECX=0H):ECX[bit 29]).\n\n  Flags Affected \u00b6\n\n   The ZF flag is set if the enqueue-store completion returns the retry\n   status; otherwise it is cleared. All other flags are cleared.\n"],
	["vpshufbitqmb", "VPSHUFBITQMB \u2014 Shuffle Bits From Quadword Elements Using Byte Indexes Into Mask\n\n                                 64/32 bit CPUID Feature                      \n   Opcode/Instruction      Op/En Mode      Flag          Description\n                                 Support   \n                                                         Extract values in    \n   EVEX.128.66.0F38.W0 8F                                xmm2 using control   \n   /r VPSHUFBITQMB k1{k2}, A     V/V       AVX512_BITALG bits of xmm3/m128    \n   xmm2, xmm3/m128                         AVX512VL      with writemask k2    \n                                                         and leave the result \n                                                         in mask register k1. \n                                                         Extract values in    \n   EVEX.256.66.0F38.W0 8F                                ymm2 using control   \n   /r VPSHUFBITQMB k1{k2}, A     V/V       AVX512_BITALG bits of ymm3/m256    \n   ymm2, ymm3/m256                         AVX512VL      with writemask k2    \n                                                         and leave the result \n                                                         in mask register k1. \n                                                         Extract values in    \n   EVEX.512.66.0F38.W0 8F                                zmm2 using control   \n   /r VPSHUFBITQMB k1{k2}, A     V/V       AVX512_BITALG bits of zmm3/m512    \n   zmm2, zmm3/m512                                       with writemask k2    \n                                                         and leave the result \n                                                         in mask register k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   The VPSHUFBITQMB instruction performs a bit gather select using second\n   source as control and first source as data. Each bit uses 6 control bits\n   (2nd source operand) to select which data bit is going to be gathered\n   (first source operand). A given bit can only access 64 different bits of\n   data (first 64 destination bits can access first 64 data bits, second 64\n   destination bits can access second 64 data bits, etc.).\n\n   Control data for each output bit is stored in 8 bit elements of SRC2, but\n   only the 6 least significant bits of each element are used.\n\n   This instruction uses write masking (zeroing only). This instruction\n   supports memory fault suppression.\n\n   The first source operand is a ZMM register. The second source operand is a\n   ZMM register or a memory location. The destination operand is a mask\n   register.\n"],
	["kxorw:kxorb:kxorq:kxord", "              KXORW/KXORB/KXORQ/KXORD \u2014 Bitwise Logical XOR Masks\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Flag Description\n                                  Support   \n   VEX.L1.0F.W0 47 /r KXORW                              Bitwise XOR 16-bit   \n   k1, k2, k3               RVR   V/V       AVX512F      masks k2 and k3 and  \n                                                         place result in k1.  \n   VEX.L1.66.0F.W0 47 /r                                 Bitwise XOR 8-bit    \n   KXORB k1, k2, k3         RVR   V/V       AVX512DQ     masks k2 and k3 and  \n                                                         place result in k1.  \n   VEX.L1.0F.W1 47 /r KXORQ                              Bitwise XOR 64-bit   \n   k1, k2, k3               RVR   V/V       AVX512BW     masks k2 and k3 and  \n                                                         place result in k1.  \n   VEX.L1.66.0F.W1 47 /r                                 Bitwise XOR 32-bit   \n   KXORD k1, k2, k3         RVR   V/V       AVX512BW     masks k2 and k3 and  \n                                                         place result in k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3                              \n   RVR   ModRM:reg (w) VEX.1vvv (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise XOR between the vector mask k2 and the vector mask k3,\n   and writes the result into vector mask k1 (three-operand form).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fscale", "                                 FSCALE \u2014 Scale\n\n   Opcode  Mode Leg Mode Description           \n   D9 FD                 Scale ST(0) by ST(1). \n\nDescription \u00b6\n\n   Truncates the value in the source operand (toward 0) to an integral value\n   and adds that value to the exponent of the destination operand. The\n   destination and source operands are floating-point values located in\n   registers ST(0) and ST(1), respectively. This instruction provides rapid\n   multiplication or division by integral powers of 2. The following table\n   shows the results obtained when scaling various classes of numbers,\n   assuming that neither overflow nor underflow occurs.\n\n   ST(1) \n             \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n             NaN \u2212\u221e  \u2212\u221e  \u2212\u221e  \u2212\u221e  \u2212\u221e  NaN \n         \u2212F  \u22120  \u2212F  \u2212F  \u2212F  \u2212F  \u2212\u221e  NaN \n   ST(0) \u22120  \u22120  \u22120  \u22120  \u22120  \u22120  NaN NaN \n         +0  +0  +0  +0  +0  +0  NaN NaN \n         +F  +0  +F  +F  +F  +F  +\u221e  NaN \n         +\u221e  NaN +\u221e  +\u221e  +\u221e  +\u221e  +\u221e  NaN \n         NaN NaN NaN NaN NaN NaN NaN NaN \n\n   Table 3-34. FSCALE Results\n\n     F Meansfinitefloating-pointvalue.\n\n   In most cases, only the exponent is changed and the mantissa (significand)\n   remains unchanged. However, when the value being scaled in ST(0) is a\n   denormal value, the mantissa is also changed and the result may turn out\n   to be a normalized number. Similarly, if overflow or underflow results\n   from a scale operation, the resulting mantissa will differ from the\n   source\u2019s mantissa.\n\n   The FSCALE instruction can also be used to reverse the action of the\n   FXTRACT instruction, as shown in the following example:\n\n   FXTRACT;\n\n   FSCALE;\n\n   FSTP ST(1);\n\n   In this example, the FXTRACT instruction extracts the significand and\n   exponent from the value in ST(0) and stores them in ST(0) and ST(1)\n   respectively. The FSCALE then scales the significand in ST(0) by the\n   exponent in ST(1), recreating the original value before the FXTRACT\n   operation was performed. The FSTP ST(1) instruction overwrites the\n   exponent (extracted by the FXTRACT instruction) with the recreated value,\n   which returns the stack to its original state with only one register\n   [ST(0)] occupied.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["vfnmadd132ss:vfnmadd213ss:vfnmadd231ss", "    VFNMADD132SS/VFNMADD213SS/VFNMADD231SS \u2014 Fused Negative Multiply-Add of\n                  ScalarSingle Precision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Multiply scalar           \n                                                    single-precision          \n   VEX.LIG.66.0F38.W0 9D /r                         floating-point value from \n   VFNMADD132SS xmm1, xmm2, A     V/V       FMA     xmm1 and xmm3/m32, negate \n   xmm3/m32                                         the multiplication result \n                                                    and add to xmm2 and put   \n                                                    result in xmm1.           \n                                                    Multiply scalar           \n                                                    single-precision          \n   VEX.LIG.66.0F38.W0 AD /r                         floating-point value from \n   VFNMADD213SS xmm1, xmm2, A     V/V       FMA     xmm1 and xmm2, negate the \n   xmm3/m32                                         multiplication result and \n                                                    add to xmm3/m32 and put   \n                                                    result in xmm1.           \n                                                    Multiply scalar           \n                                                    single-precision          \n   VEX.LIG.66.0F38.W0 BD /r                         floating-point value from \n   VFNMADD231SS xmm1, xmm2, A     V/V       FMA     xmm2 and xmm3/m32, negate \n   xmm3/m32                                         the multiplication result \n                                                    and add to xmm1 and put   \n                                                    result in xmm1.           \n                                                    Multiply scalar           \n   EVEX.LLIG.66.0F38.W0 9D                          single-precision          \n   /r VFNMADD132SS xmm1                             floating-point value from \n   {k1}{z}, xmm2,           B     V/V       AVX512F xmm1 and xmm3/m32, negate \n   xmm3/m32{er}                                     the multiplication result \n                                                    and add to xmm2 and put   \n                                                    result in xmm1.           \n                                                    Multiply scalar           \n   EVEX.LLIG.66.0F38.W0 AD                          single-precision          \n   /r VFNMADD213SS xmm1                             floating-point value from \n   {k1}{z}, xmm2,           B     V/V       AVX512F xmm1 and xmm2, negate the \n   xmm3/m32{er}                                     multiplication result and \n                                                    add to xmm3/m32 and put   \n                                                    result in xmm1.           \n                                                    Multiply scalar           \n   EVEX.LLIG.66.0F38.W0 BD                          single-precision          \n   /r VFNMADD231SS xmm1                             floating-point value from \n   {k1}{z}, xmm2,           B     V/V       AVX512F xmm2 and xmm3/m32, negate \n   xmm3/m32{er}                                     the multiplication result \n                                                    and add to xmm1 and put   \n                                                    result in xmm1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMADD132SS: Multiplies the low packed single-precision floating-point\n   value from the first source operand to the low packed single-precision\n   floating-point value in the third source operand, adds the negated\n   infinite precision intermediate result to the low packed single-precision\n   floating-point value in the second source operand, performs rounding and\n   stores the resulting packed single-precision floating-point value to the\n   destination operand (first source operand).\n\n   VFNMADD213SS: Multiplies the low packed single-precision floating-point\n   value from the second source operand to the low packed single-precision\n   floating-point value in the first source operand, adds the negated\n   infinite precision intermediate result to the low packed single-precision\n   floating-point value in the third source operand, performs rounding and\n   stores the resulting packed single-precision floating-point value to the\n   destination operand (first source operand).\n\n   VFNMADD231SS: Multiplies the low packed single-precision floating-point\n   value from the second source operand to the low packed single-precision\n   floating-point value in the third source operand, adds the negated\n   infinite precision intermediate result to the low packed single-precision\n   floating-point value in the first source operand, performs rounding and\n   stores the resulting packed single-precision floating-point value to the\n   destination operand (first source operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:32 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination is\n   updated according to the writemask.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["pand", "                               PAND \u2014 Logical AND\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F DB /r^1 PAND mm,  A     V/V       MMX      Bitwise AND mm/m64 and    \n   mm/m64                                           mm.                       \n   66 0F DB /r PAND xmm1,  A     V/V       SSE2     Bitwise AND of xmm2/m128  \n   xmm2/m128                                        and xmm1.                 \n   VEX.128.66.0F.WIG DB /r                          Bitwise AND of xmm3/m128  \n   VPAND xmm1, xmm2,       B     V/V       AVX      and xmm.                  \n   xmm3/m128               \n   VEX.256.66.0F.WIG DB /r                          Bitwise AND of ymm2, and  \n   VPAND ymm1, ymm2,       B     V/V       AVX2     ymm3/m256 and store       \n   ymm3/.m256                                       result in ymm1.           \n                                                    Bitwise AND of packed     \n   EVEX.128.66.0F.W0 DB /r                          doubleword integers in    \n   VPANDD xmm1 {k1}{z},    C     V/V       AVX512VL xmm2 and                  \n   xmm2, xmm3/m128/m32bcst                 AVX512F  xmm3/m128/m32bcst and     \n                                                    store result in xmm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND of packed     \n   EVEX.256.66.0F.W0 DB /r                          doubleword integers in    \n   VPANDD ymm1 {k1}{z},    C     V/V       AVX512VL ymm2 and                  \n   ymm2, ymm3/m256/m32bcst                 AVX512F  ymm3/m256/m32bcst and     \n                                                    store result in ymm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND of packed     \n   EVEX.512.66.0F.W0 DB /r                          doubleword integers in    \n   VPANDD zmm1 {k1}{z},    C     V/V       AVX512F  zmm2 and                  \n   zmm2, zmm3/m512/m32bcst                          zmm3/m512/m32bcst and     \n                                                    store result in zmm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND of packed     \n   EVEX.128.66.0F.W1 DB /r                 AVX512VL quadword integers in xmm2 \n   VPANDQ xmm1 {k1}{z},    C     V/V       AVX512F  and xmm3/m128/m64bcst and \n   xmm2, xmm3/m128/m64bcst                          store result in xmm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND of packed     \n   EVEX.256.66.0F.W1 DB /r                 AVX512VL quadword integers in ymm2 \n   VPANDQ ymm1 {k1}{z},    C     V/V       AVX512F  and ymm3/m256/m64bcst and \n   ymm2, ymm3/m256/m64bcst                          store result in ymm1      \n                                                    using writemask k1.       \n                                                    Bitwise AND of packed     \n   EVEX.512.66.0F.W1 DB /r                          quadword integers in zmm2 \n   VPANDQ zmm1 {k1}{z},    C     V/V       AVX512F  and zmm3/m512/m64bcst and \n   zmm2, zmm3/m512/m64bcst                          store result in zmm1      \n                                                    using writemask k1.       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical AND operation on the first source operand and\n   second source operand and stores the result in the destination operand.\n   Each bit of the result is set to 1 if the corresponding bits of the first\n   and second operands are 1, otherwise it is set to 0.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with write-mask k1 at 32/64-bit granularity.\n\n   VEX.256 encoded versions: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded versions: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["movhpd", "        MOVHPD \u2014 Move High Packed Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Move double precision      \n   66 0F 16 /r MOVHPD xmm1, A    V/V       SSE2    floating-point value from  \n   m64                                             m64 to high quadword of    \n                                                   xmm1.                      \n                                                   Merge double precision     \n   VEX.128.66.0F.WIG 16 /r  B    V/V       AVX     floating-point value from  \n   VMOVHPD xmm2, xmm1, m64                         m64 and the low quadword   \n                                                   of xmm1.                   \n                                                   Merge double precision     \n   EVEX.128.66.0F.W1 16 /r  D    V/V       AVX512F floating-point value from  \n   VMOVHPD xmm2, xmm1, m64                         m64 and the low quadword   \n                                                   of xmm1.                   \n                                                   Move double precision      \n   66 0F 17 /r MOVHPD m64,  C    V/V       SSE2    floating-point value from  \n   xmm1                                            high quadword of xmm1 to   \n                                                   m64.                       \n                                                   Move double precision      \n   VEX.128.66.0F.WIG 17 /r  C    V/V       AVX     floating-point value from  \n   VMOVHPD m64, xmm1                               high quadword of xmm1 to   \n                                                   m64.                       \n                                                   Move double precision      \n   EVEX.128.66.0F.W1 17 /r  E    V/V       AVX512F floating-point value from  \n   VMOVHPD m64, xmm1                               high quadword of xmm1 to   \n                                                   m64.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     N/A           ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n   D     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   E     Tuple1 Scalar ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n\nDescription \u00b6\n\n   This instruction cannot be used for register to register or memory to\n   memory moves.\n\n   128-bit Legacy SSE load:\n\n   Moves a double precision floating-point value from the source 64-bit\n   memory operand and stores it in the high 64-bits of the destination XMM\n   register. The lower 64bits of the XMM register are preserved. Bits\n   (MAXVL-1:128) of the corresponding destination register are preserved.\n\n   VEX.128 & EVEX encoded load:\n\n   Loads a double precision floating-point value from the source 64-bit\n   memory operand (the third operand) and stores it in the upper 64-bits of\n   the destination XMM register (first operand). The low 64-bits from the\n   first source operand (second operand) are copied to the low 64-bits of the\n   destination. Bits (MAXVL-1:128) of the corresponding destination register\n   are zeroed.\n\n   128-bit store:\n\n   Stores a double precision floating-point value from the high 64-bits of\n   the XMM register source (second operand) to the 64-bit memory location\n   (first operand).\n\n   Note: VMOVHPD (store) (VEX.128.66.0F 17 /r) is legal and has the same\n   behavior as the existing 66 0F 17 store. For VMOVHPD (store) VEX.vvvv and\n   EVEX.vvvv are reserved and must be 1111b otherwise instruction will #UD.\n\n   If VMOVHPD is encoded with VEX.L or EVEX.L\u2019L= 1, an attempt to execute the\n   instruction encoded with VEX.L or EVEX.L\u2019L= 1 will cause an #UD exception.\n"],
	["sysenter", "                          SYSENTER \u2014 Fast System Call\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n                                                        Fast call to          \n   0F 34  SYSENTER    ZO    Valid       Valid           privilege level 0     \n                                                        system procedures.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Executes a fast call to a level 0 system procedure or routine. SYSENTER is\n   a companion instruction to SYSEXIT. The instruction is optimized to\n   provide the maximum performance for system calls from user code running at\n   privilege level 3 to operating system or executive procedures running at\n   privilege level 0.\n\n   When executed in IA-32e mode, the SYSENTER instruction transitions the\n   logical processor to 64-bit mode; otherwise, the logical processor remains\n   in protected mode.\n\n   Prior to executing the SYSENTER instruction, software must specify the\n   privilege level 0 code segment and code entry point, and the privilege\n   level 0 stack segment and stack pointer by writing values to the following\n   MSRs:\n\n     * IA32_SYSENTER_CS (MSR address 174H) \u2014 The lower 16 bits of this MSR\n       are the segment selector for the privilege level 0 code segment. This\n       value is also used to determine the segment selector of the privilege\n       level 0 stack segment (see the Operation section). This value cannot\n       indicate a null selector.\n     * IA32_SYSENTER_EIP (MSR address 176H) \u2014 The value of this MSR is loaded\n       into RIP (thus, this value references the first instruction of the\n       selected operating procedure or routine). In protected mode, only bits\n       31:0 are loaded.\n     * IA32_SYSENTER_ESP (MSR address 175H) \u2014 The value of this MSR is loaded\n       into RSP (thus, this value contains the stack pointer for the\n       privilege level 0 stack). This value cannot represent a non-canonical\n       address. In protected mode, only bits 31:0 are loaded.\n\n   These MSRs can be read from and written to using RDMSR/WRMSR. The WRMSR\n   instruction ensures that the IA32_SYSENTER_EIP and IA32_SYSENTER_ESP MSRs\n   always contain canonical addresses.\n\n   While SYSENTER loads the CS and SS selectors with values derived from the\n   IA32_SYSENTER_CS MSR, the CS and SS descriptor caches are not loaded from\n   the descriptors (in GDT or LDT) referenced by those selectors. Instead,\n   the descriptor caches are loaded with fixed values. See the Operation\n   section for details. It is the responsibility of OS software to ensure\n   that the descriptors (in GDT or LDT) referenced by those selector values\n   correspond to the fixed values loaded into the descriptor caches; the\n   SYSENTER instruction does not ensure this correspondence.\n\n   The SYSENTER instruction can be invoked from all operating modes except\n   real-address mode.\n\n   The SYSENTER and SYSEXIT instructions are companion instructions, but they\n   do not constitute a call/return pair. When executing a SYSENTER\n   instruction, the processor does not save state information for the user\n   code (e.g., the instruction pointer), and neither the SYSENTER nor the\n   SYSEXIT instruction supports passing parameters on the stack.\n\n   To use the SYSENTER and SYSEXIT instructions as companion instructions for\n   transitions between privilege level 3 code and privilege level 0 operating\n   system procedures, the following conventions must be followed:\n\n     * The segment descriptors for the privilege level 0 code and stack\n       segments and for the privilege level 3 code and stack segments must be\n       contiguous in a descriptor table. This convention allows the processor\n       to compute the segment selectors from the value entered in the\n       SYSENTER_CS_MSR MSR.\n     * The fast system call \u201cstub\u201d routines executed by user code (typically\n       in shared libraries or DLLs) must save the required return IP and\n       processor state information if a return to the calling procedure is\n       required. Likewise, the operating system or executive procedures\n       called with SYSENTER instructions must have access to and use this\n       saved return and state information when returning to the user code.\n\n   The SYSENTER and SYSEXIT instructions were introduced into the IA-32\n   architecture in the Pentium II processor. The availability of these\n   instructions on a processor is indicated with the SYSENTER/SYSEXIT present\n   (SEP) feature\n\n   flag returned to the EDX register by the CPUID instruction. An operating\n   system that qualifies the SEP flag must also qualify the processor family\n   and model to ensure that the SYSENTER/SYSEXIT instructions are actually\n   present. For example:\n\n   IF CPUID SEP bit is set\n\n   THEN IF (Family = 6) and (Model < 3) and (Stepping < 3)\n\n   THEN\n\n   SYSENTER/SYSEXIT_Not_Supported; FI;\n\n   ELSE\n\n   SYSENTER/SYSEXIT_Supported; FI;\n\n   FI;\n\n   When the CPUID instruction is executed on the Pentium Pro processor (model\n   1), the processor returns a the SEP flag as set, but does not support the\n   SYSENTER/SYSEXIT instructions.\n\n   When shadow stacks are enabled at privilege level where SYSENTER\n   instruction is invoked, the SSP is saved to the IA32_PL3_SSP MSR. If\n   shadow stacks are enabled at privilege level 0, the SSP is loaded with 0.\n   Refer to Chapter 6, \u201cProcedure Calls, Interrupts, and Exceptions\u201a\u201d and\n   Chapter 17, \u201cControl-flow Enforcement Technology (CET)\u201a\u201d in the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for\n   additional CET details.\n\n   Instruction ordering. Instructions following a SYSENTER may be fetched\n   from memory before earlier instructions complete execution, but they will\n   not execute (even speculatively) until all instructions prior to the\n   SYSENTER have completed execution (the later instructions may execute\n   before data stored by the earlier instructions have become globally\n   visible).\n\nFlags Affected \u00b6\n\n   VM, IF (see Operation above).\n"],
	["maxss", "      MAXSS \u2014 Return Maximum Scalar Single Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Return the maximum scalar  \n   F3 0F 5F /r MAXSS xmm1,  A    V/V       SSE     single precision           \n   xmm2/m32                                        floating-point value       \n                                                   between xmm2/m32 and xmm1. \n   VEX.LIG.F3.0F.WIG 5F /r                         Return the maximum scalar  \n   VMAXSS xmm1, xmm2,       B    V/V       AVX     single precision           \n   xmm3/m32                                        floating-point value       \n                                                   between xmm3/m32 and xmm2. \n   EVEX.LLIG.F3.0F.W0 5F /r                        Return the maximum scalar  \n   VMAXSS xmm1 {k1}{z},     C    V/V       AVX512F single precision           \n   xmm2, xmm3/m32{sae}                             floating-point value       \n                                                   between xmm3/m32 and xmm2. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Compares the low single precision floating-point values in the first\n   source operand and the second source operand, and returns the maximum\n   value to the low doubleword of the destination operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second source operand is returned. If a value in the second source\n   operand is an SNaN, that SNaN is returned unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   source operand, either a NaN or a valid floating-point value, is written\n   to the result. If instead of this behavior, it is required that the NaN\n   from either source operand be returned, the action of MAXSS can be\n   emulated using a sequence of instructions, such as, a comparison followed\n   by AND, ANDN, and OR.\n\n   The second source operand can be an XMM register or a 32-bit memory\n   location. The first source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The destination and first source operand are\n   the same. Bits (MAXVL:32) of the corresponding destination register remain\n   unchanged.\n\n   VEX.128 and EVEX encoded version: The first source operand is an xmm\n   register encoded by VEX.vvvv. Bits (127:32) of the XMM register\n   destination are copied from corresponding bits in the first source\n   operand. Bits (MAXVL:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination\n   operand is updated according to the writemask.\n\n   Software should ensure VMAXSS is encoded with VEX.L=0. Encoding VMAXSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["pop", "                        POP \u2014 Pop a Value From the Stack\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n                                                        Pop top of stack into \n   8F /0  POP r/m16   M     Valid       Valid           m16; increment stack  \n                                                        pointer.              \n                                                        Pop top of stack into \n   8F /0  POP r/m32   M     N.E.        Valid           m32; increment stack  \n                                                        pointer.              \n                                                        Pop top of stack into \n                                                        m64; increment stack  \n   8F /0  POP r/m64   M     Valid       N.E.            pointer. Cannot       \n                                                        encode 32-bit operand \n                                                        size.                 \n                                                        Pop top of stack into \n   58+ rw POP r16     O     Valid       Valid           r16; increment stack  \n                                                        pointer.              \n                                                        Pop top of stack into \n   58+ rd POP r32     O     N.E.        Valid           r32; increment stack  \n                                                        pointer.              \n                                                        Pop top of stack into \n                                                        r64; increment stack  \n   58+ rd POP r64     O     Valid       N.E.            pointer. Cannot       \n                                                        encode 32-bit operand \n                                                        size.                 \n                                                        Pop top of stack into \n   1F     POP DS      ZO    Invalid     Valid           DS; increment stack   \n                                                        pointer.              \n                                                        Pop top of stack into \n   07     POP ES      ZO    Invalid     Valid           ES; increment stack   \n                                                        pointer.              \n                                                        Pop top of stack into \n   17     POP SS      ZO    Invalid     Valid           SS; increment stack   \n                                                        pointer.              \n                                                        Pop top of stack into \n   0F A1  POP FS      ZO    Valid       Valid           FS; increment stack   \n                                                        pointer by 16 bits.   \n                                                        Pop top of stack into \n   0F A1  POP FS      ZO    N.E.        Valid           FS; increment stack   \n                                                        pointer by 32 bits.   \n                                                        Pop top of stack into \n   0F A1  POP FS      ZO    Valid       N.E.            FS; increment stack   \n                                                        pointer by 64 bits.   \n                                                        Pop top of stack into \n   0F A9  POP GS      ZO    Valid       Valid           GS; increment stack   \n                                                        pointer by 16 bits.   \n                                                        Pop top of stack into \n   0F A9  POP GS      ZO    N.E.        Valid           GS; increment stack   \n                                                        pointer by 32 bits.   \n                                                        Pop top of stack into \n   0F A9  POP GS      ZO    Valid       N.E.            GS; increment stack   \n                                                        pointer by 64 bits.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1       Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w)   N/A       N/A       N/A       \n   O     opcode + rd (w) N/A       N/A       N/A       \n   ZO    N/A             N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the value from the top of the stack to the location specified with\n   the destination operand (or explicit opcode) and then increments the stack\n   pointer. The destination operand can be a general-purpose register, memory\n   location, or segment register.\n\n   Address and operand sizes are determined and used as follows:\n\n     * Address size. The D flag in the current code-segment descriptor\n       determines the default address size; it may be overridden by an\n       instruction prefix (67H).\n\n   The address size is used only when writing to a destination operand in\n   memory.\n\n     * Operand size. The D flag in the current code-segment descriptor\n       determines the default operand size; it may be overridden by\n       instruction prefixes (66H or REX.W).\n\n   The operand size (16, 32, or 64 bits) determines the amount by which the\n   stack pointer is incremented (2, 4 or 8).\n\n     * Stack-address size. Outside of 64-bit mode, the B flag in the current\n       stack-segment descriptor determines the size of the stack pointer (16\n       or 32 bits); in 64-bit mode, the size of the stack pointer is always\n       64 bits.\n\n   The stack-address size determines the width of the stack pointer when\n   reading from the stack in memory and when incrementing the stack pointer.\n   (As stated above, the amount by which the stack pointer is incremented is\n   determined by the operand size.)\n\n   If the destination operand is one of the segment registers DS, ES, FS, GS,\n   or SS, the value loaded into the register must be a valid segment\n   selector. In protected mode, popping a segment selector into a segment\n   register automat-\n\n   ically causes the descriptor information associated with that segment\n   selector to be loaded into the hidden (shadow) part of the segment\n   register and causes the selector and the descriptor information to be\n   validated (see the \u201cOperation\u201d section below).\n\n   A NULL value (0000-0003) may be popped into the DS, ES, FS, or GS register\n   without causing a general protection fault. However, any subsequent\n   attempt to reference a segment whose corresponding segment register is\n   loaded with a NULL value causes a general protection exception (#GP). In\n   this situation, no memory reference occurs and the saved value of the\n   segment register is NULL.\n\n   The POP instruction cannot pop a value into the CS register. To load the\n   CS register from the stack, use the RET instruction.\n\n   If the ESP register is used as a base register for addressing a\n   destination operand in memory, the POP instruction computes the effective\n   address of the operand after it increments the ESP register. For the case\n   of a 16-bit stack where ESP wraps to 0H as a result of the POP\n   instruction, the resulting location of the memory write is\n   processor-family-specific.\n\n   The POP ESP instruction increments the stack pointer (ESP) before data at\n   the old top of stack is written into the destination.\n\n   Loading the SS register with a POP instruction suppresses or inhibits some\n   debug exceptions and inhibits interrupts on the following instruction\n   boundary. (The inhibition ends after delivery of an exception or the\n   execution of the next instruction.) This behavior allows a stack pointer\n   to be loaded into the ESP register with the next instruction (POP ESP)\n   before an event can be delivered. See Section 6.8.3, \u201cMasking Exceptions\n   and Interrupts When Switching Stacks,\u201d in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3A. Intel recommends\n   that software use the LSS instruction to load the SS register and ESP\n   together.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits access to\n   additional registers (R8-R15). When in 64-bit mode, POPs using 32-bit\n   operands are not encodable and POPs to DS, ES, SS are not valid. See the\n   summary chart at the beginning of this section for encoding data and\n   limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfmsub132sh:vfnmsub132sh:vfmsub213sh:vfnmsub213sh:vfmsub231sh:vfnmsub231sh", "  VFMSUB132SH/VFNMSUB132SH/VFMSUB213SH/VFNMSUB213SH/VFMSUB231SH/VFNMSUB231SH \u2014\n                 Fused Multiply-Subtract of Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode   \n   Flag Support 64/32 CPUID Feature  \n   Instruction En Bit Mode Flag      \n   CPUID Feature Instruction En Bit  \n   Mode Flag Op/ 64/32 CPUID Feature   Support             Description\n   Instruction En Bit Mode Flag      \n   64/32 CPUID Feature Instruction   \n   En Bit Mode Flag CPUID Feature    \n   Instruction En Bit Mode Flag Op/  \n   64/32 CPUID Feature               \n                                                           Multiply FP16      \n                                                           values from xmm1   \n   EVEX.LLIG.66.MAP6.W0 9B /r                              and xmm3/m16,      \n   VFMSUB132SH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 subtract xmm2, and \n   xmm3/m16 {er}                                           store the result   \n                                                           in xmm1 subject to \n                                                           writemask k1.      \n                                                           Multiply FP16      \n                                                           values from xmm1   \n   EVEX.LLIG.66.MAP6.W0 AB /r                              and xmm2, subtract \n   VFMSUB213SH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 xmm3/m16, and      \n   xmm3/m16 {er}                                           store the result   \n                                                           in xmm1 subject to \n                                                           writemask k1.      \n                                                           Multiply FP16      \n                                                           values from xmm2   \n   EVEX.LLIG.66.MAP6.W0 BB /r                              and xmm3/m16,      \n   VFMSUB231SH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 subtract xmm1, and \n   xmm3/m16 {er}                                           store the result   \n                                                           in xmm1 subject to \n                                                           writemask k1.      \n                                                           Multiply FP16      \n                                                           values from xmm1   \n                                                           and xmm3/m16, and  \n   EVEX.LLIG.66.MAP6.W0 9F /r                              negate the value.  \n   VFNMSUB132SH xmm1{k1}{z}, xmm2,   A V/V     AVX512-FP16 Subtract xmm2 from \n   xmm3/m16 {er}                                           this value, and    \n                                                           store the result   \n                                                           in xmm1 subject to \n                                                           writemask k1.      \n                                                           Multiply FP16      \n                                                           values from xmm1   \n                                                           and xmm2, and      \n   EVEX.LLIG.66.MAP6.W0 AF /r                              negate the value.  \n   VFNMSUB213SH xmm1{k1}{z}, xmm2,   A V/V     AVX512-FP16 Subtract xmm3/m16  \n   xmm3/m16 {er}                                           from this value,   \n                                                           and store the      \n                                                           result in xmm1     \n                                                           subject to         \n                                                           writemask k1.      \n                                                           Multiply FP16      \n                                                           values from xmm2   \n                                                           and xmm3/m16, and  \n   EVEX.LLIG.66.MAP6.W0 BF /r                              negate the value.  \n   VFNMSUB231SH xmm1{k1}{z}, xmm2,   A V/V     AVX512-FP16 Subtract xmm1 from \n   xmm3/m16 {er}                                           this value, and    \n                                                           store the result   \n                                                           in xmm1 subject to \n                                                           writemask k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a scalar multiply-subtract or negated\n   multiply-subtract computation on the low FP16 values using three source\n   operands and writes the result in the destination operand. The destination\n   operand is also the first source operand. The \u201cN\u201d (negated) forms of this\n   instruction subtract the remaining operand from the negated infinite\n   precision intermediate product. The notation\u2019 \u201c132\u201d, \u201c213\u201d and \u201c231\u201d\n   indicate the use of the operands in \u00b1A * B \u2212 C, where each digit\n   corresponds to the operand number, with the destination being operand 1;\n   see Table 5-7.\n\n   Bits 127:16 of the destination operand are preserved. Bits MAXVL-1:128 of\n   the destination operand are zeroed. The low FP16 element of the\n   destination is updated according to the writemask.\n\n   Notation Operands                \n   132      dest = \u00b1 dest*src3-src2 \n   231      dest = \u00b1 src2*src3-dest \n   213      dest = \u00b1 src2*dest-src3 \n\n   Table 5-7. VF[,N]MSUB[132,213,231]SH Notation for Operands\n"],
	["bsr", "                             BSR \u2014 Bit Scan Reverse\n\n   Opcode     Instruction    Op/En 64-bit Compat/Leg Description              \n                                   Mode   Mode       \n   0F BD /r   BSR r16, r/m16 RM    Valid  Valid      Bit scan reverse on      \n                                                     r/m16.                   \n   0F BD /r   BSR r32, r/m32 RM    Valid  Valid      Bit scan reverse on      \n                                                     r/m32.                   \n   REX.W + 0F BSR r64, r/m64 RM    Valid  N.E.       Bit scan reverse on      \n   BD /r                                             r/m64.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Searches the source operand (second operand) for the most significant set\n   bit (1 bit). If a most significant 1 bit is found, its bit index is stored\n   in the destination operand (first operand). The source operand can be a\n   register or a memory location; the destination operand is a register. The\n   bit index is an unsigned offset from bit 0 of the source operand. If the\n   content source operand is 0, the content of the destination operand is\n   undefined.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The ZF flag is set to 1 if the source operand is 0; otherwise, the ZF flag\n   is cleared. The CF, OF, SF, AF, and PF flags are undefined.\n"],
	["pconfig", "                        PCONFIG \u2014 Platform Configuration\n\n   Opcode/Instruction  Op/En 64/32 bit    CPUID        Description            \n                             Mode Support Feature Flag \n                                                       This instruction is    \n                                                       used to execute        \n   NP 0F 01 C5 PCONFIG A     V/V          PCONFIG      functions for          \n                                                       configuring platform   \n                                                       features.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   A     N/A   N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The PCONFIG instruction allows software to configure certain platform\n   features. It supports these features with multiple leaf functions,\n   selecting a leaf function using the value in EAX.\n\n   Depending on the leaf function, the registers RBX, RCX, and RDX may be\n   used to provide input information or for the instruction to report output\n   information. Addresses and operands are 32 bits outside 64-bit mode and\n   are 64 bits in 64-bit mode. The value of CS.D does not affect operand size\n   or address size.\n\n   Executions of PCONFIG may fail for platform-specific reasons. An execution\n   reports failure by setting the ZF flag and loading EAX with a non-zero\n   failure reason; a successful execution clears ZF and EAX.\n\n   Each PCONFIG leaf function applies to a specific hardware block called a\n   PCONFIG target. The leaf function is supported only if the processor\n   supports that target. Each target is associated with a numerical target\n   identifier, and CPUID leaf 1BH (PCONFIG information) enumerates the\n   identifiers of the supported targets. An attempt to execute an undefined\n   leaf function, or a leaf function that applies to an unsupported target\n   identifier, results in a general-protection exception (#GP).\n\nLeaf Function MKTME_KEY_PROGRAM \u00b6\n\n   As of this writing, the only defined PCONFIG leaf function is used for key\n   programming for total memory encryption-multi-key (TME-MK).^1 This leaf\n   function is called MKTME_KEY_PROGRAM and it pertains to the TME-MK target,\n   which has target identifier 1. The leaf function is selected by loading\n   EAX with value 0. The MKTME_KEY_PROGRAM leaf function uses the EBX (or\n   RBX) register for additional input information.\n\n   Software uses the MKTME_KEY_PROGRAM leaf function to manage the encryption\n   key associated with a particular key identifier (KeyID). The leaf function\n   uses a data structure called the TME-MK key programming structure\n   (MKTME_KEY_PROGRAM_STRUCT). Software provides the address of the structure\n   (as an offset in the DS segment) in EBX (or RBX). The format of the\n   structure is given in Table 4-15.\n\n   Field       Offset (bytes) Size (bytes) Comments                           \n   KEYID       0              2            Key Identifier.                    \n                                           KeyID control: \u2022 Bits 7:0:         \n                                           key-programming command (COMMAND)  \n   KEYID_CTRL  2              4            \u2022 Bits 23:8: encryption algorithm  \n                                           (ENC_ALG) \u2022 Bits 31:24: Reserved,  \n                                           must be zero (RSVD)                \n   Ignored     6              58           Not used.                          \n   KEY_FIELD_1 64             64           Software supplied data key or      \n                                           entropy for data key.              \n   KEY_FIELD_2 128            64           Software supplied tweak key or     \n                                           entropy for tweak key.             \n\n   Table 4-15. MKTME_KEY_PROGRAM_STRUCT Format\n\n   1. Further details on TME-MK can be found here:\n\n  https://software.intel.com/sites/default/files/managed/a5/16/Multi-Key-Total-Memory-Encryption-Spec.pdf\n  \u00b6\n\n   A description of each of the fields in MKTME_KEY_PROGRAM_STRUCT is\n   provided below:\n\n     * KEYID: The key identifier (KeyID) being programmed to the MKTME\n       engine. PCONFIG causes a general-protection exception (#GP) if the\n       KeyID is zero. KeyID zero always uses the current behavior configured\n       for TME (total memory encryption), either to encrypt with platform TME\n       key or to bypass TME encryption. PCONFIG also causes a #GP if the\n       KeyID exceeds the maximum enumerated in\n       IA32_TME_CAPABILITY.MK_TME_MAX-_KEYS[bits 50:36] or configured by the\n       setting of IA32_TME_ACTIVATE.MK_TME_KEYID_BITS[bits 35:32].\n     * KEYID_CTRL: The KEYID_CTRL field comprises two sub-fields used by\n       software to control the encryption performed for the selected KeyID:\n          * Key-programming command (COMMAND; bits 7:0). This 8-bit field\n            should contain one of the following values:\n          * Key-programming command (COMMAND; bits 7:0). This 8-bit field\n            should contain one of the following values:\n     * KEYID_SET_KEY_DIRECT (value 0). With this command, software programs\n       directly the encryption key to be used for the selected KeyID.\n     * KEYID_SET_KEY_RANDOM (value 1). With this command, software has the\n       CPU generate and assign an encryption key to be used for the selected\n       KeyID using a hardware random-number generator.\n\n   If this command is used and there is insufficient entropy for the\n   random-number generator, PCONFIG will fail and report the failure by\n   loading EAX with value 2 (ENTROPY_ERROR).\n\n   Because the keys programed by PCONFIG are discarded on reset and software\n   cannot read the programmed keys, the keys programmed with this command are\n   ephemeral.\n\n     * KEYID_CLEAR_KEY (value 2). With this command, software indicates that\n       the selected KeyID should use the current behavior configured for TME\n       (see above).\n     * KEYID_NO_ENCRYPT (value 3). With this command, software indicates that\n       no encryption should be used for the selected KeyID.\n\n   If any other value is used, PCONFIG causes a #GP.\n\n   \u2014 Encryption algorithm (ENC_ALG, bits 23:8). Bits 63:48 of the\n   IA32_TME_ACTIVATE MSR (MSR index 982H) indicate which encryption\n   algorithms are supported by the platform. The 16-bit ENC_ALG field should\n   specify one of the algorithms indicated in IA32_TME_ACTIVATE. PCONFIG\n   causes a #GP if ENC_ALG does not set exactly one bit or if it sets a bit\n   whose corresponding bit is not set in IA32_TME_ACTIVATE[63:48].\n\n     * KEY_FIELD_1: Use of this field depends upon selected key-programming\n       command:\n          * If the direct key-programming command is used\n            (KEYID_SET_KEY_DIRECT), this field carries the software supplied\n            data key to be used for the KeyID.\n          * If the direct key-programming command is used\n            (KEYID_SET_KEY_DIRECT), this field carries the software supplied\n            data key to be used for the KeyID.\n          * If the random key-programming command is used\n            (KEYID_SET_KEY_RANDOM), this field carries the software supplied\n            entropy to be mixed in the CPU generated random data key.\n          * If the random key-programming command is used\n            (KEYID_SET_KEY_RANDOM), this field carries the software supplied\n            entropy to be mixed in the CPU generated random data key.\n          * This field is ignored when one of the other key-programming\n            commands is used.\n          * This field is ignored when one of the other key-programming\n            commands is used.\n\n   It is software\u2019s responsibility to ensure that the key supplied for the\n   direct key-programming option or the entropy supplied for the random\n   key-programming option does not result in weak keys. There are no explicit\n   checks in the instruction to detect or prevent weak keys.\n\n     * KEY_FIELD_2: Use of this field depends upon selected key-programming\n       command:\n          * If the direct key-programming command is used\n            (KEYID_SET_KEY_DIRECT), this field carries the software supplied\n            tweak key to be used for the KeyID.\n          * If the direct key-programming command is used\n            (KEYID_SET_KEY_DIRECT), this field carries the software supplied\n            tweak key to be used for the KeyID.\n          * If the random key-programming command is used\n            (KEYID_SET_KEY_RANDOM), this field carries the software supplied\n            entropy to be mixed in the CPU generated random tweak key.\n          * If the random key-programming command is used\n            (KEYID_SET_KEY_RANDOM), this field carries the software supplied\n            entropy to be mixed in the CPU generated random tweak key.\n          * This field is ignored when one of the other key-programming\n            commands is used.\n          * This field is ignored when one of the other key-programming\n            commands is used.\n\n   It is software\u2019s responsibility to ensure that the key supplied for the\n   direct key-programming option or the entropy supplied for the random\n   key-programming option does not result in weak keys. There are no explicit\n   checks in the instruction to detect or prevent weak keys.\n\n   All KeyIDs default to TME behavior (encrypt with TME key or bypass\n   encryption) on activation of TME-MK. Software can at any point decide to\n   change the key for a KeyID using the MKTME_KEY_PROGRAM leaf function of\n   the PCONFIG instruction. Changing the key for a KeyID does not change the\n   state of the TLB caches or memory pipeline. Software is responsible for\n   taking appropriate actions to ensure correct behavior.\n\n   The key table used by TME-MK is shared by all logical processors in a\n   platform. For this reason, execution of the MKTME_KEY_PROGRAM leaf\n   function must gain exclusive access to the key table before updating it.\n   The leaf function does this by acquiring lock (implemented in the\n   platform) and retaining that lock until the execution completes. An\n   execution of the leaf function may fail to acquire the lock if it is\n   already in use. In this situation, the leaf function will load EAX with\n   failure reason 5 (DEVICE_BUSY) indicating that software must retry. When\n   this happens, the key table is not updated, and software should retry\n   execution of PCONFIG.\n\n     Earlier versions of this manual specified that bytes 63:6 of\n     MKTME_KEY_PROGRAM_STRUCT were reserved and that PCONFIG would cause a\n     #GP if they were not all zero. This is not the case. As indicated in\n     Table 4-15, PCONFIG ignores those bytes.\n\n     They also specified that PCONFIG would cause a #GP if the upper 48 bytes\n     of each of the 64-byte key fields were not all 0. This is not the case.\n     From each of these fields, PCONFIG uses the number of bytes required by\n     the selected encryption algorithm (e.g., 32 bytes for AES-XTS 256) and\n     ignores the upper bytes.\n\n     They also specified that PCONFIG would complete and report a failure\n     reason in EAX if the structure specified an incorrect KeyID, and\n     unsupported key-programming command, or an incorrect selection of an\n     encryption algorithm. This is not the case. As indicated above (and in\n     the Operation section), those conditions cause #GP.\n"],
	["wrussd:wrussq", "                   WRUSSD/WRUSSQ \u2014 Write to User Shadow Stack\n\n                                        64/32 bit    CPUID                    \n   Opcode/Instruction             Op/En Mode Support Feature Description\n                                                     Flag    \n   66 0F 38 F5 !(11):rrr:bbb      MR    V/V          CET_SS  Write 4 bytes to \n   WRUSSD m32, r32                                           shadow stack.    \n   66 REX.W 0F 38 F5              MR    V/N.E.       CET_SS  Write 8 bytes to \n   !(11):rrr:bbb WRUSSQ m64, r64                             shadow stack.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Writes bytes in register source to a user shadow stack page. The WRUSS\n   instruction can be executed only if CPL = 0, however the processor treats\n   its shadow-stack accesses as user accesses.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["xsavec", "            XSAVEC \u2014 Save Processor Extended States With Compaction\n\n   Opcode /           Op/En 64/32 bit    CPUID        Description             \n   Instruction              Mode Support Feature Flag \n   NP 0F C7 /4 XSAVEC                                 Save state components   \n   mem                M     V/V          XSAVEC       specified by EDX:EAX to \n                                                      mem with compaction.    \n   NP REX.W + 0F C7                                   Save state components   \n   /4 XSAVEC64 mem    M     V/N.E.       XSAVEC       specified by EDX:EAX to \n                                                      mem with compaction.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a full or partial save of processor state components to the XSAVE\n   area located at the memory address specified by the destination operand.\n   The implicit EDX:EAX register pair specifies a 64-bit instruction mask.\n   The specific state components saved correspond to the bits set in the\n   requested-feature bitmap (RFBM), which is the logical-AND of EDX:EAX and\n   XCR0.\n\n   The format of the XSAVE area is detailed in Section 13.4, \u201cXSAVE Area,\u201d of\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n   Like FXRSTOR and FXSAVE, the memory format used for x87 state depends on a\n   REX.W prefix; see Section 13.5.1, \u201cx87 State\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1.\n\n   Section 13.10, \u201cOperation of XSAVEC,\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1 provides a detailed\n   description of the operation of the XSAVEC instruction. The following\n   items provide a highlevel outline:\n\n     * Execution of XSAVEC is similar to that of XSAVE. XSAVEC differs from\n       XSAVE in that it uses compaction and that it may use the init\n       optimization.\n     * XSAVEC saves state component i if and only if RFBM[i] = 1 and\n       XINUSE[i] = 1.^1 (XINUSE is a bitmap by which the processor tracks the\n       status of various state components. See Section 13.6, \u201cProcessor\n       Tracking of XSAVEManaged State\u201d of Intel^\u00ae 64 and IA-32 Architectures\n       Software Developer\u2019s Manual, Volume 1.)\n     * XSAVEC does not modify bytes 511:464 of the legacy region of the XSAVE\n       area (see Section 13.4.1, \u201cLegacy Region of an XSAVE Area\u201d of Intel^\u00ae\n       64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1).\n     * XSAVEC writes the logical AND of RFBM and XINUSE to the XSTATE_BV\n       field of the XSAVE header.^2,3 (See Section 13.4.2, \u201cXSAVE Header\u201d of\n       Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n       1.) XSAVEC sets bit 63 of the XCOMP_BV field and sets bits 62:0 of\n       that field to RFBM[62:0]. XSAVEC does not write to any parts of the\n       XSAVE header other than the XSTATE_BV and XCOMP_BV fields.\n     * XSAVEC always uses the compacted format of the extended region of the\n       XSAVE area (see Section 13.4.3, \u201cExtended Region of an XSAVE Area\u201d of\n       Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n       1).\n\n     1. There is an exception for state component 1 (SSE). MXCSR is part of\n     SSE state, but XINUSE[1] may be 0 even if MXCSR does not have its\n     initial value of 1F80H. In this case, XSAVEC saves SSE state as long as\n     RFBM[1] = 1.\n\n     2. Unlike XSAVE and XSAVEOPT, XSAVEC clears bits in the XSTATE_BV field\n     that correspond to bits that are clear in RFBM.\n\n     3. There is an exception for state component 1 (SSE). MXCSR is part of\n     SSE state, but XINUSE[1] may be 0 even if MXCSR does not have its\n     initial value of 1F80H. In this case, XSAVEC sets XSTATE_BV[1] to 1 as\n     long as RFBM[1] = 1.\n\n   Use of a destination operand not aligned to 64-byte boundary (in either\n   64-bit or 32-bit modes) results in a general-protection (#GP) exception.\n   In 64-bit mode, the upper 32 bits of RDX and RAX are ignored.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["movnti", "               MOVNTI \u2014 Store Doubleword Using Non-Temporal Hint\n\n   Opcode /            Op/En 64/32 bit    CPUID        Description            \n   Instruction               Mode Support Feature Flag \n   NP 0F C3 /r MOVNTI                                  Move doubleword from   \n   m32, r32            MR    V/V          SSE2         r32 to m32 using       \n                                                       non-temporal hint.     \n   NP REX.W + 0F C3 /r                                 Move quadword from r64 \n   MOVNTI m64, r64     MR    V/N.E.       SSE2         to m64 using           \n                                                       non-temporal hint.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the doubleword integer in the source operand (second operand) to the\n   destination operand (first operand) using a non-temporal hint to minimize\n   cache pollution during the write to memory. The source operand is a\n   general-purpose register. The destination operand is a 32-bit memory\n   location.\n\n   The non-temporal hint is implemented by using a write combining (WC)\n   memory type protocol when writing the data to memory. Using this protocol,\n   the processor does not write the data into the cache hierarchy, nor does\n   it fetch the corresponding cache line from memory into the cache\n   hierarchy. The memory type of the region being written to can override the\n   non-temporal hint, if the memory address specified for the non-temporal\n   store is in an uncacheable (UC) or write protected (WP) memory region. For\n   more information on non-temporal stores, see \u201cCaching of Temporal vs.\n   Non-Temporal Data\u201d in Chapter 10 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1.\n\n   Because the WC protocol uses a weakly-ordered memory consistency model, a\n   fencing operation implemented with the SFENCE or MFENCE instruction should\n   be used in conjunction with MOVNTI instructions if multiple processors\n   might use different memory types to read/write the destination memory\n   locations.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n"],
	["vexp2pd", "   VEXP2PD \u2014 Approximation to the Exponential 2^x of Packed Double Precision\n            Floating-PointValues With Less Than 2^-23 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes approximations   \n                                                    to the exponential 2^x    \n                                                    (with less than 2^-23 of  \n   EVEX.512.66.0F38.W1 C8                           maximum relative error)   \n   /r VEXP2PD zmm1                                  of the packed double      \n   {k1}{z},                A     V/V       AVX512ER precision floating-point  \n   zmm2/m512/m64bcst {sae}                          values from               \n                                                    zmm2/m512/m64bcst and     \n                                                    stores the floating-point \n                                                    result in zmm1with        \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4 \n   A Full ModRM:reg (r, w) ModRM:r/m (r) N/A N/A            \n\n  Description \u00b6\n\n   Computes the approximate base-2 exponential evaluation of the double\n   precision floating-point values in the source operand (the second operand)\n   and stores the results to the destination operand (the first operand)\n   using the writemask k1. The approximate base-2 exponential is evaluated\n   with less than 2^-23 of relative error.\n\n   Denormal input values are treated as zeros and do not signal #DE,\n   irrespective of MXCSR.DAZ. Denormal results are flushed to zeros and do\n   not signal #UE, irrespective of MXCSR.FTZ.\n\n   The source operand is a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n  A numerically exact implementation of VEXP2xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["emodt", "                     EMODT \u2014 Change the Type of an EPC Page\n\n   Opcode/Instruction     Op/En 64/32 bit    CPUID        Description         \n                                Mode Support Feature Flag \n                                                          This leaf function  \n   EAX = 0FH ENCLS[EMODT] IR    V/V          SGX2         changes the type of \n                                                          an existing EPC     \n                                                          page.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                     RBX          RCX                             \n   IR    EMODT (In) Return Error Address of a Address of the destination EPC  \n                    Code (Out)   SECINFO (In) page (In)                       \n\n  Description \u00b6\n\n   This leaf function modifies the type of an EPC page. The security\n   attributes are configured to prevent access to the EPC page at its new\n   type until a corresponding invocation of the EACCEPT leaf confirms the\n   modification. This instruction can only be executed when current privilege\n   level is 0.\n\n   RBX contains the effective address of a SECINFO structure while RCX\n   contains the effective address of an EPC page. The table below provides\n   additional information on the memory parameter of the EMODT leaf function.\n\nEMODT Memory Parameter Semantics \u00b6\n\n   SECINFO                              EPCPAGE                               \n   Read access permitted by Non Enclave Read/Write access permitted by        \n                                        Enclave                               \n\n   The instruction faults if any of the following:\n\nEMODT Faulting Conditions \u00b6\n\n   The operands are not properly   If unsupported security attributes are     \n   aligned.                        set.                                       \n   The Enclave is not initialized. SECS is locked by another thread.          \n   The EPC page is locked by       RCX does not contain an effective address  \n   another thread.                 of an EPC page in the running enclave.     \n   The EPC page is not valid.      \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EMODT successful.                              \n   SGX_PAGE_NOT_MODIFIABLE     The EPC page cannot be modified because it is  \n                               in the PENDING or MODIFIED state.              \n   SGX_EPC_PAGE_CONFLICT       Page is being written by EADD, EAUG, ECREATE,  \n                               ELDU/B, EMODPR, or EWB.                        \n\n   Table 38-34. EMODT Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n   Leaf  Parameter Base Concurrency Restrictions\n                   Access    On Conflict   SGX_CONFLICT VM Exit Qualification \n   EMODT Target    Exclusive SGX_EPC_PAGE_ EPC_PAGE_CONFLICT_ERROR            \n         [DS:RCX]            CONFLICT      \n\n   Table 38-35. Base Concurrency Restrictions of EMODT\n\n                  Additional Concurrency Restrictions\n                  vs. EACCEPT,                                          \n                  EACCEPTCOPY, EMODPE,   vs. EADD, EEXTEND,\n  Leaf  Parameter EM vs. EACCEPT,        EINIT               vs. ETRACK, ETRACKC\n                  EACCEPTCOPY, EMODPE,\n                  EMODPR, EMODT\n                  Access    On Conflict  Access     On       Access     On       \n                                                    Conflict            Conflict \n  EMODT Target    Exclusive SGX_EPC_PAGE Concurrent          Concurrent \n        [DS:RCX]            _CONFLICT    \n\n   Table 38-36. Additional Concurrency Restrictions of EMODT\n\n  Flags Affected \u00b6\n\n   Sets ZF if page is not modifiable or if other SGX2 instructions are\n   executing concurrently, otherwise cleared. Clears CF, PF, AF, OF, SF.\n"],
	["vreducess", "    VREDUCESS \u2014 Perform a Reduction Transformation on a Scalar Float32 Value\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Perform a reduction       \n                                                    transformation on a       \n                                                    scalar single-precision   \n                                                    floating-point value in   \n                                                    xmm3/m32 by subtracting a \n   EVEX.LLIG.66.0F3A.W0 57                          number of fraction bits   \n   /r /ib VREDUCESS xmm1   A     V/V       AVX512DQ specified by the imm8     \n   {k1}{z}, xmm2,                                   field. Also, upper        \n   xmm3/m32{sae}, imm8                              single-precision          \n                                                    floating-point values     \n                                                    (bits[127:32]) from xmm2  \n                                                    are copied to             \n                                                    xmm1[127:32]. Stores the  \n                                                    result in xmm1 register.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Perform a reduction transformation of the binary encoded single-precision\n   floating-point value in the low dword element of the second source operand\n   (the third operand) and store the reduced result in binary floating-point\n   format to the low dword element of the destination operand (the first\n   operand) under the writemask k1. Bits 127:32 of the destination operand\n   are copied from respective dword elements of the first source operand (the\n   second operand).\n\n   The reduction transformation subtracts the integer part and the leading M\n   fractional bits from the binary floating-point source value, where M is a\n   unsigned integer specified by imm8[7:4], see Figure 5-28. Specifically,\n   the reduction transformation can be expressed as:\n\n   dest = src \u2013 (ROUND(2^M*src))*2^-M;\n\n   where \u201cRound()\u201d treats \u201csrc\u201d, \u201c2^M\u201d, and their product as binary\n   floating-point numbers with normalized significand and biased exponents.\n\n   The magnitude of the reduced result can be expressed by considering src=\n   2^p*man2,\n\n   where \u2018man2\u2019 is the normalized significand and \u2018p\u2019 is the unbiased\n   exponent\n\n   Then if RC = RNE: 0<=|Reduced Result|<=2^p-M-1\n\n   Then if RC =\u0338 RNE: 0<=|Reduced Result|<2^p-M\n\n   This instruction might end up with a precision exception set. However, in\n   case of SPE set (i.e., Suppress Precision Exception, which is imm8[3]=1),\n   no precision exception is reported.\n\n   Handling of special case of input values are listed in Table 5-29.\n"],
	["finit:fninit", "                 FINIT/FNINIT \u2014 Initialize Floating-Point Unit\n\n   Opcode   Instruction 64-Bit Mode Compat/Leg Mode Description               \n                                                    Initialize FPU after      \n   9B DB E3 FINIT       Valid       Valid           checking for pending      \n                                                    unmasked floating-point   \n                                                    exceptions.               \n                                                    Initialize FPU without    \n   DB E3    FNINIT^1    Valid       Valid           checking for pending      \n                                                    unmasked floating-point   \n                                                    exceptions.               \n\n     1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Sets the FPU control, status, tag, instruction pointer, and data pointer\n   registers to their default states. The FPU control word is set to 037FH\n   (round to nearest, all exceptions masked, 64-bit precision). The status\n   word is cleared (no exception flags set, TOP is set to 0). The data\n   registers in the register stack are left unchanged, but they are all\n   tagged as empty (11B). Both the instruction and data pointers are cleared.\n\n   The FINIT instruction checks for and handles any pending unmasked\n   floating-point exceptions before performing the initialization; the FNINIT\n   instruction does not.\n\n   The assembler issues two instructions for the FINIT instruction (an FWAIT\n   instruction followed by an FNINIT instruction), and the processor executes\n   each of these instructions in separately. If an exception is generated for\n   either of these instructions, the save EIP points to the instruction that\n   caused the exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   When operating a Pentium or Intel486 processor in MS-DOS compatibility\n   mode, it is possible (under unusual circumstances) for an FNINIT\n   instruction to be interrupted prior to being executed to handle a pending\n   FPU exception. See the section titled \u201cNo-Wait FPU Instructions Can Get\n   FPU Interrupt in Window\u201d in Appendix D of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a description of\n   these circumstances. An FNINIT instruction cannot be interrupted in this\n   way on later Intel processors, except for the Intel Quark^TM X1000\n   processor.\n\n   In the Intel387 math coprocessor, the FINIT/FNINIT instruction does not\n   clear the instruction and data pointers.\n\n   This instruction affects only the x87 FPU. It does not affect the XMM and\n   MXCSR registers.\n\nFPU Flags Affected \u00b6\n\n   C0, C1, C2, C3 set to 0. \n"],
	["mulsd", "         MULSD \u2014 Multiply Scalar Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Multiply the low double    \n                                                   precision floating-point   \n   F2 0F 59 /r MULSD        A    V/V       SSE2    value in xmm2/m64 by low   \n   xmm1,xmm2/m64                                   double precision           \n                                                   floating-point value in    \n                                                   xmm1.                      \n                                                   Multiply the low double    \n   VEX.LIG.F2.0F.WIG 59 /r                         precision floating-point   \n   VMULSD xmm1,xmm2,        B    V/V       AVX     value in xmm3/m64 by low   \n   xmm3/m64                                        double precision           \n                                                   floating-point value in    \n                                                   xmm2.                      \n                                                   Multiply the low double    \n   EVEX.LLIG.F2.0F.W1 59 /r                        precision floating-point   \n   VMULSD xmm1 {k1}{z},     C    V/V       AVX512F value in xmm3/m64 by low   \n   xmm2, xmm3/m64 {er}                             double precision           \n                                                   floating-point value in    \n                                                   xmm2.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Multiplies the low double precision floating-point value in the second\n   source operand by the low double precision floating-point value in the\n   first source operand, and stores the double precision floating-point\n   result in the destination operand. The second source operand can be an XMM\n   register or a 64-bit memory location. The first source operand and the\n   destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:64) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 and EVEX encoded version: The quadword at bits 127:64 of the\n   destination operand is copied from the same bits of the first source\n   operand. Bits (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination operand\n   is updated according to the write-mask.\n\n   Software should ensure VMULSD is encoded with VEX.L=0. Encoding VMULSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["fxrstor", "              FXRSTOR \u2014 Restore x87 FPU, MMX, XMM, and MXCSR State\n\n   Opcode/Instruction  Op/En 64-Bit Compat/Leg Description                    \n                             Mode   Mode       \n   NP 0F AE /1 FXRSTOR                         Restore the x87 FPU, MMX, XMM, \n   m512byte            M     Valid  Valid      and MXCSR register state from  \n                                               m512byte.                      \n   NP REX.W + 0F AE /1                         Restore the x87 FPU, MMX, XMM, \n   FXRSTOR64 m512byte  M     Valid  N.E.       and MXCSR register state from  \n                                               m512byte.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reloads the x87 FPU, MMX technology, XMM, and MXCSR registers from the\n   512-byte memory image specified in the source operand. This data should\n   have been written to memory previously using the FXSAVE instruction, and\n   in the same format as required by the operating modes. The first byte of\n   the data should be located on a 16-byte boundary. There are three distinct\n   layouts of the FXSAVE state map: one for legacy and compatibility mode, a\n   second format for 64-bit mode FXSAVE/FXRSTOR with REX.W=0, and the third\n   format is for 64-bit mode with FXSAVE64/FXRSTOR64. Table 3-43 shows the\n   layout of the legacy/compatibility mode state information in memory and\n   describes the fields in the memory image for the FXRSTOR and FXSAVE\n   instructions. Table 3-46 shows the layout of the 64-bit mode state\n   information when REX.W is set (FXSAVE64/FXRSTOR64). Table 3-47 shows the\n   layout of the 64-bit mode state information when REX.W is clear\n   (FXSAVE/FXRSTOR).\n\n   The state image referenced with an FXRSTOR instruction must have been\n   saved using an FXSAVE instruction or be in the same format as required by\n   Table 3-43, Table 3-46, or Table 3-47. Referencing a state image saved\n   with an FSAVE, FNSAVE instruction or incompatible field layout will result\n   in an incorrect state restoration.\n\n   The FXRSTOR instruction does not flush pending x87 FPU exceptions. To\n   check and raise exceptions when loading x87 FPU state information with the\n   FXRSTOR instruction, use an FWAIT instruction after the FXRSTOR\n   instruction.\n\n   If the OSFXSR bit in control register CR4 is not set, the FXRSTOR\n   instruction may not restore the states of the XMM and MXCSR registers.\n   This behavior is implementation dependent.\n\n   If the MXCSR state contains an unmasked exception with a corresponding\n   status flag also set, loading the register with the FXRSTOR instruction\n   will not result in a SIMD floating-point error condition being generated.\n   Only the next occurrence of this unmasked exception will result in the\n   exception being generated.\n\n   Bits 16 through 32 of the MXCSR register are defined as reserved and\n   should be set to 0. Attempting to write a 1 in any of these bits from the\n   saved state image will result in a general protection exception (#GP)\n   being generated.\n\n   Bytes 464:511 of an FXSAVE image are available for software use. FXRSTOR\n   ignores the content of bytes 464:511 in an FXSAVE state image.\n"],
	["orpd", "   ORPD \u2014 Bitwise Logical OR of Packed Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Return the bitwise logical \n   66 0F 56/r ORPD xmm1,                           OR of packed double        \n   xmm2/m128               A    V/V       SSE2     precision floating-point   \n                                                   values in xmm1 and         \n                                                   xmm2/mem.                  \n                                                   Return the bitwise logical \n   VEX.128.66.0F 56 /r                             OR of packed double        \n   VORPD xmm1,xmm2,        B    V/V       AVX      precision floating-point   \n   xmm3/m128                                       values in xmm2 and         \n                                                   xmm3/mem.                  \n                                                   Return the bitwise logical \n   VEX.256.66.0F 56 /r                             OR of packed double        \n   VORPD ymm1, ymm2,       B    V/V       AVX      precision floating-point   \n   ymm3/m256                                       values in ymm2 and         \n                                                   ymm3/mem.                  \n                                                   Return the bitwise logical \n   EVEX.128.66.0F.W1 56 /r                         OR of packed double        \n   VORPD xmm1 {k1}{z},     C    V/V       AVX512VL precision floating-point   \n   xmm2, xmm3/m128/m64bcst                AVX512DQ values in xmm2 and         \n                                                   xmm3/m128/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.256.66.0F.W1 56 /r                         OR of packed double        \n   VORPD ymm1 {k1}{z},     C    V/V       AVX512VL precision floating-point   \n   ymm2, ymm3/m256/m64bcst                AVX512DQ values in ymm2 and         \n                                                   ymm3/m256/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.512.66.0F.W1 56 /r                         OR of packed double        \n   VORPD zmm1 {k1}{z},     C    V/V       AVX512DQ precision floating-point   \n   zmm2, zmm3/m512/m64bcst                         values in zmm2 and         \n                                                   zmm3/m512/m64bcst subject  \n                                                   to writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical OR of the two, four or eight packed double\n   precision floating-point values from the first source operand and the\n   second source operand, and stores the result in the destination operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with write-mask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["vscalefpd", "          VSCALEFPD \u2014 Scale Packed Float64 Values With Float64 Values\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Scale the packed double \n   EVEX.128.66.0F38.W1 2C /r                          precision               \n   VSCALEFPD xmm1 {k1}{z},   A     V/V       AVX512VL floating-point values   \n   xmm2, xmm3/m128/m64bcst                   AVX512F  in xmm2 using values    \n                                                      from xmm3/m128/m64bcst. \n                                                      Under writemask k1.     \n                                                      Scale the packed double \n   EVEX.256.66.0F38.W1 2C /r                          precision               \n   VSCALEFPD ymm1 {k1}{z},   A     V/V       AVX512VL floating-point values   \n   ymm2, ymm3/m256/m64bcst                   AVX512F  in ymm2 using values    \n                                                      from ymm3/m256/m64bcst. \n                                                      Under writemask k1.     \n                                                      Scale the packed double \n   EVEX.512.66.0F38.W1 2C /r                          precision               \n   VSCALEFPD zmm1 {k1}{z},   A     V/V       AVX512F  floating-point values   \n   zmm2,                                              in zmm2 using values    \n   zmm3/m512/m64bcst{er}                              from zmm3/m512/m64bcst. \n                                                      Under writemask k1.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a floating-point scale of the packed double precision\n   floating-point values in the first source operand by multiplying them by 2\n   to the power of the double precision floating-point values in second\n   source operand.\n\n   The equation of this operation is given by:\n\n   zmm1 := zmm2*2^floor(zmm3).\n\n   Floor(zmm3) means maximum integer value \u2264 zmm3.\n\n   If the result cannot be represented in double precision, then the proper\n   overflow response (for positive scaling operand), or the proper underflow\n   response (for negative scaling operand) is issued. The overflow and\n   underflow responses are dependent on the rounding mode (for IEEE-compliant\n   rounding), as well as on other settings in MXCSR (exception mask bits, FTZ\n   bit), and on the SAE bit.\n\n   The first source operand is a ZMM/YMM/XMM register. The second source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is a ZMM/YMM/XMM register conditionally updated with\n   writemask k1.\n\n   Handling of special-case input values are listed in Table 5-39 and Table\n   5-40.\n\n                 Src2                                                     Set IE \n                 \u00b1NaN       +Inf            -Inf            0/Denorm/Norm \n                                                                          IF     \n                                                                          either \nSrc1 \u00b1QNaN       QNaN(Src1) +INF            +0              QNaN(Src1)    source \n                                                                          is     \n                                                                          SNAN   \n     \u00b1SNaN       QNaN(Src1) QNaN(Src1)      QNaN(Src1)      QNaN(Src1)    YES    \n                                                                          IF     \n                                                                          Src2   \n     \u00b1Inf        QNaN(Src2) Src1            QNaN_Indefinite Src1          is     \n                                                                          SNAN   \n                                                                          or     \n                                                                          -INF   \n                                                                          IF     \n                                                                          Src2   \n     \u00b10          QNaN(Src2) QNaN_Indefinite Src1            Src1          is     \n                                                                          SNAN   \n                                                                          or     \n                                                                          +INF   \n                                                                          IF     \n     Denorm/Norm QNaN(Src2) \u00b1INF (Src1      \u00b10 (Src1 sign)  Compute       Src2   \n                            sign)                           Result        is     \n                                                                          SNAN   \n\n   Table 5-39. VSCALEFPD/SD/PS/SS Special Cases\n\n   Special Case       Returned value                              Faults    \n   |result| < 2^-1074 \u00b10 or \u00b1Min-Denormal (Src1 sign)             Underflow \n   |result| \u2265 2^1024  \u00b1INF (Src1 sign) or \u00b1Max-normal (Src1 sign) Overflow  \n\n   Table 5-40. Additional VSCALEFPD/SD Special Cases\n"],
	["leave", "                       LEAVE \u2014 High Level Procedure Exit\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n   C9     LEAVE       ZO    Valid       Valid           Set SP to BP, then    \n                                                        pop BP.               \n   C9     LEAVE       ZO    N.E.        Valid           Set ESP to EBP, then  \n                                                        pop EBP.              \n   C9     LEAVE       ZO    Valid       N.E.            Set RSP to RBP, then  \n                                                        pop RBP.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Releases the stack frame set up by an earlier ENTER instruction. The LEAVE\n   instruction copies the frame pointer (in the EBP register) into the stack\n   pointer register (ESP), which releases the stack space allocated to the\n   stack frame. The old frame pointer (the frame pointer for the calling\n   procedure that was saved by the ENTER instruction) is then popped from the\n   stack into the EBP register, restoring the calling procedure\u2019s stack\n   frame.\n\n   A RET instruction is commonly executed following a LEAVE instruction to\n   return program control to the calling procedure.\n\n   See \u201cProcedure Calls for Block-Structured Languages\u201d in Chapter 7 of the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1,\n   for detailed information on the use of the ENTER and LEAVE instructions.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 64 bits;\n   32-bit operation cannot be encoded. See the summary chart at the beginning\n   of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtqq2pd", "    VCVTQQ2PD \u2014 Convert Packed Quadword Integers to Packed Double Precision\n                              Floating-PointValues\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Convert two packed        \n   EVEX.128.F3.0F.W1 E6 /r                          quadword integers from    \n   VCVTQQ2PD xmm1 {k1}{z}, A     V/V       AVX512VL xmm2/m128/m64bcst to      \n   xmm2/m128/m64bcst                       AVX512DQ packed double precision   \n                                                    floating-point values in  \n                                                    xmm1 with writemask k1.   \n                                                    Convert four packed       \n   EVEX.256.F3.0F.W1 E6 /r                          quadword integers from    \n   VCVTQQ2PD ymm1 {k1}{z}, A     V/V       AVX512VL ymm2/m256/m64bcst to      \n   ymm2/m256/m64bcst                       AVX512DQ packed double precision   \n                                                    floating-point values in  \n                                                    ymm1 with writemask k1.   \n                                                    Convert eight packed      \n                                                    quadword integers from    \n   EVEX.512.F3.0F.W1 E6 /r                          zmm2/m512/m64bcst to      \n   VCVTQQ2PD zmm1 {k1}{z}, A     V/V       AVX512DQ eight packed double       \n   zmm2/m512/m64bcst{er}                            precision floating-point  \n                                                    values in zmm1 with       \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed quadword integers in the source operand (second operand)\n   to packed double precision floating-point values in the destination\n   operand (first operand).\n\n   The source operand is a ZMM/YMM/XMM register or a 512/256/128-bit memory\n   location. The destination operation is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["f2xm1", "                              F2XM1 \u2014 Compute 2x\u20131\n\n   Opcode  Mode Leg Mode Description                       \n   D9 F0                 Replace ST(0) with (2^ST(0) \u2013 1). \n\nDescription \u00b6\n\n   Computes the exponential value of 2 to the power of the source operand\n   minus 1. The source operand is located in register ST(0) and the result is\n   also stored in ST(0). The value of the source operand must lie in the\n   range \u20131.0 to +1.0. If the source value is outside this range, the result\n   is undefined.\n\n   The following table shows the results obtained when computing the\n   exponential value of various classes of numbers, assuming that neither\n   overflow nor underflow occurs.\n\n   ST(0) SRC   ST(0) DEST   \n   \u2212 1.0 to \u22120 \u2212 0.5 to \u2212 0 \n   \u22120          \u22120           \n   +0          +0           \n   + 0 to +1.0 + 0 to 1.0   \n\n   Table 3-16. Results Obtained from F2XM1\n\n   Values other than 2 can be exponentiated using the following formula:\n\n   _xy _:= 2(y \u2217 log_2x)\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["bndstx", "            BNDSTX \u2014 Store Extended Bounds Using Address Translation\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Description\n                            Support   Flag    \n                                              Store the bounds in bnd and the \n                                              pointer value in the index      \n   NP 0F 1B /r BNDSTX MR    V/V       MPX     register of mib to a bound      \n   mib, bnd                                   table entry (BTE) with address  \n                                              translation using the base of   \n                                              mib.                            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1                                    Operand 2     Operand 3 \n   MR    SIB.base (r): Address of pointer             ModRM:reg (r) N/A       \n         SIB.index(r)                                 \n\nDescription \u00b6\n\n   BNDSTX uses the linear address constructed from the displacement and base\n   register of the SIB-addressing form of the memory operand (mib) to perform\n   address translation to store to a bound table entry. The bounds in the\n   source operand bnd are written to the lower and upper bounds in the BTE.\n   The content of the index register of mib is written to the pointer value\n   field in the BTE.\n\n   This instruction does not cause memory access to the linear address of mib\n   nor the effective address referenced by the base, and does not read or\n   write any flags.\n\n   Segment overrides apply to the linear address computation with the base of\n   mib, and are used during address translation to generate the address of\n   the bound table entry. By default, the address of the BTE is assumed to be\n   linear address. There are no segmentation checks performed on the base of\n   mib.\n\n   The base of mib will not be checked for canonical address violation as it\n   does not access memory.\n\n   Any encoding of this instruction that does not specify base or index\n   register will treat those registers as zero (constant). The reg-reg form\n   of this instruction will remain a NOP.\n\n   The scale field of the SIB byte has no effect on these instructions and is\n   ignored.\n\n   The bound register may be partially updated on memory faults. The order in\n   which memory operands are loaded is implementation specific.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cvtss2si", " CVTSS2SI \u2014 Convert Scalar Single Precision Floating-Point Value to Doubleword\n                                    Integer\n\n                          Op / 64/32 bit    CPUID                             \n   Opcode/Instruction     En   Mode Support Feature Description\n                                            Flag    \n                                                    Convert one single        \n   F3 0F 2D /r CVTSS2SI                             precision floating-point  \n   r32, xmm1/m32          A    V/V          SSE     value from xmm1/m32 to    \n                                                    one signed doubleword     \n                                                    integer in r32.           \n                                                    Convert one single        \n   F3 REX.W 0F 2D /r                                precision floating-point  \n   CVTSS2SI r64, xmm1/m32 A    V/N.E.       SSE     value from xmm1/m32 to    \n                                                    one signed quadword       \n                                                    integer in r64.           \n                                                    Convert one single        \n   VEX.LIG.F3.0F.W0 2D /r                           precision floating-point  \n   ^1 VCVTSS2SI r32,      A    V/V          AVX     value from xmm1/m32 to    \n   xmm1/m32                                         one signed doubleword     \n                                                    integer in r32.           \n                                                    Convert one single        \n   VEX.LIG.F3.0F.W1 2D /r                           precision floating-point  \n   ^1 VCVTSS2SI r64,      A    V/N.E.^2     AVX     value from xmm1/m32 to    \n   xmm1/m32                                         one signed quadword       \n                                                    integer in r64.           \n                                                    Convert one single        \n   EVEX.LLIG.F3.0F.W0 2D                            precision floating-point  \n   /r VCVTSS2SI r32,      B    V/V          AVX512F value from xmm1/m32 to    \n   xmm1/m32{er}                                     one signed doubleword     \n                                                    integer in r32.           \n                                                    Convert one single        \n   EVEX.LLIG.F3.0F.W1 2D                            precision floating-point  \n   /r VCVTSS2SI r64,      B    V/N.E.^2     AVX512F value from xmm1/m32 to    \n   xmm1/m32{er}                                     one signed quadword       \n                                                    integer in r64.           \n\n     1. Software should ensure VCVTSS2SI is encoded with VEX.L=0. Encoding\n     VCVTSS2SI with VEX.L=1 may encounter unpredictable behavior across\n     different processor generations.\n\n     2. VEX.W1/EVEX.W1 in non-64 bit is ignored; the instructions behaves as\n     if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A          ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts a single precision floating-point value in the source operand\n   (the second operand) to a signed doubleword integer (or signed quadword\n   integer if operand size is 64 bits) in the destination operand (the first\n   operand). The source operand can be an XMM register or a memory location.\n   The destination operand is a general-purpose register. When the source\n   operand is an XMM register, the single precision floating-point value is\n   contained in the low doubleword of the register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (2^w-1, where w\n   represents the number of bits in the destination format) is returned.\n\n   Legacy SSE instructions: In 64-bit mode, Use of the REX.W prefix promotes\n   the instruction to produce 64-bit data. See the summary chart at the\n   beginning of this section for encoding data and limits.\n\n   VEX.W1 and EVEX.W1 versions: promotes the instruction to produce 64-bit\n   data in 64-bit mode.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCVTSS2SI is encoded with VEX.L=0. Encoding\n   VCVTSS2SI with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["call", "                             CALL \u2014 Call Procedure\n\n   Opcode   Instruction   Op/En 64-bit  Compat/Leg Description                \n                                Mode    Mode       \n                                                   Call near, relative,       \n   E8 cw    CALL rel16    D     N.S.    Valid      displacement relative to   \n                                                   next instruction.          \n                                                   Call near, relative,       \n                                                   displacement relative to   \n   E8 cd    CALL rel32    D     Valid   Valid      next instruction. 32-bit   \n                                                   displacement sign extended \n                                                   to 64-bits in 64-bit mode. \n                                                   Call near, absolute        \n   FF /2    CALL r/m16    M     N.E.    Valid      indirect, address given in \n                                                   r/m16.                     \n                                                   Call near, absolute        \n   FF /2    CALL r/m32    M     N.E.    Valid      indirect, address given in \n                                                   r/m32.                     \n                                                   Call near, absolute        \n   FF /2    CALL r/m64    M     Valid   N.E.       indirect, address given in \n                                                   r/m64.                     \n   9A cd    CALL ptr16:16 D     Invalid Valid      Call far, absolute,        \n                                                   address given in operand.  \n   9A cp    CALL ptr16:32 D     Invalid Valid      Call far, absolute,        \n                                                   address given in operand.  \n                                                   Call far, absolute         \n                                                   indirect address given in  \n                                                   m16:16. In 32-bit mode: if \n                                                   selector points to a gate, \n                                                   then RIP = 32-bit zero     \n   FF /3    CALL m16:16   M     Valid   Valid      extended displacement      \n                                                   taken from gate; else RIP  \n                                                   = zero extended 16-bit     \n                                                   offset from far pointer    \n                                                   referenced in the          \n                                                   instruction.               \n                                                   In 64-bit mode: If         \n                                                   selector points to a gate, \n                                                   then RIP = 64-bit          \n                                                   displacement taken from    \n   FF /3    CALL m16:32   M     Valid   Valid      gate; else RIP = zero      \n                                                   extended 32-bit offset     \n                                                   from far pointer           \n                                                   referenced in the          \n                                                   instruction.               \n                                                   In 64-bit mode: If         \n                                                   selector points to a gate, \n                                                   then RIP = 64-bit          \n   REX.W FF CALL m16:64   M     Valid   N.E.       displacement taken from    \n   /3                                              gate; else RIP = 64-bit    \n                                                   offset from far pointer    \n                                                   referenced in the          \n                                                   instruction.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   D     Offset        N/A       N/A       N/A       \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Saves procedure linking information on the stack and branches to the\n   called procedure specified using the target operand. The target operand\n   specifies the address of the first instruction in the called procedure.\n   The operand can be an immediate value, a general-purpose register, or a\n   memory location.\n\n   This instruction can be used to execute four types of calls:\n\n     * Near Call \u2014 A call to a procedure in the current code segment (the\n       segment currently pointed to by the CS register), sometimes referred\n       to as an intra-segment call.\n     * Far Call \u2014 A call to a procedure located in a different segment than\n       the current code segment, sometimes referred to as an inter-segment\n       call.\n     * Inter-privilege-level far call \u2014 A far call to a procedure in a\n       segment at a different privilege level than that of the currently\n       executing program or procedure.\n     * Task switch \u2014 A call to a procedure located in a different task.\n\n   The latter two call types (inter-privilege-level call and task switch) can\n   only be executed in protected mode. See \u201cCalling Procedures Using Call and\n   RET\u201d in Chapter 6 of the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1, for additional information on near, far, and\n   inter-privilege-level calls. See Chapter 8, \u201cTask Management,\u201d in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A,\n   for information on performing task switches with the CALL instruction.\n\n   Near Call. When executing a near call, the processor pushes the value of\n   the EIP register (which contains the offset of the instruction following\n   the CALL instruction) on the stack (for use later as a return-instruction\n   pointer). The processor then branches to the address in the current code\n   segment specified by the target operand. The target operand specifies\n   either an absolute offset in the code segment (an offset from the base of\n   the code segment) or a relative offset (a signed displacement relative to\n   the current value of the instruction pointer in the EIP register; this\n   value points to the instruction following the CALL instruction). The CS\n   register is not changed on near calls.\n\n   For a near call absolute, an absolute offset is specified indirectly in a\n   general-purpose register or a memory location (r/m16, r/m32, or r/m64).\n   The operand-size attribute determines the size of the target operand (16,\n   32 or 64 bits). When in 64-bit mode, the operand size for near call (and\n   all near branches) is forced to 64-bits. Absolute offsets are loaded\n   directly into the EIP(RIP) register. If the operand size attribute is 16,\n   the upper two bytes of the EIP register are cleared, resulting in a\n   maximum instruction pointer size of 16 bits. When accessing an absolute\n   offset indirectly using the stack pointer [ESP] as the base register, the\n   base value used is the value of the ESP before the instruction executes.\n\n   A relative offset (rel16 or rel32) is generally specified as a label in\n   assembly code. But at the machine code level, it is encoded as a signed,\n   16- or 32-bit immediate value. This value is added to the value in the\n   EIP(RIP) register. In 64-bit mode the relative offset is always a 32-bit\n   immediate value which is sign extended to 64-bits before it is added to\n   the value in the RIP register for the target calculation. As with absolute\n   offsets, the operand-size attribute determines the size of the target\n   operand (16, 32, or 64 bits). In 64-bit mode the target operand will\n   always be 64-bits because the operand size is forced to 64-bits for near\n   branches.\n\n   Far Calls in Real-Address or Virtual-8086 Mode. When executing a far call\n   in real- address or virtual-8086 mode, the processor pushes the current\n   value of both the CS and EIP registers on the stack for use as a\n   return-instruction pointer. The processor then performs a \u201cfar branch\u201d to\n   the code segment and offset specified with the target operand for the\n   called procedure. The target operand specifies an absolute far address\n   either directly with a pointer (ptr16:16 or ptr16:32) or indirectly with a\n   memory location (m16:16 or m16:32). With the pointer method, the segment\n   and offset of the called procedure is encoded in the instruction using a\n   4-byte (16-bit operand size) or 6-byte (32-bit operand size) far address\n   immediate. With the indirect method, the target operand specifies a memory\n   location that contains a 4-byte (16-bit operand size) or 6-byte (32-bit\n   operand size) far address. The operand-size attribute determines the size\n   of the offset (16 or 32 bits) in the far address. The far address is\n   loaded directly into the CS and EIP registers. If the operand-size\n   attribute is 16, the upper two bytes of the EIP register are cleared.\n\n   Far Calls in Protected Mode. When the processor is operating in protected\n   mode, the CALL instruction can be used to perform the following types of\n   far calls:\n\n     * Far call to the same privilege level\n     * Far call to a different privilege level (inter-privilege level call)\n     * Task switch (far call to another task)\n\n   In protected mode, the processor always uses the segment selector part of\n   the far address to access the corresponding descriptor in the GDT or LDT.\n   The descriptor type (code segment, call gate, task gate, or TSS) and\n   access rights determine the type of call operation to be performed.\n\n   If the selected descriptor is for a code segment, a far call to a code\n   segment at the same privilege level is performed. (If the selected code\n   segment is at a different privilege level and the code segment is\n   non-conforming, a general-protection exception is generated.) A far call\n   to the same privilege level in protected mode is very similar to one\n   carried out in real-address or virtual-8086 mode. The target operand\n   specifies an absolute far address either directly with a pointer (ptr16:16\n   or ptr16:32) or indirectly with a memory location (m16:16 or m16:32). The\n   operand- size attribute determines the size of the offset (16 or 32 bits)\n   in the far address. The new code segment selector and its descriptor are\n   loaded into CS register; the offset from the instruction is loaded into\n   the EIP register.\n\n   A call gate (described in the next paragraph) can also be used to perform\n   a far call to a code segment at the same privilege level. Using this\n   mechanism provides an extra level of indirection and is the preferred\n   method of making calls between 16-bit and 32-bit code segments.\n\n   When executing an inter-privilege-level far call, the code segment for the\n   procedure being called must be accessed through a call gate. The segment\n   selector specified by the target operand identifies the call gate. The\n   target operand can specify the call gate segment selector either directly\n   with a pointer (ptr16:16 or ptr16:32) or indirectly with a memory location\n   (m16:16 or m16:32). The processor obtains the segment selector for the new\n   code segment and the new instruction pointer (offset) from the call gate\n   descriptor. (The offset from the target operand is ignored when a call\n   gate is used.)\n\n   On inter-privilege-level calls, the processor switches to the stack for\n   the privilege level of the called procedure. The segment selector for the\n   new stack segment is specified in the TSS for the currently running task.\n   The branch to the new code segment occurs after the stack switch. (Note\n   that when using a call gate to perform a far call to a segment at the same\n   privilege level, no stack switch occurs.) On the new stack, the processor\n   pushes the segment selector and stack pointer for the calling procedure\u2019s\n   stack, an optional set of parameters from the calling procedures stack,\n   and the segment selector and instruction pointer for the calling\n   procedure\u2019s code segment. (A value in the call gate descriptor determines\n   how many parameters to copy to the new stack.) Finally, the processor\n   branches to the address of the procedure being called within the new code\n   segment.\n\n   Executing a task switch with the CALL instruction is similar to executing\n   a call through a call gate. The target operand specifies the segment\n   selector of the task gate for the new task activated by the switch (the\n   offset in the target operand is ignored). The task gate in turn points to\n   the TSS for the new task, which contains the segment selectors for the\n   task\u2019s code and stack segments. Note that the TSS also contains the EIP\n   value for the next instruction that was to be executed before the calling\n   task was suspended. This instruction pointer value is loaded into the EIP\n   register to re-start the calling task.\n\n   The CALL instruction can also specify the segment selector of the TSS\n   directly, which eliminates the indirection of the task gate. See Chapter\n   8, \u201cTask Management,\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3A, for information on the mechanics of a task\n   switch.\n\n   When you execute at task switch with a CALL instruction, the nested task\n   flag (NT) is set in the EFLAGS register and the new TSS\u2019s previous task\n   link field is loaded with the old task\u2019s TSS selector. Code is expected to\n   suspend this nested task by executing an IRET instruction which, because\n   the NT flag is set, automatically uses the previous task link to return to\n   the calling task. (See \u201cTask Linking\u201d in Chapter 8 of the Intel^\u00ae 64 and\n   IA-32 Architectures Software Developer\u2019s Manual, Volume 3A, for\n   information on nested tasks.) Switching tasks with the CALL instruction\n   differs in this regard from JMP instruction. JMP does not set the NT flag\n   and therefore does not expect an IRET instruction to suspend the task.\n\n   Mixing 16-Bit and 32-Bit Calls. When making far calls between 16-bit and\n   32-bit code segments, use a call gate. If the far call is from a 32-bit\n   code segment to a 16-bit code segment, the call should be made from the\n   first 64 KBytes of the 32-bit code segment. This is because the\n   operand-size attribute of the instruction is set to 16, so only a 16-bit\n   return address offset can be saved. Also, the call should be made using a\n   16-bit call gate so that 16-bit values can be pushed on the stack. See\n   Chapter 22, \u201cMixing 16-Bit and 32-Bit Code,\u201d in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3B, for more\n   information.\n\n   Far Calls in Compatibility Mode. When the processor is operating in\n   compatibility mode, the CALL instruction can be used to perform the\n   following types of far calls:\n\n     * Far call to the same privilege level, remaining in compatibility mode\n     * Far call to the same privilege level, transitioning to 64-bit mode\n     * Far call to a different privilege level (inter-privilege level call),\n       transitioning to 64-bit mode\n\n   Note that a CALL instruction can not be used to cause a task switch in\n   compatibility mode since task switches are not supported in IA-32e mode.\n\n   In compatibility mode, the processor always uses the segment selector part\n   of the far address to access the corresponding descriptor in the GDT or\n   LDT. The descriptor type (code segment, call gate) and access rights\n   determine the type of call operation to be performed.\n\n   If the selected descriptor is for a code segment, a far call to a code\n   segment at the same privilege level is performed. (If the selected code\n   segment is at a different privilege level and the code segment is\n   non-conforming, a general-protection exception is generated.) A far call\n   to the same privilege level in compatibility mode is very similar to one\n   carried out in protected mode. The target operand specifies an absolute\n   far address either directly with a pointer (ptr16:16 or ptr16:32) or\n   indirectly with a memory location (m16:16 or m16:32). The operand-size\n   attribute determines the size of the offset (16 or 32 bits) in the far\n   address. The new code segment selector and its descriptor are loaded into\n   CS register and the offset from the instruction is loaded into the EIP\n   register. The difference is that 64-bit mode may be entered. This\n   specified by the L bit in the new code segment descriptor.\n\n   Note that a 64-bit call gate (described in the next paragraph) can also be\n   used to perform a far call to a code segment at the same privilege level.\n   However, using this mechanism requires that the target code segment\n   descriptor have the L bit set, causing an entry to 64-bit mode.\n\n   When executing an inter-privilege-level far call, the code segment for the\n   procedure being called must be accessed through a 64-bit call gate. The\n   segment selector specified by the target operand identifies the call gate.\n   The target\n\n   operand can specify the call gate segment selector either directly with a\n   pointer (ptr16:16 or ptr16:32) or indirectly with a memory location\n   (m16:16 or m16:32). The processor obtains the segment selector for the new\n   code segment and the new instruction pointer (offset) from the 16-byte\n   call gate descriptor. (The offset from the target operand is ignored when\n   a call gate is used.)\n\n   On inter-privilege-level calls, the processor switches to the stack for\n   the privilege level of the called procedure. The segment selector for the\n   new stack segment is set to NULL. The new stack pointer is specified in\n   the TSS for the currently running task. The branch to the new code segment\n   occurs after the stack switch. (Note that when using a call gate to\n   perform a far call to a segment at the same privilege level, an implicit\n   stack switch occurs as a result of entering 64-bit mode. The SS selector\n   is unchanged, but stack segment accesses use a segment base of 0x0, the\n   limit is ignored, and the default stack size is 64-bits. The full value of\n   RSP is used for the offset, of which the upper 32-bits are undefined.) On\n   the new stack, the processor pushes the segment selector and stack pointer\n   for the calling procedure\u2019s stack and the segment selector and instruction\n   pointer for the calling procedure\u2019s code segment. (Parameter copy is not\n   supported in IA-32e mode.) Finally, the processor branches to the address\n   of the procedure being called within the new code segment.\n\n   Near/(Far) Calls in 64-bit Mode. When the processor is operating in 64-bit\n   mode, the CALL instruction can be used to perform the following types of\n   far calls:\n\n     * Far call to the same privilege level, transitioning to compatibility\n       mode\n     * Far call to the same privilege level, remaining in 64-bit mode\n     * Far call to a different privilege level (inter-privilege level call),\n       remaining in 64-bit mode\n\n   Note that in this mode the CALL instruction can not be used to cause a\n   task switch in 64-bit mode since task switches are not supported in IA-32e\n   mode.\n\n   In 64-bit mode, the processor always uses the segment selector part of the\n   far address to access the corresponding descriptor in the GDT or LDT. The\n   descriptor type (code segment, call gate) and access rights determine the\n   type of call operation to be performed.\n\n   If the selected descriptor is for a code segment, a far call to a code\n   segment at the same privilege level is performed. (If the selected code\n   segment is at a different privilege level and the code segment is\n   non-conforming, a general-protection exception is generated.) A far call\n   to the same privilege level in 64-bit mode is very similar to one carried\n   out in compatibility mode. The target operand specifies an absolute far\n   address indirectly with a memory location (m16:16, m16:32 or m16:64). The\n   form of CALL with a direct specification of absolute far address is not\n   defined in 64-bit mode. The operand-size attribute determines the size of\n   the offset (16, 32, or 64 bits) in the far address. The new code segment\n   selector and its descriptor are loaded into the CS register; the offset\n   from the instruction is loaded into the EIP register. The new code segment\n   may specify entry either into compatibility or 64-bit mode, based on the L\n   bit value.\n\n   A 64-bit call gate (described in the next paragraph) can also be used to\n   perform a far call to a code segment at the same privilege level. However,\n   using this mechanism requires that the target code segment descriptor have\n   the L bit set.\n\n   When executing an inter-privilege-level far call, the code segment for the\n   procedure being called must be accessed through a 64-bit call gate. The\n   segment selector specified by the target operand identifies the call gate.\n   The target operand can only specify the call gate segment selector\n   indirectly with a memory location (m16:16, m16:32 or m16:64). The\n   processor obtains the segment selector for the new code segment and the\n   new instruction pointer (offset) from the 16-byte call gate descriptor.\n   (The offset from the target operand is ignored when a call gate is used.)\n\n   On inter-privilege-level calls, the processor switches to the stack for\n   the privilege level of the called procedure. The segment selector for the\n   new stack segment is set to NULL. The new stack pointer is specified in\n   the TSS for the currently running task. The branch to the new code segment\n   occurs after the stack switch.\n\n   Note that when using a call gate to perform a far call to a segment at the\n   same privilege level, an implicit stack switch occurs as a result of\n   entering 64-bit mode. The SS selector is unchanged, but stack segment\n   accesses use a segment base of 0x0, the limit is ignored, and the default\n   stack size is 64-bits. (The full value of RSP is used for the offset.) On\n   the new stack, the processor pushes the segment selector and stack pointer\n   for the calling procedure\u2019s stack and the segment selector and instruction\n   pointer for the calling procedure\u2019s code segment. (Parameter copy is not\n   supported in IA-32e mode.) Finally, the processor branches to the address\n   of the procedure being called within the new code segment.\n\n   Refer to Chapter 6, \u201cProcedure Calls, Interrupts, and Exceptions\u201a\u201d and\n   Chapter 17, \u201cControl-flow Enforcement Technology (CET)\u201a\u201d in the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for CET\n   details.\n\n   Instruction ordering. Instructions following a far call may be fetched\n   from memory before earlier instructions complete execution, but they will\n   not execute (even speculatively) until all instructions prior to the far\n   call have completed execution (the later instructions may execute before\n   data stored by the earlier instructions have become globally visible).\n\n   Instructions sequentially following a near indirect CALL instruction\n   (i.e., those not at the target) may be executed speculatively. If software\n   needs to prevent this (e.g., in order to prevent a speculative execution\n   side channel), then an LFENCE instruction opcode can be placed after the\n   near indirect CALL in order to block speculative execution.\n\nFlags Affected \u00b6\n\n   All flags are affected if a task switch occurs; no flags are affected if a\n   task switch does not occur.\n"],
	["fyl2xp1", "                        FYL2XP1 \u2014 Compute y \u2217 log2(x +1)\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Replace ST(1) with ST(1) \u2217  \n   D9 F9  FYL2XP1     Valid       Valid           log_2(ST(0) + 1.0) and pop  \n                                                  the register stack.         \n\nDescription \u00b6\n\n   Computes (ST(1) \u2217 log_2(ST(0) + 1.0)), stores the result in register\n   ST(1), and pops the FPU register stack. The source operand in ST(0) must\n   be in the range:\n\n   \u2013(1\u2013 2\u20442))to(1\u2013 2\u20442)\n\n   The source operand in ST(1) can range from \u2212\u221e to +\u221e. If the ST(0) operand\n   is outside of its acceptable range, the result is undefined and software\n   should not rely on an exception being generated. Under some circumstances\n   exceptions may be generated when ST(0) is out of range, but this behavior\n   is implementation specific and not guaranteed.\n\n   The following table shows the results obtained when taking the log epsilon\n   of various classes of numbers, assuming that underflow does not occur.\n\n   ST(0) -0 +0 \u2212(1\u2212( 2\u20442 ))to\u22120 +0to+(1-( 2\u20442 )) NaN * * NaN +\u221e \u2212\u221e \u2212\u221e ST(1)\n   \u2212F +F +0 -0 \u2212F NaN \u22120 +0 +0 -0 \u22120 NaN +0 \u22120 \u22120 +0 +0 NaN +F \u2212F \u22120 +0 +F\n   NaN +\u221e * * +\u221e NaN \u2212\u221e NaN NaN NaN NaN NaN NaN Table 3-49. FYL2XP1 Results\n\n     F Means finite floating-point value.\n\n     * Indicatesfloating-pointinvalid-operation(#IA)exception.\n\n   This instruction provides optimal accuracy for values of epsilon [the\n   value in register ST(0)] that are close to 0. For small epsilon (\u03b5)\n   values, more significant digits can be retained by using the FYL2XP1\n   instruction than by using (\u03b5+1) as an argument to the FYL2X instruction.\n   The (\u03b5+1) expression is commonly found in compound interest and annuity\n   calculations. The result can be simply converted into a value in another\n   logarithm base by including a scale factor in the ST(1) source operand.\n   The following equation is used to calculate the scale factor for a\n   particular logarithm base, where n is the logarithm base desired for the\n   result of the FYL2XP1 instruction:\n\n   scale factor := log_n 2\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["vcvtsd2sh", "              VCVTSD2SH \u2014 Convert Low FP64 Value to an FP16 Value\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert the low FP64 \n                                                         value in xmm3/m64 to \n                                                         an FP16 value and    \n   EVEX.LLIG.F2.MAP5.W1 5A /r                            store the result in  \n   VCVTSD2SH xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 the low element of   \n   xmm3/m64 {er}                                         xmm1 subject to      \n                                                         writemask k1. Bits   \n                                                         127:16 of xmm2 are   \n                                                         copied to            \n                                                         xmm1[127:16].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP64 value in the second source operand\n   to an FP16 value, and stores the result in the low element of the\n   destination operand.\n\n   When the conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n"],
	["vgatherdps:vgatherdpd", " VGATHERDPS/VGATHERDPD \u2014 Gather Packed Single, Packed Double with Signed Dword\n                                    Indices\n\n                                64/32 Bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Using signed dword         \n   EVEX.128.66.0F38.W0 92                          indices, gather            \n   /vsib VGATHERDPS xmm1  A     V/V       AVX512VL single-precision           \n   {k1}, vm32x                            AVX512F  floating-point values from \n                                                   memory using k1 as         \n                                                   completion mask.           \n                                                   Using signed dword         \n   EVEX.256.66.0F38.W0 92                          indices, gather            \n   /vsib VGATHERDPS ymm1  A     V/V       AVX512VL single-precision           \n   {k1}, vm32y                            AVX512F  floating-point values from \n                                                   memory using k1 as         \n                                                   completion mask.           \n                                                   Using signed dword         \n   EVEX.512.66.0F38.W0 92                          indices, gather            \n   /vsib VGATHERDPS zmm1  A     V/V       AVX512F  single-precision           \n   {k1}, vm32z                                     floating-point values from \n                                                   memory using k1 as         \n                                                   completion mask.           \n                                                   Using signed dword         \n   EVEX.128.66.0F38.W1 92                 AVX512VL indices, gather float64    \n   /vsib VGATHERDPD xmm1  A     V/V       AVX512F  vector into float64 vector \n   {k1}, vm32x                                     xmm1 using k1 as           \n                                                   completion mask.           \n                                                   Using signed dword         \n   EVEX.256.66.0F38.W1 92                 AVX512VL indices, gather float64    \n   /vsib VGATHERDPD ymm1  A     V/V       AVX512F  vector into float64 vector \n   {k1}, vm32x                                     ymm1 using k1 as           \n                                                   completion mask.           \n                                                   Using signed dword         \n   EVEX.512.66.0F38.W1 92                          indices, gather float64    \n   /vsib VGATHERDPD zmm1  A     V/V       AVX512F  vector into float64 vector \n   {k1}, vm32y                                     zmm1 using k1 as           \n                                                   completion mask.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2               Operand 3 Operand 4 \n         Tuple1                   BaseReg (R): VSIB:base,                     \n   A     Scalar     ModRM:reg (w) VectorReg(R):           N/A       N/A\n                                  VSIB:index              \n\n  Description \u00b6\n\n   A set of single-precision/double precision faulting-point memory locations\n   pointed by base address BASE_ADDR and index vector V_INDEX with scale\n   SCALE are gathered. The result is written into a vector register. The\n   elements are specified via the VSIB (i.e., the index register is a vector\n   register, holding packed indices). Elements will only be loaded if their\n   corresponding mask bit is one. If an element\u2019s mask bit is not set, the\n   corresponding element of the destination register is left unchanged. The\n   entire mask register will be set to zero by this instruction unless it\n   triggers an exception.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the right most one with its mask bit set). When this happens,\n   the destination register and the mask register (k1) are partially updated;\n   those elements that have been gathered are placed into the destination\n   register and have their mask bits set to zero. If any traps or interrupts\n   are pending from already gathered elements, they will be delivered in lieu\n   of the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data element size is less than the index element size, the higher\n   part of the destination register and the mask register do not correspond\n   to any elements being gathered. This instruction sets those higher parts\n   to zero. It may update these unused elements to one or both of those\n   registers even if the instruction triggers an exception, and even if the\n   instruction triggers the exception before gathering any elements.\n\n   Note that:\n\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination zmm will be completed (and non-faulting).\n       Individual elements closer to the MSB may or may not be completed. If\n       a given element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n\n   Note that the presence of VSIB byte is enforced in this instruction.\n   Hence, the instruction will #UD fault if ModRM.rm is different than 100b.\n\n   This instruction has special disp8*N and alignment rules. N is considered\n   to be the size of a single vector element.\n\n   The scaled index may require more bits to represent than the address bits\n   used by the processor (e.g., in 32-bit mode, if the scale is greater than\n   one). In this case, the most significant bits beyond the number of address\n   bits are ignored.\n\n   The instruction will #UD fault if the destination vector zmm1 is the same\n   as index vector VINDEX. The instruction will #UD fault if the k0 mask\n   register is specified.\n"],
	["kshiftrw:kshiftrb:kshiftrq:kshiftrd", "        KSHIFTRW/KSHIFTRB/KSHIFTRQ/KSHIFTRD \u2014 Shift Right Mask Registers\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   VEX.L0.66.0F3A.W1 30 /r                          Shift right 16 bits in k2 \n   KSHIFTRW k1, k2, imm8   RRI   V/V       AVX512F  by immediate and write    \n                                                    result in k1.             \n   VEX.L0.66.0F3A.W0 30 /r                          Shift right 8 bits in k2  \n   KSHIFTRB k1, k2, imm8   RRI   V/V       AVX512DQ by immediate and write    \n                                                    result in k1.             \n   VEX.L0.66.0F3A.W1 31 /r                          Shift right 64 bits in k2 \n   KSHIFTRQ k1, k2, imm8   RRI   V/V       AVX512BW by immediate and write    \n                                                    result in k1.             \n   VEX.L0.66.0F3A.W0 31 /r                          Shift right 32 bits in k2 \n   KSHIFTRD k1, k2, imm8   RRI   V/V       AVX512BW by immediate and write    \n                                                    result in k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2                              Operand 3 \n   RRI   ModRM:reg (w) ModRM:r/m (r, ModRM:[7:6] must be 11b) imm8      \n\nDescription \u00b6\n\n   Shifts 8/16/32/64 bits in the second operand (source operand) right by the\n   count specified in immediate and place the least significant 8/16/32/64\n   bits of the result in the destination operand. The higher bits of the\n   destination are zero-extended. The destination is set to zero if the count\n   value is greater than 7 (for byte shift), 15 (for word shift), 31 (for\n   doubleword shift) or 63 (for quadword shift).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cvtsd2ss", "CVTSD2SS \u2014 Convert Scalar Double Precision Floating-Point Value to Scalar Single\n                         PrecisionFloating-Point Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Convert one double          \n                                                  precision floating-point    \n   F2 0F 5A /r CVTSD2SS    A    V/V       SSE2    value in xmm2/m64 to one    \n   xmm1, xmm2/m64                                 single precision            \n                                                  floating-point value in     \n                                                  xmm1.                       \n                                                  Convert one double          \n                                                  precision floating-point    \n   VEX.LIG.F2.0F.WIG 5A /r                        value in xmm3/m64 to one    \n   VCVTSD2SS xmm1,xmm2,    B    V/V       AVX     single precision            \n   xmm3/m64                                       floating-point value and    \n                                                  merge with high bits in     \n                                                  xmm2.                       \n                                                  Convert one double          \n   EVEX.LLIG.F2.0F.W1 5A                          precision floating-point    \n   /r VCVTSD2SS xmm1                              value in xmm3/m64 to one    \n   {k1}{z}, xmm2,          C    V/V       AVX512F single precision            \n   xmm3/m64{er}                                   floating-point value and    \n                                                  merge with high bits in     \n                                                  xmm2 under writemask k1.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Converts a double precision floating-point value in the \u201cconvert-from\u201d\n   source operand (the second operand in SSE2 version, otherwise the third\n   operand) to a single precision floating-point value in the destination\n   operand.\n\n   When the \u201cconvert-from\u201d operand is an XMM register, the double precision\n   floating-point value is contained in the low quadword of the register. The\n   result is stored in the low doubleword of the destination operand. When\n   the conversion is inexact, the value returned is rounded according to the\n   rounding control bits in the MXCSR register.\n\n   128-bit Legacy SSE version: The \u201cconvert-from\u201d source operand (the second\n   operand) is an XMM register or memory location. Bits (MAXVL-1:32) of the\n   corresponding destination register remain unchanged. The destination\n   operand is an XMM register.\n\n   VEX.128 and EVEX encoded versions: The \u201cconvert-from\u201d source operand (the\n   third operand) can be an XMM register or a 64-bit memory location. The\n   first source and destination operands are XMM registers. Bits (127:32) of\n   the XMM register destination are copied from the corresponding bits in the\n   first source operand. Bits (MAXVL-1:128) of the destination register are\n   zeroed.\n\n   EVEX encoded version: the converted result in written to the low\n   doubleword element of the destination under the writemask.\n\n   Software should ensure VCVTSD2SS is encoded with VEX.L=0. Encoding\n   VCVTSD2SS with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["fsqrt", "                              FSQRT \u2014 Square Root\n\n   Opcode  Mode Leg Mode Description                                          \n   D9 FA                 Computes square root of ST(0) and stores the result  \n                         in ST(0).                                            \n\nDescription \u00b6\n\n   Computes the square root of the source value in the ST(0) register and\n   stores the result in ST(0).\n\n   The following table shows the results obtained when taking the square root\n   of various classes of numbers, assuming that neither overflow nor\n   underflow occurs.\n\n   SRC (ST(0)) DEST (ST(0)) \n   \u2212\u221e          *            \n   \u2212F          *            \n   \u22120          \u22120           \n   +0          +0           \n   +F          +F           \n   +\u221e          +\u221e           \n   NaN         NaN          \n\n   Table 3-37. FSQRT Results\n\n     F Meansfinitefloating-pointvalue.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["movdq2q", "          MOVDQ2Q \u2014 Move Quadword from XMM to MMX Technology Register\n\n   Opcode   Instruction     Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   F2 0F D6 MOVDQ2Q mm, xmm RM    Valid  Valid      Move low quadword from    \n   /r                                               xmm to mmx register.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the low quadword from the source operand (second operand) to the\n   destination operand (first operand). The source operand is an XMM register\n   and the destination operand is an MMX technology register.\n\n   This instruction causes a transition from x87 FPU to MMX technology\n   operation (that is, the x87 FPU top-of-stack pointer is set to 0 and the\n   x87 FPU tag word is set to all 0s [valid]). If this instruction is\n   executed while an x87 FPU floating-point exception is pending, the\n   exception is handled before the MOVDQ2Q instruction is executed.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["kshiftlw:kshiftlb:kshiftlq:kshiftld", "        KSHIFTLW/KSHIFTLB/KSHIFTLQ/KSHIFTLD \u2014 Shift Left Mask Registers\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   VEX.L0.66.0F3A.W1 32 /r                          Shift left 16 bits in k2  \n   KSHIFTLW k1, k2, imm8   RRI   V/V       AVX512F  by immediate and write    \n                                                    result in k1.             \n   VEX.L0.66.0F3A.W0 32 /r                          Shift left 8 bits in k2   \n   KSHIFTLB k1, k2, imm8   RRI   V/V       AVX512DQ by immediate and write    \n                                                    result in k1.             \n   VEX.L0.66.0F3A.W1 33 /r                          Shift left 64 bits in k2  \n   KSHIFTLQ k1, k2, imm8   RRI   V/V       AVX512BW by immediate and write    \n                                                    result in k1.             \n   VEX.L0.66.0F3A.W0 33 /r                          Shift left 32 bits in k2  \n   KSHIFTLD k1, k2, imm8   RRI   V/V       AVX512BW by immediate and write    \n                                                    result in k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2                              Operand 3 \n   RRI   ModRM:reg (w) ModRM:r/m (r, ModRM:[7:6] must be 11b) imm8      \n\nDescription \u00b6\n\n   Shifts 8/16/32/64 bits in the second operand (source operand) left by the\n   count specified in immediate byte and place the least significant\n   8/16/32/64 bits of the result in the destination operand. The higher bits\n   of the destination are zero-extended. The destination is set to zero if\n   the count value is greater than 7 (for byte shift), 15 (for word shift),\n   31 (for doubleword shift) or 63 (for quadword shift).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["aam", "                      AAM \u2014 ASCII Adjust AX After Multiply\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Mode Description           \n   D4 0A  AAM         ZO    Invalid     Valid           ASCII adjust AX after \n                                                        multiply.             \n                                                        Adjust AX after       \n   D4 ib  AAM imm8    ZO    Invalid     Valid           multiply to number    \n                                                        base imm8.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Adjusts the result of the multiplication of two unpacked BCD values to\n   create a pair of unpacked (base 10) BCD values. The AX register is the\n   implied source and destination operand for this instruction. The AAM\n   instruction is only useful when it follows an MUL instruction that\n   multiplies (binary multiplication) two unpacked BCD values and stores a\n   word result in the AX register. The AAM instruction then adjusts the\n   contents of the AX register to contain the correct 2-digit unpacked (base\n   10) BCD result.\n\n   The generalized version of this instruction allows adjustment of the\n   contents of the AX to create two unpacked digits of any number base (see\n   the \u201cOperation\u201d section below). Here, the imm8 byte is set to the selected\n   number base (for example, 08H for octal, 0AH for decimal, or 0CH for base\n   12 numbers). The AAM mnemonic is interpreted by all assemblers to mean\n   adjust to ASCII (base 10) values. To adjust to values in another number\n   base, the instruction must be hand coded in machine code (D4 imm8).\n\n   This instruction executes as described in compatibility mode and legacy\n   mode. It is not valid in 64-bit mode.\n\nFlags Affected \u00b6\n\n   The SF, ZF, and PF flags are set according to the resulting binary value\n   in the AL register. The OF, AF, and CF flags are undefined.\n"],
	["pcmpistri", "        PCMPISTRI \u2014 Packed Compare Implicit Length Strings, Return Index\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature Description\n                                   Support   Flag    \n                                                     Perform a packed         \n   66 0F 3A 63 /r imm8                               comparison of string     \n   PCMPISTRI xmm1,           RM    V/V       SSE4_2  data with implicit       \n   xmm2/m128, imm8                                   lengths, generating an   \n                                                     index, and storing the   \n                                                     result in ECX.           \n                                                     Perform a packed         \n   VEX.128.66.0F3A.WIG 63 /r                         comparison of string     \n   ib VPCMPISTRI xmm1,       RM    V/V       AVX     data with implicit       \n   xmm2/m128, imm8                                   lengths, generating an   \n                                                     index, and storing the   \n                                                     result in ECX.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   The instruction compares data from two strings based on the encoded value\n   in the imm8 control byte (see Section 4.1, \u201cImm8 Control Byte Operation\n   for PCMPESTRI / PCMPESTRM / PCMPISTRI / PCMPISTRM\u201d), and generates an\n   index stored to ECX.\n\n   Each string is represented by a single value. The value is an xmm (or\n   possibly m128 for the second operand) which contains the data elements of\n   the string (byte or word data). Each input byte/word is augmented with a\n   valid/invalid tag. A byte/word is considered valid only if it has a lower\n   index than the least significant null byte/word. (The least significant\n   null byte/word is also considered invalid.)\n\n   The comparison and aggregation operations are performed according to the\n   encoded value of imm8 bit fields (see Section 4.1). The index of the first\n   (or last, according to imm8[6]) set bit of IntRes2 is returned in ECX. If\n   no bits are set in IntRes2, ECX is set to 16 (8).\n\n   Note that the Arithmetic Flags are written in a non-standard manner in\n   order to supply the most relevant information:\n\n   CFlag \u2013 Reset if IntRes2 is equal to zero, set otherwise\n\n   ZFlag \u2013 Set if any byte/word of xmm2/mem128 is null, reset otherwise\n\n   SFlag \u2013 Set if any byte/word of xmm1 is null, reset otherwise\n\n   OFlag \u2013IntRes2[0]\n\n   AFlag \u2013 Reset\n\n   PFlag \u2013 Reset\n\n   Note: In VEX.128 encoded version, VEX.vvvv is reserved and must be 1111b,\n   VEX.L must be 0, otherwise the instruction will #UD.\n\nEffective Operand Size \u00b6\n\n   Operating mode/size Operand 1 Operand 2 Result \n   16 bit              xmm       xmm/m128  ECX    \n   32 bit              xmm       xmm/m128  ECX    \n   64 bit              xmm       xmm/m128  ECX    \n"],
	["ldtilecfg", "                      LDTILECFG \u2014 Load Tile Configuration\n\n                                        64/32 bit CPUID                       \n   Opcode/Instruction             Op/En Mode      Feature  Description\n                                        Support   Flag     \n   VEX.128.NP.0F38.W0 49                                   Load tile          \n   !(11):000:bbb LDTILECFG m512   A     V/N.E.    AMX-TILE configuration as   \n                                                           specified in m512. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (r) N/A       N/A       N/A       \n\n  Description \u00b6\n\n   The LDTILECFG instruction takes an operand containing a pointer to a\n   64-byte memory location containing the description of the tiles to be\n   supported. In order to configure the tiles, the AMX-TILE bit in CPUID must\n   be set and the operating system has to have enabled the tiles\n   architecture.\n\n   The memory area contains the palette and describes how many tiles are\n   being used and defines each tile in terms of rows and column bytes.\n   Requests must be compatible with the restrictions provided by CPUID; see\n   Table 3-10 below.\n\n   Byte(s) Field Name             Description                                 \n   0       palette                Palette selects the supported configuration \n                                  of the tiles that will be used.             \n   1       start_row              start_row is used for storing the restart   \n                                  values for interrupted operations.          \n   2-15    reserved, must be zero \n   16-17   tile0.colsb            Tile 0 bytes per row.                       \n   18-19   tile1.colsb            Tile 1 bytes per row.                       \n   20-21   tile2.colsb            Tile 2 bytes per row.                       \n   ...     (sequence continues)   \n   30-31   tile7.colsb            Tile 7 bytes per row.                       \n   32-47   reserved, must be zero \n   48      tile0.rows             Tile 0 rows.                                \n   49      tile1.rows             Tile 1 rows.                                \n   50      tile2.rows             Tile 2 rows.                                \n   ...     (sequence continues)   \n   55      tile7.rows             Tile 7 rows.                                \n   56-63   reserved, must be zero \n\n   Table 3-10. Memory Area Layout\n\n   If a tile row and column pair is not used to specify tile parameters, they\n   must have the value zero. All enabled tiles (based on the palette) must be\n   configured. Specifying tile parameters for more tiles than the\n   implementation limit or the palette limit results in a #GP fault.\n\n   If the palette_id is zero, that signifies the INIT state for both TILECFG\n   and TILEDATA. Tiles are zeroed in the INIT state. The only legal non-INIT\n   value for palette_id is 1.\n\n   Any attempt to execute the LDTILECFG instruction inside an Intel TSX\n   transaction will result in a transaction abort.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["vpermpd", "           VPERMPD \u2014 Permute Double Precision Floating-Point Elements\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Permute double precision  \n   VEX.256.66.0F3A.W1 01 /r                         floating-point elements   \n   ib VPERMPD ymm1,         A    V/V       AVX2     in ymm2/m256 using        \n   ymm2/m256, imm8                                  indices in imm8 and store \n                                                    the result in ymm1.       \n                                                    Permute double precision  \n   EVEX.256.66.0F3A.W1 01                           floating-point elements   \n   /r ib VPERMPD ymm1       B    V/V       AVX512VL in ymm2/m256/m64bcst      \n   {k1}{z},                                AVX512F  using indexes in imm8 and \n   ymm2/m256/m64bcst, imm8                          store the result in ymm1  \n                                                    subject to writemask k1.  \n                                                    Permute double precision  \n   EVEX.512.66.0F3A.W1 01                           floating-point elements   \n   /r ib VPERMPD zmm1       B    V/V       AVX512F  in zmm2/m512/m64bcst      \n   {k1}{z},                                         using indices in imm8 and \n   zmm2/m512/m64bcst, imm8                          store the result in zmm1  \n                                                    subject to writemask k1.  \n                                                    Permute double precision  \n   EVEX.256.66.0F38.W1 16                           floating-point elements   \n   /r VPERMPD ymm1 {k1}{z}, C    V/V       AVX512VL in ymm3/m256/m64bcst      \n   ymm2, ymm3/m256/m64bcst                 AVX512F  using indexes in ymm2 and \n                                                    store the result in ymm1  \n                                                    subject to writemask k1.  \n                                                    Permute double precision  \n   EVEX.512.66.0F38.W1 16                           floating-point elements   \n   /r VPERMPD zmm1 {k1}{z}, C    V/V       AVX512F  in zmm3/m512/m64bcst      \n   zmm2, zmm3/m512/m64bcst                          using indices in zmm2 and \n                                                    store the result in zmm1  \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   C     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   The imm8 version: Copies quadword elements of double precision\n   floating-point values from the source operand (the second operand) to the\n   destination operand (the first operand) according to the indices specified\n   by the immediate operand (the third operand). Each two-bit value in the\n   immediate byte selects a qword element in the source operand.\n\n   VEX version: The source operand can be a YMM register or a memory\n   location. Bits (MAXVL-1:256) of the corresponding destination register are\n   zeroed.\n\n   In EVEX.512 encoded version, The elements in the destination are updated\n   using the writemask k1 and the imm8 bits are reused as control bits for\n   the upper 256-bit half when the control bits are coming from immediate.\n   The source operand can be a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 64-bit memory location.\n\n   The imm8 versions: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b\n   otherwise instructions will #UD.\n\n   The vector control version: Copies quadword elements of double precision\n   floating-point values from the second source operand (the third operand)\n   to the destination operand (the first operand) according to the indices in\n   the first source operand (the second operand). The first 3 bits of each 64\n   bit element in the index operand selects which quadword in the second\n   source operand to copy. The first and second operands are ZMM registers,\n   the third operand can be a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 64-bit memory location. The elements in\n   the destination are updated using the writemask k1.\n\n   Note that this instruction permits a qword in the source operand to be\n   copied to multiple locations in the destination operand.\n\n   If VPERMPD is encoded with VEX.L= 0, an attempt to execute the instruction\n   encoded with VEX.L= 0 will cause an #UD exception.\n"],
	["vmcall", "                          VMCALL \u2014 Call to VM Monitor\n\n   Opcode/Instruction Op/En Description                            \n   0F 01 C1 VMCALL    ZO    Call to VM monitor by causing VM exit. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    NA        NA        NA        NA        \n\nDescription \u00b6\n\n   This instruction allows guest software can make a call for service into an\n   underlying VM monitor. The details of the programming interface for such\n   calls are VMM-specific; this instruction does nothing more than cause a VM\n   exit, registering the appropriate exit reason.\n\n   Use of this instruction in VMX root operation invokes an SMM monitor (see\n   Section 32.15.2). This invocation will activate the dual-monitor treatment\n   of system-management interrupts (SMIs) and system-management mode (SMM) if\n   it is not already active (see Section 32.15.6).\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["minss", "      MINSS \u2014 Return Minimum Scalar Single Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Return the minimum scalar  \n   F3 0F 5D /r MINSS        A    V/V       SSE     single precision           \n   xmm1,xmm2/m32                                   floating-point value       \n                                                   between xmm2/m32 and xmm1. \n   VEX.LIG.F3.0F.WIG 5D /r                         Return the minimum scalar  \n   VMINSS xmm1,xmm2,        B    V/V       AVX     single precision           \n   xmm3/m32                                        floating-point value       \n                                                   between xmm3/m32 and xmm2. \n   EVEX.LLIG.F3.0F.W0 5D /r                        Return the minimum scalar  \n   VMINSS xmm1 {k1}{z},     C    V/V       AVX512F single precision           \n   xmm2, xmm3/m32{sae}                             floating-point value       \n                                                   between xmm3/m32 and xmm2. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Compares the low single precision floating-point values in the first\n   source operand and the second source operand and returns the minimum value\n   to the low doubleword of the destination operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second source operand is returned. If a value in the second operand is\n   an SNaN, that SNaN is returned unchanged to the destination (that is, a\n   QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   source operand, either a NaN or a valid floating-point value, is written\n   to the result. If instead of this behavior, it is required that the NaN in\n   either source operand be returned, the action of MINSD can be emulated\n   using a sequence of instructions, such as, a comparison followed by AND,\n   ANDN, and OR.\n\n   The second source operand can be an XMM register or a 32-bit memory\n   location. The first source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The destination and first source operand are\n   the same. Bits (MAXVL:32) of the corresponding destination register remain\n   unchanged.\n\n   VEX.128 and EVEX encoded version: The first source operand is an xmm\n   register encoded by (E)VEX.vvvv. Bits (127:32) of the XMM register\n   destination are copied from corresponding bits in the first source\n   operand. Bits (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination\n   operand is updated according to the writemask.\n\n   Software should ensure VMINSS is encoded with VEX.L=0. Encoding VMINSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["xrstors", "             XRSTORS \u2014 Restore Processor Extended States Supervisor\n\n   Opcode /            Op/En 64/32 bit    CPUID        Description            \n   Instruction               Mode Support Feature Flag \n   NP 0F C7 /3 XRSTORS                                 Restore state          \n   mem                 M     V/V          XSS          components specified   \n                                                       by EDX:EAX from mem.   \n   NP REX.W + 0F C7 /3                                 Restore state          \n   XRSTORS64 mem       M     V/N.E.       XSS          components specified   \n                                                       by EDX:EAX from mem.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a full or partial restore of processor state components from the\n   XSAVE area located at the memory address specified by the source operand.\n   The implicit EDX:EAX register pair specifies a 64-bit instruction mask.\n   The specific state components restored correspond to the bits set in the\n   requested-feature bitmap (RFBM), which is the logical-AND of EDX:EAX and\n   the logical-OR of XCR0 with the IA32_XSS MSR. XRSTORS may be executed only\n   if CPL = 0.\n\n   The format of the XSAVE area is detailed in Section 13.4, \u201cXSAVE Area,\u201d of\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1.\n   Like FXRSTOR and FXSAVE, the memory format used for x87 state depends on a\n   REX.W prefix; see Section 13.5.1, \u201cx87 State\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1.\n\n   Section 13.12, \u201cOperation of XRSTORS,\u201d of Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1 provides a detailed\n   description of the operation of the XRSTOR instruction. The following\n   items provide a high-level outline:\n\n     * Execution of XRSTORS is similar to that of the compacted form of\n       XRSTOR; XRSTORS cannot restore from an XSAVE area in which the\n       extended region is in the standard format (see Section 13.4.3,\n       \u201cExtended Region of an XSAVE Area\u201d of Intel^\u00ae 64 and IA-32\n       Architectures Software Developer\u2019s Manual, Volume 1).\n     * XRSTORS differs from XRSTOR in that it can restore state components\n       corresponding to bits set in the IA32_XSS MSR.\n     * If RFBM[i] = 0, XRSTORS does not update state component i.\n     * If RFBM[i] = 1 and bit i is clear in the XSTATE_BV field in the XSAVE\n       header, XRSTORS initializes state component i.\n     * If RFBM[i] = 1 and XSTATE_BV[i] = 1, XRSTORS loads state component i\n       from the XSAVE area.\n     * If XRSTORS attempts to load MXCSR with an illegal value, a\n       general-protection exception (#GP) occurs.\n     * XRSTORS loads the internal value XRSTOR_INFO, which may be used to\n       optimize a subsequent execution of XSAVEOPT or XSAVES.\n     * Immediately following an execution of XRSTORS, the processor tracks as\n       in-use (not in initial configuration) any state component i for which\n       RFBM[i] = 1 and XSTATE_BV[i] = 1; it tracks as modified any state\n       component i for which RFBM[i] = 0.\n\n   Use of a source operand not aligned to 64-byte boundary (for 64-bit and\n   32-bit modes) results in a general-protection (#GP) exception. In 64-bit\n   mode, the upper 32 bits of RDX and RAX are ignored.\n\n   See Section 13.6, \u201cProcessor Tracking of XSAVE-Managed State,\u201d of Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1 for\n   discussion of the bitmaps XINUSE and XMODIFIED and of the quantity\n   XRSTOR_INFO.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pminsd:pminsq", "               PMINSD/PMINSQ \u2014 Minimum of Packed Signed Integers\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction     Op/E n Mode      Feature  Description\n                                 Support   Flag     \n                                                    Compare packed signed     \n   66 0F 38 39 /r PMINSD                            dword integers in xmm1    \n   xmm1, xmm2/m128        A      V/V       SSE4_1   and xmm2/m128 and store   \n                                                    packed minimum values in  \n                                                    xmm1.                     \n                                                    Compare packed signed     \n   VEX.128.66.0F38.WIG 39                           dword integers in xmm2    \n   /r VPMINSD xmm1, xmm2, B      V/V       AVX      and xmm3/m128 and store   \n   xmm3/m128                                        packed minimum values in  \n                                                    xmm1.                     \n                                                    Compare packed signed     \n   VEX.256.66.0F38.WIG 39                           dword integers in ymm2    \n   /r VPMINSD ymm1, ymm2, B      V/V       AVX2     and ymm3/m128 and store   \n   ymm3/m256                                        packed minimum values in  \n                                                    ymm1.                     \n   EVEX.128.66.0F38.W0 39                           Compare packed signed     \n   /r VPMINSD xmm1                         AVX512VL dword integers in xmm2    \n   {k1}{z}, xmm2,         C      V/V       AVX512F  and xmm3/m128 and store   \n   xmm3/m128/m32bcst                                packed minimum values in  \n                                                    xmm1 under writemask k1.  \n   EVEX.256.66.0F38.W0 39                           Compare packed signed     \n   /r VPMINSD ymm1                         AVX512VL dword integers in ymm2    \n   {k1}{z}, ymm2,         C      V/V       AVX512F  and ymm3/m256 and store   \n   ymm3/m256/m32bcst                                packed minimum values in  \n                                                    ymm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.512.66.0F38.W0 39                           dword integers in zmm2    \n   /r VPMINSD zmm1        C      V/V       AVX512F  and zmm3/m512/m32bcst and \n   {k1}{z}, zmm2,                                   store packed minimum      \n   zmm3/m512/m32bcst                                values in zmm1 under      \n                                                    writemask k1.             \n   EVEX.128.66.0F38.W1 39                           Compare packed signed     \n   /r VPMINSQ xmm1                         AVX512VL qword integers in xmm2    \n   {k1}{z}, xmm2,         C      V/V       AVX512F  and xmm3/m128 and store   \n   xmm3/m128/m64bcst                                packed minimum values in  \n                                                    xmm1 under writemask k1.  \n   EVEX.256.66.0F38.W1 39                           Compare packed signed     \n   /r VPMINSQ ymm1                         AVX512VL qword integers in ymm2    \n   {k1}{z}, ymm2,         C      V/V       AVX512F  and ymm3/m256 and store   \n   ymm3/m256/m64bcst                                packed minimum values in  \n                                                    ymm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.512.66.0F38.W1 39                           qword integers in zmm2    \n   /r VPMINSQ zmm1        C      V/V       AVX512F  and zmm3/m512/m64bcst and \n   {k1}{z}, zmm2,                                   store packed minimum      \n   zmm3/m512/m64bcst                                values in zmm1 under      \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed signed dword or qword integers in\n   the second source operand and the first source operand and returns the\n   minimum value for each pair of integers to the destination operand.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers. Bits (MAXVL-1:256) of the corresponding destination\n   register are zeroed.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register;\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n"],
	["fclex:fnclex", "                        FCLEX/FNCLEX \u2014 Clear Exceptions\n\n   Opcode^1\n\n         Instruction 64-Bit Mode Compat/Leg Mode Description                  \n                                                 Clear floating-point         \n   9B DB                                         exception flags after        \n   E2    FCLEX       Valid       Valid           checking for pending         \n                                                 unmasked floating-point      \n                                                 exceptions.                  \n                                                 Clear floating-point         \n                                                 exception flags without      \n   DB E2 FNCLEX^1    Valid       Valid           checking for pending         \n                                                 unmasked floating-point      \n                                                 exceptions.                  \n\n     1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Clears the floating-point exception flags (PE, UE, OE, ZE, DE, and IE),\n   the exception summary status flag (ES), the stack fault flag (SF), and the\n   busy flag (B) in the FPU status word. The FCLEX instruction checks for and\n   handles any pending unmasked floating-point exceptions before clearing the\n   exception flags; the FNCLEX instruction does not.\n\n   The assembler issues two instructions for the FCLEX instruction (an FWAIT\n   instruction followed by an FNCLEX instruction), and the processor executes\n   each of these instructions separately. If an exception is generated for\n   either of these instructions, the save EIP points to the instruction that\n   caused the exception.\n\nIA-32 Architecture Compatibility \u00b6\n\n   When operating a Pentium or Intel486 processor in MS-DOS* compatibility\n   mode, it is possible (under unusual circumstances) for an FNCLEX\n   instruction to be interrupted prior to being executed to handle a pending\n   FPU exception. See the section titled \u201cNo-Wait FPU Instructions Can Get\n   FPU Interrupt in Window\u201d in Appendix D of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a description of\n   these circumstances. An FNCLEX instruction cannot be interrupted in this\n   way on later Intel processors, except for the Intel Quark^TM X1000\n   processor.\n\n   This instruction affects only the x87 FPU floating-point exception flags.\n   It does not affect the SIMD floating-point exception flags in the MXCSR\n   register.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   The PE, UE, OE, ZE, DE, IE, ES, SF, and B flags in the FPU status word are\n   cleared. The C0, C1, C2, and C3 flags are undefined.\n"],
	["movdqu:vmovdqu8:vmovdqu16:vmovdqu32:vmovdqu64", " MOVDQU/VMOVDQU8/VMOVDQU16/VMOVDQU32/VMOVDQU64 \u2014 Move Unaligned Packed Integer\n                                     Values\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Flag Description\n                                  Support   \n                                                         Move unaligned       \n   F3 0F 6F /r MOVDQU xmm1, A     V/V       SSE2         packed integer       \n   xmm2/m128                                             values from          \n                                                         xmm2/m128 to xmm1.   \n                                                         Move unaligned       \n   F3 0F 7F /r MOVDQU       B     V/V       SSE2         packed integer       \n   xmm2/m128, xmm1                                       values from xmm1 to  \n                                                         xmm2/m128.           \n                                                         Move unaligned       \n   VEX.128.F3.0F.WIG 6F /r  A     V/V       AVX          packed integer       \n   VMOVDQU xmm1, xmm2/m128                               values from          \n                                                         xmm2/m128 to xmm1.   \n                                                         Move unaligned       \n   VEX.128.F3.0F.WIG 7F /r  B     V/V       AVX          packed integer       \n   VMOVDQU xmm2/m128, xmm1                               values from xmm1 to  \n                                                         xmm2/m128.           \n                                                         Move unaligned       \n   VEX.256.F3.0F.WIG 6F /r  A     V/V       AVX          packed integer       \n   VMOVDQU ymm1, ymm2/m256                               values from          \n                                                         ymm2/m256 to ymm1.   \n                                                         Move unaligned       \n   VEX.256.F3.0F.WIG 7F /r  B     V/V       AVX          packed integer       \n   VMOVDQU ymm2/m256, ymm1                               values from ymm1 to  \n                                                         ymm2/m256.           \n                                                         Move unaligned       \n   EVEX.128.F2.0F.W0 6F /r                  AVX512VL     packed byte integer  \n   VMOVDQU8 xmm1 {k1}{z},   C     V/V       AVX512BW     values from          \n   xmm2/m128                                             xmm2/m128 to xmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.256.F2.0F.W0 6F /r                  AVX512VL     packed byte integer  \n   VMOVDQU8 ymm1 {k1}{z},   C     V/V       AVX512BW     values from          \n   ymm2/m256                                             ymm2/m256 to ymm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.512.F2.0F.W0 6F /r                               packed byte integer  \n   VMOVDQU8 zmm1 {k1}{z},   C     V/V       AVX512BW     values from          \n   zmm2/m512                                             zmm2/m512 to zmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.128.F2.0F.W0 7F /r                  AVX512VL     packed byte integer  \n   VMOVDQU8 xmm2/m128       D     V/V       AVX512BW     values from xmm1 to  \n   {k1}{z}, xmm1                                         xmm2/m128 using      \n                                                         writemask k1.        \n                                                         Move unaligned       \n   EVEX.256.F2.0F.W0 7F /r                  AVX512VL     packed byte integer  \n   VMOVDQU8 ymm2/m256       D     V/V       AVX512BW     values from ymm1 to  \n   {k1}{z}, ymm1                                         ymm2/m256 using      \n                                                         writemask k1.        \n                                                         Move unaligned       \n   EVEX.512.F2.0F.W0 7F /r                               packed byte integer  \n   VMOVDQU8 zmm2/m512       D     V/V       AVX512BW     values from zmm1 to  \n   {k1}{z}, zmm1                                         zmm2/m512 using      \n                                                         writemask k1.        \n                                                         Move unaligned       \n   EVEX.128.F2.0F.W1 6F /r                  AVX512VL     packed word integer  \n   VMOVDQU16 xmm1 {k1}{z},  C     V/V       AVX512BW     values from          \n   xmm2/m128                                             xmm2/m128 to xmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.256.F2.0F.W1 6F /r                  AVX512VL     packed word integer  \n   VMOVDQU16 ymm1 {k1}{z},  C     V/V       AVX512BW     values from          \n   ymm2/m256                                             ymm2/m256 to ymm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.512.F2.0F.W1 6F /r                               packed word integer  \n   VMOVDQU16 zmm1 {k1}{z},  C     V/V       AVX512BW     values from          \n   zmm2/m512                                             zmm2/m512 to zmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.128.F2.0F.W1 7F /r                  AVX512VL     packed word integer  \n   VMOVDQU16 xmm2/m128      D     V/V       AVX512BW     values from xmm1 to  \n   {k1}{z}, xmm1                                         xmm2/m128 using      \n                                                         writemask k1.        \n                                                         Move unaligned       \n   EVEX.256.F2.0F.W1 7F /r                  AVX512VL     packed word integer  \n   VMOVDQU16 ymm2/m256      D     V/V       AVX512BW     values from ymm1 to  \n   {k1}{z}, ymm1                                         ymm2/m256 using      \n                                                         writemask k1.        \n                                                         Move unaligned       \n   EVEX.512.F2.0F.W1 7F /r                               packed word integer  \n   VMOVDQU16 zmm2/m512      D     V/V       AVX512BW     values from zmm1 to  \n   {k1}{z}, zmm1                                         zmm2/m512 using      \n                                                         writemask k1.        \n                                                         Move unaligned       \n   EVEX.128.F3.0F.W0 6F /r                  AVX512VL     packed doubleword    \n   VMOVDQU32 xmm1 {k1}{z},  C     V/V       AVX512F      integer values from  \n   xmm2/mm128                                            xmm2/m128 to xmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.256.F3.0F.W0 6F /r                  AVX512VL     packed doubleword    \n   VMOVDQU32 ymm1 {k1}{z},  C     V/V       AVX512F      integer values from  \n   ymm2/m256                                             ymm2/m256 to ymm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.512.F3.0F.W0 6F /r                               packed doubleword    \n   VMOVDQU32 zmm1 {k1}{z},  C     V/V       AVX512F      integer values from  \n   zmm2/m512                                             zmm2/m512 to zmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.128.F3.0F.W0 7F /r                  AVX512VL     packed doubleword    \n   VMOVDQU32 xmm2/m128      D     V/V       AVX512F      integer values from  \n   {k1}{z}, xmm1                                         xmm1 to xmm2/m128    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.256.F3.0F.W0 7F /r                  AVX512VL     packed doubleword    \n   VMOVDQU32 ymm2/m256      D     V/V       AVX512F      integer values from  \n   {k1}{z}, ymm1                                         ymm1 to ymm2/m256    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.512.F3.0F.W0 7F /r                               packed doubleword    \n   VMOVDQU32 zmm2/m512      D     V/V       AVX512F      integer values from  \n   {k1}{z}, zmm1                                         zmm1 to zmm2/m512    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.128.F3.0F.W1 6F /r                  AVX512VL     packed quadword      \n   VMOVDQU64 xmm1 {k1}{z},  C     V/V       AVX512F      integer values from  \n   xmm2/m128                                             xmm2/m128 to xmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.256.F3.0F.W1 6F /r                  AVX512VL     packed quadword      \n   VMOVDQU64 ymm1 {k1}{z},  C     V/V       AVX512F      integer values from  \n   ymm2/m256                                             ymm2/m256 to ymm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.512.F3.0F.W1 6F /r                               packed quadword      \n   VMOVDQU64 zmm1 {k1}{z},  C     V/V       AVX512F      integer values from  \n   zmm2/m512                                             zmm2/m512 to zmm1    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.128.F3.0F.W1 7F /r                  AVX512VL     packed quadword      \n   VMOVDQU64 xmm2/m128      D     V/V       AVX512F      integer values from  \n   {k1}{z}, xmm1                                         xmm1 to xmm2/m128    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.256.F3.0F.W1 7F /r                  AVX512VL     packed quadword      \n   VMOVDQU64 ymm2/m256      D     V/V       AVX512F      integer values from  \n   {k1}{z}, ymm1                                         ymm1 to ymm2/m256    \n                                                         using writemask k1.  \n                                                         Move unaligned       \n   EVEX.512.F3.0F.W1 7F /r                               packed quadword      \n   VMOVDQU64 zmm2/m512      D     V/V       AVX512F      integer values from  \n   {k1}{z}, zmm1                                         zmm1 to zmm2/m512    \n                                                         using writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   EVEX encoded versions:\n\n   Moves 128, 256 or 512 bits of packed byte/word/doubleword/quadword integer\n   values from the source operand (the second operand) to the destination\n   operand (first operand). This instruction can be used to load a vector\n   register from a memory location, to store the contents of a vector\n   register into a memory location, or to move data between two vector\n   registers.\n\n   The destination operand is updated at 8-bit (VMOVDQU8), 16-bit\n   (VMOVDQU16), 32-bit (VMOVDQU32), or 64-bit (VMOVDQU64) granularity\n   according to the writemask.\n\n   VEX.256 encoded version:\n\n   Moves 256 bits of packed integer values from the source operand (second\n   operand) to the destination operand (first operand). This instruction can\n   be used to load a YMM register from a 256-bit memory location, to store\n   the contents of a YMM register into a 256-bit memory location, or to move\n   data between two YMM registers.\n\n   Bits (MAXVL-1:256) of the destination register are zeroed.\n\n   128-bit versions:\n\n   Moves 128 bits of packed integer values from the source operand (second\n   operand) to the destination operand (first operand). This instruction can\n   be used to load an XMM register from a 128-bit memory location, to store\n   the contents of an XMM register into a 128-bit memory location, or to move\n   data between two XMM registers.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   When the source or destination operand is a memory operand, the operand\n   may be unaligned to any alignment without causing a general-protection\n   exception (#GP) to be generated\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed.\n"],
	["nop", "                               NOP \u2014 No Operation\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n   NP 90    NOP         ZO    Valid  Valid      One byte no-operation         \n                                                instruction.                  \n   NP 0F 1F NOP r/m16   M     Valid  Valid      Multi-byte no-operation       \n   /0                                           instruction.                  \n   NP 0F 1F NOP r/m32   M     Valid  Valid      Multi-byte no-operation       \n   /0                                           instruction.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   ZO    N/A           N/A       N/A       N/A       \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   This instruction performs no operation. It is a one-byte or multi-byte NOP\n   that takes up space in the instruction stream but does not impact machine\n   context, except for the EIP register.\n\n   The multi-byte form of NOP is available on processors with model encoding:\n\n     * CPUID.01H.EAX[Bytes 11:8] = 0110B or 1111B\n\n   The multi-byte NOP instruction does not alter the content of a register\n   and will not issue a memory operation. The instruction\u2019s operation is the\n   same in non-64-bit modes and 64-bit mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["movapd", "      MOVAPD \u2014 Move Aligned Packed Double Precision Floating-Point Values\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Move aligned packed       \n   66 0F 28 /r MOVAPD      A     V/V       SSE2     double precision          \n   xmm1, xmm2/m128                                  floating-point values     \n                                                    from xmm2/mem to xmm1.    \n                                                    Move aligned packed       \n   66 0F 29 /r MOVAPD      B     V/V       SSE2     double precision          \n   xmm2/m128, xmm1                                  floating-point values     \n                                                    from xmm1 to xmm2/mem.    \n                                                    Move aligned packed       \n   VEX.128.66.0F.WIG 28 /r A     V/V       AVX      double precision          \n   VMOVAPD xmm1, xmm2/m128                          floating-point values     \n                                                    from xmm2/mem to xmm1.    \n                                                    Move aligned packed       \n   VEX.128.66.0F.WIG 29 /r B     V/V       AVX      double precision          \n   VMOVAPD xmm2/m128, xmm1                          floating-point values     \n                                                    from xmm1 to xmm2/mem.    \n                                                    Move aligned packed       \n   VEX.256.66.0F.WIG 28 /r A     V/V       AVX      double precision          \n   VMOVAPD ymm1, ymm2/m256                          floating-point values     \n                                                    from ymm2/mem to ymm1.    \n                                                    Move aligned packed       \n   VEX.256.66.0F.WIG 29 /r B     V/V       AVX      double precision          \n   VMOVAPD ymm2/m256, ymm1                          floating-point values     \n                                                    from ymm1 to ymm2/mem.    \n                                                    Move aligned packed       \n   EVEX.128.66.0F.W1 28 /r                 AVX512VL double precision          \n   VMOVAPD xmm1 {k1}{z},   C     V/V       AVX512F  floating-point values     \n   xmm2/m128                                        from xmm2/m128 to xmm1    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.256.66.0F.W1 28 /r                 AVX512VL double precision          \n   VMOVAPD ymm1 {k1}{z},   C     V/V       AVX512F  floating-point values     \n   ymm2/m256                                        from ymm2/m256 to ymm1    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.512.66.0F.W1 28 /r                          double precision          \n   VMOVAPD zmm1 {k1}{z},   C     V/V       AVX512F  floating-point values     \n   zmm2/m512                                        from zmm2/m512 to zmm1    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.128.66.0F.W1 29 /r                 AVX512VL double precision          \n   VMOVAPD xmm2/m128       D     V/V       AVX512F  floating-point values     \n   {k1}{z}, xmm1                                    from xmm1 to xmm2/m128    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.256.66.0F.W1 29 /r                 AVX512VL double precision          \n   VMOVAPD ymm2/m256       D     V/V       AVX512F  floating-point values     \n   {k1}{z}, ymm1                                    from ymm1 to ymm2/m256    \n                                                    using writemask k1.       \n                                                    Move aligned packed       \n   EVEX.512.66.0F.W1 29 /r                          double precision          \n   VMOVAPD zmm2/m512       D     V/V       AVX512F  floating-point values     \n   {k1}{z}, zmm1                                    from zmm1 to zmm2/m512    \n                                                    using writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves 2, 4 or 8 double precision floating-point values from the source\n   operand (second operand) to the destination operand (first operand). This\n   instruction can be used to load an XMM, YMM or ZMM register from an\n   128-bit, 256-bit or 512-bit memory location, to store the contents of an\n   XMM, YMM or ZMM register into a 128-bit, 256-bit or 512-bit memory\n   location, or to move data between two XMM, two YMM or two ZMM registers.\n\n   When the source or destination operand is a memory operand, the operand\n   must be aligned on a 16-byte (128-bit versions), 32-byte (256-bit version)\n   or 64-byte (EVEX.512 encoded version) boundary or a general-protection\n\n   exception (#GP) will be generated. For EVEX encoded versions, the operand\n   must be aligned to the size of the memory operand. To move double\n   precision floating-point values to and from unaligned memory locations,\n   use the VMOVUPD instruction.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   EVEX.512 encoded version:\n\n   Moves 512 bits of packed double precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a ZMM register from a\n   512-bit float64 memory location, to store the contents of a ZMM register\n   into a 512-bit float64 memory location, or to move data between two ZMM\n   registers. When the source or destination operand is a memory operand, the\n   operand must be aligned on a 64-byte boundary or a general-protection\n   exception (#GP) will be generated. To move single precision floating-point\n   values to and from unaligned memory locations, use the VMOVUPD\n   instruction.\n\n   VEX.256 and EVEX.256 encoded versions:\n\n   Moves 256 bits of packed double precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a YMM register from a\n   256-bit memory location, to store the contents of a YMM register into a\n   256-bit memory location, or to move data between two YMM registers. When\n   the source or destination operand is a memory operand, the operand must be\n   aligned on a 32-byte boundary or a general-protection exception (#GP) will\n   be generated. To move double precision floating-point values to and from\n   unaligned memory locations, use the VMOVUPD instruction.\n\n   128-bit versions:\n\n   Moves 128 bits of packed double precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load an XMM register from a\n   128-bit memory location, to store the contents of an XMM register into a\n   128-bit memory location, or to move data between two XMM registers. When\n   the source or destination operand is a memory operand, the operand must be\n   aligned on a 16-byte boundary or a general-protection exception (#GP) will\n   be generated. To move single precision floating-point values to and from\n   unaligned memory locations, use the VMOVUPD instruction.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding ZMM\n   destination register remain unchanged.\n\n   (E)VEX.128 encoded version: Bits (MAXVL-1:128) of the destination ZMM\n   register destination are zeroed.\n"],
	["vpmovqb:vpmovsqb:vpmovusqb", "            VPMOVQB/VPMOVSQB/VPMOVUSQB \u2014 Down Convert QWord to Byte\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature  Description\n                               Support   Flag     \n                                                  Converts 2 packed quad-word \n   EVEX.128.F3.0F38.W0 32                AVX512VL integers from xmm2 into 2   \n   /r VPMOVQB xmm1/m16    A    V/V       AVX512F  packed byte integers in     \n   {k1}{z}, xmm2                                  xmm1/m16 with truncation    \n                                                  under writemask k1.         \n                                                  Converts 2 packed signed    \n   EVEX.128.F3.0F38.W0 22                         quad-word integers from     \n   /r VPMOVSQB xmm1/m16   A    V/V       AVX512VL xmm2 into 2 packed signed   \n   {k1}{z}, xmm2                         AVX512F  byte integers in xmm1/m16   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 2 packed unsigned  \n   EVEX.128.F3.0F38.W0 12                         quad-word integers from     \n   /r VPMOVUSQB xmm1/m16  A    V/V       AVX512VL xmm2 into 2 packed unsigned \n   {k1}{z}, xmm2                         AVX512F  byte integers in xmm1/m16   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 4 packed quad-word \n   EVEX.256.F3.0F38.W0 32                AVX512VL integers from ymm2 into 4   \n   /r VPMOVQB xmm1/m32    A    V/V       AVX512F  packed byte integers in     \n   {k1}{z}, ymm2                                  xmm1/m32 with truncation    \n                                                  under writemask k1.         \n                                                  Converts 4 packed signed    \n   EVEX.256.F3.0F38.W0 22                         quad-word integers from     \n   /r VPMOVSQB xmm1/m32   A    V/V       AVX512VL ymm2 into 4 packed signed   \n   {k1}{z}, ymm2                         AVX512F  byte integers in xmm1/m32   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 4 packed unsigned  \n   EVEX.256.F3.0F38.W0 12                         quad-word integers from     \n   /r VPMOVUSQB xmm1/m32  A    V/V       AVX512VL ymm2 into 4 packed unsigned \n   {k1}{z}, ymm2                         AVX512F  byte integers in xmm1/m32   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 8 packed quad-word \n   EVEX.512.F3.0F38.W0 32                         integers from zmm2 into 8   \n   /r VPMOVQB xmm1/m64    A    V/V       AVX512F  packed byte integers in     \n   {k1}{z}, zmm2                                  xmm1/m64 with truncation    \n                                                  under writemask k1.         \n                                                  Converts 8 packed signed    \n   EVEX.512.F3.0F38.W0 22                         quad-word integers from     \n   /r VPMOVSQB xmm1/m64   A    V/V       AVX512F  zmm2 into 8 packed signed   \n   {k1}{z}, zmm2                                  byte integers in xmm1/m64   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 8 packed unsigned  \n   EVEX.512.F3.0F38.W0 12                         quad-word integers from     \n   /r VPMOVUSQB xmm1/m64  A    V/V       AVX512F  zmm2 into 8 packed unsigned \n   {k1}{z}, zmm2                                  byte integers in xmm1/m64   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Eighth Mem ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   VPMOVQB down converts 64-bit integer elements in the source operand (the\n   second operand) into packed byte elements using truncation. VPMOVSQB\n   converts signed 64-bit integers into packed signed bytes using signed\n   saturation. VPMOVUSQB convert unsigned quad-word values into unsigned byte\n   values using unsigned saturation. The source operand is a vector register.\n   The destination operand is an XMM register or a memory location.\n\n   Down-converted byte elements are written to the destination operand (the\n   first operand) from the least-significant byte. Byte elements of the\n   destination operand are updated according to the writemask. Bits\n   (MAXVL-1:64) of the destination are zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["roundps", "         ROUNDPS \u2014 Round Packed Single Precision Floating-Point Values\n\n                                  64/32 bit CPUID                             \n   Opcode*/Instruction      Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Round packed single       \n   66 0F 3A 08 /r ib                                precision floating-point  \n   ROUNDPS xmm1, xmm2/m128, RMI   V/V       SSE4_1  values in xmm2/m128 and   \n   imm8                                             place the result in xmm1. \n                                                    The rounding mode is      \n                                                    determined by imm8.       \n                                                    Round packed single       \n   VEX.128.66.0F3A.WIG 08                           precision floating-point  \n   /r ib VROUNDPS xmm1,     RMI   V/V       AVX     values in xmm2/m128 and   \n   xmm2/m128, imm8                                  place the result in xmm1. \n                                                    The rounding mode is      \n                                                    determined by imm8.       \n                                                    Round packed single       \n   VEX.256.66.0F3A.WIG 08                           precision floating-point  \n   /r ib VROUNDPS ymm1,     RMI   V/V       AVX     values in ymm2/m256 and   \n   ymm2/m256, imm8                                  place the result in ymm1. \n                                                    The rounding mode is      \n                                                    determined by imm8.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RMI   ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Round the 4 single precision floating-point values in the source operand\n   (second operand) using the rounding mode specified in the immediate\n   operand (third operand) and place the results in the destination operand\n   (first operand). The rounding process rounds each input floating-point\n   value to an integer value and returns the integer result as a single\n   precision floating-point value.\n\n   The immediate operand specifies control fields for the rounding operation,\n   three bit fields are defined and shown in Figure 4-24. Bit 3 of the\n   immediate byte controls processor behavior for a precision exception, bit\n   2 selects the source of rounding mode control. Bits 1:0 specify a\n   non-sticky rounding-mode value (Table 4-18 lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the source operand second source operand or a\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The source operand is a YMM register or a 256-bit\n   memory location. The destination operand is a YMM register.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b\n   otherwise instructions will #UD.\n"],
	["movsd", "       MOVSD \u2014 Move or Merge Scalar Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Move scalar double         \n   F2 0F 10 /r MOVSD xmm1,  A    V/V       SSE2    precision floating-point   \n   xmm2                                            value from xmm2 to xmm1    \n                                                   register.                  \n                                                   Load scalar double         \n   F2 0F 10 /r MOVSD xmm1,  A    V/V       SSE2    precision floating-point   \n   m64                                             value from m64 to xmm1     \n                                                   register.                  \n                                                   Move scalar double         \n   F2 0F 11 /r MOVSD        C    V/V       SSE2    precision floating-point   \n   xmm1/m64, xmm2                                  value from xmm2 register   \n                                                   to xmm1/m64.               \n                                                   Merge scalar double        \n   VEX.LIG.F2.0F.WIG 10 /r  B    V/V       AVX     precision floating-point   \n   VMOVSD xmm1, xmm2, xmm3                         value from xmm2 and xmm3   \n                                                   to xmm1 register.          \n                                                   Load scalar double         \n   VEX.LIG.F2.0F.WIG 10 /r  D    V/V       AVX     precision floating-point   \n   VMOVSD xmm1, m64                                value from m64 to xmm1     \n                                                   register.                  \n                                                   Merge scalar double        \n   VEX.LIG.F2.0F.WIG 11 /r  E    V/V       AVX     precision floating-point   \n   VMOVSD xmm1, xmm2, xmm3                         value from xmm2 and xmm3   \n                                                   registers to xmm1.         \n                                                   Store scalar double        \n   VEX.LIG.F2.0F.WIG 11 /r  C    V/V       AVX     precision floating-point   \n   VMOVSD m64, xmm1                                value from xmm1 register   \n                                                   to m64.                    \n                                                   Merge scalar double        \n   EVEX.LLIG.F2.0F.W1 10 /r                        precision floating-point   \n   VMOVSD xmm1 {k1}{z},     B    V/V       AVX512F value from xmm2 and xmm3   \n   xmm2, xmm3                                      registers to xmm1 under    \n                                                   writemask k1.              \n                                                   Load scalar double         \n   EVEX.LLIG.F2.0F.W1 10 /r                        precision floating-point   \n   VMOVSD xmm1 {k1}{z}, m64 F    V/V       AVX512F value from m64 to xmm1     \n                                                   register under writemask   \n                                                   k1.                        \n                                                   Merge scalar double        \n   EVEX.LLIG.F2.0F.W1 11 /r                        precision floating-point   \n   VMOVSD xmm1 {k1}{z},     E    V/V       AVX512F value from xmm2 and xmm3   \n   xmm2, xmm3                                      registers to xmm1 under    \n                                                   writemask k1.              \n                                                   Store scalar double        \n   EVEX.LLIG.F2.0F.W1 11 /r G    V/V       AVX512F precision floating-point   \n   VMOVSD m64 {k1}, xmm1                           value from xmm1 register   \n                                                   to m64 under writemask k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     N/A           ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n   D     N/A           ModRM:reg (w)    ModRM:r/m (r) N/A           N/A       \n   E     N/A           ModRM:r/m (w)    EVEX.vvvv (r) ModRM:reg (r) N/A       \n   F     Tuple1 Scalar ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   G     Tuple1 Scalar ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n\nDescription \u00b6\n\n   Moves a scalar double precision floating-point value from the source\n   operand (second operand) to the destination operand (first operand). The\n   source and destination operands can be XMM registers or 64-bit memory\n   locations. This instruction can be used to move a double precision\n   floating-point value to and from the low quadword of an XMM register and a\n   64-bit memory location, or to move a double precision floating-point value\n   between the low quadwords of two XMM registers. The instruction cannot be\n   used to transfer data between memory locations.\n\n   Legacy version: When the source and destination operands are XMM\n   registers, bits MAXVL:64 of the destination operand remains unchanged.\n   When the source operand is a memory location and destination operand is an\n   XMM\n\n   registers, the quadword at bits 127:64 of the destination operand is\n   cleared to all 0s, bits MAXVL:128 of the destination operand remains\n   unchanged.\n\n   VEX and EVEX encoded register-register syntax: Moves a scalar double\n   precision floating-point value from the second source operand (the third\n   operand) to the low quadword element of the destination operand (the first\n   operand). Bits 127:64 of the destination operand are copied from the first\n   source operand (the second operand). Bits (MAXVL-1:128) of the\n   corresponding destination register are zeroed.\n\n   VEX and EVEX encoded memory store syntax: When the source operand is a\n   memory location and destination operand is an XMM registers, bits MAXVL:64\n   of the destination operand is cleared to all 0s.\n\n   EVEX encoded versions: The low quadword of the destination is updated\n   according to the writemask.\n\n   Note: For VMOVSD (memory store and load forms), VEX.vvvv and EVEX.vvvv are\n   reserved and must be 1111b, otherwise instruction will #UD.\n"],
	["pshufw", "                         PSHUFW \u2014 Shuffle Packed Words\n\n   Opcode/Instruction    Op/En 64-Bit Compat/Leg Description                  \n                               Mode   Mode       \n                                                 Shuffle the words in mm2/m64 \n   NP 0F 70 /r ib PSHUFW RMI   Valid  Valid      based on the encoding in     \n   mm1, mm2/m64, imm8                            imm8 and store the result in \n                                                 mm1.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RMI   ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Copies words from the source operand (second operand) and inserts them in\n   the destination operand (first operand) at word locations selected with\n   the order operand (third operand). This operation is similar to the\n   operation used by the PSHUFD instruction, which is illustrated in Figure\n   4-16. For the PSHUFW instruction, each 2-bit field in the order operand\n   selects the contents of one word location in the destination operand. The\n   encodings of the order operand fields select words from the source operand\n   to be copied to the destination operand.\n\n   The source operand can be an MMX technology register or a 64-bit memory\n   location. The destination operand is an MMX technology register. The order\n   operand is an 8-bit immediate. Note that this instruction permits a word\n   in the source operand to be copied to more than one word location in the\n   destination operand.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15).\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pcmpeqb:pcmpeqw:pcmpeqd", "            PCMPEQB/PCMPEQW/PCMPEQD \u2014 Compare Packed Data for Equal\n\n                         Op/ 64/32 bit CPUID                                  \n   Opcode/Instruction    En  Mode      Feature  Description\n                             Support   Flag     \n   NP 0F 74 /r^1 PCMPEQB A   V/V       MMX      Compare packed bytes in       \n   mm, mm/m64                                   mm/m64 and mm for equality.   \n   66 0F 74 /r PCMPEQB                          Compare packed bytes in       \n   xmm1, xmm2/m128       A   V/V       SSE2     xmm2/m128 and xmm1 for        \n                                                equality.                     \n   NP 0F 75 /r^1 PCMPEQW A   V/V       MMX      Compare packed words in       \n   mm, mm/m64                                   mm/m64 and mm for equality.   \n   66 0F 75 /r PCMPEQW                          Compare packed words in       \n   xmm1, xmm2/m128       A   V/V       SSE2     xmm2/m128 and xmm1 for        \n                                                equality.                     \n   NP 0F 76 /r^1 PCMPEQD A   V/V       MMX      Compare packed doublewords in \n   mm, mm/m64                                   mm/m64 and mm for equality.   \n   66 0F 76 /r PCMPEQD                          Compare packed doublewords in \n   xmm1, xmm2/m128       A   V/V       SSE2     xmm2/m128 and xmm1 for        \n                                                equality.                     \n   VEX.128.66.0F.WIG 74                         Compare packed bytes in       \n   /r VPCMPEQB xmm1,     B   V/V       AVX      xmm3/m128 and xmm2 for        \n   xmm2, xmm3/m128                              equality.                     \n   VEX.128.66.0F.WIG 75                         Compare packed words in       \n   /r VPCMPEQW xmm1,     B   V/V       AVX      xmm3/m128 and xmm2 for        \n   xmm2, xmm3/m128                              equality.                     \n   VEX.128.66.0F.WIG 76                         Compare packed doublewords in \n   /r VPCMPEQD xmm1,     B   V/V       AVX      xmm3/m128 and xmm2 for        \n   xmm2, xmm3/m128                              equality.                     \n   VEX.256.66.0F.WIG 74                         Compare packed bytes in       \n   /r VPCMPEQB ymm1,     B   V/V       AVX2     ymm3/m256 and ymm2 for        \n   ymm2, ymm3 /m256                             equality.                     \n   VEX.256.66.0F.WIG 75                         Compare packed words in       \n   /r VPCMPEQW ymm1,     B   V/V       AVX2     ymm3/m256 and ymm2 for        \n   ymm2, ymm3 /m256                             equality.                     \n   VEX.256.66.0F.WIG 76                         Compare packed doublewords in \n   /r VPCMPEQD ymm1,     B   V/V       AVX2     ymm3/m256 and ymm2 for        \n   ymm2, ymm3 /m256                             equality.                     \n                                                Compare Equal between int32   \n   EVEX.128.66.0F.W0 76                         vector xmm2 and int32 vector  \n   /r VPCMPEQD k1 {k2},                AVX512VL xmm3/m128/m32bcst, and set    \n   xmm2,                 C   V/V       AVX512F  vector mask k1 to reflect the \n   xmm3/m128/m32bcst                            zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n                                                Compare Equal between int32   \n   EVEX.256.66.0F.W0 76                         vector ymm2 and int32 vector  \n   /r VPCMPEQD k1 {k2},                AVX512VL ymm3/m256/m32bcst, and set    \n   ymm2,                 C   V/V       AVX512F  vector mask k1 to reflect the \n   ymm3/m256/m32bcst                            zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n                                                Compare Equal between int32   \n   EVEX.512.66.0F.W0 76                         vectors in zmm2 and           \n   /r VPCMPEQD k1 {k2},  C   V/V       AVX512F  zmm3/m512/m32bcst, and set    \n   zmm2,                                        destination k1 according to   \n   zmm3/m512/m32bcst                            the comparison results under  \n                                                writemask k2.                 \n                                                Compare packed bytes in       \n                                                xmm3/m128 and xmm2 for        \n   EVEX.128.66.0F.WIG 74               AVX512VL equality and set vector mask  \n   /r VPCMPEQB k1 {k2},  D   V/V       AVX512BW k1 to reflect the             \n   xmm2, xmm3 /m128                             zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n                                                Compare packed bytes in       \n                                                ymm3/m256 and ymm2 for        \n   EVEX.256.66.0F.WIG 74               AVX512VL equality and set vector mask  \n   /r VPCMPEQB k1 {k2},  D   V/V       AVX512BW k1 to reflect the             \n   ymm2, ymm3 /m256                             zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n                                                Compare packed bytes in       \n                                                zmm3/m512 and zmm2 for        \n   EVEX.512.66.0F.WIG 74                        equality and set vector mask  \n   /r VPCMPEQB k1 {k2},  D   V/V       AVX512BW k1 to reflect the             \n   zmm2, zmm3 /m512                             zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n                                                Compare packed words in       \n                                                xmm3/m128 and xmm2 for        \n   EVEX.128.66.0F.WIG 75               AVX512VL equality and set vector mask  \n   /r VPCMPEQW k1 {k2},  D   V/V       AVX512BW k1 to reflect the             \n   xmm2, xmm3 /m128                             zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n                                                Compare packed words in       \n                                                ymm3/m256 and ymm2 for        \n   EVEX.256.66.0F.WIG 75               AVX512VL equality and set vector mask  \n   /r VPCMPEQW k1 {k2},  D   V/V       AVX512BW k1 to reflect the             \n   ymm2, ymm3 /m256                             zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n                                                Compare packed words in       \n                                                zmm3/m512 and zmm2 for        \n   EVEX.512.66.0F.WIG 75                        equality and set vector mask  \n   /r VPCMPEQW k1 {k2},  D   V/V       AVX512BW k1 to reflect the             \n   zmm2, zmm3 /m512                             zero/nonzero status of each   \n                                                element of the result, under  \n                                                writemask.                    \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare for equality of the packed bytes, words, or\n   doublewords in the destination operand (first operand) and the source\n   operand (second operand). If a pair of data elements is equal, the\n   corresponding data element in the destination operand is set to all 1s;\n   otherwise, it is set to all 0s.\n\n   The (V)PCMPEQB instruction compares the corresponding bytes in the\n   destination and source operands; the (V)PCMPEQW instruction compares the\n   corresponding words in the destination and source operands; and the\n   (V)PCMPEQD instruction compares the corresponding doublewords in the\n   destination and source operands.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The second source operand can be an XMM\n   register or a 128-bit memory location. The first source and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand can be an XMM register\n   or a 128-bit memory location. The first source and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM register\n   are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n\n   EVEX encoded VPCMPEQD: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. The destination operand (first\n   operand) is a mask register updated according to the writemask k2.\n\n   EVEX encoded VPCMPEQB/W: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location. The destination operand\n   (first operand) is a mask register updated according to the writemask k2.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["bt", "                                 BT \u2014 Bit Test\n\n   Opcode      Instruction    Op/En 64-bit Compat/Leg Description             \n                                    Mode   Mode       \n   0F A3 /r    BT r/m16, r16  MR    Valid  Valid      Store selected bit in   \n                                                      CF flag.                \n   0F A3 /r    BT r/m32, r32  MR    Valid  Valid      Store selected bit in   \n                                                      CF flag.                \n   REX.W + 0F  BT r/m64, r64  MR    Valid  N.E.       Store selected bit in   \n   A3 /r                                              CF flag.                \n   0F BA /4 ib BT r/m16, imm8 MI    Valid  Valid      Store selected bit in   \n                                                      CF flag.                \n   0F BA /4 ib BT r/m32, imm8 MI    Valid  Valid      Store selected bit in   \n                                                      CF flag.                \n   REX.W + 0F  BT r/m64, imm8 MI    Valid  N.E.       Store selected bit in   \n   BA /4 ib                                           CF flag.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (r) ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r) imm8          N/A       N/A       \n\nDescription \u00b6\n\n   Selects the bit in a bit string (specified with the first operand, called\n   the bit base) at the bit-position designated by the bit offset (specified\n   by the second operand) and stores the value of the bit in the CF flag. The\n   bit base operand can be a register or a memory location; the bit offset\n   operand can be a register or an immediate value:\n\n     * If the bit base operand specifies a register, the instruction takes\n       the modulo 16, 32, or 64 of the bit offset operand (modulo size\n       depends on the mode and register size; 64-bit operands are available\n       only in 64-bit mode).\n     * If the bit base operand specifies a memory location, the operand\n       represents the address of the byte in memory that contains the bit\n       base (bit 0 of the specified byte) of the bit string. The range of the\n       bit position that can be referenced by the offset operand depends on\n       the operand size.\n\n   See also: Bit(BitBase, BitOffset) on page 3-11.\n\n   Some assemblers support immediate bit offsets larger than 31 by using the\n   immediate bit offset field in combination with the displacement field of\n   the memory operand. In this case, the low-order 3 or 5 bits (3 for 16-bit\n   operands, 5 for 32-bit operands) of the immediate bit offset are stored in\n   the immediate bit offset field, and the high-order bits are shifted and\n   combined with the byte displacement in the addressing mode by the\n   assembler. The processor will ignore the high order bits if they are not\n   zero.\n\n   When accessing a bit in memory, the processor may access 4 bytes starting\n   from the memory address for a 32-bit operand size, using by the following\n   relationship:\n\n   Effective Address + (4 \u2217 (BitOffset DIV 32))\n\n   Or, it may access 2 bytes starting from the memory address for a 16-bit\n   operand, using this relationship:\n\n   Effective Address + (2 \u2217 (BitOffset DIV 16))\n\n   It may do so even when only a single byte needs to be accessed to reach\n   the given bit. When using this bit addressing mechanism, software should\n   avoid referencing areas of memory close to address space holes. In\n   particular, it should avoid references to memory-mapped I/O registers.\n   Instead, software should use the MOV instructions to load from or store to\n   these addresses, and use the register form of these instructions to\n   manipulate the data.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bit operands. See the summary chart at the beginning of this section for\n   encoding data and limits.\n\nFlags Affected \u00b6\n\n   The CF flag contains the value of the selected bit. The ZF flag is\n   unaffected. The OF, SF, AF, and PF flags are undefined.\n"],
	["stui", "                         STUI \u2014 Set User Interrupt Flag\n\n   Opcode/Instruction Op/En 64/32 bit Mode CPUID Feature Description          \n                            Support        Flag          \n   F3 0F 01 EF STUI   ZO    V/I            UINTR         Set user interrupt   \n                                                         flag.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   STUI sets the user interrupt flag (UIF). Its effect takes place\n   immediately; a user interrupt may be delivered on the instruction boundary\n   following STUI. (This is in contrast with STI, whose effect is delayed by\n   one instruction).\n\n   An execution of STUI inside a transactional region causes a transactional\n   abort; the abort loads EAX as it would have had it been due to an\n   execution of STI.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["addpd", "           ADDPD \u2014 Add Packed Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Add packed double          \n   66 0F 58 /r ADDPD xmm1,                         precision floating-point   \n   xmm2/m128               A    V/V       SSE2     values from xmm2/mem to    \n                                                   xmm1 and store result in   \n                                                   xmm1.                      \n                                                   Add packed double          \n   VEX.128.66.0F.WIG 58 /r                         precision floating-point   \n   VADDPD xmm1,xmm2,       B    V/V       AVX      values from xmm3/mem to    \n   xmm3/m128                                       xmm2 and store result in   \n                                                   xmm1.                      \n                                                   Add packed double          \n   VEX.256.66.0F.WIG 58 /r                         precision floating-point   \n   VADDPD ymm1, ymm2,      B    V/V       AVX      values from ymm3/mem to    \n   ymm3/m256                                       ymm2 and store result in   \n                                                   ymm1.                      \n                                                   Add packed double          \n   EVEX.128.66.0F.W1 58 /r                         precision floating-point   \n   VADDPD xmm1 {k1}{z},    C    V/V       AVX512VL values from                \n   xmm2, xmm3/m128/m64bcst                AVX512F  xmm3/m128/m64bcst to xmm2  \n                                                   and store result in xmm1   \n                                                   with writemask k1.         \n                                                   Add packed double          \n   EVEX.256.66.0F.W1 58 /r                         precision floating-point   \n   VADDPD ymm1 {k1}{z},    C    V/V       AVX512VL values from                \n   ymm2, ymm3/m256/m64bcst                AVX512F  ymm3/m256/m64bcst to ymm2  \n                                                   and store result in ymm1   \n                                                   with writemask k1.         \n                                                   Add packed double          \n   EVEX.512.66.0F.W1 58 /r                         precision floating-point   \n   VADDPD zmm1 {k1}{z},    C    V/V       AVX512F  values from                \n   zmm2,                                           zmm3/m512/m64bcst to zmm2  \n   zmm3/m512/m64bcst{er}                           and store result in zmm1   \n                                                   with writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds two, four or eight packed double precision floating-point values from\n   the first source operand to the second source operand, and stores the\n   packed double precision floating-point result in the destination operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. The upper bits (MAXVL-1:256) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: the first source operand is a XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper Bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["vcvttsh2si", "    VCVTTSH2SI \u2014 Convert with Truncation Low FP16 Value to a Signed Integer\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode    \n   Flag Support 64/32 CPUID Feature   \n   Instruction En Bit Mode Flag CPUID \n   Feature Instruction En Bit Mode    \n   Flag Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag 64/32 \n   CPUID Feature Instruction En Bit   \n   Mode Flag CPUID Feature            \n   Instruction En Bit Mode Flag Op/   \n   64/32 CPUID Feature                \n                                                            Convert FP16      \n                                                            value in the low  \n                                                            element of        \n   EVEX.LLIG.F3.MAP5.W0 2C /r         A V/V^1   AVX512-FP16 xmm1/m16 to a     \n   VCVTTSH2SI r32, xmm1/m16 {sae}                           signed integer    \n                                                            and store the     \n                                                            result in r32     \n                                                            using truncation. \n                                                            Convert FP16      \n                                                            value in the low  \n                                                            element of        \n   EVEX.LLIG.F3.MAP5.W1 2C /r         A V/N.E.  AVX512-FP16 xmm1/m16 to a     \n   VCVTTSH2SI r64, xmm1/m16 {sae}                           signed integer    \n                                                            and store the     \n                                                            result in r64     \n                                                            using truncation. \n\n     1. Outside of 64b mode, the EVEX.W field is ignored. The instruction\n     behaves as if W=0 was used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP16 element in the source operand to a\n   signed integer in the destination general purpose register.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer indefinite value is returned.\n"],
	["pmovmskb", "                           PMOVMSKB \u2014 Move Byte Mask\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n   NP 0F D7 /r^1 PMOVMSKB                          Move a byte mask of mm to  \n   reg, mm                 RM    V/V       SSE     reg. The upper bits of r32 \n                                                   or r64 are zeroed          \n   66 0F D7 /r PMOVMSKB                            Move a byte mask of xmm to \n   reg, xmm                RM    V/V       SSE2    reg. The upper bits of r32 \n                                                   or r64 are zeroed          \n                                                   Move a byte mask of xmm1   \n   VEX.128.66.0F.WIG D7 /r RM    V/V       AVX     to reg. The upper bits of  \n   VPMOVMSKB reg, xmm1                             r32 or r64 are filled with \n                                                   zeros.                     \n   VEX.256.66.0F.WIG D7 /r                         Move a 32-bit mask of ymm1 \n   VPMOVMSKB reg, ymm1     RM    V/V       AVX2    to reg. The upper bits of  \n                                                   r64 are filled with zeros. \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Creates a mask made up of the most significant bit of each byte of the\n   source operand (second operand) and stores the result in the low byte or\n   word of the destination operand (first operand).\n\n   The byte mask is 8 bits for 64-bit source operand, 16 bits for 128-bit\n   source operand and 32 bits for 256-bit source operand. The destination\n   operand is a general-purpose register.\n\n   In 64-bit mode, the instruction can access additional registers\n   (XMM8-XMM15, R8-R15) when used with a REX.R prefix. The default operand\n   size is 64-bit in 64-bit mode.\n\n   Legacy SSE version: The source operand is an MMX technology register.\n\n   128-bit Legacy SSE version: The source operand is an XMM register.\n\n   VEX.128 encoded version: The source operand is an XMM register.\n\n   VEX.256 encoded version: The source operand is a YMM register.\n\n   Note: VEX.vvvv is reserved and must be 1111b.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["wrmsr", "                    WRMSR \u2014 Write to Model Specific Register\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n                                                        Write the value in    \n   0F 30  WRMSR       ZO    Valid       Valid           EDX:EAX to MSR        \n                                                        specified by ECX.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Writes the contents of registers EDX:EAX into the 64-bit model specific\n   register (MSR) specified in the ECX register. (On processors that support\n   the Intel 64 architecture, the high-order 32 bits of RCX are ignored.) The\n   contents of the EDX register are copied to high-order 32 bits of the\n   selected MSR and the contents of the EAX register are copied to low-order\n   32 bits of the MSR. (On processors that support the Intel 64 architecture,\n   the high-order 32 bits of each of RAX and RDX are ignored.) Undefined or\n   reserved bits in an MSR should be set to values previously read.\n\n   This instruction must be executed at privilege level 0 or in real-address\n   mode; otherwise, a general protection exception #GP(0) is generated.\n   Specifying a reserved or unimplemented MSR address in ECX will also cause\n   a general protection exception. The processor will also generate a general\n   protection exception if software attempts to write to bits in a reserved\n   MSR.\n\n   When the WRMSR instruction is used to write to an MTRR, the TLBs are\n   invalidated. This includes global entries (see \u201cTranslation Lookaside\n   Buffers (TLBs)\u201d in Chapter 3 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3A).\n\n   MSRs control functions for testability, execution tracing,\n   performance-monitoring and machine check errors. Chapter 2,\n   \u201cModel-Specific Registers (MSRs),\u201d of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 4, lists all MSRs that\n   can be written with this instruction and their addresses. Note that each\n   processor family has its own set of MSRs.\n\n   The WRMSR instruction is a serializing instruction (see \u201cSerializing\n   Instructions\u201d in Chapter 9 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3A). Note that WRMSR to the\n   IA32_TSC_DEADLINE MSR (MSR index 6E0H) and the X2APIC MSRs (MSR indices\n   802H to 83FH) are not serializing.\n\n   The CPUID instruction should be used to determine whether MSRs are\n   supported (CPUID.01H:EDX[5] = 1) before using this instruction.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The MSRs and the ability to read them with the WRMSR instruction were\n   introduced into the IA-32 architecture with the Pentium processor.\n   Execution of this instruction by an IA-32 processor earlier than the\n   Pentium processor results in an invalid opcode exception #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["xlat:xlatb", "                     XLAT/XLATB \u2014 Table Look-up Translation\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   D7         XLAT m8     ZO    Valid  Valid      Set AL to memory byte       \n                                                  DS:[(E)BX + unsigned AL].   \n   D7         XLATB       ZO    Valid  Valid      Set AL to memory byte       \n                                                  DS:[(E)BX + unsigned AL].   \n   REX.W + D7 XLATB       ZO    Valid  N.E.       Set AL to memory byte [RBX  \n                                                  + unsigned AL].             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Locates a byte entry in a table in memory, using the contents of the AL\n   register as a table index, then copies the contents of the table entry\n   back into the AL register. The index in the AL register is treated as an\n   unsigned integer. The XLAT and XLATB instructions get the base address of\n   the table in memory from either the DS:EBX or the DS:BX registers\n   (depending on the address-size attribute of the instruction, 32 or 16,\n   respectively). (The DS segment may be overridden with a segment override\n   prefix.)\n\n   At the assembly-code level, two forms of this instruction are allowed: the\n   \u201cexplicit-operand\u201d form and the \u201cno-operand\u201d form. The explicit-operand\n   form (specified with the XLAT mnemonic) allows the base address of the\n   table to be specified explicitly with a symbol. This explicit-operands\n   form is provided to allow documentation; however, note that the\n   documentation provided by this form can be misleading. That is, the symbol\n   does not have to specify the correct base address. The base address is\n   always specified by the DS:(E)BX registers, which must be loaded correctly\n   before the XLAT instruction is executed.\n\n   The no-operands form (XLATB) provides a \u201cshort form\u201d of the XLAT\n   instructions. Here also the processor assumes that the DS:(E)BX registers\n   contain the base address of the table.\n\n   In 64-bit mode, operation is similar to that in legacy or compatibility\n   mode. AL is used to specify the table index (the operand size is fixed at\n   8 bits). RBX, however, is used to specify the table\u2019s base address. See\n   the summary chart at the beginning of this section for encoding data and\n   limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["esetcontext", "               ESETCONTEXT \u2014 Set the ENCLAVECONTEXT Field in SECS\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Description\n                            Support   Flag    \n   EAX = 02H          IR    V/V       EAX[5]  This leaf function sets the     \n   ENCLV[ESETCONTEXT]                         ENCLAVECONTEXT field in SECS.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                           RCX                      RDX           \n                          Return error Address of the           Context Value \n   IR    ESETCONTEXT (In) code (Out)   destination EPC page     (In, EA)      \n                                       (In, EA)                 \n\n  Description \u00b6\n\n   The ESETCONTEXT leaf overwrites the ENCLAVECONTEXT field in the SECS.\n   ECREATE and ELD of an SECS set the ENCLAVECONTEXT field in the SECS to the\n   address of the SECS (for access later in ERDINFO). The ESETCONTEXT\n   instruction allows a VMM to overwrite the default context value if\n   necessary, for example, if the VMM is emulating ECREATE or ELD on behalf\n   of the guest.\n\n   The content of RCX is an effective address of the SECS page to be updated,\n   RDX contains the address pointing to the value to be stored in the SECS.\n   The DS segment is used to create linear address. Segment override is not\n   supported.\n\n   The instruction fails if:\n\n     * The operand is not properly aligned.\n     * RCX does not refer to an SECS page.\n\nESETCONTEXT Memory Parameter Semantics \u00b6\n\n   EPCPAGE                          CONTEXT                                   \n   Read access permitted by Enclave Read/Write access permitted by Non        \n                                    Enclave                                   \n\n   The instruction faults if any of the following:\n\nESETCONTEXT Faulting Conditions \u00b6\n\n   A memory operand effective address is outside   A memory operand is not    \n   the DS segment limit (32b mode).                properly aligned.          \n   DS segment is unusable (32b mode).              A page fault occurs in     \n                                                   accessing memory operands. \n   A memory address is in a non-canonical form     \n   (64b mode).                                     \n\n  Concurrency Restrictions \u00b6\n\n                             Base Concurrency Restrictions\n   Leaf        Parameter     Access On Conflict   SGX_CONFLICT VM Exit        \n                                                  Qualification               \n   ESETCONTEXT SECS [DS:RCX] Shared SGX_EPC_PAGE_ \n                                    CONFLICT      \n\n   Table 38-80. Base Concurrency Restrictions of ESETCONTEXT\n\n                         Additional Concurrency Restrictions\n                         vs. EACCEPT, EACCEPTCOPY,                           \n                         vs. EADD, EEXTEND, EINIT  vs. EADD,                 \n                         vs. ETRACK, ETRACKC       EEXTEND, EINIT\n                         Access vs. ETRACK,        vs. EADD,      vs. ETRACK,\n                         ETRACKC Access On         EEXTEND, EINIT ETRACKC\n                         Conflict Access vs.       vs. ETRACK,  \n   Leaf        Parameter ETRACK, ETRACKC Access On ETRACKC\n                         Conflict EMODPE, EMODPR,\n                         EMODT                   \n                         Access On Conflict      \n                         Access On Conflict      \n                         Access Access On        \n                         Conflict Access On      \n                         Conflict                \n   ESETCONTEXT SECS      Concurrent                Concurrent     Concurrent \n               [DS:RCX]  \n\n   Table 38-81. Additional Concurrency Restrictions of ESETCONTEXT\n\n  Flags Affected \u00b6\n\n   ZF is set if ESETCONTEXT fails due to concurrent operation with another\n   SGX instruction; otherwise cleared.\n\n   CF, PF, AF, OF, and SF are cleared.\n"],
	["vrndscaless", " VRNDSCALESS \u2014 Round Scalar Float32 Value to Include a Given Number of Fraction\n                                      Bits\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Rounds scalar              \n                                                   single-precision           \n   EVEX.LLIG.66.0F3A.W0 0A                         floating-point value in    \n   /r ib VRNDSCALESS xmm1  A     V/V       AVX512F xmm3/m32 to a number of    \n   {k1}{z}, xmm2,                                  fraction bits specified by \n   xmm3/m32{sae}, imm8                             the imm8 field. Stores the \n                                                   result in xmm1 register    \n                                                   under writemask.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Rounds the single-precision floating-point value in the low doubleword\n   element of the second source operand (the third operand) by the rounding\n   mode specified in the immediate operand (see Figure 5-29) and places the\n   result in the corresponding element of the destination operand (the first\n   operand) according to the writemask. The double-word elements at bits\n   127:32 of the destination are copied from the first source operand (the\n   second operand).\n\n   The destination and first source operands are XMM registers, the 2nd\n   source operand can be an XMM register or memory location. Bits MAXVL-1:128\n   of the destination register are cleared.\n\n   The rounding process rounds the input to an integral value, plus number\n   bits of fraction that are specified by imm8[7:4] (to be included in the\n   result) and returns the result as a single-precision floating-point value.\n\n   It should be noticed that no overflow is induced while executing this\n   instruction (although the source is scaled by the imm8[7:4] value).\n\n   The immediate operand also specifies control fields for the rounding\n   operation, three bit fields are defined and shown in the \u201cImmediate\n   Control Description\u201d figure below. Bit 3 of the immediate byte controls\n   the processor behavior for a precision exception, bit 2 selects the source\n   of rounding mode control. Bits 1:0 specify a non-sticky rounding-mode\n   value (immediate control tables below lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   The sign of the result of this instruction is preserved, including the\n   sign of zero.\n\n   The formula of the operation for VRNDSCALESS is\n\n   ROUND(x) = 2^-M*Round_to_INT(x*2^M, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   M=imm[7:4];\n\n   The operation of x*2^M is computed as if the exponent range is unlimited\n   (i.e., no overflow ever occurs).\n\n   VRNDSCALESS is a more general form of the VEX-encoded VROUNDSS\n   instruction. In VROUNDSS, the formula of the operation on each element is\n\n   ROUND(x) = Round_to_INT(x, round_ctrl),\n\n   round_ctrl = imm[3:0];\n\n   EVEX encoded version: The source operand is a XMM register or a 32-bit\n   memory location. The destination operand is a XMM register.\n\n   Handling of special case of input values are listed in Table 5-31.\n"],
	["vrcp28ps", "     VRCP28PS \u2014 Approximation to the Reciprocal of Packed Single Precision\n            Floating-Point ValuesWith Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes the approximate  \n                                                    reciprocals ( < 2^-28     \n   EVEX.512.66.0F38.W0 CA                           relative error) of the    \n   /r VRCP28PS zmm1        A     V/V       AVX512ER packed single-precision   \n   {k1}{z},                                         floating-point values in  \n   zmm2/m512/m32bcst {sae}                          zmm2/m512/m32bcst and     \n                                                    stores the results in     \n                                                    zmm1. Under writemask.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4 \n   A Full ModRM:reg (w) ModRM:r/m (r) N/A N/A               \n\n  Description \u00b6\n\n   Computes the reciprocal approximation of the float32 values in the source\n   operand (the second operand) and store the results to the destination\n   operand (the first operand) using the writemask k1. The approximate\n   reciprocal is evaluated with less than 2^-28 of maximum relative error\n   prior to final rounding. The final results are rounded to < 2^-23 relative\n   error before written to the destination.\n\n   Denormal input values are treated as zeros and do not signal #DE,\n   irrespective of MXCSR.DAZ. Denormal results are flushed to zeros and do\n   not signal #UE, irrespective of MXCSR.FTZ.\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. If any source element is \u00b1\u221e, \u00b10.0 is returned for that\n   element. Also, if any source element is \u00b10.0, \u00b1\u221e is returned for that\n   element.\n\n   The source operand is a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n  A numerically exact implementation of VRCP28xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["aesenclast", "           AESENCLAST \u2014 Perform Last Round of an AES Encryption Flow\n\n                                   64/32-bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                             Flag     \n                                                      Perform the last round  \n                                                      of an AES encryption    \n   66 0F 38 DD /r AESENCLAST A     V/V       AES      flow, using one 128-bit \n   xmm1, xmm2/m128                                    data (state) from xmm1  \n                                                      with one 128-bit round  \n                                                      key from xmm2/m128.     \n                                                      Perform the last round  \n                                                      of an AES encryption    \n   VEX.128.66.0F38.WIG DD /r                          flow, using one 128-bit \n   VAESENCLAST xmm1, xmm2,   B     V/V       AES AVX  data (state) from xmm2  \n   xmm3/m128                                          with one 128-bit round  \n                                                      key from xmm3/m128;     \n                                                      store the result in     \n                                                      xmm1.                   \n                                                      Perform the last round  \n                                                      of an AES encryption    \n   VEX.256.66.0F38.WIG DD /r                          flow, using two 128-bit \n   VAESENCLAST ymm1, ymm2,   B     V/V       VAES     data (state) from ymm2  \n   ymm3/m256                                          with two 128-bit round  \n                                                      keys from ymm3/m256;    \n                                                      store the result in     \n                                                      ymm1.                   \n                                                      Perform the last round  \n                                                      of an AES encryption    \n   EVEX.128.66.0F38.WIG DD                            flow, using one 128-bit \n   /r VAESENCLAST xmm1,      C     V/V       VAES     data (state) from xmm2  \n   xmm2, xmm3/m128                           AVX512VL with one 128-bit round  \n                                                      key from xmm3/m128;     \n                                                      store the result in     \n                                                      xmm1.                   \n                                                      Perform the last round  \n                                                      of an AES encryption    \n   EVEX.256.66.0F38.WIG DD                            flow, using two 128-bit \n   /r VAESENCLAST ymm1,      C     V/V       VAES     data (state) from ymm2  \n   ymm2, ymm3/m256                           AVX512VL with two 128-bit round  \n                                                      keys from ymm3/m256;    \n                                                      store the result in     \n                                                      ymm1.                   \n                                                      Perform the last round  \n                                                      of an AES encryption    \n   EVEX.512.66.0F38.WIG DD                            flow, using four        \n   /r VAESENCLAST zmm1,      C     V/V       VAES     128-bit data (state)    \n   zmm2, zmm3/m512                           AVX512F  from zmm2 with four     \n                                                      128-bit round keys from \n                                                      zmm3/m512; store the    \n                                                      result in zmm1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A      ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A      ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   This instruction performs the last round of an AES encryption flow using\n   one/two/four (depending on vector length) 128-bit data (state) from the\n   first source operand with one/two/four (depending on vector length) round\n   key(s) from the second source operand, and stores the result in the\n   destination operand.\n\n   VEX and EVEX encoded versions of the instruction allows 3-operand\n   (non-destructive) operation. The legacy encoded versions of the\n   instruction require that the first source operand and the destination\n   operand are the same and must be an XMM register.\n\n   The EVEX encoded form of this instruction does not support memory fault\n   suppression.\n"],
	["vgetexpss", "VGETEXPSS \u2014 Convert Exponents of Scalar Single Precision Floating-Point Value to\n                      SinglePrecision Floating-Point Value\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Convert the biased         \n                                                   exponent (bits 30:23) of   \n                                                   the low single-precision   \n                                                   floating-point value in    \n   EVEX.LLIG.66.0F38.W0 43                         xmm3/m32 to a              \n   /r VGETEXPSS xmm1                               single-precision           \n   {k1}{z}, xmm2,          A     V/V       AVX512F floating-point value       \n   xmm3/m32{sae}                                   representing unbiased      \n                                                   integer exponent. Stores   \n                                                   the result to xmm1 under   \n                                                   the writemask k1 and merge \n                                                   with the other elements of \n                                                   xmm2.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Extracts the biased exponent from the normalized single-precision\n   floating-point representation of the low double-word data element of the\n   source operand (the third operand) as unbiased signed integer value, or\n   convert the denormal representation of input data to unbiased negative\n   integer values. The integer value of the unbiased exponent is converted to\n   single-precision floating-point value and written to the destination\n   operand (the first operand) as single-precision floating-point numbers.\n   Bits (127:32) of the XMM register destination are copied from\n   corresponding bits in the first source operand.\n\n   The destination must be a XMM register, the source operand can be a XMM\n   register or a float32 memory location.\n\n   If writemasking is used, the low doubleword element of the destination\n   operand is conditionally updated depending on the value of writemask\n   register k1. If writemasking is not used, the low doubleword element of\n   the destination operand is unconditionally updated.\n\n   Each GETEXP operation converts the exponent value into a floating-point\n   number (permitting input value in denormal representation). Special cases\n   of input values are listed in Table 5-17.\n\n   The formula is:\n\n   GETEXP(x) = floor(log_2(|x|))\n\n   Notation floor(x) stands for maximal integer not exceeding real number x.\n\n   Software usage of VGETEXPxx and VGETMANTxx instructions generally involve\n   a combination of GETEXP operation and GETMANT operation (see VGETMANTPD).\n   Thus VGETEXPxx instruction do not require software to handle SIMD\n   floating-point exceptions.\n"],
	["vrcp14pd", "      VRCP14PD \u2014 Compute Approximate Reciprocals of Packed Float64 Values\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Computes the approximate   \n   EVEX.128.66.0F38.W1 4C                          reciprocals of the packed  \n   /r VRCP14PD xmm1                       AVX512VL double precision           \n   {k1}{z},               A     V/V       AVX512F  floating-point values in   \n   xmm2/m128/m64bcst                               xmm2/m128/m64bcst and      \n                                                   stores the results in      \n                                                   xmm1. Under writemask.     \n                                                   Computes the approximate   \n   EVEX.256.66.0F38.W1 4C                          reciprocals of the packed  \n   /r VRCP14PD ymm1                       AVX512VL double precision           \n   {k1}{z},               A     V/V       AVX512F  floating-point values in   \n   ymm2/m256/m64bcst                               ymm2/m256/m64bcst and      \n                                                   stores the results in      \n                                                   ymm1. Under writemask.     \n                                                   Computes the approximate   \n   EVEX.512.66.0F38.W1 4C                          reciprocals of the packed  \n   /r VRCP14PD zmm1                                double precision           \n   {k1}{z},               A     V/V       AVX512F  floating-point values in   \n   zmm2/m512/m64bcst                               zmm2/m512/m64bcst and      \n                                                   stores the results in      \n                                                   zmm1. Under writemask.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate\n   reciprocals of eight/four/two packed double precision floating-point\n   values in the source operand (the second operand) and stores the packed\n   double precision floating-point results in the destination operand. The\n   maximum relative error for this approximation is less than 2^-14_.\n\n   The source operand can be a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 64-bit memory location. The destination\n   operand is a ZMM register conditionally updated according to the\n   writemask.\n\n   The VRCP14PD instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. A denormal source value will be treated as\n   zero only in case of DAZ bit set in MXCSR. Otherwise it is treated\n   correctly (i.e., not as a 0.0). Underflow results are flushed to zero only\n   in case of FTZ bit set in MXCSR. Otherwise it will be treated correctly\n   (i.e., correct underflow result is written) with the sign of the operand.\n   When a source value is a SNaN or QNaN, the SNaN is converted to a QNaN or\n   the source QNaN is returned.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n   Input value       Result value Comments                                 \n   _0 \u2264 X \u2264 2^-1024  INF          Very small denormal                      \n   -2^-1024 \u2264 X \u2264 -0 -INF         Very small denormal                      \n   _X > 21022        Underflow    Up to 18 bits of fractions are returned* \n   _X < -2^1022      -Underflow   Up to 18 bits of fractions are returned* \n   _X = 2-n          _2^n         \n   X = -2^-n         -2^n         \n\n   Table 5-26. VRCP14PD/VRCP14SD Special Cases\n\n   * in this case the mantissa is shifted right by one or two bits\n\n  A numerically exact implementation of VRCP14xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["cvtsi2sd", "CVTSI2SD \u2014 Convert Doubleword Integer to Scalar Double Precision Floating-Point\n                                     Value\n\n                          Op / 64/32 bit    CPUID                             \n   Opcode/Instruction     En   Mode Support Feature Description\n                                            Flag    \n                                                    Convert one signed        \n   F2 0F 2A /r CVTSI2SD                             doubleword integer from   \n   xmm1, r32/m32          A    V/V          SSE2    r32/m32 to one double     \n                                                    precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   F2 REX.W 0F 2A /r                                quadword integer from     \n   CVTSI2SD xmm1, r/m64   A    V/N.E.       SSE2    r/m64 to one double       \n                                                    precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   VEX.LIG.F2.0F.W0 2A /r                           doubleword integer from   \n   VCVTSI2SD xmm1, xmm2,  B    V/V          AVX     r/m32 to one double       \n   r/m32                                            precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   VEX.LIG.F2.0F.W1 2A /r                           quadword integer from     \n   VCVTSI2SD xmm1, xmm2,  B    V/N.E.^1     AVX     r/m64 to one double       \n   r/m64                                            precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   EVEX.LLIG.F2.0F.W0 2A                            doubleword integer from   \n   /r VCVTSI2SD xmm1,     C    V/V          AVX512F r/m32 to one double       \n   xmm2, r/m32                                      precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one signed        \n   EVEX.LLIG.F2.0F.W1 2A                            quadword integer from     \n   /r VCVTSI2SD xmm1,     C    V/N.E.^1     AVX512F r/m64 to one double       \n   xmm2, r/m64{er}                                  precision floating-point  \n                                                    value in xmm1.            \n\n     1. VEX.W1/EVEX.W1 in non-64 bit is ignored; the instructions behaves as\n     if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Converts a signed doubleword integer (or signed quadword integer if\n   operand size is 64 bits) in the \u201cconvert-from\u201d source operand to a double\n   precision floating-point value in the destination operand. The result is\n   stored in the low quadword of the destination operand, and the high\n   quadword left unchanged. When conversion is inexact, the value returned is\n   rounded according to the rounding control bits in the MXCSR register.\n\n   The second source operand can be a general-purpose register or a 32/64-bit\n   memory location. The first source and destination operands are XMM\n   registers.\n\n   128-bit Legacy SSE version: Use of the REX.W prefix promotes the\n   instruction to 64-bit operands. The \u201cconvert-from\u201d source operand (the\n   second operand) is a general-purpose register or memory location. The\n   destination is an XMM register Bits (MAXVL-1:64) of the corresponding\n   destination register remain unchanged.\n\n   VEX.128 and EVEX encoded versions: The \u201cconvert-from\u201d source operand (the\n   third operand) can be a general-purpose register or a memory location. The\n   first source and destination operands are XMM registers. Bits (127:64) of\n   the XMM register destination are copied from the corresponding bits in the\n   first source operand. Bits (MAXVL-1:128) of the destination register are\n   zeroed.\n\n   EVEX.W0 version: attempt to encode this instruction with EVEX embedded\n   rounding is ignored.\n\n   VEX.W1 and EVEX.W1 versions: promotes the instruction to use 64-bit input\n   value in 64-bit mode.\n\n   Software should ensure VCVTSI2SD is encoded with VEX.L=0. Encoding\n   VCVTSI2SD with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["vpcmpb:vpcmpub", "             VPCMPB/VPCMPUB \u2014 Compare Packed Byte Values Into Mask\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Compare packed signed   \n                                                      byte values in          \n                                                      xmm3/m128 and xmm2      \n   EVEX.128.66.0F3A.W0 3F /r                 AVX512VL using bits 2:0 of imm8  \n   ib VPCMPB k1 {k2}, xmm2,  A     V/V       AVX512BW as a comparison         \n   xmm3/m128, imm8                                    predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed signed   \n                                                      byte values in          \n                                                      ymm3/m256 and ymm2      \n   EVEX.256.66.0F3A.W0 3F /r                 AVX512VL using bits 2:0 of imm8  \n   ib VPCMPB k1 {k2}, ymm2,  A     V/V       AVX512BW as a comparison         \n   ymm3/m256, imm8                                    predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed signed   \n                                                      byte values in          \n                                                      zmm3/m512 and zmm2      \n   EVEX.512.66.0F3A.W0 3F /r                          using bits 2:0 of imm8  \n   ib VPCMPB k1 {k2}, zmm2,  A     V/V       AVX512BW as a comparison         \n   zmm3/m512, imm8                                    predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed unsigned \n                                                      byte values in          \n                                                      xmm3/m128 and xmm2      \n   EVEX.128.66.0F3A.W0 3E /r                 AVX512VL using bits 2:0 of imm8  \n   ib VPCMPUB k1 {k2}, xmm2, A     V/V       AVX512BW as a comparison         \n   xmm3/m128, imm8                                    predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed unsigned \n                                                      byte values in          \n                                                      ymm3/m256 and ymm2      \n   EVEX.256.66.0F3A.W0 3E /r                 AVX512VL using bits 2:0 of imm8  \n   ib VPCMPUB k1 {k2}, ymm2, A     V/V       AVX512BW as a comparison         \n   ymm3/m256, imm8                                    predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n                                                      Compare packed unsigned \n                                                      byte values in          \n                                                      zmm3/m512 and zmm2      \n   EVEX.512.66.0F3A.W0 3E /r                          using bits 2:0 of imm8  \n   ib VPCMPUB k1 {k2}, zmm2, A     V/V       AVX512BW as a comparison         \n   zmm3/m512, imm8                                    predicate with          \n                                                      writemask k2 and leave  \n                                                      the result in mask      \n                                                      register k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a SIMD compare of the packed byte values in the second source\n   operand and the first source operand and returns the results of the\n   comparison to the mask destination operand. The comparison predicate\n   operand (immediate byte) specifies the type of comparison performed on\n   each pair of packed values in the two source operands. The result of each\n   comparison is a single mask bit result of 1 (comparison true) or 0\n   (comparison false).\n\n   VPCMPB performs a comparison between pairs of signed byte values.\n\n   VPCMPUB performs a comparison between pairs of unsigned byte values.\n\n   The first source operand (second operand) is a ZMM/YMM/XMM register. The\n   second source operand can be a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location. The destination operand (first operand) is a mask\n   register k1. Up to 64/32/16 comparisons are performed with results written\n   to the destination operand under the writemask k2.\n\n   The comparison predicate operand is an 8-bit immediate: bits 2:0 define\n   the type of comparison to be performed. Bits 3 through 7 of the immediate\n   are reserved. Compiler can implement the pseudo-op mnemonic listed in\n   Table 5-21.\n\n   Pseudo-Op                   PCMPM Implementation       \n   VPCMPEQ* reg1, reg2, reg3   VPCMP* reg1, reg2, reg3, 0 \n   VPCMPLT* reg1, reg2, reg3   VPCMP*reg1, reg2, reg3, 1  \n   VPCMPLE* reg1, reg2, reg3   VPCMP* reg1, reg2, reg3, 2 \n   VPCMPNEQ* reg1, reg2, reg3  VPCMP* reg1, reg2, reg3, 4 \n   VPPCMPNLT* reg1, reg2, reg3 VPCMP* reg1, reg2, reg3, 5 \n   VPCMPNLE* reg1, reg2, reg3  VPCMP* reg1, reg2, reg3, 6 \n\n   Table 5-21. Pseudo-Op and VPCMP* Implementation\n"],
	["blsr", "                          BLSR \u2014 Reset Lowest Set Bit\n\n                              64/32-bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                                        Flag    \n                                                Reset lowest set bit of       \n   VEX.LZ.0F38.W0 F3 /1 VM    V/V       BMI1    r/m32, keep all other bits of \n   BLSR r32, r/m32                              r/m32 and write result to     \n                                                r32.                          \n                                                Reset lowest set bit of       \n   VEX.LZ.0F38.W1 F3 /1 VM    V/N.E.    BMI1    r/m64, keep all other bits of \n   BLSR r64, r/m64                              r/m64 and write result to     \n                                                r64.                          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1    Operand 2     Operand 3 Operand 4 \n   VM    VEX.vvvv (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Copies all bits from the source operand to the destination operand and\n   resets (=0) the bit position in the destination operand that corresponds\n   to the lowest set bit of the source operand. If the source operand is zero\n   BLSR sets CF.\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   ZF and SF flags are updated based on the result. CF is set if the source\n   is zero. OF flag is cleared. AF and PF flags are undefined.\n"],
	["knotw:knotb:knotq:knotd", "                  KNOTW/KNOTB/KNOTQ/KNOTD \u2014 NOT Mask Register\n\n   Opcode/Instruction        Op/En 64/32 bit    CPUID        Description      \n                                   Mode Support Feature Flag \n   VEX.L0.0F.W0 44 /r KNOTW  RR    V/V          AVX512F      Bitwise NOT of   \n   k1, k2                                                    16 bits mask k2. \n   VEX.L0.66.0F.W0 44 /r     RR    V/V          AVX512DQ     Bitwise NOT of 8 \n   KNOTB k1, k2                                              bits mask k2.    \n   VEX.L0.0F.W1 44 /r KNOTQ  RR    V/V          AVX512BW     Bitwise NOT of   \n   k1, k2                                                    64 bits mask k2. \n   VEX.L0.66.0F.W1 44 /r     RR    V/V          AVX512BW     Bitwise NOT of   \n   KNOTD k1, k2                                              32 bits mask k2. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2                              \n   RR    ModRM:reg (w) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise NOT of vector mask k2 and writes the result into vector\n   mask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["divss", "          DIVSS \u2014 Divide Scalar Single Precision Floating-Point Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Divide low single          \n                                                   precision floating-point   \n   F3 0F 5E /r DIVSS xmm1,  A    V/V       SSE     value in xmm1 by low       \n   xmm2/m32                                        single precision           \n                                                   floating-point value in    \n                                                   xmm2/m32.                  \n                                                   Divide low single          \n   VEX.LIG.F3.0F.WIG 5E /r                         precision floating-point   \n   VDIVSS xmm1, xmm2,       B    V/V       AVX     value in xmm2 by low       \n   xmm3/m32                                        single precision           \n                                                   floating-point value in    \n                                                   xmm3/m32.                  \n                                                   Divide low single          \n   EVEX.LLIG.F3.0F.W0 5E /r                        precision floating-point   \n   VDIVSS xmm1 {k1}{z},     C    V/V       AVX512F value in xmm2 by low       \n   xmm2, xmm3/m32{er}                              single precision           \n                                                   floating-point value in    \n                                                   xmm3/m32.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Divides the low single precision floating-point value in the first source\n   operand by the low single precision floating-point value in the second\n   source operand, and stores the single precision floating-point result in\n   the destination operand. The second source operand can be an XMM register\n   or a 32-bit memory location.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:32) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The first source operand is an xmm register\n   encoded by VEX.vvvv. The three high-order doublewords of the destination\n   operand are copied from the first source operand. Bits (MAXVL-1:128) of\n   the destination register are zeroed.\n\n   EVEX.128 encoded version: The first source operand is an xmm register\n   encoded by EVEX.vvvv. The doubleword elements of the destination operand\n   at bits 127:32 are copied from the first source operand. Bits\n   (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX version: The low doubleword element of the destination is updated\n   according to the writemask.\n\n   Software should ensure VDIVSS is encoded with VEX.L=0. Encoding VDIVSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["vcvtuqq2ph", "  VCVTUQQ2PH \u2014 Convert Packed Unsigned Quadword Integers to Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert two packed   \n                                                         unsigned doubleword  \n   EVEX.128.F2.MAP5.W1 7A /r                             integers from        \n   VCVTUQQ2PH xmm1{k1}{z},         A V/V     AVX512-FP16 xmm2/m128/m64bcst to \n   xmm2/m128/m64bcst                         AVX512VL    packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n                                                         Convert four packed  \n                                                         unsigned doubleword  \n   EVEX.256.F2.MAP5.W1 7A /r                             integers from        \n   VCVTUQQ2PH xmm1{k1}{z},         A V/V     AVX512-FP16 ymm2/m256/m64bcst to \n   ymm2/m256/m64bcst                         AVX512VL    packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n                                                         Convert eight packed \n                                                         unsigned doubleword  \n   EVEX.512.F2.MAP5.W1 7A /r                             integers from        \n   VCVTUQQ2PH xmm1{k1}{z},         A V/V     AVX512-FP16 zmm2/m512/m64bcst to \n   zmm2/m512/m64bcst {er}                                packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed unsigned quadword integers in the source\n   operand to packed FP16 values in the destination operand. The destination\n   elements are updated according to the writemask.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   If the result of the convert operation is overflow and MXCSR.OM=0 then a\n   SIMD exception will be raised with OE=1, PE=1.\n"],
	["ucomiss", " UCOMISS \u2014 Unordered Compare Scalar Single Precision Floating-Point Values and\n                                   Set EFLAGS\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Compare low single          \n   NP 0F 2E /r UCOMISS                            precision floating-point    \n   xmm1, xmm2/m32          A    V/V       SSE     values in xmm1 and          \n                                                  xmm2/mem32 and set the      \n                                                  EFLAGS flags accordingly.   \n                                                  Compare low single          \n   VEX.LIG.0F.WIG 2E /r                           precision floating-point    \n   VUCOMISS xmm1, xmm2/m32 A    V/V       AVX     values in xmm1 and          \n                                                  xmm2/mem32 and set the      \n                                                  EFLAGS flags accordingly.   \n                                                  Compare low single          \n   EVEX.LLIG.0F.W0 2E /r                          precision floating-point    \n   VUCOMISS xmm1,          B    V/V       AVX512F values in xmm1 and          \n   xmm2/m32{sae}                                  xmm2/mem32 and set the      \n                                                  EFLAGS flags accordingly.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Compares the single precision floating-point values in the low doublewords\n   of operand 1 (first operand) and operand 2 (second operand), and sets the\n   ZF, PF, and CF flags in the EFLAGS register according to the result\n   (unordered, greater than, less than, or equal). The OF, SF, and AF flags\n   in the EFLAGS register are set to 0. The unordered result is returned if\n   either source operand is a NaN (QNaN or SNaN).\n\n   Operand 1 is an XMM register; operand 2 can be an XMM register or a 32 bit\n   memory location.\n\n   The UCOMISS instruction differs from the COMISS instruction in that it\n   signals a SIMD floating-point invalid operation exception (#I) only if a\n   source operand is an SNaN. The COMISS instruction signals an invalid\n   operation exception when a source operand is either a QNaN or SNaN.\n\n   The EFLAGS register is not updated if an unmasked SIMD floating-point\n   exception is generated.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCOMISS is encoded with VEX.L=0. Encoding VCOMISS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["enclv", "        ENCLV \u2014 Execute an Enclave VMM Function of Specified Leaf Number\n\n   Opcode/Instruction Op/En 64/32 bit    CPUID        Description             \n                            Mode Support Feature Flag \n                                                      This instruction is     \n                                                      used to execute         \n                                                      privileged SGX leaf     \n   NP 0F 01 C0 ENCLV  ZO    V/V          NA           functions that are      \n                                                      reserved for VMM use.   \n                                                      They are used for       \n                                                      managing the enclaves.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Implicit Register Operands \n   ZO    NA        NA        NA        See Section 38.3           \n\n  Description \u00b6\n\n   The ENCLV instruction invokes the virtualization SGX leaf functions for\n   managing enclaves in a virtualized environment. Software specifies the\n   leaf function by setting the appropriate value in the register EAX as\n   input. The registers RBX, RCX, and RDX have leaf-specific purpose, and may\n   act as input, as output, or may be unused. In non 64-bit mode, the\n   instruction ignores upper 32 bits of the RAX register.\n\n   The ENCLV instruction produces an invalid-opcode exception (#UD) if CR0.PE\n   = 0 or RFLAGS.VM = 1, if it is executed in system-management mode (SMM),\n   or not in VMX operation. Additionally, any attempt to execute the\n   instruction when CPL > 0 results in #UD. The instruction produces a\n   general-protection exception (#GP) if CR0.PG = 0 or if an attempt is made\n   to invoke an undefined leaf function.\n\n   Software in VMX root mode of operation can enable execution of the ENCLV\n   instruction in VMX non-root mode by setting enable ENCLV execution control\n   in the VMCS. If enable ENCLV execution control in the VMCS is clear,\n   execution of the ENCLV instruction in VMX non-root mode results in #UD.\n\n   When execution of ENCLV instruction in VMX non-root mode is enabled,\n   software in VMX root operation can intercept the invocation of various\n   ENCLV leaf functions in VMX non-root operation by setting the\n   corresponding bits in the ENCLV-exiting bitmap.\n\n   Addresses and operands are 32 bits in 32-bit mode (IA32_EFER.LMA == 0 ||\n   CS.L == 0) and are 64 bits in 64-bit mode (IA32_EFER.LMA == 1 && CS.L ==\n   1). CS.D value has no impact on address calculation.\n\n   Segment override prefixes and address-size override prefixes are ignored,\n   as is the REX prefix in 64-bit mode.\n\n  Flags Affected \u00b6\n\n   See individual leaf functions.\n"],
	["sha256rnds2", "              SHA256RNDS2 \u2014 Perform Two Rounds of SHA256 Operation\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Description\n                            Support   Flag    \n                                              Perform 2 rounds of SHA256      \n                                              operation using an initial      \n                                              SHA256 state (C,D,G,H) from     \n                                              xmm1, an initial SHA256 state   \n   NP 0F 38 CB /r                             (A,B,E,F) from xmm2/m128, and a \n   SHA256RNDS2 xmm1,  RMI   V/V       SHA     pre-computed sum of the next 2  \n   xmm2/m128, <XMM0>                          round message dwords and the    \n                                              corresponding round constants   \n                                              from the implicit operand XMM0, \n                                              storing the updated SHA256      \n                                              state (A,B,E,F) result in xmm1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3         \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) Implicit XMM0 (r) \n\nDescription \u00b6\n\n   The SHA256RNDS2 instruction performs 2 rounds of SHA256 operation using an\n   initial SHA256 state (C,D,G,H) from the first operand, an initial SHA256\n   state (A,B,E,F) from the second operand, and a pre-computed sum of the\n   next 2 round message dwords and the corresponding round constants from the\n   implicit operand xmm0. Note that only the two lower dwords of XMM0 are\n   used by the instruction.\n\n   The updated SHA256 state (A,B,E,F) is written to the first operand, and\n   the second operand can be used as the updated state (C,D,G,H) in later\n   rounds.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["loadiwkey", "             LOADIWKEY \u2014 Load Internal Wrapping Key With Key Locker\n\n                                          64/32-bit CPUID                     \n   Opcode/Instruction               Op/En Mode      Feature Description\n                                                    Flag    \n                                                            Load internal     \n   F3 0F 38 DC 11:rrr:bbb LOADIWKEY A     V/V       KL      wrapping key from \n   xmm1, xmm2, <EAX>, <XMM0>                                xmm1, xmm2, and   \n                                                            XMM0.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3        Operand 4         \n   A     N/A   ModRM:reg (r) ModRM:r/m (r) Implicit EAX (r) Implicit XMM0 (r) \n\nDescription \u00b6\n\n   The LOADIWKEY^1 instruction writes the Key Locker internal wrapping key,\n   which is called IWKey. This IWKey is used by the ENCODEKEY* instructions\n   to wrap keys into handles. Conversely, the AESENC/DEC*KL instructions use\n   IWKey to unwrap those keys from the handles and help verify the handle\n   integrity. For security reasons, no instruction is designed to allow\n   software to directly read the IWKey value.\n\n   IWKey includes two cryptographic keys as well as metadata. The two\n   cryptographic keys are loaded from register sources so that LOADIWKEY can\n   be executed without the keys ever being in memory.\n\n   The key input operands are:\n\n     * The 256-bit encryption key is loaded from the two explicit operands.\n     * The 128-bit integrity key is loaded from the implicit operand XMM0.\n\n   The implicit operand EAX specifies the KeySource and whether backing up\n   the key is permitted:\n\n     * EAX[0] \u2013 When set, the wrapping key being initialized is not permitted\n       to be backed up to platform-scoped storage.\n     * EAX[4:1] \u2013 This specifies the KeySource, which is the type of key.\n       Currently only two encodings are supported. A KeySource of 0 indicates\n       that the key input operands described above should be directly stored\n       as the internal wrapping keys. LOADIWKEY with a KeySource of 1 will\n       have random numbers from the on-chip random number generator XORed\n       with the source registers (including XMM0) so that the software that\n       executes the LOADIWKEY does not know the actual IWKey encryption and\n       integrity keys. Software can choose to put additional random data into\n       the source registers so that other sources of random data are combined\n       with the hardware random number generator supplied value. Software\n       should always check ZF after executing LOADIWKEY with KeySource of 1\n       as this operation may fail due to it being unable to get sufficient\n       full-entropy data from the on-chip random number generator. Both\n       KeySource of 0 and 1 specify that IWKey be used with the AES-GCM-SIV\n       algorithm. CPUID.19H.ECX[1] enumerates support for KeySource of 1. All\n       other KeySource encodings are reserved.\n     * EAX[31:5] \u2013 Reserved.\n\n   1. Further details on Key Locker and usage of this instruction can be\n   found here:\n\n  https://software.intel.com/content/www/us/en/develop/download/intel-key-locker-specification.html.\n  \u00b6\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to full-entropy random data not being received from RDSEED. The\n   other arithmetic flags (OF, SF, AF, PF, CF) are cleared to 0.\n"],
	["prefetchwt1", "PREFETCHWT1 \u2014 Prefetch Vector Data Into Caches With Intent to Write and T1 Hint\n\n                              64/32 bit CPUID Feature                         \n   Opcode/Instruction   Op/En Mode      Flag          Description\n                              Support   \n                                                      Move data from m8       \n   0F 0D /2 PREFETCHWT1 M     V/V       PREFETCHWT1   closer to the processor \n   m8                                                 using T1 hint with      \n                                                      intent to write.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   M ModRM:r/m (r) N/A N/A N/A                   \n\nDescription \u00b6\n\n   Fetches the line of data from memory that contains the byte specified with\n   the source operand to a location in the cache hierarchy specified by an\n   intent to write hint (so that data is brought into \u2018Exclusive\u2019 state via a\n   request for ownership) and a locality hint:\n\n     * T1 (temporal data with respect to first level cache)\u2014prefetch data\n       into the second level cache.\n\n   The source operand is a byte memory location. (The locality hints are\n   encoded into the machine level instruction using bits 3 through 5 of the\n   ModR/M byte. Use of any ModR/M value other than the specified ones will\n   lead to unpredictable behavior.)\n\n   If the line selected is already present in the cache hierarchy at a level\n   closer to the processor, no data movement occurs. Prefetches from\n   uncacheable or WC memory are ignored.\n\n   The PREFETCHWT1 instruction is merely a hint and does not affect program\n   behavior. If executed, this instruction moves data closer to the processor\n   in anticipation of future use.\n\n   The implementation of prefetch locality hints is implementation-dependent,\n   and can be overloaded or ignored by a processor implementation. The amount\n   of data prefetched is also processor implementation-dependent. It will,\n   however, be a minimum of 32 bytes. Additional details of the\n   implementation-dependent locality hints are described in Section 9.5,\n   \u201cMemory Optimization Using Prefetch\u201d of the Intel\u00ae 64 and IA-32\n   Architectures Optimization Reference Manual.\n\n   It should be noted that processors are free to speculatively fetch and\n   cache data from system memory regions that are assigned a memory-type that\n   permits speculative reads (that is, the WB, WC, and WT memory types). A\n   PREFETCHWT1 instruction is considered a hint to this speculative behavior.\n   Because this speculative fetching can occur at any time and is not tied to\n   instruction execution, a PREFETCHWT1 instruction is not ordered with\n   respect to the fence instructions (MFENCE, SFENCE, and LFENCE) or locked\n   memory references. A PREFETCHWT1 instruction is also unordered with\n   respect to CLFLUSH and CLFLUSHOPT instructions, other PREFETCHWT1\n   instructions, or any other general instruction. It is ordered with respect\n   to serializing instructions such as CPUID, WRMSR, OUT, and MOV CR.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFlags Affected \u00b6\n\n   All flags are affected.\n"],
	["bsf", "                             BSF \u2014 Bit Scan Forward\n\n   Opcode     Instruction    Op/En 64-bit Compat/Leg Description              \n                                   Mode   Mode       \n   0F BC /r   BSF r16, r/m16 RM    Valid  Valid      Bit scan forward on      \n                                                     r/m16.                   \n   0F BC /r   BSF r32, r/m32 RM    Valid  Valid      Bit scan forward on      \n                                                     r/m32.                   \n   REX.W + 0F BSF r64, r/m64 RM    Valid  N.E.       Bit scan forward on      \n   BC /r                                             r/m64.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Searches the source operand (second operand) for the least significant set\n   bit (1 bit). If a least significant 1 bit is found, its bit index is\n   stored in the destination operand (first operand). The source operand can\n   be a register or a memory location; the destination operand is a register.\n   The bit index is an unsigned offset from bit 0 of the source operand. If\n   the content of the source operand is 0, the content of the destination\n   operand is undefined.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The ZF flag is set to 1 if the source operand is 0; otherwise, the ZF flag\n   is cleared. The CF, OF, SF, AF, and PF flags are undefined.\n"],
	["subsd", "         SUBSD \u2014 Subtract Scalar Double Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Subtract the low double    \n   F2 0F 5C /r SUBSD xmm1,                         precision floating-point   \n   xmm2/m64                 A    V/V       SSE2    value in xmm2/m64 from     \n                                                   xmm1 and store the result  \n                                                   in xmm1.                   \n                                                   Subtract the low double    \n   VEX.LIG.F2.0F.WIG 5C /r                         precision floating-point   \n   VSUBSD xmm1,xmm2,        B    V/V       AVX     value in xmm3/m64 from     \n   xmm3/m64                                        xmm2 and store the result  \n                                                   in xmm1.                   \n                                                   Subtract the low double    \n   EVEX.LLIG.F2.0F.W1 5C /r                        precision floating-point   \n   VSUBSD xmm1 {k1}{z},     C    V/V       AVX512F value in xmm3/m64 from     \n   xmm2, xmm3/m64{er}                              xmm2 and store the result  \n                                                   in xmm1 under writemask    \n                                                   k1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Subtract the low double precision floating-point value in the second\n   source operand from the first source operand and stores the double\n   precision floating-point result in the low quadword of the destination\n   operand.\n\n   The second source operand can be an XMM register or a 64-bit memory\n   location. The first source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The destination and first source operand are\n   the same. Bits (MAXVL-1:64) of the corresponding destination register\n   remain unchanged.\n\n   VEX.128 and EVEX encoded versions: Bits (127:64) of the XMM register\n   destination are copied from corresponding bits in the first source\n   operand. Bits (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination operand\n   is updated according to the write-mask.\n\n   Software should ensure VSUBSD is encoded with VEX.L=0. Encoding VSUBSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["vreducepd", "     VREDUCEPD \u2014 Perform Reduction Transformation on Packed Float64 Values\n\n                                    64/32 bit CPUID                           \n   Opcode/Instruction         Op/En Mode      Feature  Description\n                                    Support   Flag     \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed double          \n                                                       precision              \n                                                       floating-point values  \n   EVEX.128.66.0F3A.W1 56 /r                  AVX512VL in xmm2/m128/m32bcst   \n   ib VREDUCEPD xmm1 {k1}{z}, A     V/V       AVX512DQ by subtracting a       \n   xmm2/m128/m64bcst, imm8                             number of fraction     \n                                                       bits specified by the  \n                                                       imm8 field. Stores the \n                                                       result in xmm1         \n                                                       register under         \n                                                       writemask k1.          \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed double          \n                                                       precision              \n                                                       floating-point values  \n   EVEX.256.66.0F3A.W1 56 /r                  AVX512VL in ymm2/m256/m32bcst   \n   ib VREDUCEPD ymm1 {k1}{z}, A     V/V       AVX512DQ by subtracting a       \n   ymm2/m256/m64bcst, imm8                             number of fraction     \n                                                       bits specified by the  \n                                                       imm8 field. Stores the \n                                                       result in ymm1         \n                                                       register under         \n                                                       writemask k1.          \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       double precision       \n                                                       floating-point values  \n   EVEX.512.66.0F3A.W1 56 /r                           in zmm2/m512/m32bcst   \n   ib VREDUCEPD zmm1 {k1}{z}, A     V/V       AVX512DQ by subtracting a       \n   zmm2/m512/m64bcst{sae},                             number of fraction     \n   imm8                                                bits specified by the  \n                                                       imm8 field. Stores the \n                                                       result in zmm1         \n                                                       register under         \n                                                       writemask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\n  Description \u00b6\n\n   Perform reduction transformation of the packed binary encoded double\n   precision floating-point values in the source operand (the second operand)\n   and store the reduced results in binary floating-point format to the\n   destination operand (the first operand) under the writemask k1.\n\n   The reduction transformation subtracts the integer part and the leading M\n   fractional bits from the binary floating-point source value, where M is a\n   unsigned integer specified by imm8[7:4], see Figure 5-28. Specifically,\n   the reduction transformation can be expressed as:\n\n   dest = src \u2013 (ROUND(2^M*src))*2^-M;\n\n   where \u201cRound()\u201d treats \u201csrc\u201d, \u201c2^M\u201d, and their product as binary\n   floating-point numbers with normalized significand and biased exponents.\n\n   The magnitude of the reduced result can be expressed by considering src=\n   2^p*man2,\n\n   where \u2018man2\u2019 is the normalized significand and \u2018p\u2019 is the unbiased\n   exponent\n\n   Then if RC = RNE: 0<=|Reduced Result|<=2^p-M-1\n\n   Then if RC =\u0338 RNE: 0<=|Reduced Result|<2^p-M\n\n   This instruction might end up with a precision exception set. However, in\n   case of SPE set (i.e., Suppress Precision Exception, which is imm8[3]=1),\n   no precision exception is reported.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   10 imm8 SP R Round Control Override Fixed point length Suppress Precision\n   Exception: Imm8[3] Imm8[1:0] = 00b : Round nearest even Round Select:\n   Imm8[2] Imm8[3] = 0b : Use MXCSR exception mask Imm8[7:4] : Number of\n   fixed points to subtract Imm8[1:0] = 01b : Round down Imm8[2] = 0b : Use\n   Imm8[1:0] Imm8[3] = 1b : Suppress Imm8[1:0] = 10b : Round up Imm8[2] = 1b\n   : Use MXCSR Imm8[1:0] = 11b : Truncate Figure 5-28. Imm8 Controls for\n   VREDUCEPD/SD/PS/SS\n\n   Handling of special case of input values are listed in Table 5-29.\n\n                                       Round Mode    Returned value      \n   |Src1| < 2^-M-1                     RNE           Src1                \n                                       RPI, Src1 > 0 Round (Src1-2^-M) * \n   |Src1| < 2^-M                       RPI, Src1 \u2264 0 Src1                \n                                       RNI, Src1 \u2265 0 Src1                \n                                       RNI, Src1 < 0 Round (Src1+2^-M) * \n   Src1 = \u00b10, or Dest = \u00b10 (Src1!=INF) NOT RNI       +0.0                \n                                       RNI           -0.0                \n   Src1 = \u00b1INF                         any           +0.0                \n   Src1= \u00b1NAN                          n/a           QNaN(Src1)          \n\n   Table 5-29. VREDUCEPD/SD/PS/SS Special Cases\n\n   * Round control = (imm8.MS1)? MXCSR.RC: imm8.RC\n"],
	["popcnt", "              POPCNT \u2014 Return the Count of Number of Bits Set to 1\n\n   Opcode      Instruction      Op/En 64-Bit     Compat/Leg    Description    \n                                      Mode       Mode          \n   F3 0F B8 /r POPCNT r16,      RM    Valid      Valid         POPCNT on      \n               r/m16                                           r/m16          \n   F3 0F B8 /r POPCNT r32,      RM    Valid      Valid         POPCNT on      \n               r/m32                                           r/m32          \n   F3 REX.W 0F POPCNT r64,      RM    Valid      N.E.          POPCNT on      \n   B8 /r       r/m64                                           r/m64          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   This instruction calculates the number of bits set to 1 in the second\n   operand (source) and returns the count in the first operand (a destination\n   register).\n\nFlags Affected \u00b6\n\n   OF, SF, ZF, AF, CF, PF are all cleared. ZF is set if SRC = 0, otherwise ZF\n   is cleared.\n"],
	["rsm", "                    RSM \u2014 Resume From System Management Mode\n\n   Opcode* Instruction Op/En 64-Bit Mode Compat/Leg Mode Description          \n   0F AA   RSM         ZO    Valid       Valid           Resume operation of  \n                                                         interrupted program. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Returns program control from system management mode (SMM) to the\n   application program or operating-system procedure that was interrupted\n   when the processor received an SMM interrupt. The processor\u2019s state is\n   restored from the dump created upon entering SMM. If the processor detects\n   invalid state information during state restoration, it enters the shutdown\n   state. The following invalid information can cause a shutdown:\n\n     * Any reserved bit of CR4 is set to 1.\n     * Any illegal combination of bits in CR0, such as (PG=1 and PE=0) or\n       (NW=1 and CD=0).\n     * (Intel Pentium and Intel486TM processors only.) The value stored in\n       the state dump base field is not a 32-KByte aligned address.\n\n   The contents of the model-specific registers are not affected by a return\n   from SMM.\n\n   The SMM state map used by RSM supports resuming processor context for\n   non-64-bit modes and 64-bit mode.\n\n   See Chapter 32, \u201cSystem Management Mode,\u201d in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3C, for more information\n   about SMM and the behavior of the RSM instruction.\n\nFlags Affected \u00b6\n\n   All.\n"],
	["vgetmantps", "VGETMANTPS \u2014 Extract Float32 Vector of Normalized Mantissas From Float32 Vector\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Get normalized mantissa \n                                                      from float32 vector     \n   EVEX.128.66.0F3A.W0 26 /r                          xmm2/m128/m32bcst and   \n   ib VGETMANTPS xmm1                        AVX512VL store the result in     \n   {k1}{z},                  A     V/V       AVX512F  xmm1, using imm8 for    \n   xmm2/m128/m32bcst, imm8                            sign control and        \n                                                      mantissa interval       \n                                                      normalization, under    \n                                                      writemask.              \n                                                      Get normalized mantissa \n                                                      from float32 vector     \n   EVEX.256.66.0F3A.W0 26 /r                          ymm2/m256/m32bcst and   \n   ib VGETMANTPS ymm1                        AVX512VL store the result in     \n   {k1}{z},                  A     V/V       AVX512F  ymm1, using imm8 for    \n   ymm2/m256/m32bcst, imm8                            sign control and        \n                                                      mantissa interval       \n                                                      normalization, under    \n                                                      writemask.              \n                                                      Get normalized mantissa \n                                                      from float32 vector     \n   EVEX.512.66.0F3A.W0 26 /r                          zmm2/m512/m32bcst and   \n   ib VGETMANTPS zmm1                                 store the result in     \n   {k1}{z},                  A     V/V       AVX512F  zmm1, using imm8 for    \n   zmm2/m512/m32bcst{sae},                            sign control and        \n   imm8                                               mantissa interval       \n                                                      normalization, under    \n                                                      writemask.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\n  Description \u00b6\n\n   Convert single-precision floating values in the source operand (the second\n   operand) to single-precision floating-point values with the mantissa\n   normalization and sign control specified by the imm8 byte, see Figure\n   5-15. The converted results are written to the destination operand (the\n   first operand) using writemask k1. The normalized mantissa is specified by\n   interv (imm8[1:0]) and the sign control (sc) is specified by bits 3:2 of\n   the immediate byte.\n\n   The destination operand is a ZMM/YMM/XMM register updated under the\n   writemask. The source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 32-bit memory location.\n\n   For each input single-precision floating-point value x, The conversion\n   operation is:\n\n   GetMant(x) = \u00b12^k|x.significand|\n\n   where:\n\n   1 <= |x.significand| < 2\n\n   Unbiased exponent k can be either 0 or -1, depending on the interval range\n   defined by interv, the range of the significand and whether the exponent\n   of the source is even or odd. The sign of the final result is determined\n   by sc and the source sign. The encoded value of imm8[1:0] and sign control\n   are shown in Figure 5-15.\n\n   Each converted single-precision floating-point result is encoded according\n   to the sign control, the unbiased exponent k (adding bias) and a mantissa\n   normalized to the range specified by interv.\n\n   The GetMant() function follows Table 5-18 when dealing with floating-point\n   special numbers.\n\n   This instruction is writemasked, so only those elements with the\n   corresponding bit set in vector mask register k1 are computed and stored\n   into the destination. Elements in zmm1 with the corresponding bit clear in\n   k1 retain their previous values.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, VEX.L must be 0; otherwise\n   instructions will #UD.\n"],
	["vscatterpf1dps:vscatterpf1qps:vscatterpf1dpd:vscatterpf1qpd", "      VSCATTERPF1DPS/VSCATTERPF1QPS/VSCATTERPF1DPD/VSCATTERPF1QPD \u2014 Sparse\n PrefetchPacked SP/DP Data Values With Signed Dword, Signed Qword Indices Using\n                          T1 Hint With Intentto Write\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Using signed dword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W0 C6                           byte memory locations     \n   /6 /vsib VSCATTERPF1DPS A     V/V       AVX512PF containing                \n   vm32z {k1}                                       single-precision data     \n                                                    using writemask k1 and T1 \n                                                    hint with intent to       \n                                                    write.                    \n                                                    Using signed qword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W0 C7                           byte memory locations     \n   /6 /vsib VSCATTERPF1QPS A     V/V       AVX512PF containing                \n   vm64z {k1}                                       single-precision data     \n                                                    using writemask k1 and T1 \n                                                    hint with intent to       \n                                                    write.                    \n                                                    Using signed dword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W1 C6                           byte memory locations     \n   /6 /vsib VSCATTERPF1DPD A     V/V       AVX512PF containing double         \n   vm32y {k1}                                       precision data using      \n                                                    writemask k1 and T1 hint  \n                                                    with intent to write.     \n                                                    Using signed qword        \n                                                    indices, prefetch sparse  \n   EVEX.512.66.0F38.W1 C7                           byte memory locations     \n   /6 /vsib VSCATTERPF1QPD A     V/V       AVX512PF containing double         \n   vm64z {k1}                                       precision data using      \n                                                    writemask k1 and T1 hint  \n                                                    with intent to write.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1                   Operand 2 Operand 3 Operand 4 \n   A     Tuple1     BaseReg (R): VSIB:base,     N/A       N/A       N/A       \n         Scalar     VectorReg(R): VSIB:index    \n\n  Description \u00b6\n\n   The instruction conditionally prefetches up to sixteen 32-bit or eight\n   64-bit integer byte data elements. The elements are specified via the VSIB\n   (i.e., the index register is an zmm, holding packed indices). Elements\n   will only be prefetched if their corresponding mask bit is one.\n\n   cache lines will be brought into exclusive state (RFO) specified by a\n   locality hint (T1):\n\n     * T1 (temporal data)\u2014prefetch data into the second level cache.\n\n   [PS data] For dword indices, the instruction will prefetch sixteen memory\n   locations. For qword indices, the instruction will prefetch eight values.\n\n   [PD data] For dword and qword indices, the instruction will prefetch eight\n   memory locations.\n\n   Note that:\n\n   (1) The prefetches may happen in any order (or not at all). The\n   instruction is a hint.\n\n   (2) The mask is left unchanged.\n\n   (3) Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n\n   (4) No FP nor memory faults may be produced by this instruction.\n\n   (5) Prefetches do not handle cache line splits\n\n   (6) A #UD is signaled if the memory operand is encoded without the SIB\n   byte.\n"],
	["vpcompressq", "      VPCOMPRESSQ \u2014 Store Sparse Packed Quadword Integer Values Into Dense\n                                Memory/Register\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n   EVEX.128.66.0F38.W1 8B /r                          Compress packed         \n   VPCOMPRESSQ xmm1/m128     A     V/V       AVX512VL quadword integer values \n   {k1}{z}, xmm2                             AVX512F  from xmm2 to xmm1/m128  \n                                                      using control mask k1.  \n   EVEX.256.66.0F38.W1 8B /r                          Compress packed         \n   VPCOMPRESSQ ymm1/m256     A     V/V       AVX512VL quadword integer values \n   {k1}{z}, ymm2                             AVX512F  from ymm2 to ymm1/m256  \n                                                      using control mask k1.  \n   EVEX.512.66.0F38.W1 8B /r                          Compress packed         \n   VPCOMPRESSQ zmm1/m512     A     V/V       AVX512F  quadword integer values \n   {k1}{z}, zmm2                                      from zmm2 to zmm1/m512  \n                                                      using control mask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   Compress (stores) up to 8/4/2 quadword integer values from the source\n   operand (second operand) to the destination operand (first operand). The\n   source operand is a ZMM/YMM/XMM register, the destination operand can be a\n   ZMM/YMM/XMM register or a 512/256/128-bit memory location.\n\n   The opmask register k1 selects the active elements (partial vector or\n   possibly non-contiguous if less than 8 active elements) from the source\n   operand to compress into a contiguous vector. The contiguous vector is\n   written to the destination starting from the low element of the\n   destination operand.\n\n   Memory destination version: Only the contiguous vector is written to the\n   destination memory location. EVEX.z must be zero.\n\n   Register destination version: If the vector length of the contiguous\n   vector is less than that of the input vector in the source operand, the\n   upper bits of the destination register are unmodified if EVEX.z is not\n   set, otherwise the upper bits are zeroed.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["movmskpd", "      MOVMSKPD \u2014 Extract Packed Double Precision Floating-Point Sign Mask\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Extract 2-bit sign mask    \n   66 0F 50 /r MOVMSKPD    RM    V/V       SSE2    from xmm and store in reg. \n   reg, xmm                                        The upper bits of r32 or   \n                                                   r64 are filled with zeros. \n                                                   Extract 2-bit sign mask    \n   VEX.128.66.0F.WIG 50 /r RM    V/V       AVX     from xmm2 and store in     \n   VMOVMSKPD reg, xmm2                             reg. The upper bits of r32 \n                                                   or r64 are zeroed.         \n                                                   Extract 4-bit sign mask    \n   VEX.256.66.0F.WIG 50 /r RM    V/V       AVX     from ymm2 and store in     \n   VMOVMSKPD reg, ymm2                             reg. The upper bits of r32 \n                                                   or r64 are zeroed.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Extracts the sign bits from the packed double precision floating-point\n   values in the source operand (second operand), formats them into a 2-bit\n   mask, and stores the mask in the destination operand (first operand). The\n   source operand is an XMM register, and the destination operand is a\n   general-purpose register. The mask is stored in the 2 low-order bits of\n   the destination operand. Zero-extend the upper bits of the destination.\n\n   In 64-bit mode, the instruction can access additional registers\n   (XMM8-XMM15, R8-R15) when used with a REX.R prefix. The default operand\n   size is 64-bit in 64-bit mode.\n\n   128-bit versions: The source operand is a YMM register. The destination\n   operand is a general purpose register.\n\n   VEX.256 encoded version: The source operand is a YMM register. The\n   destination operand is a general purpose register.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["lds:les:lfs:lgs:lss", "                     LDS/LES/LFS/LGS/LSS \u2014 Load Far Pointer\n\n   Opcode   Instruction    Op/En 64-Bit  Compat/Leg Description               \n                                 Mode    Mode       \n   C5 /r    LDS r16,m16:16 RM    Invalid Valid      Load DS:r16 with far      \n                                                    pointer from memory.      \n   C5 /r    LDS r32,m16:32 RM    Invalid Valid      Load DS:r32 with far      \n                                                    pointer from memory.      \n   0F B2 /r LSS r16,m16:16 RM    Valid   Valid      Load SS:r16 with far      \n                                                    pointer from memory.      \n   0F B2 /r LSS r32,m16:32 RM    Valid   Valid      Load SS:r32 with far      \n                                                    pointer from memory.      \n   REX + 0F LSS r64,m16:64 RM    Valid   N.E.       Load SS:r64 with far      \n   B2 /r                                            pointer from memory.      \n   C4 /r    LES r16,m16:16 RM    Invalid Valid      Load ES:r16 with far      \n                                                    pointer from memory.      \n   C4 /r    LES r32,m16:32 RM    Invalid Valid      Load ES:r32 with far      \n                                                    pointer from memory.      \n   0F B4 /r LFS r16,m16:16 RM    Valid   Valid      Load FS:r16 with far      \n                                                    pointer from memory.      \n   0F B4 /r LFS r32,m16:32 RM    Valid   Valid      Load FS:r32 with far      \n                                                    pointer from memory.      \n   REX + 0F LFS r64,m16:64 RM    Valid   N.E.       Load FS:r64 with far      \n   B4 /r                                            pointer from memory.      \n   0F B5 /r LGS r16,m16:16 RM    Valid   Valid      Load GS:r16 with far      \n                                                    pointer from memory.      \n   0F B5 /r LGS r32,m16:32 RM    Valid   Valid      Load GS:r32 with far      \n                                                    pointer from memory.      \n   REX + 0F LGS r64,m16:64 RM    Valid   N.E.       Load GS:r64 with far      \n   B5 /r                                            pointer from memory.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Loads a far pointer (segment selector and offset) from the second operand\n   (source operand) into a segment register and the first operand\n   (destination operand). The source operand specifies a 48-bit or a 32-bit\n   pointer in memory depending on the current setting of the operand-size\n   attribute (32 bits or 16 bits, respectively). The instruction opcode and\n   the destination operand specify a segment register/general-purpose\n   register pair. The 16-bit segment selector from the source operand is\n   loaded into the segment register specified with the opcode (DS, SS, ES,\n   FS, or GS). The 32-bit or 16-bit offset is loaded into the register\n   specified with the destination operand.\n\n   If one of these instructions is executed in protected mode, additional\n   information from the segment descriptor pointed to by the segment selector\n   in the source operand is loaded in the hidden part of the selected segment\n   register.\n\n   Also in protected mode, a NULL selector (values 0000 through 0003) can be\n   loaded into DS, ES, FS, or GS registers without causing a protection\n   exception. (Any subsequent reference to a segment whose corresponding\n   segment register is loaded with a NULL selector, causes a\n   general-protection exception (#GP) and no memory reference to the segment\n   occurs.)\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.W promotes operation to specify a source\n   operand referencing an 80-bit pointer (16-bit selector, 64-bit offset) in\n   memory. Using a REX prefix in the form of REX.R permits access to\n   additional registers (R8-R15). See the summary chart at the beginning of\n   this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["monitor", "                        MONITOR \u2014 Set Up Monitor Address\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                Sets up a linear address      \n                                                range to be monitored by      \n                                                hardware and activates the    \n   0F 01 C8 MONITOR     ZO    Valid  Valid      monitor. The address range    \n                                                should be a write-back memory \n                                                caching type. The address is  \n                                                DS:RAX/EAX/AX.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The MONITOR instruction arms address monitoring hardware using an address\n   specified in EAX (the address range that the monitoring hardware checks\n   for store operations can be determined by using CPUID). A store to an\n   address within the specified address range triggers the monitoring\n   hardware. The state of monitor hardware is used by MWAIT.\n\n   The address is specified in RAX/EAX/AX and the size is based on the\n   effective address size of the encoded instruction. By default, the DS\n   segment is used to create a linear address that is monitored. Segment\n   overrides can be used.\n\n   ECX and EDX are also used. They communicate other information to MONITOR.\n   ECX specifies optional extensions. EDX specifies optional hints; it does\n   not change the architectural behavior of the instruction. For the Pentium\n   4 processor (family 15, model 3), no extensions or hints are defined.\n   Undefined hints in EDX are ignored by the processor; undefined extensions\n   in ECX raises a general protection fault.\n\n   The address range must use memory of the write-back type. Only write-back\n   memory will correctly trigger the monitoring hardware. Additional\n   information on determining what address range to use in order to prevent\n   false wake-ups is described in Chapter 9, \u201cMultiple-Processor Management\u201a\u201d\n   of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3A.\n\n   The MONITOR instruction is ordered as a load operation with respect to\n   other memory transactions. The instruction is subject to the permission\n   checking and faults associated with a byte load. Like a load, MONITOR sets\n   the A-bit but not the D-bit in page tables.\n\n   CPUID.01H:ECX.MONITOR[bit 3] indicates the availability of MONITOR and\n   MWAIT in the processor. When set, MONITOR may be executed only at\n   privilege level 0 (use at any other privilege level results in an\n   invalid-opcode exception). The operating system or system BIOS may disable\n   this instruction by using the IA32_MISC_ENABLE MSR; disabling MONITOR\n   clears the CPUID feature flag and causes execution to generate an\n   invalid-opcode exception.\n\n   The instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n"],
	["ficom:ficomp", "                         FICOM/FICOMP \u2014 Compare Integer\n\n   Opcode Instruction   64-Bit Mode Compat/Leg Mode Description               \n   DE /2  FICOM m16int  Valid       Valid           Compare ST(0) with        \n                                                    m16int.                   \n   DA /2  FICOM m32int  Valid       Valid           Compare ST(0) with        \n                                                    m32int.                   \n   DE /3  FICOMP m16int Valid       Valid           Compare ST(0) with m16int \n                                                    and pop stack register.   \n   DA /3  FICOMP m32int Valid       Valid           Compare ST(0) with m32int \n                                                    and pop stack register.   \n\nDescription \u00b6\n\n   Compares the value in ST(0) with an integer source operand and sets the\n   condition code flags C0, C2, and C3 in the FPU status word according to\n   the results (see table below). The integer value is converted to double\n   extended-precision floating-point format before the comparison is made.\n\n   Condition   C3 C2 C0 \n   ST(0) > SRC 0  0  0  \n   ST(0) < SRC 0  0  1  \n   ST(0) = SRC 1  0  0  \n   Unordered   1  1  1  \n\n   Table 3-26. FICOM/FICOMP Results\n\n   These instructions perform an \u201cunordered comparison.\u201d An unordered\n   comparison also checks the class of the numbers being compared (see\n   \u201cFXAM\u2014Examine Floating-Point\u201d in this chapter). If either operand is a NaN\n   or is in an undefined format, the condition flags are set to \u201cunordered.\u201d\n\n   The sign of zero is ignored, so that \u20130.0 := +0.0.\n\n   The FICOMP instructions pop the register stack following the comparison.\n   To pop the register stack, the processor marks the ST(0) register empty\n   and increments the stack pointer (TOP) by 1.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0.                   \n   C0, C2, C3 See table on previous page. \n"],
	["fcmovcc", "                   FCMOVcc \u2014 Floating-Point Conditional Move\n\n   Opcode^1\n\n           Instruction     64-Bit Mode Compat/ _1 Description                 \n                                       Leg Mode   \n   DA C0+i FCMOVB ST(0),   Valid       Valid      Move if below (CF=1).       \n           ST(i)           \n   DA C8+i FCMOVE ST(0),   Valid       Valid      Move if equal (ZF=1).       \n           ST(i)           \n   DA D0+i FCMOVBE ST(0),  Valid       Valid      Move if below or equal      \n           ST(i)                                  (CF=1 or ZF=1).             \n   DA D8+i FCMOVU ST(0),   Valid       Valid      Move if unordered (PF=1).   \n           ST(i)           \n   DB C0+i FCMOVNB ST(0),  Valid       Valid      Move if not below (CF=0).   \n           ST(i)           \n   DB C8+i FCMOVNE ST(0),  Valid       Valid      Move if not equal (ZF=0).   \n           ST(i)           \n   DB D0+i FCMOVNBE ST(0), Valid       Valid      Move if not below or equal  \n           ST(i)                                  (CF=0 and ZF=0).            \n   DB D8+i FCMOVNU ST(0),  Valid       Valid      Move if not unordered       \n           ST(i)                                  (PF=0).                     \n\n     1. See IA-32 Architecture Compatibility section below.\n\nDescription \u00b6\n\n   Tests the status flags in the EFLAGS register and moves the source operand\n   (second operand) to the destination operand (first operand) if the given\n   test condition is true. The condition for each mnemonic os given in the\n   Description column above and in Chapter 8 in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1. The source operand is\n   always in the ST(i) register and the destination operand is always ST(0).\n\n   The FCMOVcc instructions are useful for optimizing small IF constructions.\n   They also help eliminate branching overhead for IF operations and the\n   possibility of branch mispredictions by the processor.\n\n   A processor may not support the FCMOVcc instructions. Software can check\n   if the FCMOVcc instructions are supported by checking the processor\u2019s\n   feature information with the CPUID instruction (see \u201cCOMISS\u2014Compare Scalar\n   Ordered Single Precision Floating-Point Values and Set EFLAGS\u201d in this\n   chapter). If both the CMOV and FPU feature bits are set, the FCMOVcc\n   instructions are supported.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The FCMOVcc instructions were introduced to the IA-32 Architecture in the\n   P6 family processors and are not available in earlier IA-32 processors.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred. \n   C0, C2, C3 Undefined.                            \n\nInteger Flags Affected \u00b6\n\n   None.\n"],
	["bextr", "                           BEXTR \u2014 Bit Field Extract\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Contiguous bitwise extract \n   VEX.LZ.0F38.W0 F7 /r    RMV   V/V       BMI1    from r/m32 using r32b as   \n   BEXTR r32a, r/m32, r32b                         control; store result in   \n                                                   r32a.                      \n                                                   Contiguous bitwise extract \n   VEX.LZ.0F38.W1 F7 /r    RMV   V/N.E.    BMI1    from r/m64 using r64b as   \n   BEXTR r64a, r/m64, r64b                         control; store result in   \n                                                   r64a.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3    Operand 4 \n   RMV   ModRM:reg (w) ModRM:r/m (r) VEX.vvvv (r) N/A       \n\nDescription \u00b6\n\n   Extracts contiguous bits from the first source operand (the second\n   operand) using an index value and length value specified in the second\n   source operand (the third operand). Bit 7:0 of the second source operand\n   specifies the starting bit position of bit extraction. A START value\n   exceeding the operand size will not extract any bits from the second\n   source operand. Bit 15:8 of the second source operand specifies the\n   maximum number of bits (LENGTH) beginning at the START position to\n   extract. Only bit positions up to (OperandSize -1) of the first source\n   operand are extracted. The extracted bits are written to the destination\n   register, starting from the least significant bit. All higher order bits\n   in the destination operand (starting at bit position LENGTH) are zeroed.\n   The destination register is cleared if no bits are extracted.\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   ZF is updated based on the result. AF, SF, and PF are undefined. All other\n   flags are cleared.\n"],
	["sha1rnds4", "               SHA1RNDS4 \u2014 Perform Four Rounds of SHA1 Operation\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Description\n                            Support   Flag    \n                                              Performs four rounds of SHA1    \n                                              operation operating on SHA1     \n                                              state (A,B,C,D) from xmm1, with \n   NP 0F 3A CC /r ib                          a pre-computed sum of the next  \n   SHA1RNDS4 xmm1,    RMI   V/V       SHA     4 round message dwords and      \n   xmm2/m128, imm8                            state variable E from           \n                                              xmm2/m128. The immediate byte   \n                                              controls logic functions and    \n                                              round constants.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   The SHA1RNDS4 instruction performs four rounds of SHA1 operation using an\n   initial SHA1 state (A,B,C,D) from the first operand (which is a source\n   operand and the destination operand) and some pre-computed sum of the next\n   4 round message dwords, and state variable E from the second operand (a\n   source operand). The updated SHA1 state (A,B,C,D) after four rounds of\n   processing is stored in the destination operand.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtudq2pd", "   VCVTUDQ2PD \u2014 Convert Packed Unsigned Doubleword Integers to Packed Double\n                         PrecisionFloating-Point Values\n\n                              64/32 Bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature  Description\n                              Support   Flag     \n                                                 Convert two packed unsigned  \n   EVEX.128.F3.0F.W0 7A                          doubleword integers from     \n   /r VCVTUDQ2PD xmm1   A     V/V       AVX512VL ymm2/m64/m32bcst to packed   \n   {k1}{z},                             AVX512F  double precision             \n   xmm2/m64/m32bcst                              floating-point values in     \n                                                 zmm1 with writemask k1.      \n                                                 Convert four packed unsigned \n   EVEX.256.F3.0F.W0 7A                          doubleword integers from     \n   /r VCVTUDQ2PD ymm1   A     V/V       AVX512VL xmm2/m128/m32bcst to packed  \n   {k1}{z},                             AVX512F  double precision             \n   xmm2/m128/m32bcst                             floating-point values in     \n                                                 zmm1 with writemask k1.      \n                                                 Convert eight packed         \n   EVEX.512.F3.0F.W0 7A                          unsigned doubleword integers \n   /r VCVTUDQ2PD zmm1                            from ymm2/m256/m32bcst to    \n   {k1}{z},             A     V/V       AVX512F  eight packed double          \n   ymm2/m256/m32bcst                             precision floating-point     \n                                                 values in zmm1 with          \n                                                 writemask k1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed unsigned doubleword integers in the source operand (second\n   operand) to packed double precision floating-point values in the\n   destination operand (first operand).\n\n   The source operand is a YMM/XMM/XMM (low 64 bits) register, a\n   256/128/64-bit memory location or a 256/128/64-bit vector broadcasted from\n   a 32-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register conditionally updated with writemask k1.\n\n   Attempt to encode this instruction with EVEX embedded rounding is ignored.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["clui", "                        CLUI \u2014 Clear User Interrupt Flag\n\n   Opcode/Instruction Op/En 64/32 bit    CPUID        Description             \n                            Mode Support Feature Flag \n                                                      Clear user interrupt    \n   F3 0F 01 EE CLUI   ZO    V/I          UINTR        flag; user interrupts   \n                                                      blocked when user       \n                                                      interrupt flag cleared. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\n  Description \u00b6\n\n   CLUI clears the user interrupt flag (UIF). Its effect takes place\n   immediately: a user interrupt cannot be delivered on the instruction\n   boundary following CLUI.\n\n   An execution of CLUI inside a transactional region causes a transactional\n   abort; the abort loads EAX as it would have had it been caused due to an\n   execution of CLI.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["vpmovdw:vpmovsdw:vpmovusdw", "            VPMOVDW/VPMOVSDW/VPMOVUSDW \u2014 Down Convert DWord to Word\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature  Description\n                               Support   Flag     \n                                                  Converts 4 packed           \n   EVEX.128.F3.0F38.W0 33                         double-word integers from   \n   /r VPMOVDW xmm1/m64    A    V/V       AVX512VL xmm2 into 4 packed word     \n   {k1}{z}, xmm2                         AVX512F  integers in xmm1/m64 with   \n                                                  truncation under writemask  \n                                                  k1.                         \n                                                  Converts 4 packed signed    \n   EVEX.128.F3.0F38.W0 23                         double-word integers from   \n   /r VPMOVSDW xmm1/m64   A    V/V       AVX512VL xmm2 into 4 packed signed   \n   {k1}{z}, xmm2                         AVX512F  word integers in ymm1/m64   \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 4 packed unsigned  \n   EVEX.128.F3.0F38.W0 13                         double-word integers from   \n   /r VPMOVUSDW xmm1/m64  A    V/V       AVX512VL xmm2 into 4 packed unsigned \n   {k1}{z}, xmm2                         AVX512F  word integers in xmm1/m64   \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 8 packed           \n   EVEX.256.F3.0F38.W0 33                         double-word integers from   \n   /r VPMOVDW xmm1/m128   A    V/V       AVX512VL ymm2 into 8 packed word     \n   {k1}{z}, ymm2                         AVX512F  integers in xmm1/m128 with  \n                                                  truncation under writemask  \n                                                  k1.                         \n                                                  Converts 8 packed signed    \n   EVEX.256.F3.0F38.W0 23                         double-word integers from   \n   /r VPMOVSDW xmm1/m128  A    V/V       AVX512VL ymm2 into 8 packed signed   \n   {k1}{z}, ymm2                         AVX512F  word integers in xmm1/m128  \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 8 packed unsigned  \n   EVEX.256.F3.0F38.W0 13                         double-word integers from   \n   /r VPMOVUSDW xmm1/m128 A    V/V       AVX512VL ymm2 into 8 packed unsigned \n   {k1}{z}, ymm2                         AVX512F  word integers in xmm1/m128  \n                                                  using unsigned saturation   \n                                                  under writemask k1.         \n                                                  Converts 16 packed          \n   EVEX.512.F3.0F38.W0 33                         double-word integers from   \n   /r VPMOVDW ymm1/m256   A    V/V       AVX512F  zmm2 into 16 packed word    \n   {k1}{z}, zmm2                                  integers in ymm1/m256 with  \n                                                  truncation under writemask  \n                                                  k1.                         \n                                                  Converts 16 packed signed   \n   EVEX.512.F3.0F38.W0 23                         double-word integers from   \n   /r VPMOVSDW ymm1/m256  A    V/V       AVX512F  zmm2 into 16 packed signed  \n   {k1}{z}, zmm2                                  word integers in ymm1/m256  \n                                                  using signed saturation     \n                                                  under writemask k1.         \n                                                  Converts 16 packed unsigned \n                                                  double-word integers from   \n   EVEX.512.F3.0F38.W0 13                         zmm2 into 16 packed         \n   /r VPMOVUSDW ymm1/m256 A    V/V       AVX512F  unsigned word integers in   \n   {k1}{z}, zmm2                                  ymm1/m256 using unsigned    \n                                                  saturation under writemask  \n                                                  k1.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   VPMOVDW down converts 32-bit integer elements in the source operand (the\n   second operand) into packed words using truncation. VPMOVSDW converts\n   signed 32-bit integers into packed signed words using signed saturation.\n   VPMOVUSDW convert unsigned double-word values into unsigned word values\n   using unsigned saturation.\n\n   The source operand is a ZMM/YMM/XMM register. The destination operand is a\n   YMM/XMM/XMM register or a 256/128/64-bit memory location.\n\n   Down-converted word elements are written to the destination operand (the\n   first operand) from the least-significant word. Word elements of the\n   destination operand are updated according to the writemask. Bits\n   (MAXVL-1:256/128/64) of the register destination are zeroed.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["setcc", "                         SETcc \u2014 Set Byte on Condition\n\n   Opcode   Instruction   Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   0F 97    SETA r/m8     M     Valid  Valid      Set byte if above (CF=0 and \n                                                  ZF=0).                      \n   REX + 0F SETA r/m8^1   M     Valid  N.E.       Set byte if above (CF=0 and \n   97                                             ZF=0).                      \n   0F 93    SETAE r/m8    M     Valid  Valid      Set byte if above or equal  \n                                                  (CF=0).                     \n   REX + 0F SETAE r/m8^1  M     Valid  N.E.       Set byte if above or equal  \n   93                                             (CF=0).                     \n   0F 92    SETB r/m8     M     Valid  Valid      Set byte if below (CF=1).   \n   REX + 0F SETB r/m8^1   M     Valid  N.E.       Set byte if below (CF=1).   \n   92       \n   0F 96    SETBE r/m8    M     Valid  Valid      Set byte if below or equal  \n                                                  (CF=1 or ZF=1).             \n   REX + 0F SETBE r/m8^1  M     Valid  N.E.       Set byte if below or equal  \n   96                                             (CF=1 or ZF=1).             \n   0F 92    SETC r/m8     M     Valid  Valid      Set byte if carry (CF=1).   \n   REX + 0F SETC r/m8^1   M     Valid  N.E.       Set byte if carry (CF=1).   \n   92       \n   0F 94    SETE r/m8     M     Valid  Valid      Set byte if equal (ZF=1).   \n   REX + 0F SETE r/m8^1   M     Valid  N.E.       Set byte if equal (ZF=1).   \n   94       \n   0F 9F    SETG r/m8     M     Valid  Valid      Set byte if greater (ZF=0   \n                                                  and SF=OF).                 \n   REX + 0F SETG r/m8^1   M     Valid  N.E.       Set byte if greater (ZF=0   \n   9F                                             and SF=OF).                 \n   0F 9D    SETGE r/m8    M     Valid  Valid      Set byte if greater or      \n                                                  equal (SF=OF).              \n   REX + 0F SETGE r/m8^1  M     Valid  N.E.       Set byte if greater or      \n   9D                                             equal (SF=OF).              \n   0F 9C    SETL r/m8     M     Valid  Valid      Set byte if less (SF=\u0338 OF). \n   REX + 0F SETL r/m8^1   M     Valid  N.E.       Set byte if less (SF=\u0338 OF). \n   9C       \n   0F 9E    SETLE r/m8    M     Valid  Valid      Set byte if less or equal   \n                                                  (ZF=1 or SF=\u0338 OF).          \n   REX + 0F SETLE r/m8^1  M     Valid  N.E.       Set byte if less or equal   \n   9E                                             (ZF=1 or SF=\u0338 OF).          \n   0F 96    SETNA r/m8    M     Valid  Valid      Set byte if not above (CF=1 \n                                                  or ZF=1).                   \n   REX + 0F SETNA r/m8^1  M     Valid  N.E.       Set byte if not above (CF=1 \n   96                                             or ZF=1).                   \n   0F 92    SETNAE r/m8   M     Valid  Valid      Set byte if not above or    \n                                                  equal (CF=1).               \n   REX + 0F SETNAE r/m8^1 M     Valid  N.E.       Set byte if not above or    \n   92                                             equal (CF=1).               \n   0F 93    SETNB r/m8    M     Valid  Valid      Set byte if not below       \n                                                  (CF=0).                     \n   REX + 0F SETNB r/m8^1  M     Valid  N.E.       Set byte if not below       \n   93                                             (CF=0).                     \n   0F 97    SETNBE r/m8   M     Valid  Valid      Set byte if not below or    \n                                                  equal (CF=0 and ZF=0).      \n   REX + 0F SETNBE r/m8^1 M     Valid  N.E.       Set byte if not below or    \n   97                                             equal (CF=0 and ZF=0).      \n   0F 93    SETNC r/m8    M     Valid  Valid      Set byte if not carry       \n                                                  (CF=0).                     \n   REX + 0F SETNC r/m8^1  M     Valid  N.E.       Set byte if not carry       \n   93                                             (CF=0).                     \n   0F 95    SETNE r/m8    M     Valid  Valid      Set byte if not equal       \n                                                  (ZF=0).                     \n   REX + 0F SETNE r/m8^1  M     Valid  N.E.       Set byte if not equal       \n   95                                             (ZF=0).                     \n   0F 9E    SETNG r/m8    M     Valid  Valid      Set byte if not greater     \n                                                  (ZF=1 or SF=\u0338 OF)           \n   REX + 0F SETNG r/m8^1  M     Valid  N.E.       Set byte if not greater     \n   9E                                             (ZF=1 or SF=\u0338 OF).          \n   0F 9C    SETNGE r/m8   M     Valid  Valid      Set byte if not greater or  \n                                                  equal (SF=\u0338 OF).            \n   REX + 0F SETNGE r/m8^1 M     Valid  N.E.       Set byte if not greater or  \n   9C                                             equal (SF=\u0338 OF).            \n   0F 9D    SETNL r/m8    M     Valid  Valid      Set byte if not less        \n                                                  (SF=OF).                    \n   REX + 0F SETNL r/m8^1  M     Valid  N.E.       Set byte if not less        \n   9D                                             (SF=OF).                    \n   0F 9F    SETNLE r/m8   M     Valid  Valid      Set byte if not less or     \n                                                  equal (ZF=0 and SF=OF).     \n   REX + 0F SETNLE r/m8^1 M     Valid  N.E.       Set byte if not less or     \n   9F                                             equal (ZF=0 and SF=OF).     \n   0F 91    SETNO r/m8    M     Valid  Valid      Set byte if not overflow    \n                                                  (OF=0).                     \n   REX + 0F SETNO r/m8^1  M     Valid  N.E.       Set byte if not overflow    \n   91                                             (OF=0).                     \n   0F 9B    SETNP r/m8    M     Valid  Valid      Set byte if not parity      \n                                                  (PF=0).                     \n   REX + 0F SETNP r/m8^1  M     Valid  N.E.       Set byte if not parity      \n   9B                                             (PF=0).                     \n   0F 99    SETNS r/m8    M     Valid  Valid      Set byte if not sign        \n                                                  (SF=0).                     \n   REX + 0F SETNS r/m8^1  M     Valid  N.E.       Set byte if not sign        \n   99                                             (SF=0).                     \n   0F 95    SETNZ r/m8    M     Valid  Valid      Set byte if not zero        \n                                                  (ZF=0).                     \n   REX + 0F SETNZ r/m8^1  M     Valid  N.E.       Set byte if not zero        \n   95                                             (ZF=0).                     \n   0F 90    SETO r/m8     M     Valid  Valid      Set byte if overflow (OF=1) \n   REX + 0F SETO r/m8^1   M     Valid  N.E.       Set byte if overflow        \n   90                                             (OF=1).                     \n   0F 9A    SETP r/m8     M     Valid  Valid      Set byte if parity (PF=1).  \n   REX + 0F SETP r/m8^1   M     Valid  N.E.       Set byte if parity (PF=1).  \n   9A       \n   0F 9A    SETPE r/m8    M     Valid  Valid      Set byte if parity even     \n                                                  (PF=1).                     \n   REX + 0F SETPE r/m8^1  M     Valid  N.E.       Set byte if parity even     \n   9A                                             (PF=1).                     \n   0F 9B    SETPO r/m8    M     Valid  Valid      Set byte if parity odd      \n                                                  (PF=0).                     \n   REX + 0F SETPO r/m8^1  M     Valid  N.E.       Set byte if parity odd      \n   9B                                             (PF=0).                     \n   0F 98    SETS r/m8     M     Valid  Valid      Set byte if sign (SF=1).    \n   REX + 0F SETS r/m8^1   M     Valid  N.E.       Set byte if sign (SF=1).    \n   98       \n   0F 94    SETZ r/m8     M     Valid  Valid      Set byte if zero (ZF=1).    \n   REX + 0F SETZ r/m8^1   M     Valid  N.E.       Set byte if zero (ZF=1).    \n   94       \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Sets the destination operand to 0 or 1 depending on the settings of the\n   status flags (CF, SF, OF, ZF, and PF) in the EFLAGS register. The\n   destination operand points to a byte register or a byte in memory. The\n   condition code suffix (cc) indicates the condition being tested for.\n\n   The terms \u201cabove\u201d and \u201cbelow\u201d are associated with the CF flag and refer to\n   the relationship between two unsigned integer values. The terms \u201cgreater\u201d\n   and \u201cless\u201d are associated with the SF and OF flags and refer to the\n   relationship between two signed integer values.\n\n   Many of the SETcc instruction opcodes have alternate mnemonics. For\n   example, SETG (set byte if greater) and SETNLE (set if not less or equal)\n   have the same opcode and test for the same condition: ZF equals 0 and SF\n   equals OF. These alternate mnemonics are provided to make code more\n   intelligible. Appendix B, \u201cEFLAGS Condition Codes,\u201d in the Intel^\u00ae 64 and\n   IA-32 Architectures Software Developer\u2019s Manual, Volume 1, shows the\n   alternate mnemonics for various test conditions.\n\n   Some languages represent a logical one as an integer with all bits set.\n   This representation can be obtained by choosing the logically opposite\n   condition for the SETcc instruction, then decrementing the result. For\n   example, to test for overflow, use the SETNO instruction, then decrement\n   the result.\n\n   The reg field of the ModR/M byte is not used for the SETCC instruction and\n   those opcode bits are ignored by the processor.\n\n   In IA-64 mode, the operand size is fixed at 8 bits. Use of REX prefix\n   enable uniform addressing to additional byte registers. Otherwise, this\n   instruction\u2019s operation is the same as in legacy mode and compatibility\n   mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvttpd2udq", "  VCVTTPD2UDQ \u2014 Convert With Truncation Packed Double Precision Floating-Point\n                  Values toPacked Unsigned Doubleword Integers\n\n                                   64/32 Bit CPUID                            \n   Opcode Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Convert two packed      \n                                                      double precision        \n   EVEX.128.0F.W1 78 /r                               floating-point values   \n   VCVTTPD2UDQ xmm1 {k1}{z}, A     V/V       AVX512VL in xmm2/m128/m64bcst to \n   xmm2/m128/m64bcst                         AVX512F  two unsigned doubleword \n                                                      integers in xmm1 using  \n                                                      truncation subject to   \n                                                      writemask k1.           \n                                                      Convert four packed     \n                                                      double precision        \n                                                      floating-point values   \n   EVEX.256.0F.W1 78 02 /r                   AVX512VL in ymm2/m256/m64bcst to \n   VCVTTPD2UDQ xmm1 {k1}{z}, A     V/V       AVX512F  four unsigned           \n   ymm2/m256/m64bcst                                  doubleword integers in  \n                                                      xmm1 using truncation   \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Convert eight packed    \n                                                      double precision        \n                                                      floating-point values   \n   EVEX.512.0F.W1 78 /r                               in zmm2/m512/m64bcst to \n   VCVTTPD2UDQ ymm1 {k1}{z}, A     V/V       AVX512F  eight unsigned          \n   zmm2/m512/m64bcst{sae}                             doubleword integers in  \n                                                      ymm1 using truncation   \n                                                      subject to writemask    \n                                                      k1.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation packed double precision floating-point values in\n   the source operand (the second operand) to packed unsigned doubleword\n   integers in the destination operand (the first operand).\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   The source operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location, or a 512/256/128-bit vector broadcasted from a 64-bit memory\n   location. The destination operand is a YMM/XMM/XMM (low 64 bits) register\n   conditionally updated with writemask k1. The upper bits (MAXVL-1:256) of\n   the corresponding destination are zeroed.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["sqrtsd", "  SQRTSD \u2014 Compute Square Root of Scalar Double Precision Floating-Point Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Computes square root of the \n   F2 0F 51/r SQRTSD                              low double precision        \n   xmm1,xmm2/m64           A    V/V       SSE2    floating-point value in     \n                                                  xmm2/m64 and stores the     \n                                                  results in xmm1.            \n                                                  Computes square root of the \n                                                  low double precision        \n                                                  floating-point value in     \n   VEX.LIG.F2.0F.WIG 51/r                         xmm3/m64 and stores the     \n   VSQRTSD xmm1,xmm2,      B    V/V       AVX     results in xmm1. Also,      \n   xmm3/m64                                       upper double precision      \n                                                  floating-point value        \n                                                  (bits[127:64]) from xmm2 is \n                                                  copied to xmm1[127:64].     \n                                                  Computes square root of the \n                                                  low double precision        \n                                                  floating-point value in     \n   EVEX.LLIG.F2.0F.W1 51/r                        xmm3/m64 and stores the     \n   VSQRTSD xmm1 {k1}{z},   C    V/V       AVX512F results in xmm1 under       \n   xmm2, xmm3/m64{er}                             writemask k1. Also, upper   \n                                                  double precision            \n                                                  floating-point value        \n                                                  (bits[127:64]) from xmm2 is \n                                                  copied to xmm1[127:64].     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Computes the square root of the low double precision floating-point value\n   in the second source operand and stores the double precision\n   floating-point result in the destination operand. The second source\n   operand can be an XMM register or a 64-bit memory location. The first\n   source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. The quadword at bits 127:64 of the destination\n   operand remains unchanged. Bits (MAXVL-1:64) of the corresponding\n   destination register remain unchanged.\n\n   VEX.128 and EVEX encoded versions: Bits 127:64 of the destination operand\n   are copied from the corresponding bits of the first source operand. Bits\n   (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination operand\n   is updated according to the write-mask.\n\n   Software should ensure VSQRTSD is encoded with VEX.L=0. Encoding VSQRTSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["pushf:pushfd:pushfq", "           PUSHF/PUSHFD/PUSHFQ \u2014 Push EFLAGS Register Onto the Stack\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n   9C     PUSHF       ZO    Valid       Valid           Push lower 16 bits of \n                                                        EFLAGS.               \n   9C     PUSHFD      ZO    N.E.        Valid           Push EFLAGS.          \n   9C     PUSHFQ      ZO    Valid       N.E.            Push RFLAGS.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Decrements the stack pointer by 4 (if the current operand-size attribute\n   is 32) and pushes the entire contents of the EFLAGS register onto the\n   stack, or decrements the stack pointer by 2 (if the operand-size attribute\n   is 16) and pushes the lower 16 bits of the EFLAGS register (that is, the\n   FLAGS register) onto the stack. These instructions reverse the operation\n   of the POPF/POPFD instructions.\n\n   When copying the entire EFLAGS register to the stack, the VM and RF flags\n   (bits 16 and 17) are not copied; instead, the values for these flags are\n   cleared in the EFLAGS image stored on the stack. See Chapter 3 of the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1,\n   for more information about the EFLAGS register.\n\n   The PUSHF (push flags) and PUSHFD (push flags double) mnemonics reference\n   the same opcode. The PUSHF instruction is intended for use when the\n   operand-size attribute is 16 and the PUSHFD instruction for when the\n   operand-size attribute is 32. Some assemblers may force the operand size\n   to 16 when PUSHF is used and to 32 when PUSHFD is used. Others may treat\n   these mnemonics as synonyms (PUSHF/PUSHFD) and use the current setting of\n   the operand-size attribute to determine the size of values to be pushed\n   from the stack, regardless of the mnemonic used.\n\n   In 64-bit mode, the instruction\u2019s default operation is to decrement the\n   stack pointer (RSP) by 8 and pushes RFLAGS on the stack. 16-bit operation\n   is supported using the operand size override prefix 66H. 32-bit operand\n   size cannot be encoded in this mode. When copying RFLAGS to the stack, the\n   VM and RF flags (bits 16 and 17) are not copied; instead, values for these\n   flags are cleared in the RFLAGS image stored on the stack.\n\n   When operating in virtual-8086 mode (EFLAGS.VM = 1) without the\n   virtual-8086 mode extensions (CR4.VME = 0), the PUSHF/PUSHFD instructions\n   can be used only if IOPL = 3; otherwise, a general-protection exception\n   (#GP) occurs. If the virtual-8086 mode extensions are enabled (CR4.VME =\n   1), PUSHF (but not PUSHFD) can be executed in virtual-8086 mode with IOPL\n   < 3.\n\n   (The protected-mode virtual-interrupt feature \u2014 enabled by setting CR4.PVI\n   \u2014 affects the CLI and STI instructions in the same manner as the\n   virtual-8086 mode extensions. PUSHF, however, is not affected by CR4.PVI.)\n\n   In the real-address mode, if the ESP or SP register is 1 when PUSHF/PUSHFD\n   instruction executes: an #SS exception is generated but not delivered (the\n   stack error reported prevents #SS delivery). Next, the processor generates\n   a #DF exception and enters a shutdown state as described in the #DF\n   discussion in Chapter 6 of the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3A.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["sarx:shlx:shrx", "                 SARX/SHLX/SHRX \u2014 Shift Without Affecting Flags\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n   VEX.LZ.F3.0F38.W0 F7 /r                         Shift r/m32 arithmetically \n   SARX r32a, r/m32, r32b  RMV   V/V       BMI2    right with count specified \n                                                   in r32b.                   \n   VEX.LZ.66.0F38.W0 F7 /r                         Shift r/m32 logically left \n   SHLX r32a, r/m32, r32b  RMV   V/V       BMI2    with count specified in    \n                                                   r32b.                      \n   VEX.LZ.F2.0F38.W0 F7 /r                         Shift r/m32 logically      \n   SHRX r32a, r/m32, r32b  RMV   V/V       BMI2    right with count specified \n                                                   in r32b.                   \n   VEX.LZ.F3.0F38.W1 F7 /r                         Shift r/m64 arithmetically \n   SARX r64a, r/m64, r64b  RMV   V/N.E.    BMI2    right with count specified \n                                                   in r64b.                   \n   VEX.LZ.66.0F38.W1 F7 /r                         Shift r/m64 logically left \n   SHLX r64a, r/m64, r64b  RMV   V/N.E.    BMI2    with count specified in    \n                                                   r64b.                      \n   VEX.LZ.F2.0F38.W1 F7 /r                         Shift r/m64 logically      \n   SHRX r64a, r/m64, r64b  RMV   V/N.E.    BMI2    right with count specified \n                                                   in r64b.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3    Operand 4 \n   RMV   ModRM:reg (w) ModRM:r/m (r) VEX.vvvv (r) N/A       \n\nDescription \u00b6\n\n   Shifts the bits of the first source operand (the second operand) to the\n   left or right by a COUNT value specified in the second source operand (the\n   third operand). The result is written to the destination operand (the\n   first operand).\n\n   The shift arithmetic right (SARX) and shift logical right (SHRX)\n   instructions shift the bits of the destination operand to the right\n   (toward less significant bit locations), SARX keeps and propagates the\n   most significant bit (sign bit) while shifting.\n\n   The logical shift left (SHLX) shifts the bits of the destination operand\n   to the left (toward more significant bit locations).\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\n   If the value specified in the first source operand exceeds OperandSize -1,\n   the COUNT value is masked.\n\n   SARX,SHRX, and SHLX instructions do not update flags.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvttpd2qq", "  VCVTTPD2QQ \u2014 Convert With Truncation Packed Double Precision Floating-Point\n                       Values toPacked Quadword Integers\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     double precision         \n   EVEX.128.66.0F.W1 7A /r                           floating-point values    \n   VCVTTPD2QQ xmm1 {k1}{z}, A     V/V       AVX512VL from zmm2/m128/m64bcst   \n   xmm2/m128/m64bcst                        AVX512DQ to two packed quadword   \n                                                     integers in zmm1 using   \n                                                     truncation with          \n                                                     writemask k1.            \n                                                     Convert four packed      \n                                                     double precision         \n   EVEX.256.66.0F.W1 7A /r                           floating-point values    \n   VCVTTPD2QQ ymm1 {k1}{z}, A     V/V       AVX512VL from ymm2/m256/m64bcst   \n   ymm2/m256/m64bcst                        AVX512DQ to four packed quadword  \n                                                     integers in ymm1 using   \n                                                     truncation with          \n                                                     writemask k1.            \n                                                     Convert eight packed     \n                                                     double precision         \n   EVEX.512.66.0F.W1 7A /r                           floating-point values    \n   VCVTTPD2QQ zmm1 {k1}{z}, A     V/V       AVX512DQ from zmm2/m512 to eight  \n   zmm2/m512/m64bcst{sae}                            packed quadword integers \n                                                     in zmm1 using truncation \n                                                     with writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation packed double precision floating-point values in\n   the source operand (second operand) to packed quadword integers in the\n   destination operand (first operand).\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register or a\n   512/256/128-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register conditionally updated with writemask k1.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the indefinite integer value (2^w-1, where w\n   represents the number of bits in the destination format) is returned.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["movss", "       MOVSS \u2014 Move or Merge Scalar Single Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Merge scalar single        \n   F3 0F 10 /r MOVSS xmm1,  A    V/V       SSE     precision floating-point   \n   xmm2                                            value from xmm2 to xmm1    \n                                                   register.                  \n                                                   Load scalar single         \n   F3 0F 10 /r MOVSS xmm1,  A    V/V       SSE     precision floating-point   \n   m32                                             value from m32 to xmm1     \n                                                   register.                  \n                                                   Merge scalar single        \n   VEX.LIG.F3.0F.WIG 10 /r  B    V/V       AVX     precision floating-point   \n   VMOVSS xmm1, xmm2, xmm3                         value from xmm2 and xmm3   \n                                                   to xmm1 register           \n                                                   Load scalar single         \n   VEX.LIG.F3.0F.WIG 10 /r  D    V/V       AVX     precision floating-point   \n   VMOVSS xmm1, m32                                value from m32 to xmm1     \n                                                   register.                  \n                                                   Move scalar single         \n   F3 0F 11 /r MOVSS        C    V/V       SSE     precision floating-point   \n   xmm2/m32, xmm1                                  value from xmm1 register   \n                                                   to xmm2/m32.               \n                                                   Move scalar single         \n   VEX.LIG.F3.0F.WIG 11 /r  E    V/V       AVX     precision floating-point   \n   VMOVSS xmm1, xmm2, xmm3                         value from xmm2 and xmm3   \n                                                   to xmm1 register.          \n                                                   Move scalar single         \n   VEX.LIG.F3.0F.WIG 11 /r  C    V/V       AVX     precision floating-point   \n   VMOVSS m32, xmm1                                value from xmm1 register   \n                                                   to m32.                    \n                                                   Move scalar single         \n   EVEX.LLIG.F3.0F.W0 10 /r                        precision floating-point   \n   VMOVSS xmm1 {k1}{z},     B    V/V       AVX512F value from xmm2 and xmm3   \n   xmm2, xmm3                                      to xmm1 register under     \n                                                   writemask k1.              \n                                                   Move scalar single         \n   EVEX.LLIG.F3.0F.W0 10 /r F    V/V       AVX512F precision floating-point   \n   VMOVSS xmm1 {k1}{z}, m32                        values from m32 to xmm1    \n                                                   under writemask k1.        \n                                                   Move scalar single         \n   EVEX.LLIG.F3.0F.W0 11 /r                        precision floating-point   \n   VMOVSS xmm1 {k1}{z},     E    V/V       AVX512F value from xmm2 and xmm3   \n   xmm2, xmm3                                      to xmm1 register under     \n                                                   writemask k1.              \n                                                   Move scalar single         \n   EVEX.LLIG.F3.0F.W0 11 /r G    V/V       AVX512F precision floating-point   \n   VMOVSS m32 {k1}, xmm1                           values from xmm1 to m32    \n                                                   under writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     N/A           ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n   D     N/A           ModRM:reg (w)    ModRM:r/m (r) N/A           N/A       \n   E     N/A           ModRM:r/m (w)    EVEX.vvvv (r) ModRM:reg (r) N/A       \n   F     Tuple1 Scalar ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   G     Tuple1 Scalar ModRM:r/m (w)    ModRM:reg (r) N/A           N/A       \n\nDescription \u00b6\n\n   Moves a scalar single precision floating-point value from the source\n   operand (second operand) to the destination operand (first operand). The\n   source and destination operands can be XMM registers or 32-bit memory\n   locations. This instruction can be used to move a single precision\n   floating-point value to and from the low doubleword of an XMM register and\n   a 32-bit memory location, or to move a single precision floating-point\n   value between the low doublewords of two XMM registers. The instruction\n   cannot be used to transfer data between memory locations.\n\n   Legacy version: When the source and destination operands are XMM\n   registers, bits (MAXVL-1:32) of the corresponding destination register are\n   unmodified. When the source operand is a memory location and destination\n\n   operand is an XMM registers, Bits (127:32) of the destination operand is\n   cleared to all 0s, bits MAXVL:128 of the destination operand remains\n   unchanged.\n\n   VEX and EVEX encoded register-register syntax: Moves a scalar single\n   precision floating-point value from the second source operand (the third\n   operand) to the low doubleword element of the destination operand (the\n   first operand). Bits 127:32 of the destination operand are copied from the\n   first source operand (the second operand). Bits (MAXVL-1:128) of the\n   corresponding destination register are zeroed.\n\n   VEX and EVEX encoded memory load syntax: When the source operand is a\n   memory location and destination operand is an XMM registers, bits MAXVL:32\n   of the destination operand is cleared to all 0s.\n\n   EVEX encoded versions: The low doubleword of the destination is updated\n   according to the writemask.\n\n   Note: For memory store form instruction \u201cVMOVSS m32, xmm1\u201d, VEX.vvvv is\n   reserved and must be 1111b otherwise instruction will #UD. For memory\n   store form instruction \u201cVMOVSS mv {k1}, xmm1\u201d, EVEX.vvvv is reserved and\n   must be 1111b otherwise instruction will #UD.\n\n   Software should ensure VMOVSS is encoded with VEX.L=0. Encoding VMOVSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["cvtpi2ps", "      CVTPI2PS \u2014 Convert Packed Dword Integers to Packed Single Precision\n                             Floating-Point Values\n\n   Opcode/Instruction   Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                Convert two signed doubleword \n   NP 0F 2A /r CVTPI2PS RM    Valid  Valid      integers from mm/m64 to two   \n   xmm, mm/m64                                  single precision              \n                                                floating-point values in xmm. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two packed signed doubleword integers in the source operand\n   (second operand) to two packed single precision floating-point values in\n   the destination operand (first operand).\n\n   The source operand can be an MMX technology register or a 64-bit memory\n   location. The destination operand is an XMM register. The results are\n   stored in the low quadword of the destination operand, and the high\n   quadword remains unchanged. When a conversion is inexact, the value\n   returned is rounded according to the rounding control bits in the MXCSR\n   register.\n\n   This instruction causes a transition from x87 FPU to MMX technology\n   operation (that is, the x87 FPU top-of-stack pointer is set to 0 and the\n   x87 FPU tag word is set to all 0s [valid]). If this instruction is\n   executed while an x87 FPU floating-point exception is pending, the\n   exception is handled before the CVTPI2PS instruction is executed.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["btc", "                         BTC \u2014 Bit Test and Complement\n\n   Opcode     Instruction     Op/En 64-bit Compat/Leg Description             \n                                    Mode   Mode       \n   0F BB /r   BTC r/m16, r16  MR    Valid  Valid      Store selected bit in   \n                                                      CF flag and complement. \n   0F BB /r   BTC r/m32, r32  MR    Valid  Valid      Store selected bit in   \n                                                      CF flag and complement. \n   REX.W + 0F BTC r/m64, r64  MR    Valid  N.E.       Store selected bit in   \n   BB /r                                              CF flag and complement. \n   0F BA /7   BTC r/m16, imm8 MI    Valid  Valid      Store selected bit in   \n   ib                                                 CF flag and complement. \n   0F BA /7   BTC r/m32, imm8 MI    Valid  Valid      Store selected bit in   \n   ib                                                 CF flag and complement. \n   REX.W + 0F BTC r/m64, imm8 MI    Valid  N.E.       Store selected bit in   \n   BA /7 ib                                           CF flag and complement. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8          N/A       N/A       \n\nDescription \u00b6\n\n   Selects the bit in a bit string (specified with the first operand, called\n   the bit base) at the bit-position designated by the bit offset operand\n   (second operand), stores the value of the bit in the CF flag, and\n   complements the selected bit in the bit string. The bit base operand can\n   be a register or a memory location; the bit offset operand can be a\n   register or an immediate value:\n\n     * If the bit base operand specifies a register, the instruction takes\n       the modulo 16, 32, or 64 of the bit offset operand (modulo size\n       depends on the mode and register size; 64-bit operands are available\n       only in 64-bit mode). This allows any bit position to be selected.\n     * If the bit base operand specifies a memory location, the operand\n       represents the address of the byte in memory that contains the bit\n       base (bit 0 of the specified byte) of the bit string. The range of the\n       bit position that can be referenced by the offset operand depends on\n       the operand size.\n\n   See also: Bit(BitBase, BitOffset) on page 3-11.\n\n   Some assemblers support immediate bit offsets larger than 31 by using the\n   immediate bit offset field in combination with the displacement field of\n   the memory operand. See \u201cBT\u2014Bit Test\u201d in this chapter for more information\n   on this addressing mechanism.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\nFlags Affected \u00b6\n\n   The CF flag contains the value of the selected bit before it is\n   complemented. The ZF flag is unaffected. The OF, SF, AF, and PF flags are\n   undefined.\n"],
	["rorx", "              RORX \u2014 Rotate Right Logical Without Affecting Flags\n\n                                  64/32-bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                            Flag    \n                                                    Rotate 32-bit r/m32 right \n   VEX.LZ.F2.0F3A.W0 F0 /r  RMI   V/V       BMI2    imm8 times without        \n   ib RORX r32, r/m32, imm8                         affecting arithmetic      \n                                                    flags.                    \n                                                    Rotate 64-bit r/m64 right \n   VEX.LZ.F2.0F3A.W1 F0 /r  RMI   V/N.E.    BMI2    imm8 times without        \n   ib RORX r64, r/m64, imm8                         affecting arithmetic      \n                                                    flags.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RMI   ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Rotates the bits of second operand right by the count value specified in\n   imm8 without affecting arithmetic flags. The RORX instruction does not\n   read or write the arithmetic flags.\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvtusi2sd", "VCVTUSI2SD \u2014 Convert Unsigned Integer to Scalar Double Precision Floating-Point\n                                     Value\n\n                               64/32 Bit    CPUID                             \n   Opcode/Instruction    Op/En Mode Support Feature Description\n                                            Flag    \n                                                    Convert one unsigned      \n   EVEX.LLIG.F2.0F.W0 7B                            doubleword integer from   \n   /r VCVTUSI2SD xmm1,   A     V/V          AVX512F r/m32 to one double       \n   xmm2, r/m32                                      precision floating-point  \n                                                    value in xmm1.            \n                                                    Convert one unsigned      \n   EVEX.LLIG.F2.0F.W1 7B                            quadword integer from     \n   /r VCVTUSI2SD xmm1,   A     V/N.E.^1     AVX512F r/m64 to one double       \n   xmm2, r/m64{er}                                  precision floating-point  \n                                                    value in xmm1.            \n\n     1. For this specific instruction, EVEX.W in non-64 bit is ignored; the\n     instruction behaves as if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Converts an unsigned doubleword integer (or unsigned quadword integer if\n   operand size is 64 bits) in the second source operand to a double\n   precision floating-point value in the destination operand. The result is\n   stored in the low quadword of the destination operand. When conversion is\n   inexact, the value returned is rounded according to the rounding control\n   bits in the MXCSR register.\n\n   The second source operand can be a general-purpose register or a 32/64-bit\n   memory location. The first source and destination operands are XMM\n   registers. Bits (127:64) of the XMM register destination are copied from\n   corresponding bits in the first source operand. Bits (MAXVL-1:128) of the\n   destination register are zeroed.\n\n   EVEX.W1 version: promotes the instruction to use 64-bit input value in\n   64-bit mode.\n\n   EVEX.W0 version: attempt to encode this instruction with EVEX embedded\n   rounding is ignored.\n"],
	["bndmk", "                              BNDMK \u2014 Make Bounds\n\n                                64/32 bit    CPUID                            \n   Opcode/Instruction     Op/En Mode Support Feature Description\n                                             Flag    \n   F3 0F 1B /r BNDMK bnd,                            Make lower and upper     \n   m32                    RM    N.E./V       MPX     bounds from m32 and      \n                                                     store them in bnd.       \n   F3 0F 1B /r BNDMK bnd,                            Make lower and upper     \n   m64                    RM    V/N.E.       MPX     bounds from m64 and      \n                                                     store them in bnd.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Makes bounds from the second operand and stores the lower and upper bounds\n   in the bound register bnd. The second operand must be a memory operand.\n   The content of the base register from the memory operand is stored in the\n   lower bound bnd.LB. The 1's complement of the effective address of m32/m64\n   is stored in the upper bound b.UB. Computation of m32/m64 has identical\n   behavior to LEA.\n\n   This instruction does not cause any memory access, and does not read or\n   write any flags.\n\n   If the instruction did not specify base register, the lower bound will be\n   zero. The reg-reg form of this instruction retains legacy behavior (NOP).\n\n   The instruction causes an invalid-opcode exception (#UD) if executed in\n   64-bit mode with RIP-relative addressing.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["packuswb", "                    PACKUSWB \u2014 Pack With Unsigned Saturation\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Converts 4 signed word    \n                                                    integers from mm and 4    \n   NP 0F 67 /r^1 PACKUSWB  A     V/V       MMX      signed word integers from \n   mm, mm/m64                                       mm/m64 into 8 unsigned    \n                                                    byte integers in mm using \n                                                    unsigned saturation.      \n                                                    Converts 8 signed word    \n                                                    integers from xmm1 and 8  \n   66 0F 67 /r PACKUSWB                             signed word integers from \n   xmm1, xmm2/m128         A     V/V       SSE2     xmm2/m128 into 16         \n                                                    unsigned byte integers in \n                                                    xmm1 using unsigned       \n                                                    saturation.               \n                                                    Converts 8 signed word    \n                                                    integers from xmm2 and 8  \n   VEX.128.66.0F.WIG 67 /r                          signed word integers from \n   VPACKUSWB xmm1, xmm2,   B     V/V       AVX      xmm3/m128 into 16         \n   xmm3/m128                                        unsigned byte integers in \n                                                    xmm1 using unsigned       \n                                                    saturation.               \n                                                    Converts 16 signed word   \n                                                    integers from ymm2 and    \n   VEX.256.66.0F.WIG 67 /r                          16signed word integers    \n   VPACKUSWB ymm1, ymm2,   B     V/V       AVX2     from ymm3/m256 into 32    \n   ymm3/m256                                        unsigned byte integers in \n                                                    ymm1 using unsigned       \n                                                    saturation.               \n                                                    Converts signed word      \n   EVEX.128.66.0F.WIG 67                            integers from xmm2 and    \n   /r VPACKUSWB                            AVX512VL signed word integers from \n   xmm1{k1}{z}, xmm2,      C     V/V       AVX512BW xmm3/m128 into unsigned   \n   xmm3/m128                                        byte integers in xmm1     \n                                                    using unsigned saturation \n                                                    under writemask k1.       \n                                                    Converts signed word      \n   EVEX.256.66.0F.WIG 67                            integers from ymm2 and    \n   /r VPACKUSWB                            AVX512VL signed word integers from \n   ymm1{k1}{z}, ymm2,      C     V/V       AVX512BW ymm3/m256 into unsigned   \n   ymm3/m256                                        byte integers in ymm1     \n                                                    using unsigned saturation \n                                                    under writemask k1.       \n                                                    Converts signed word      \n   EVEX.512.66.0F.WIG 67                            integers from zmm2 and    \n   /r VPACKUSWB                                     signed word integers from \n   zmm1{k1}{z}, zmm2,      C     V/V       AVX512BW zmm3/m512 into unsigned   \n   zmm3/m512                                        byte integers in zmm1     \n                                                    using unsigned saturation \n                                                    under writemask k1.       \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Converts 4, 8, 16, or 32 signed word integers from the destination operand\n   (first operand) and 4, 8, 16, or 32 signed word integers from the source\n   operand (second operand) into 8, 16, 32 or 64 unsigned byte integers and\n   stores the result in the destination operand. (See Figure 4-6 for an\n   example of the packing operation.) If a signed word integer value is\n   beyond the range of an unsigned byte integer (that is, greater than FFH or\n   less than 00H), the saturated unsigned byte integer value of FFH or 00H,\n   respectively, is stored in the destination.\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand is a ZMM register or a 512-bit memory location. The\n   destination operand is a ZMM register.\n\n   VEX.256 and EVEX.256 encoded versions: The first source operand is a YMM\n   register. The second source operand is a YMM register or a 256-bit memory\n   location. The destination operand is a YMM register. The upper bits\n   (MAXVL-1:256) of the corresponding ZMM register destination are zeroed.\n\n   VEX.128 and EVEX.128 encoded versions: The first source operand is an XMM\n   register. The second source operand is an XMM register or 128-bit memory\n   location. The destination operand is an XMM register. The upper bits\n   (MAXVL-1:128) of the corresponding register destination are zeroed.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding register destination are\n   unmodified.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["encodekey256", "               ENCODEKEY256 \u2014 Encode 256-Bit Key With Key Locker\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                          Flag    \n   F3 0F 38 FB 11:rrr:bbb                         Wrap a 256-bit AES key from \n   ENCODEKEY256 r32, r32  A     V/V       AESKLE  XMM1:XMM0 into a key handle \n   <XMM0-6>                                       and store it in XMM0\u20143.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operands 3\u20144       Operands 5\u20149    \n   A     N/A   ModRM:reg (w) ModRM:r/m (r) Implicit XMM0\u20141    Implicit XMM2\u20146 \n                                           (r, w)             (w)             \n\nDescription \u00b6\n\n   The ENCODEKEY256^1 instruction wraps a 256-bit AES key from the implicit\n   operand XMM1:XMM0 into a key handle that is then stored in the implicit\n   destination operands XMM0-3.\n\n   The explicit source operand is a general-purpose register and specifies\n   what handle restrictions should be built into the handle.\n\n   The explicit destination operand is populated with information on the\n   source of the key and its attributes. XMM4 through XMM6 are reserved for\n   future usages and software should not rely upon them being zeroed.\n\nFlags Affected \u00b6\n\n   All arithmetic flags (OF, SF, ZF, AF, PF, CF) are cleared to 0. Although\n   they are cleared for the currently defined operations, future extensions\n   may report information in the flags.\n"],
	["vpcompressb:vcompressw", "   VPCOMPRESSB/VCOMPRESSW \u2014 Store Sparse Packed Byte/Word Integer Values Into\n                              DenseMemory/Register\n\n                                  64/32 bit CPUID Feature                     \n   Opcode/Instruction       Op/En Mode      Flag          Description\n                                  Support   \n                                                          Compress up to 128  \n   EVEX.128.66.0F38.W0 63                   AVX512_VBMI2  bits of packed byte \n   /r VPCOMPRESSB m128{k1}, A     V/V       AVX512VL      values from xmm1 to \n   xmm1                                                   m128 with writemask \n                                                          k1.                 \n                                                          Compress up to 128  \n   EVEX.128.66.0F38.W0 63                   AVX512_VBMI2  bits of packed byte \n   /r VPCOMPRESSB           B     V/V       AVX512VL      values from xmm2 to \n   xmm1{k1}{z}, xmm2                                      xmm1 with writemask \n                                                          k1.                 \n                                                          Compress up to 256  \n   EVEX.256.66.0F38.W0 63                   AVX512_VBMI2  bits of packed byte \n   /r VPCOMPRESSB m256{k1}, A     V/V       AVX512VL      values from ymm1 to \n   ymm1                                                   m256 with writemask \n                                                          k1.                 \n                                                          Compress up to 256  \n   EVEX.256.66.0F38.W0 63                   AVX512_VBMI2  bits of packed byte \n   /r VPCOMPRESSB           B     V/V       AVX512VL      values from ymm2 to \n   ymm1{k1}{z}, ymm2                                      ymm1 with writemask \n                                                          k1.                 \n                                                          Compress up to 512  \n   EVEX.512.66.0F38.W0 63                                 bits of packed byte \n   /r VPCOMPRESSB m512{k1}, A     V/V       AVX512_VBMI2  values from zmm1 to \n   zmm1                                                   m512 with writemask \n                                                          k1.                 \n                                                          Compress up to 512  \n   EVEX.512.66.0F38.W0 63                                 bits of packed byte \n   /r VPCOMPRESSB           B     V/V       AVX512_VBMI2  values from zmm2 to \n   zmm1{k1}{z}, zmm2                                      zmm1 with writemask \n                                                          k1.                 \n                                                          Compress up to 128  \n   EVEX.128.66.0F38.W1 63                   AVX512_VBMI2  bits of packed word \n   /r VPCOMPRESSW m128{k1}, A     V/V       AVX512VL      values from xmm1 to \n   xmm1                                                   m128 with writemask \n                                                          k1.                 \n                                                          Compress up to 128  \n   EVEX.128.66.0F38.W1 63                   AVX512_VBMI2  bits of packed word \n   /r VPCOMPRESSW           B     V/V       AVX512VL      values from xmm2 to \n   xmm1{k1}{z}, xmm2                                      xmm1 with writemask \n                                                          k1.                 \n                                                          Compress up to 256  \n   EVEX.256.66.0F38.W1 63                   AVX512_VBMI2  bits of packed word \n   /r VPCOMPRESSW m256{k1}, A     V/V       AVX512VL      values from ymm1 to \n   ymm1                                                   m256 with writemask \n                                                          k1.                 \n                                                          Compress up to 256  \n   EVEX.256.66.0F38.W1 63                   AVX512_VBMI2  bits of packed word \n   /r VPCOMPRESSW           B     V/V       AVX512VL      values from ymm2 to \n   ymm1{k1}{z}, ymm2                                      ymm1 with writemask \n                                                          k1.                 \n                                                          Compress up to 512  \n   EVEX.512.66.0F38.W1 63                                 bits of packed word \n   /r VPCOMPRESSW m512{k1}, A     V/V       AVX512_VBMI2  values from zmm1 to \n   zmm1                                                   m512 with writemask \n                                                          k1.                 \n                                                          Compress up to 512  \n   EVEX.512.66.0F38.W1 63                                 bits of packed word \n   /r VPCOMPRESSW           B     V/V       AVX512_VBMI2  values from zmm2 to \n   zmm1{k1}{z}, zmm2                                      zmm1 with writemask \n                                                          k1.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple         Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   B     N/A           ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   Compress (stores) up to 64 byte values or 32 word values from the source\n   operand (second operand) to the destination operand (first operand), based\n   on the active elements determined by the writemask operand. Note:\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   Moves up to 512 bits of packed byte values from the source operand (second\n   operand) to the destination operand (first operand). This instruction is\n   used to store partial contents of a vector register into a byte vector or\n   single memory location using the active elements in operand writemask.\n\n   Memory destination version: Only the contiguous vector is written to the\n   destination memory location. EVEX.z must be zero.\n\n   Register destination version: If the vector length of the contiguous\n   vector is less than that of the input vector in the source operand, the\n   upper bits of the destination register are unmodified if EVEX.z is not\n   set, otherwise the upper bits are zeroed.\n\n   This instruction supports memory fault suppression.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["vp4dpwssds", "      VP4DPWSSDS \u2014 Dot Product of Signed Words With Dword Accumulation and\n                            Saturation(4-Iterations)\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply signed words \n                                                        from source register  \n   EVEX.512.F2.0F38.W0 53                               block indicated by    \n   /r VP4DPWSSDS                                        zmm2 by signed words  \n   zmm1{k1}{z}, zmm2+3,   A     V/V       AVX512_4VNNIW from m128 and         \n   m128                                                 accumulate the        \n                                                        resulting dword       \n                                                        results with signed   \n                                                        saturation in zmm1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4          \n   A Tuple1_4X ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   This instruction computes 4 sequential register source-block dot-products\n   of two signed word operands with doubleword accumulation and signed\n   saturation. The memory operand is sequentially selected in each of the\n   four steps.\n\n   In the above box, the notation of \u201c+3\u201d is used to denote that the\n   instruction accesses 4 source registers based on that operand; sources are\n   consecutive, start in a multiple of 4 boundary, and contain the encoded\n   register operand.\n\n   This instruction supports memory fault suppression. The entire memory\n   operand is loaded if any bit of the lowest 16-bits of the mask is set to 1\n   or if a \u201cno masking\u201d encoding is used.\n\n   The tuple type Tuple1_4X implies that four 32-bit elements (16 bytes) are\n   referenced by the memory operation portion of this instruction.\n"],
	["vzeroupper", "             VZEROUPPER \u2014 Zero Upper Bits of YMM and ZMM Registers\n\n                             64/32 bit    CPUID                               \n   Opcode/Instruction Op /En Mode Support Feature Description\n                                          Flag    \n   VEX.128.0F.WIG 77                              Zero bits in positions 128  \n   VZEROUPPER         ZO     V/V          AVX     and higher of some YMM and  \n                                                  ZMM registers.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   In 64-bit mode, the instruction zeroes the bits in positions 128 and\n   higher in YMM0-YMM15 and ZMM0-ZMM15. Outside 64-bit mode, it zeroes those\n   bits only in YMM0-YMM7 and ZMM0-ZMM7. VZEROUPPER does not modify the lower\n   128 bits of these registers and it does not modify ZMM16-ZMM31.\n\n   This instruction is recommended when transitioning between AVX and legacy\n   SSE code; it will eliminate performance penalties caused by false\n   dependencies.\n\n   Note: VEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD. In Compatibility and legacy 32-bit mode only the lower 8 registers\n   are modified.\n"],
	["movntpd", "MOVNTPD \u2014 Store Packed Double Precision Floating-Point Values Using Non-Temporal\n                                      Hint\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Move packed double         \n   66 0F 2B /r MOVNTPD     A    V/V       SSE2     precision values in xmm1   \n   m128, xmm1                                      to m128 using non-temporal \n                                                   hint.                      \n                                                   Move packed double         \n   VEX.128.66.0F.WIG 2B /r A    V/V       AVX      precision values in xmm1   \n   VMOVNTPD m128, xmm1                             to m128 using non-temporal \n                                                   hint.                      \n                                                   Move packed double         \n   VEX.256.66.0F.WIG 2B /r A    V/V       AVX      precision values in ymm1   \n   VMOVNTPD m256, ymm1                             to m256 using non-temporal \n                                                   hint.                      \n                                                   Move packed double         \n   EVEX.128.66.0F.W1 2B /r B    V/V       AVX512VL precision values in xmm1   \n   VMOVNTPD m128, xmm1                    AVX512F  to m128 using non-temporal \n                                                   hint.                      \n                                                   Move packed double         \n   EVEX.256.66.0F.W1 2B /r B    V/V       AVX512VL precision values in ymm1   \n   VMOVNTPD m256, ymm1                    AVX512F  to m256 using non-temporal \n                                                   hint.                      \n                                                   Move packed double         \n   EVEX.512.66.0F.W1 2B /r B    V/V       AVX512F  precision values in zmm1   \n   VMOVNTPD m512, zmm1                             to m512 using non-temporal \n                                                   hint.                      \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. ModRM.MOD != 011B\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   B     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the packed double precision floating-point values in the source\n   operand (second operand) to the destination operand (first operand) using\n   a non-temporal hint to prevent caching of the data during the write to\n   memory. The source operand is an XMM register, YMM register or ZMM\n   register, which is assumed to contain packed double precision,\n   floating-pointing data. The destination operand is a 128-bit, 256-bit or\n   512-bit memory location. The memory operand must be aligned on a 16-byte\n   (128-bit version), 32-byte (VEX.256 encoded version) or 64-byte (EVEX.512\n   encoded version) boundary otherwise a general-protection exception (#GP)\n   will be generated.\n\n   The non-temporal hint is implemented by using a write combining (WC)\n   memory type protocol when writing the data to memory. Using this protocol,\n   the processor does not write the data into the cache hierarchy, nor does\n   it fetch the corresponding cache line from memory into the cache\n   hierarchy. The memory type of the region being written to can override the\n   non-temporal hint, if the memory address specified for the non-temporal\n   store is in an uncacheable (UC) or write protected (WP) memory region. For\n   more information on non-temporal stores, see \u201cCaching of Temporal vs.\n   Non-Temporal Data\u201d in Chapter 10 in the IA-32 Intel Architecture Software\n   Developer\u2019s Manual, Volume 1.\n\n   Because the WC protocol uses a weakly-ordered memory consistency model, a\n   fencing operation implemented with the SFENCE or MFENCE instruction should\n   be used in conjunction with MOVNTPD instructions if multiple processors\n   might use different memory types to read/write the destination memory\n   locations.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, VEX.L must be\n   0; otherwise instructions will #UD.\n"],
	["setssbsy", "                       SETSSBSY \u2014 Mark Shadow Stack Busy\n\n                              64/32 bit    CPUID                              \n   Opcode/Instruction   Op/En Mode Support Feature Description\n                                           Flag    \n                                                   Set busy flag in           \n   F3 0F 01 E8 SETSSBSY ZO    V/V          CET_SS  supervisor shadow stack    \n                                                   token reference by         \n                                                   IA32_PL0_SSP.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The SETSSBSY instruction verifies the presence of a non-busy supervisor\n   shadow stack token at the address in the IA32_PL0_SSP MSR and marks it\n   busy. Following successful execution of the instruction, the SSP is set to\n   the value of the IA32_PL0_SSP MSR.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vexpandpd", "VEXPANDPD \u2014 Load Sparse Packed Double Precision Floating-Point Values From Dense\n                                     Memory\n\n                                64/32 Bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n   EVEX.128.66.0F38.W1 88                          Expand packed double       \n   /r VEXPANDPD xmm1      A     V/V       AVX512VL precision floating-point   \n   {k1}{z}, xmm2/m128                     AVX512F  values from xmm2/m128 to   \n                                                   xmm1 using writemask k1.   \n   EVEX.256.66.0F38.W1 88                          Expand packed double       \n   /r VEXPANDPD ymm1      A     V/V       AVX512VL precision floating-point   \n   {k1}{z}, ymm2/m256                     AVX512F  values from ymm2/m256 to   \n                                                   ymm1 using writemask k1.   \n   EVEX.512.66.0F38.W1 88                          Expand packed double       \n   /r VEXPANDPD zmm1      A     V/V       AVX512F  precision floating-point   \n   {k1}{z}, zmm2/m512                              values from zmm2/m512 to   \n                                                   zmm1 using writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Expand (load) up to 8/4/2, contiguous, double precision floating-point\n   values of the input vector in the source operand (the second operand) to\n   sparse elements in the destination operand (the first operand) selected by\n   the writemask k1.\n\n   The destination operand is a ZMM/YMM/XMM register, the source operand can\n   be a ZMM/YMM/XMM register or a 512/256/128-bit memory location.\n\n   The input vector starts from the lowest element in the source operand. The\n   writemask register k1 selects the destination elements (a partial vector\n   or sparse elements if less than 8 elements) to be replaced by the\n   ascending elements in the input vector. Destination elements not selected\n   by the writemask k1 are either unmodified or zeroed, depending on EVEX.z.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["unpcklps", "  UNPCKLPS \u2014 Unpack and Interleave Low Packed Single Precision Floating-Point\n                                     Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Unpacks and Interleaves    \n   NP 0F 14 /r UNPCKLPS                            single precision           \n   xmm1, xmm2/m128         A    V/V       SSE      floating-point values from \n                                                   low quadwords of xmm1 and  \n                                                   xmm2/m128.                 \n                                                   Unpacks and Interleaves    \n   VEX.128.0F.WIG 14 /r                            single precision           \n   VUNPCKLPS xmm1,xmm2,    B    V/V       AVX      floating-point values from \n   xmm3/m128                                       low quadwords of xmm2 and  \n                                                   xmm3/m128.                 \n                                                   Unpacks and Interleaves    \n   VEX.256.0F.WIG 14 /r                            single precision           \n   VUNPCKLPS               B    V/V       AVX      floating-point values from \n   ymm1,ymm2,ymm3/m256                             low quadwords of ymm2 and  \n                                                   ymm3/m256.                 \n                                                   Unpacks and Interleaves    \n                                                   single precision           \n   EVEX.128.0F.W0 14 /r                   AVX512VL floating-point values from \n   VUNPCKLPS xmm1 {k1}{z}, C    V/V       AVX512F  low quadwords of xmm2 and  \n   xmm2, xmm3/m128/m32bcst                         xmm3/mem and write result  \n                                                   to xmm1 subject to write   \n                                                   mask k1.                   \n                                                   Unpacks and Interleaves    \n                                                   single precision           \n   EVEX.256.0F.W0 14 /r                   AVX512VL floating-point values from \n   VUNPCKLPS ymm1 {k1}{z}, C    V/V       AVX512F  low quadwords of ymm2 and  \n   ymm2, ymm3/m256/m32bcst                         ymm3/mem and write result  \n                                                   to ymm1 subject to write   \n                                                   mask k1.                   \n                                                   Unpacks and Interleaves    \n                                                   single precision           \n   EVEX.512.0F.W0 14 /r                            floating-point values from \n   VUNPCKLPS zmm1 {k1}{z}, C    V/V       AVX512F  low quadwords of zmm2 and  \n   zmm2, zmm3/m512/m32bcst                         zmm3/m512/m32bcst and      \n                                                   write result to zmm1       \n                                                   subject to write mask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs an interleaved unpack of the low single precision floating-point\n   values from the first source operand and the second source operand.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified. When unpacking from a memory\n   operand, an implementation may fetch only the appropriate 64 bits;\n   however, alignment to 16-byte boundary and normal segment checking will\n   still be enforced.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   X7 X6 X5 X4 X3 X2 X1 X0 SRC2 Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 DEST Y5 X5 Y4 X4 Y1\n   X1 Y0 X0 Figure 4-28. VUNPCKLPS Operation\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand is a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register, a 256-bit memory location, or a\n   256-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a YMM register, conditionally updated using writemask k1.\n\n   EVEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is a XMM register, a 128-bit memory location, or a\n   128-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a XMM register, conditionally updated using writemask k1.\n"],
	["fmul:fmulp:fimul", "                          FMUL/FMULP/FIMUL \u2014 Multiply\n\n   Opcode  Instruction  64-Bit Compat/Leg Mode Description                    \n                        Mode   \n   D8 /1   FMUL m32fp   Valid  Valid           Multiply ST(0) by m32fp and    \n                                               store result in ST(0).         \n   DC /1   FMUL m64fp   Valid  Valid           Multiply ST(0) by m64fp and    \n                                               store result in ST(0).         \n   D8 C8+i FMUL ST(0),  Valid  Valid           Multiply ST(0) by ST(i) and    \n           ST(i)                               store result in ST(0).         \n   DC C8+i FMUL ST(i),  Valid  Valid           Multiply ST(i) by ST(0) and    \n           ST(0)                               store result in ST(i).         \n           FMULP ST(i),                        Multiply ST(i) by ST(0), store \n   DE C8+i ST(0)        Valid  Valid           result in ST(i), and pop the   \n                                               register stack.                \n                                               Multiply ST(1) by ST(0), store \n   DE C9   FMULP        Valid  Valid           result in ST(1), and pop the   \n                                               register stack.                \n   DA /1   FIMUL m32int Valid  Valid           Multiply ST(0) by m32int and   \n                                               store result in ST(0).         \n   DE /1   FIMUL m16int Valid  Valid           Multiply ST(0) by m16int and   \n                                               store result in ST(0).         \n\nDescription \u00b6\n\n   Multiplies the destination and source operands and stores the product in\n   the destination location. The destination operand is always an FPU data\n   register; the source operand can be an FPU data register or a memory\n   location. Source operands in memory can be in single precision or double\n   precision floating-point format or in word or doubleword integer format.\n\n   The no-operand version of the instruction multiplies the contents of the\n   ST(1) register by the contents of the ST(0) register and stores the\n   product in the ST(1) register. The one-operand version multiplies the\n   contents of the ST(0) register by the contents of a memory location\n   (either a floating-point or an integer value) and stores the product in\n   the ST(0) register. The two-operand version, multiplies the contents of\n   the ST(0) register by the contents of the ST(i) register, or vice versa,\n   with the result being stored in the register specified with the first\n   operand (the destination operand).\n\n   The FMULP instructions perform the additional operation of popping the FPU\n   register stack after storing the product. To pop the register stack, the\n   processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1. The no-operand version of the floating-point multiply\n   instructions always results in the register stack being popped. In some\n   assemblers, the mnemonic for this instruction is FMUL rather than FMULP.\n\n   The FIMUL instructions convert an integer source operand to double\n   extended-precision floating-point format before performing the\n   multiplication.\n\n   The sign of the result is always the exclusive-OR of the source signs,\n   even if one or more of the values being multiplied is 0 or \u221e. When the\n   source operand is an integer 0, it is treated as a +0.\n\n   The following table shows the results obtained when multiplying various\n   classes of numbers, assuming that neither overflow nor underflow occurs.\n\n   DEST\n           \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n       \u2212\u221e  +\u221e  +\u221e  *   *   \u2212\u221e  \u2212\u221e  NaN \n       \u2212F  +\u221e  +F  +0  \u22120  \u2212F  \u2212\u221e  NaN \n       \u2212I  +\u221e  +F  +0  \u22120  \u2212F  \u2212\u221e  NaN \n   SRC \u22120  *   +0  +0  \u22120  \u22120  *   NaN \n       +0  *   \u22120  \u22120  +0  +0  *   NaN \n       +I  \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n       +F  \u2212\u221e  \u2212F  \u22120  +0  +F  +\u221e  NaN \n       +\u221e  \u2212\u221e  \u2212\u221e  *   *   +\u221e  +\u221e  NaN \n       NaN NaN NaN NaN NaN NaN NaN NaN \n\n   Table 3-29. FMUL/FMULP/FIMUL Results\n\n     F Means finite floating-point value.\n\n     I Means Integer.\n\n     * Indicatesinvalid-arithmetic-operand(#IA)exception.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["eblock", "                     EBLOCK \u2014 Mark a page in EPC as Blocked\n\n                                 64/32 bit    CPUID                           \n   Opcode/Instruction      Op/En Mode Support Feature Description\n                                              Flag    \n                                                      This leaf function      \n   EAX = 09H ENCLS[EBLOCK] IR    V/V          SGX1    marks a page in the EPC \n                                                      as blocked.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                                 RCX                              \n   IR    EBLOCK (In) Return error code (Out) Effective address of the EPC     \n                                             page (In)                        \n\n  Description \u00b6\n\n   This leaf function causes an EPC page to be marked as BLOCKED. This\n   instruction can only be executed when current privilege level is 0.\n\n   The content of RCX is an effective address of an EPC page. The DS segment\n   is used to create linear address. Segment override is not supported.\n\n   An error code is returned in RAX.\n\n   The table below provides additional information on the memory parameter of\n   EBLOCK leaf function.\n\nEBLOCK Memory Parameter Semantics \u00b6\n\n   EPCPAGE                                \n   Read/Write access permitted by Enclave \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EBLOCK successful.                             \n                               Page already blocked. This value is used to    \n                               indicate to a VMM that the page was already in \n   SGX_BLKSTATE                BLOCKED state as a result of EBLOCK and thus   \n                               will need to be restored to this state when it \n                               is eventually reloaded (using ELDB).           \n                               SECS locked for Entry Epoch update. This value \n   SGX_ENTRYEPOCH_LOCKED       indicates that an ETRACK is currently          \n                               executing on the SECS. The EBLOCK should be    \n                               reattempted.                                   \n   SGX_NOTBLOCKABLE            Page type is not one which can be blocked.     \n   SGX_PG_INVLD                Page is not valid and cannot be blocked.       \n   SGX_EPC_PAGE_CONFLICT       Page is being written by EADD, EAUG, ECREATE,  \n                               ELDU/B, EMODT, or EWB.                         \n\n   Table 38-12. EBLOCK Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                          Base Concurrency Restrictions\n   Leaf   Parameter       Access On Conflict   SGX_CONFLICT VM Exit           \n                                               Qualification                  \n   EBLOCK Target [DS:RCX] Shared SGX_EPC_PAGE_ \n                                 CONFLICT      \n\n   Table 38-13. Base Concurrency Restrictions of EBLOCK\n\n                    Additional Concurrency Restrictions\n                    vs. EACCEPT, EACCEPTCOPY, vs.  vs. EADD,                 \n                    EADD, EEXTEND, EINIT vs.       EEXTEND, EINIT            \n                    ETRACK, ETRACKC Access vs.     vs. EADD,      vs. ETRACK,\n                    ETRACK, ETRACKC Access On      EEXTEND, EINIT ETRACKC\n   Leaf   Parameter Conflict Access vs. ETRACK,    vs. ETRACK,  \n                    ETRACKC Access On Conflict     ETRACKC      \n                    EMODPE, EMODPR, EMODT       \n                    Access On Conflict Access   \n                    On Conflict Access Access   \n                    On Conflict Access On       \n                    Conflict                    \n   EBLOCK Target    Concurrent                     Concurrent     Concurrent \n          [DS:RCX]  \n\n   Table 38-14. Additional Concurrency Restrictions of EBLOCK\n\n  Flags Affected \u00b6\n\n   Sets ZF if SECS is in use or invalid, otherwise cleared. Sets CF if page\n   is BLOCKED or not blockable, otherwise cleared. Clears PF, AF, OF, SF.\n"],
	["eadd", "                 EADD \u2014 Add a Page to an Uninitialized Enclave\n\n   Opcode/Instruction    Op/En 64/32 bit    CPUID        Description          \n                               Mode Support Feature Flag \n                                                         This leaf function   \n   EAX = 01H ENCLS[EADD] IR    V/V          SGX1         adds a page to an    \n                                                         uninitialized        \n                                                         enclave.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX       RBX                   RCX                                  \n   IR    EADD (In) Address of a PAGEINFO Address of the destination EPC page  \n                   (In)                  (In)                                 \n\n  Description \u00b6\n\n   This leaf function copies a source page from non-enclave memory into the\n   EPC, associates the EPC page with an SECS page residing in the EPC, and\n   stores the linear address and security attributes in EPCM. As part of the\n   association, the enclave offset and the security attributes are measured\n   and extended into the SECS.MRENCLAVE. This instruction can only be\n   executed when current privilege level is 0.\n\n   RBX contains the effective address of a PAGEINFO structure while RCX\n   contains the effective address of an EPC page. The table below provides\n   additional information on the memory parameter of EADD leaf function.\n\nEADD Memory Parameter Semantics \u00b6\n\n   PAGEINFO    PAGEINFO.SECS     PAGEINFO.SRCPGE  PAGEINFO.SECINFO EPCPAGE    \n   Read access Read/Write access Read access      Read access      Write      \n   permitted   permitted by      permitted by Non permitted by Non access     \n   by Non      Enclave           Enclave          Enclave          permitted  \n   Enclave                                                         by Enclave \n\n   The instruction faults if any of the following:\n\nEADD Faulting Conditions \u00b6\n\n   The operands are not properly  Unsupported security attributes are set.    \n   aligned.                       \n   Refers to an invalid SECS.     Reference is made to an SECS that is locked \n                                  by another thread.                          \n   The EPC page is locked by      RCX does not contain an effective address   \n   another thread.                of an EPC page.                             \n                                  If security attributes specifies a TCS and  \n   The EPC page is already valid. the source page specifies unsupported TCS   \n                                  values or fields.                           \n   The SECS has been initialized. The specified enclave offset is outside of  \n                                  the enclave address space.                  \n\n  Concurrency Restrictions \u00b6\n\n                              Base Concurrency Restrictions\n   Leaf Parameter             Access    On       SGX_CONFLICT VM Exit         \n                                        Conflict Qualification                \n        Target [DS:RCX]       Exclusive #GP      EPC_PAGE_CONFLICT_EXCEPTION  \n   EADD SECS                  Shared    #GP      \n        [DS:RBX]PAGEINFO.SECS \n\n   Table 38-8. Base Concurrency Restrictions of EADD\n\n                           Additional Concurrency Restrictions\n                           vs. EACCEPT,                                       \n                           EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\nLeaf Parameter             EMODPE, EMODPR,     EINIT\n                           EMODT      \n                           Access     On       Access     On       Access     On       \n                                      Conflict            Conflict            Conflict \n     Target [DS:RCX]       Concurrent          Concurrent          Concurrent \nEADD SECS                  Concurrent          Exclusive  #GP      Concurrent \n     [DS:RBX]PAGEINFO.SECS \n\n   Table 38-9. Additional Concurrency Restrictions of EADD\n\n  Flags Affected \u00b6\n\n   None\n"],
	["aesdec256kl", "  AESDEC256KL \u2014 Perform 14 Rounds of AES Decryption Flow With Key Locker Using\n                                  256-Bit Key\n\n                               64/32-bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                                         Flag    \n   F3 0F 38 DF                                   Decrypt xmm using 256-bit    \n   !(11):rrr:bbb         A     V/V       AESKLE  AES key indicated by handle  \n   AESDEC256KL xmm, m512                         at m512 and store result in  \n                                                 xmm.                         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3 Operand 4 \n   A     N/A   ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   The AESDEC256KL^1 instruction performs 14 rounds of AES to decrypt the\n   first operand using the 256-bit key indicated by the handle from the\n   second operand. It stores the result in the first operand if the operation\n   succeeds (e.g., does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n"],
	["vcvtps2qq", "  VCVTPS2QQ \u2014 Convert Packed Single Precision Floating-Point Values to Packed\n                         SignedQuadword Integer Values\n\n                           Op / 64/32 Bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Convert two packed single  \n                                                   precision floating-point   \n   EVEX.128.66.0F.W0 7B /r                AVX512VL values from                \n   VCVTPS2QQ xmm1 {k1}{z}, A    V/V       AVX512DQ xmm2/m64/m32bcst to two    \n   xmm2/m64/m32bcst                                packed signed quadword     \n                                                   values in xmm1 subject to  \n                                                   writemask k1.              \n                                                   Convert four packed single \n                                                   precision floating-point   \n   EVEX.256.66.0F.W0 7B /r                AVX512VL values from                \n   VCVTPS2QQ ymm1 {k1}{z}, A    V/V       AVX512DQ xmm2/m128/m32bcst to four  \n   xmm2/m128/m32bcst                               packed signed quadword     \n                                                   values in ymm1 subject to  \n                                                   writemask k1.              \n                                                   Convert eight packed       \n                                                   single precision           \n   EVEX.512.66.0F.W0 7B /r                         floating-point values from \n   VCVTPS2QQ zmm1 {k1}{z}, A    V/V       AVX512DQ ymm2/m256/m32bcst to eight \n   ymm2/m256/m32bcst{er}                           packed signed quadword     \n                                                   values in zmm1 subject to  \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts eight packed single precision floating-point values in the source\n   operand to eight signed quadword integers in the destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (2^w-1, where w\n   represents the number of bits in the destination format) is returned.\n\n   The source operand is a YMM/XMM/XMM (low 64- bits) register or a\n   256/128/64-bit memory location. The destination operation is a ZMM/YMM/XMM\n   register conditionally updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n"],
	["minpd", "        MINPD \u2014 Minimum of Packed Double Precision Floating-Point Values\n\n                              Op 64/32 bit CPUID                              \n   Opcode/Instruction         /  Mode      Feature  Description\n                              En Support   Flag     \n                                                    Return the minimum double \n   66 0F 5D /r MINPD xmm1,    A  V/V       SSE2     precision floating-point  \n   xmm2/m128                                        values between xmm1 and   \n                                                    xmm2/mem                  \n   VEX.128.66.0F.WIG 5D /r                          Return the minimum double \n   VMINPD xmm1, xmm2,         B  V/V       AVX      precision floating-point  \n   xmm3/m128                                        values between xmm2 and   \n                                                    xmm3/mem.                 \n                                                    Return the minimum packed \n   VEX.256.66.0F.WIG 5D /r                          double precision          \n   VMINPD ymm1, ymm2,         B  V/V       AVX      floating-point values     \n   ymm3/m256                                        between ymm2 and          \n                                                    ymm3/mem.                 \n                                                    Return the minimum packed \n                                                    double precision          \n   EVEX.128.66.0F.W1 5D /r                 AVX512VL floating-point values     \n   VMINPD xmm1 {k1}{z}, xmm2, C  V/V       AVX512F  between xmm2 and          \n   xmm3/m128/m64bcst                                xmm3/m128/m64bcst and     \n                                                    store result in xmm1      \n                                                    subject to writemask k1.  \n                                                    Return the minimum packed \n                                                    double precision          \n   EVEX.256.66.0F.W1 5D /r                 AVX512VL floating-point values     \n   VMINPD ymm1 {k1}{z}, ymm2, C  V/V       AVX512F  between ymm2 and          \n   ymm3/m256/m64bcst                                ymm3/m256/m64bcst and     \n                                                    store result in ymm1      \n                                                    subject to writemask k1.  \n                                                    Return the minimum packed \n                                                    double precision          \n   EVEX.512.66.0F.W1 5D /r                          floating-point values     \n   VMINPD zmm1 {k1}{z}, zmm2, C  V/V       AVX512F  between zmm2 and          \n   zmm3/m512/m64bcst{sae}                           zmm3/m512/m64bcst and     \n                                                    store result in zmm1      \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed double precision floating-point\n   values in the first source operand and the second source operand and\n   returns the minimum value for each pair of values to the destination\n   operand.\n\n   If the values being compared are both 0.0s (of either sign), the value in\n   the second operand (source operand) is returned. If a value in the second\n   operand is an SNaN, then SNaN is forwarded unchanged to the destination\n   (that is, a QNaN version of the SNaN is not returned).\n\n   If only one value is a NaN (SNaN or QNaN) for this instruction, the second\n   operand (source operand), either a NaN or a valid floating-point value, is\n   written to the result. If instead of this behavior, it is required that\n   the NaN source operand (from either the first or second operand) be\n   returned, the action of MINPD can be emulated using a sequence of\n   instructions, such as, a comparison followed by AND, ANDN, and OR.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. The upper bits (MAXVL-1:256) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["paddb:paddw:paddd:paddq", "                 PADDB/PADDW/PADDD/PADDQ \u2014 Add Packed Integers\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n   NP 0F FC /r^1 PADDB mm, A    V/V       MMX      Add packed byte integers   \n   mm/m64                                          from mm/m64 and mm.        \n   NP 0F FD /r^1 PADDW mm, A    V/V       MMX      Add packed word integers   \n   mm/m64                                          from mm/m64 and mm.        \n   NP 0F FE /r^1 PADDD mm,                         Add packed doubleword      \n   mm/m64                  A    V/V       MMX      integers from mm/m64 and   \n                                                   mm.                        \n   NP 0F D4 /r^1 PADDQ mm,                         Add packed quadword        \n   mm/m64                  A    V/V       MMX      integers from mm/m64 and   \n                                                   mm.                        \n   66 0F FC /r PADDB xmm1, A    V/V       SSE2     Add packed byte integers   \n   xmm2/m128                                       from xmm2/m128 and xmm1.   \n   66 0F FD /r PADDW xmm1, A    V/V       SSE2     Add packed word integers   \n   xmm2/m128                                       from xmm2/m128 and xmm1.   \n   66 0F FE /r PADDD xmm1,                         Add packed doubleword      \n   xmm2/m128               A    V/V       SSE2     integers from xmm2/m128    \n                                                   and xmm1.                  \n   66 0F D4 /r PADDQ xmm1,                         Add packed quadword        \n   xmm2/m128               A    V/V       SSE2     integers from xmm2/m128    \n                                                   and xmm1.                  \n   VEX.128.66.0F.WIG FC /r                         Add packed byte integers   \n   VPADDB xmm1, xmm2,      B    V/V       AVX      from xmm2, and xmm3/m128   \n   xmm3/m128                                       and store in xmm1.         \n   VEX.128.66.0F.WIG FD /r                         Add packed word integers   \n   VPADDW xmm1, xmm2,      B    V/V       AVX      from xmm2, xmm3/m128 and   \n   xmm3/m128                                       store in xmm1.             \n   VEX.128.66.0F.WIG FE /r                         Add packed doubleword      \n   VPADDD xmm1, xmm2,      B    V/V       AVX      integers from xmm2,        \n   xmm3/m128                                       xmm3/m128 and store in     \n                                                   xmm1.                      \n   VEX.128.66.0F.WIG D4 /r                         Add packed quadword        \n   VPADDQ xmm1, xmm2,      B    V/V       AVX      integers from xmm2,        \n   xmm3/m128                                       xmm3/m128 and store in     \n                                                   xmm1.                      \n   VEX.256.66.0F.WIG FC /r                         Add packed byte integers   \n   VPADDB ymm1, ymm2,      B    V/V       AVX2     from ymm2, and ymm3/m256   \n   ymm3/m256                                       and store in ymm1.         \n   VEX.256.66.0F.WIG FD /r                         Add packed word integers   \n   VPADDW ymm1, ymm2,      B    V/V       AVX2     from ymm2, ymm3/m256 and   \n   ymm3/m256                                       store in ymm1.             \n   VEX.256.66.0F.WIG FE /r                         Add packed doubleword      \n   VPADDD ymm1, ymm2,      B    V/V       AVX2     integers from ymm2,        \n   ymm3/m256                                       ymm3/m256 and store in     \n                                                   ymm1.                      \n   VEX.256.66.0F.WIG D4 /r                         Add packed quadword        \n   VPADDQ ymm1, ymm2,      B    V/V       AVX2     integers from ymm2,        \n   ymm3/m256                                       ymm3/m256 and store in     \n                                                   ymm1.                      \n   EVEX.128.66.0F.WIG FC                           Add packed byte integers   \n   /r VPADDB xmm1 {k1}{z}, C    V/V       AVX512VL from xmm2, and xmm3/m128   \n   xmm2, xmm3/m128                        AVX512BW and store in xmm1 using    \n                                                   writemask k1.              \n   EVEX.128.66.0F.WIG FD                           Add packed word integers   \n   /r VPADDW xmm1 {k1}{z}, C    V/V       AVX512VL from xmm2, and xmm3/m128   \n   xmm2, xmm3/m128                        AVX512BW and store in xmm1 using    \n                                                   writemask k1.              \n                                                   Add packed doubleword      \n   EVEX.128.66.0F.W0 FE /r                AVX512VL integers from xmm2, and    \n   VPADDD xmm1 {k1}{z},    D    V/V       AVX512F  xmm3/m128/m32bcst and      \n   xmm2, xmm3/m128/m32bcst                         store in xmm1 using        \n                                                   writemask k1.              \n                                                   Add packed quadword        \n   EVEX.128.66.0F.W1 D4 /r                AVX512VL integers from xmm2, and    \n   VPADDQ xmm1 {k1}{z},    D    V/V       AVX512F  xmm3/m128/m64bcst and      \n   xmm2, xmm3/m128/m64bcst                         store in xmm1 using        \n                                                   writemask k1.              \n   EVEX.256.66.0F.WIG FC                           Add packed byte integers   \n   /r VPADDB ymm1 {k1}{z}, C    V/V       AVX512VL from ymm2, and ymm3/m256   \n   ymm2, ymm3/m256                        AVX512BW and store in ymm1 using    \n                                                   writemask k1.              \n   EVEX.256.66.0F.WIG FD                           Add packed word integers   \n   /r VPADDW ymm1 {k1}{z}, C    V/V       AVX512VL from ymm2, and ymm3/m256   \n   ymm2, ymm3/m256                        AVX512BW and store in ymm1 using    \n                                                   writemask k1.              \n                                                   Add packed doubleword      \n   EVEX.256.66.0F.W0 FE /r                AVX512VL integers from ymm2,        \n   VPADDD ymm1 {k1}{z},    D    V/V       AVX512F  ymm3/m256/m32bcst and      \n   ymm2, ymm3/m256/m32bcst                         store in ymm1 using        \n                                                   writemask k1.              \n                                                   Add packed quadword        \n   EVEX.256.66.0F.W1 D4 /r                AVX512VL integers from ymm2,        \n   VPADDQ ymm1 {k1}{z},    D    V/V       AVX512F  ymm3/m256/m64bcst and      \n   ymm2, ymm3/m256/m64bcst                         store in ymm1 using        \n                                                   writemask k1.              \n   EVEX.512.66.0F.WIG FC                           Add packed byte integers   \n   /r VPADDB zmm1 {k1}{z}, C    V/V       AVX512BW from zmm2, and zmm3/m512   \n   zmm2, zmm3/m512                                 and store in zmm1 using    \n                                                   writemask k1.              \n   EVEX.512.66.0F.WIG FD                           Add packed word integers   \n   /r VPADDW zmm1 {k1}{z}, C    V/V       AVX512BW from zmm2, and zmm3/m512   \n   zmm2, zmm3/m512                                 and store in zmm1 using    \n                                                   writemask k1.              \n                                                   Add packed doubleword      \n   EVEX.512.66.0F.W0 FE /r                         integers from zmm2,        \n   VPADDD zmm1 {k1}{z},    D    V/V       AVX512F  zmm3/m512/m32bcst and      \n   zmm2, zmm3/m512/m32bcst                         store in zmm1 using        \n                                                   writemask k1.              \n                                                   Add packed quadword        \n   EVEX.512.66.0F.W1 D4 /r                         integers from zmm2,        \n   VPADDQ zmm1 {k1}{z},    D    V/V       AVX512F  zmm3/m512/m64bcst and      \n   zmm2, zmm3/m512/m64bcst                         store in zmm1 using        \n                                                   writemask k1.              \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD add of the packed integers from the source operand (second\n   operand) and the destination operand (first operand), and stores the\n   packed integer results in the destination operand. See Figure 9-4 in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 1,\n   for an illustration of a SIMD operation. Overflow is handled with\n   wraparound, as described in the following paragraphs.\n\n   The PADDB and VPADDB instructions add packed byte integers from the first\n   source operand and second source operand and store the packed integer\n   results in the destination operand. When an individual result is too large\n   to be represented in 8 bits (overflow), the result is wrapped around and\n   the low 8 bits are written to the destination operand (that is, the carry\n   is ignored).\n\n   The PADDW and VPADDW instructions add packed word integers from the first\n   source operand and second source operand and store the packed integer\n   results in the destination operand. When an individual result is too large\n   to\n\n   be represented in 16 bits (overflow), the result is wrapped around and the\n   low 16 bits are written to the destination operand (that is, the carry is\n   ignored).\n\n   The PADDD and VPADDD instructions add packed doubleword integers from the\n   first source operand and second source operand and store the packed\n   integer results in the destination operand. When an individual result is\n   too large to be represented in 32 bits (overflow), the result is wrapped\n   around and the low 32 bits are written to the destination operand (that\n   is, the carry is ignored).\n\n   The PADDQ and VPADDQ instructions add packed quadword integers from the\n   first source operand and second source operand and store the packed\n   integer results in the destination operand. When a quadword result is too\n   large to be represented in 64 bits (overflow), the result is wrapped\n   around and the low 64 bits are written to the destination operand (that\n   is, the carry is ignored).\n\n   Note that the (V)PADDB, (V)PADDW, (V)PADDD and (V)PADDQ instructions can\n   operate on either unsigned or signed (two's complement notation) packed\n   integers; however, it does not set bits in the EFLAGS register to indicate\n   overflow and/or a carry. To prevent undetected overflow conditions,\n   software must control the ranges of values operated on.\n\n   EVEX encoded VPADDD/Q: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register updated\n   according to the write-mask.\n\n   EVEX encoded VPADDB/W: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register updated\n   according to the writemask.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. the upper bits (MAXVL-1:256) of the\n   destination are cleared.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n"],
	["vreducesh", "       VREDUCESH \u2014 Perform Reduction Transformation on Scalar FP16 Value\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En bit     \n   Mode Flag CPUID Feature        \n   Instruction En bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En bit Mode Flag   \n   CPUID Feature Instruction En   \n   bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Perform a reduction   \n                                                        transformation on the \n                                                        low binary encoded    \n                                                        FP16 value in         \n                                                        xmm3/m16 by           \n   EVEX.LLIG.NP.0F3A.W0 57 /r /ib                       subtracting a number  \n   VREDUCESH xmm1{k1}{z}, xmm2,   A V/V     AVX512-FP16 of fraction bits      \n   xmm3/m16 {sae}, imm8                                 specified by the imm8 \n                                                        field. Store the      \n                                                        result in xmm1        \n                                                        subject to writemask  \n                                                        k1. Bits 127:16 from  \n                                                        xmm2 are copied to    \n                                                        xmm1[127:16].         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\n  Description \u00b6\n\n   This instruction performs a reduction transformation of the low binary\n   encoded FP16 value in the source operand (the second operand) and store\n   the reduced result in binary FP format to the low element of the\n   destination operand (the first operand) under the writemask k1. For\n   further details see the description of VREDUCEPH.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n\n   This instruction might end up with a precision exception set. However, in\n   case of SPE set (i.e., Suppress Precision Exception, which is imm8[3]=1),\n   no precision exception is reported.\n\n   This instruction may generate tiny non-zero result. If it does so, it does\n   not report underflow exception, even if underflow exceptions are unmasked\n   (UM flag in MXCSR register is 0).\n\n   For special cases, see Table 5-30.\n"],
	["vpdpbusd", "             VPDPBUSD \u2014 Multiply and Add Unsigned and Signed Bytes\n\n                                64/32 bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply groups of 4  \n                                                        pairs of signed bytes \n                                                        in xmm3/m128 with     \n   VEX.128.66.0F38.W0 50                                corresponding         \n   /r VPDPBUSD xmm1,      A     V/V       AVX-VNNI      unsigned bytes of     \n   xmm2, xmm3/m128                                      xmm2, summing those   \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result in xmm1.       \n                                                        Multiply groups of 4  \n                                                        pairs of signed bytes \n                                                        in ymm3/m256 with     \n   VEX.256.66.0F38.W0 50                                corresponding         \n   /r VPDPBUSD ymm1,      A     V/V       AVX-VNNI      unsigned bytes of     \n   ymm2, ymm3/m256                                      ymm2, summing those   \n                                                        products and adding   \n                                                        them to doubleword    \n                                                        result in ymm1.       \n                                                        Multiply groups of 4  \n                                                        pairs of signed bytes \n                                                        in xmm3/m128/m32bcst  \n   EVEX.128.66.0F38.W0 50                               with corresponding    \n   /r VPDPBUSD            B     V/V       AVX512_VNNI   unsigned bytes of     \n   xmm1{k1}{z}, xmm2,                     AVX512VL      xmm2, summing those   \n   xmm3/m128/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in xmm1 under  \n                                                        writemask k1.         \n                                                        Multiply groups of 4  \n                                                        pairs of signed bytes \n                                                        in ymm3/m256/m32bcst  \n   EVEX.256.66.0F38.W0 50                               with corresponding    \n   /r VPDPBUSD            B     V/V       AVX512_VNNI   unsigned bytes of     \n   ymm1{k1}{z}, ymm2,                     AVX512VL      ymm2, summing those   \n   ymm3/m256/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in ymm1 under  \n                                                        writemask k1.         \n                                                        Multiply groups of 4  \n                                                        pairs of signed bytes \n                                                        in zmm3/m512/m32bcst  \n   EVEX.512.66.0F38.W0 50                               with corresponding    \n   /r VPDPBUSD            B     V/V       AVX512_VNNI   unsigned bytes of     \n   zmm1{k1}{z}, zmm2,                                   zmm2, summing those   \n   zmm3/m512/m32bcst                                    products and adding   \n                                                        them to doubleword    \n                                                        result in zmm1 under  \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A   ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full  ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Multiplies the individual unsigned bytes of the first source operand by\n   the corresponding signed bytes of the second source operand, producing\n   intermediate signed word results. The word results are then summed and\n   accumulated in the destination dword element size operand.\n\n   This instruction supports memory fault suppression.\n"],
	["fprem", "                           FPREM \u2014 Partial Remainder\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Replace ST(0) with the      \n   D9 F8  FPREM       Valid       Valid           remainder obtained from     \n                                                  dividing ST(0) by ST(1).    \n\nDescription \u00b6\n\n   Computes the remainder obtained from dividing the value in the ST(0)\n   register (the dividend) by the value in the ST(1) register (the divisor or\n   modulus), and stores the result in ST(0). The remainder represents the\n   following value:\n\n   Remainder := ST(0) \u2212 (Q \u2217 ST(1))\n\n   Here, Q is an integer value that is obtained by truncating the\n   floating-point number quotient of [ST(0) / ST(1)] toward zero. The sign of\n   the remainder is the same as the sign of the dividend. The magnitude of\n   the remainder is less than that of the modulus, unless a partial remainder\n   was computed (as described below).\n\n   This instruction produces an exact result; the inexact-result exception\n   does not occur and the rounding control has no effect. The following table\n   shows the results obtained when computing the remainder of various classes\n   of numbers, assuming that underflow does not occur.\n\n   ST(1) \n             -\u221e    -F       -0  +0  +F       +\u221e    NaN \n         -\u221e  *     *        *   *   *        *     NaN \n         -F  ST(0) -F or -0 *   *   -F or -0 ST(0) NaN \n   ST(0) -0  -0    -0       *   *   -0       -0    NaN \n         +0  +0    +0       *   *   +0       +0    NaN \n         +F  ST(0) +F or +0 *   *   +F or +0 ST(0) NaN \n         +\u221e  *     *        *   *   *        *     NaN \n         NaN NaN   NaN      NaN NaN NaN      NaN   NaN \n\n   Table 3-31. FPREM Results\n\n     F Meansfinitefloating-pointvalue.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   When the result is 0, its sign is the same as that of the dividend. When\n   the modulus is \u221e, the result is equal to the value in ST(0).\n\n   The FPREM instruction does not compute the remainder specified in IEEE Std\n   754. The IEEE specified remainder can be computed with the FPREM1\n   instruction. The FPREM instruction is provided for compatibility with the\n   Intel 8087 and Intel287 math coprocessors.\n\n   The FPREM instruction gets its name \u201cpartial remainder\u201d because of the way\n   it computes the remainder. This instruction arrives at a remainder through\n   iterative subtraction. It can, however, reduce the exponent of ST(0) by no\n   more than 63 in one execution of the instruction. If the instruction\n   succeeds in producing a remainder that is less than the modulus, the\n   operation is complete and the C2 flag in the FPU status word is cleared.\n   Otherwise, C2 is set, and the result in ST(0) is called the partial\n   remainder. The exponent of the partial remainder will be less than the\n   exponent of the original dividend by at least 32. Software can re-execute\n   the instruction (using the partial remainder in ST(0) as the dividend)\n   until C2 is cleared. (Note that while executing such a\n   remainder-computation loop, a higher-priority interrupting routine that\n   needs the FPU can force a context switch in-between the instructions in\n   the loop.)\n\n   An important use of the FPREM instruction is to reduce the arguments of\n   periodic functions. When reduction is complete, the instruction stores the\n   three least-significant bits of the quotient in the C3, C1, and C0 flags\n   of the FPU\n\n   status word. This information is important in argument reduction for the\n   tangent function (using a modulus of \u03c0/4), because it locates the original\n   angle in the correct one of eight sectors of the unit circle.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C0 Set to bit 2 (Q2) of the quotient.                                      \n   C1 Set to 0 if stack underflow occurred; otherwise, set to least           \n      significant bit of quotient (Q0).                                       \n   C2 Set to 0 if reduction complete; set to 1 if incomplete.                 \n   C3 Set to bit 1 (Q1) of the quotient.                                      \n"],
	["fldcw", "                       FLDCW \u2014 Load x87 FPU Control Word\n\n   Opcode  Mode Leg Mode Description                        \n   D9 /5                 Load FPU control word from m2byte. \n\nDescription \u00b6\n\n   Loads the 16-bit source operand into the FPU control word. The source\n   operand is a memory location. This instruction is typically used to\n   establish or change the FPU\u2019s mode of operation.\n\n   If one or more exception flags are set in the FPU status word prior to\n   loading a new FPU control word and the new control word unmasks one or\n   more of those exceptions, a floating-point exception will be generated\n   upon execution of the next floating-point instruction (except for the\n   no-wait floating-point instructions, see the section titled \u201cSoftware\n   Exception Handling\u201d in Chapter 8 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1). To avoid raising exceptions when\n   changing FPU operating modes, clear any pending exceptions (using the\n   FCLEX or FNCLEX instruction) before loading the new control word.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C0, C1, C2, C3 undefined. \n"],
	["ereport", "             EREPORT \u2014 Create a Cryptographic Report of the Enclave\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n   EAX = 00H                                     This leaf function creates a \n   ENCLU[EREPORT]     IR    V/V          SGX1    cryptographic report of the  \n                                                 enclave.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX          RBX             RCX             RDX                     \n                      Address of      Address of      Address where the       \n   IR    EREPORT (In) TARGETINFO (In) REPORTDATA (In) REPORT is written to in \n                                                      an OUTPUTDATA (In)      \n\n  Description \u00b6\n\n   This leaf function creates a cryptographic REPORT that describes the\n   contents of the enclave. This instruction leaf can only be executed when\n   inside the enclave. The cryptographic report can be used by other enclaves\n   to determine that the enclave is running on the same platform.\n\n   RBX contains the effective address of the MRENCLAVE value of the enclave\n   that will authenticate the REPORT output, using the REPORT key delivered\n   by EGETKEY command for that enclave. RCX contains the effective address of\n   a 64-byte REPORTDATA structure, which allows the caller of the instruction\n   to associate data with the enclave from which the instruction is called.\n   RDX contains the address where the REPORT will be output by the\n   instruction.\n\nEREPORT Memory Parameter Semantics \u00b6\n\n   TARGETINFO             REPORTDATA             OUTPUTDATA                   \n   Read access by Enclave Read access by Enclave Read/Write access by Enclave \n\n   This instruction leaf perform the following:\n\n   1. Validate the 3 operands (RBX, RCX, RDX) are inside the enclave.\n\n   2. Compute a report key for the target enclave, as indicated by the value\n   located in RBX(TARGETINFO).\n\n   3. Assemble the enclave SECS data to complete the REPORT structure\n   (including the data provided using the RCX (REPORTDATA) operand).\n\n   4. Computes a cryptographic hash over REPORT structure.\n\n   5. Add the computed hash to the REPORT structure.\n\n   6. Output the completed REPORT structure to the address in RDX\n   (OUTPUTDATA).\n\n   The instruction fails if the operands are not properly aligned.\n\n   CR_REPORT_KEYID, used to provide key wearout protection, is populated with\n   a statistically unique value on boot of the platform by a trusted entity\n   within the SGX TCB.\n\n   The instruction faults if any of the following:\n\nEREPORT Faulting Conditions \u00b6\n\n   An effective address not properly An memory address does not resolve in an \n   aligned.                          EPC page.                                \n   If accessing an invalid EPC page. If the EPC page is blocked.              \n   May page fault.                   \n\n  Concurrency Restrictions \u00b6\n\n                      Base Concurrency Restrictions\n   Leaf    Parameter  Access     On Conflict SGX_CONFLICT VM Exit             \n                                             Qualification                    \n           TARGETINFO Concurrent \n           [DS:RBX]   \n   EREPORT REPORTDATA Concurrent \n           [DS:RCX]   \n           OUTPUTDATA Concurrent \n           [DS:RDX]   \n\n   Table 38-72. Base Concurrency Restrictions of EREPORT\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT,                                       \n                     EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\n  Leaf    Parameter  EMODPE, EMODPR,     EINIT\n                     EMODT      \n                     Access     On       Access     On       Access     On       \n                                Conflict            Conflict            Conflict \n          TARGETINFO Concurrent          Concurrent          Concurrent \n          [DS:RBX]   \n  EREPORT REPORTDATA Concurrent          Concurrent          Concurrent \n          [DS:RCX]   \n          OUTPUTDATA Concurrent          Concurrent          Concurrent \n          [DS:RDX]   \n\n   Table 38-73. Additional Concurrency Restrictions of EREPORT\n\n  Flags Affected \u00b6\n\n   None\n"],
	["movq", "                              MOVQ \u2014 Move Quadword\n\n                                   64/32-bit CPUID                            \n   Opcode/Instruction       Op/ En Mode      Feature Description\n                                             Flag    \n   NP 0F 6F /r MOVQ mm,     A      V/V       MMX     Move quadword from       \n   mm/m64                                            mm/m64 to mm.            \n   NP 0F 7F /r MOVQ mm/m64, B      V/V       MMX     Move quadword from mm to \n   mm                                                mm/m64.                  \n   F3 0F 7E /r MOVQ xmm1,   A      V/V       SSE2    Move quadword from       \n   xmm2/m64                                          xmm2/mem64 to xmm1.      \n   VEX.128.F3.0F.WIG 7E /r  A      V/V       AVX     Move quadword from xmm2  \n   VMOVQ xmm1, xmm2/m64                              to xmm1.                 \n   EVEX.128.F3.0F.W1 7E /r  C      V/V       AVX512F Move quadword from       \n   VMOVQ xmm1, xmm2/m64                              xmm2/m64 to xmm1.        \n   66 0F D6 /r MOVQ         B      V/V       SSE2    Move quadword from xmm1  \n   xmm2/m64, xmm1                                    to xmm2/mem64.           \n   VEX.128.66.0F.WIG D6 /r  B      V/V       AVX     Move quadword from xmm2  \n   VMOVQ xmm1/m64, xmm2                              register to xmm1/m64.    \n   EVEX.128.66.0F.W1 D6 /r  D      V/V       AVX512F Move quadword from xmm2  \n   VMOVQ xmm1/m64, xmm2                              register to xmm1/m64.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A           ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Copies a quadword from the source operand (second operand) to the\n   destination operand (first operand). The source and destination operands\n   can be MMX technology registers, XMM registers, or 64-bit memory\n   locations. This instruction can be used to move a quadword between two MMX\n   technology registers or between an MMX technology register and a 64-bit\n   memory location, or to move data between two XMM registers or between an\n   XMM register and a 64-bit memory location. The instruction cannot be used\n   to transfer data between memory locations.\n\n   When the source operand is an XMM register, the low quadword is moved;\n   when the destination operand is an XMM register, the quadword is stored to\n   the low quadword of the register, and the high quadword is cleared to all\n   0s.\n\n   In 64-bit mode and if not encoded using VEX/EVEX, use of the REX prefix in\n   the form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   If VMOVQ is encoded with VEX.L= 1, an attempt to execute the instruction\n   encoded with VEX.L= 1 will cause an #UD exception.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcvttph2udq", "      VCVTTPH2UDQ \u2014 Convert with Truncation Packed FP16 Values to Unsigned\n                               DoublewordIntegers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Convert four packed    \n                                                       FP16 values in         \n                                                       xmm2/m64/m16bcst to    \n   EVEX.128.NP.MAP5.W0 78 /r               AVX512-FP16 four unsigned          \n   VCVTTPH2UDQ xmm1{k1}{z},      A V/V     AVX512VL    doubleword integers,   \n   xmm2/m64/m16bcst                                    and store the result   \n                                                       in xmm1 using          \n                                                       truncation subject to  \n                                                       writemask k1.          \n                                                       Convert eight packed   \n                                                       FP16 values in         \n                                                       xmm2/m128/m16bcst to   \n   EVEX.256.NP.MAP5.W0 78 /r               AVX512-FP16 eight unsigned         \n   VCVTTPH2UDQ ymm1{k1}{z},      A V/V     AVX512VL    doubleword integers,   \n   xmm2/m128/m16bcst                                   and store the result   \n                                                       in ymm1 using          \n                                                       truncation subject to  \n                                                       writemask k1.          \n                                                       Convert sixteen packed \n                                                       FP16 values in         \n                                                       ymm2/m256/m16bcst to   \n   EVEX.512.NP.MAP5.W0 78 /r                           sixteen unsigned       \n   VCVTTPH2UDQ zmm1{k1}{z},      A V/V     AVX512-FP16 doubleword integers,   \n   ymm2/m256/m16bcst {sae}                             and store the result   \n                                                       in zmm1 using          \n                                                       truncation subject to  \n                                                       writemask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   unsigned doubleword integers in the destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer indefinite value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["daa", "                     DAA \u2014 Decimal Adjust AL After Addition\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n   27     DAA         ZO    Invalid     Valid           Decimal adjust AL     \n                                                        after addition.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Adjusts the sum of two packed BCD values to create a packed BCD result.\n   The AL register is the implied source and destination operand. The DAA\n   instruction is only useful when it follows an ADD instruction that adds\n   (binary addition) two 2-digit, packed BCD values and stores a byte result\n   in the AL register. The DAA instruction then adjusts the contents of the\n   AL register to contain the correct 2-digit, packed BCD result. If a\n   decimal carry is detected, the CF and AF flags are set accordingly.\n\n   This instruction executes as described above in compatibility mode and\n   legacy mode. It is not valid in 64-bit mode.\n\nExample \u00b6\n\n   ADD AL, BL Before: AL=79H BL=35H EFLAGS(OSZAPC)=XXXXXX\n\n   After: AL=AEH BL=35H EFLAGS(0SZAPC)=110000\n\n   DAA Before: AL=AEH BL=35H EFLAGS(OSZAPC)=110000\n\n   After: AL=14H BL=35H EFLAGS(0SZAPC)=X00111\n\n   DAA Before: AL=2EH BL=35H EFLAGS(OSZAPC)=110000\n\n   After: AL=34H BL=35H EFLAGS(0SZAPC)=X00101\n\nFlags Affected \u00b6\n\n   The CF and AF flags are set if the adjustment of the value results in a\n   decimal carry in either digit of the result (see the \u201cOperation\u201d section\n   above). The SF, ZF, and PF flags are set according to the result. The OF\n   flag is undefined.\n"],
	["pusha:pushad", "               PUSHA/PUSHAD \u2014 Push All General-Purpose Registers\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n                                                        Push AX, CX, DX, BX,  \n   60     PUSHA       ZO    Invalid     Valid           original SP, BP, SI,  \n                                                        and DI.               \n                                                        Push EAX, ECX, EDX,   \n   60     PUSHAD      ZO    Invalid     Valid           EBX, original ESP,    \n                                                        EBP, ESI, and EDI.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Pushes the contents of the general-purpose registers onto the stack. The\n   registers are stored on the stack in the following order: EAX, ECX, EDX,\n   EBX, ESP (original value), EBP, ESI, and EDI (if the current operand-size\n   attribute is 32) and AX, CX, DX, BX, SP (original value), BP, SI, and DI\n   (if the operand-size attribute is 16). These instructions perform the\n   reverse operation of the POPA/POPAD instructions. The value pushed for the\n   ESP or SP register is its value before prior to pushing the first register\n   (see the \u201cOperation\u201d section below).\n\n   The PUSHA (push all) and PUSHAD (push all double) mnemonics reference the\n   same opcode. The PUSHA instruction is intended for use when the\n   operand-size attribute is 16 and the PUSHAD instruction for when the\n   operand-size attribute is 32. Some assemblers may force the operand size\n   to 16 when PUSHA is used and to 32 when PUSHAD is used. Others may treat\n   these mnemonics as synonyms (PUSHA/PUSHAD) and use the current setting of\n   the operand-size attribute to determine the size of values to be pushed\n   from the stack, regardless of the mnemonic used.\n\n   In the real-address mode, if the ESP or SP register is 1, 3, or 5 when\n   PUSHA/PUSHAD executes: an #SS exception is generated but not delivered\n   (the stack error reported prevents #SS delivery). Next, the processor\n   generates a #DF exception and enters a shutdown state as described in the\n   #DF discussion in Chapter 6 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3A.\n\n   This instruction executes as described in compatibility mode and legacy\n   mode. It is not valid in 64-bit mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["ktestw:ktestb:ktestq:ktestd", "       KTESTW/KTESTB/KTESTQ/KTESTD \u2014 Packed Bit Test Masks and Set Flags\n\n                               64/32 bit CPUID                                \n   Opcode/Instruction    Op En Mode      Feature  Description\n                               Support   Flag     \n   VEX.L0.0F.W0 99 /r                             Set ZF and CF depending on  \n   KTESTW k1, k2         RR    V/V       AVX512DQ sign bit AND and ANDN of 16 \n                                                  bits mask register sources. \n   VEX.L0.66.0F.W0 99 /r                          Set ZF and CF depending on  \n   KTESTB k1, k2         RR    V/V       AVX512DQ sign bit AND and ANDN of 8  \n                                                  bits mask register sources. \n   VEX.L0.0F.W1 99 /r                             Set ZF and CF depending on  \n   KTESTQ k1, k2         RR    V/V       AVX512BW sign bit AND and ANDN of 64 \n                                                  bits mask register sources. \n   VEX.L0.66.0F.W1 99 /r                          Set ZF and CF depending on  \n   KTESTD k1, k2         RR    V/V       AVX512BW sign bit AND and ANDN of 32 \n                                                  bits mask register sources. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2                              \n   RR    ModRM:reg (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise comparison of the bits of the first source operand and\n   corresponding bits in the second source operand. If the AND operation\n   produces all zeros, the ZF is set else the ZF is clear. If the bitwise AND\n   operation of the inverted first source operand with the second source\n   operand produces all zeros the CF is set else the CF is clear. Only the\n   EFLAGS register is updated.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["movsx:movsxd", "                    MOVSX/MOVSXD \u2014 Move With Sign-Extension\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n   0F BE /r MOVSX r16,  RM    Valid  Valid      Move byte to word with        \n            r/m8                                sign-extension.               \n   0F BE /r MOVSX r32,  RM    Valid  Valid      Move byte to doubleword with  \n            r/m8                                sign-extension.               \n   REX.W +  MOVSX r64,  RM    Valid  N.E.       Move byte to quadword with    \n   0F BE /r r/m8                                sign-extension.               \n   0F BF /r MOVSX r32,  RM    Valid  Valid      Move word to doubleword, with \n            r/m16                               sign-extension.               \n   REX.W +  MOVSX r64,  RM    Valid  N.E.       Move word to quadword with    \n   0F BF /r r/m16                               sign-extension.               \n   63 /r^1  MOVSXD r16, RM    Valid  N.E.       Move word to word with        \n            r/m16                               sign-extension.               \n   63 /r^1  MOVSXD r32, RM    Valid  N.E.       Move doubleword to doubleword \n            r/m32                               with sign-extension.          \n   REX.W +  MOVSXD r64, RM    Valid  N.E.       Move doubleword to quadword   \n   63 /r    r/m32                               with sign-extension.          \n\n     1. The use of MOVSXD without REX.W in 64-bit mode is discouraged.\n     Regular MOV should be used instead of using MOVSXD without REX.W.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Copies the contents of the source operand (register or memory location) to\n   the destination operand (register) and sign extends the value to 16 or 32\n   bits (see Figure 7-6 in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1). The size of the converted value depends on\n   the operand-size attribute.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["blendps", "         BLENDPS \u2014 Blend Packed Single Precision Floating-Point Values\n\n                                  64/32-bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                            Flag    \n                                                    Select packed single      \n                                                    precision floating-point  \n   66 0F 3A 0C /r ib                                values from xmm1 and      \n   BLENDPS xmm1, xmm2/m128, RMI   V/V       SSE4_1  xmm2/m128 from mask       \n   imm8                                             specified in imm8 and     \n                                                    store the values into     \n                                                    xmm1.                     \n                                                    Select packed single      \n   VEX.128.66.0F3A.WIG 0C                           precision floating-point  \n   /r ib VBLENDPS xmm1,     RVMI  V/V       AVX     values from xmm2 and      \n   xmm2, xmm3/m128, imm8                            xmm3/m128 from mask in    \n                                                    imm8 and store the values \n                                                    in xmm1.                  \n                                                    Select packed single      \n   VEX.256.66.0F3A.WIG 0C                           precision floating-point  \n   /r ib VBLENDPS ymm1,     RVMI  V/V       AVX     values from ymm2 and      \n   ymm2, ymm3/m256, imm8                            ymm3/m256 from mask in    \n                                                    imm8 and store the values \n                                                    in ymm1.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Packed single precision floating-point values from the second source\n   operand (third operand) are conditionally merged with values from the\n   first source operand (second operand) and written to the destination\n   operand (first operand). The immediate bits [7:0] determine whether the\n   corresponding single precision floating-point value in the destination is\n   copied from the second source or first source. If a bit in the mask,\n   corresponding to a word, is \u201c1\u201d, then the single precision floating-point\n   value in the second source operand is copied, else the value in the first\n   source operand is copied.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: The first source operand an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding YMM register destination are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n"],
	["movdqa:vmovdqa32:vmovdqa64", "        MOVDQA/VMOVDQA32/VMOVDQA64 \u2014 Move Aligned Packed Integer Values\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Flag Description\n                                  Support   \n   66 0F 6F /r MOVDQA xmm1,                              Move aligned packed  \n   xmm2/m128                A     V/V       SSE2         integer values from  \n                                                         xmm2/mem to xmm1.    \n   66 0F 7F /r MOVDQA                                    Move aligned packed  \n   xmm2/m128, xmm1          B     V/V       SSE2         integer values from  \n                                                         xmm1 to xmm2/mem.    \n   VEX.128.66.0F.WIG 6F /r                               Move aligned packed  \n   VMOVDQA xmm1, xmm2/m128  A     V/V       AVX          integer values from  \n                                                         xmm2/mem to xmm1.    \n   VEX.128.66.0F.WIG 7F /r                               Move aligned packed  \n   VMOVDQA xmm2/m128, xmm1  B     V/V       AVX          integer values from  \n                                                         xmm1 to xmm2/mem.    \n   VEX.256.66.0F.WIG 6F /r                               Move aligned packed  \n   VMOVDQA ymm1, ymm2/m256  A     V/V       AVX          integer values from  \n                                                         ymm2/mem to ymm1.    \n   VEX.256.66.0F.WIG 7F /r                               Move aligned packed  \n   VMOVDQA ymm2/m256, ymm1  B     V/V       AVX          integer values from  \n                                                         ymm1 to ymm2/mem.    \n                                                         Move aligned packed  \n   EVEX.128.66.0F.W0 6F /r                  AVX512VL     doubleword integer   \n   VMOVDQA32 xmm1 {k1}{z},  C     V/V       AVX512F      values from          \n   xmm2/m128                                             xmm2/m128 to xmm1    \n                                                         using writemask k1.  \n                                                         Move aligned packed  \n   EVEX.256.66.0F.W0 6F /r                  AVX512VL     doubleword integer   \n   VMOVDQA32 ymm1 {k1}{z},  C     V/V       AVX512F      values from          \n   ymm2/m256                                             ymm2/m256 to ymm1    \n                                                         using writemask k1.  \n                                                         Move aligned packed  \n   EVEX.512.66.0F.W0 6F /r                               doubleword integer   \n   VMOVDQA32 zmm1 {k1}{z},  C     V/V       AVX512F      values from          \n   zmm2/m512                                             zmm2/m512 to zmm1    \n                                                         using writemask k1.  \n                                                         Move aligned packed  \n   EVEX.128.66.0F.W0 7F /r                  AVX512VL     doubleword integer   \n   VMOVDQA32 xmm2/m128      D     V/V       AVX512F      values from xmm1 to  \n   {k1}{z}, xmm1                                         xmm2/m128 using      \n                                                         writemask k1.        \n                                                         Move aligned packed  \n   EVEX.256.66.0F.W0 7F /r                  AVX512VL     doubleword integer   \n   VMOVDQA32 ymm2/m256      D     V/V       AVX512F      values from ymm1 to  \n   {k1}{z}, ymm1                                         ymm2/m256 using      \n                                                         writemask k1.        \n                                                         Move aligned packed  \n   EVEX.512.66.0F.W0 7F /r                               doubleword integer   \n   VMOVDQA32 zmm2/m512      D     V/V       AVX512F      values from zmm1 to  \n   {k1}{z}, zmm1                                         zmm2/m512 using      \n                                                         writemask k1.        \n                                                         Move aligned packed  \n   EVEX.128.66.0F.W1 6F /r                  AVX512VL     quadword integer     \n   VMOVDQA64 xmm1 {k1}{z},  C     V/V       AVX512F      values from          \n   xmm2/m128                                             xmm2/m128 to xmm1    \n                                                         using writemask k1.  \n                                                         Move aligned packed  \n   EVEX.256.66.0F.W1 6F /r                  AVX512VL     quadword integer     \n   VMOVDQA64 ymm1 {k1}{z},  C     V/V       AVX512F      values from          \n   ymm2/m256                                             ymm2/m256 to ymm1    \n                                                         using writemask k1.  \n                                                         Move aligned packed  \n   EVEX.512.66.0F.W1 6F /r                               quadword integer     \n   VMOVDQA64 zmm1 {k1}{z},  C     V/V       AVX512F      values from          \n   zmm2/m512                                             zmm2/m512 to zmm1    \n                                                         using writemask k1.  \n                                                         Move aligned packed  \n   EVEX.128.66.0F.W1 7F /r                  AVX512VL     quadword integer     \n   VMOVDQA64 xmm2/m128      D     V/V       AVX512F      values from xmm1 to  \n   {k1}{z}, xmm1                                         xmm2/m128 using      \n                                                         writemask k1.        \n                                                         Move aligned packed  \n   EVEX.256.66.0F.W1 7F /r                  AVX512VL     quadword integer     \n   VMOVDQA64 ymm2/m256      D     V/V       AVX512F      values from ymm1 to  \n   {k1}{z}, ymm1                                         ymm2/m256 using      \n                                                         writemask k1.        \n                                                         Move aligned packed  \n   EVEX.512.66.0F.W1 7F /r                               quadword integer     \n   VMOVDQA64 zmm2/m512      D     V/V       AVX512F      values from zmm1 to  \n   {k1}{z}, zmm1                                         zmm2/m512 using      \n                                                         writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   EVEX encoded versions:\n\n   Moves 128, 256 or 512 bits of packed doubleword/quadword integer values\n   from the source operand (the second operand) to the destination operand\n   (the first operand). This instruction can be used to load a vector\n   register from an int32/int64 memory location, to store the contents of a\n   vector register into an int32/int64 memory location, or to move data\n   between two ZMM registers. When the source or destination operand is a\n   memory operand, the operand must be aligned on a 16\n   (EVEX.128)/32(EVEX.256)/64(EVEX.512)-byte boundary or a general-protection\n   exception (#GP) will be generated. To move integer data to and from\n   unaligned memory locations, use the VMOVDQU instruction.\n\n   The destination operand is updated at 32-bit (VMOVDQA32) or 64-bit\n   (VMOVDQA64) granularity according to the writemask.\n\n   VEX.256 encoded version:\n\n   Moves 256 bits of packed integer values from the source operand (second\n   operand) to the destination operand (first operand). This instruction can\n   be used to load a YMM register from a 256-bit memory location, to store\n   the contents of a YMM register into a 256-bit memory location, or to move\n   data between two YMM registers.\n\n   When the source or destination operand is a memory operand, the operand\n   must be aligned on a 32-byte boundary or a general-protection exception\n   (#GP) will be generated. To move integer data to and from unaligned memory\n   locations, use the VMOVDQU instruction. Bits (MAXVL-1:256) of the\n   destination register are zeroed.\n\n   128-bit versions:\n\n   Moves 128 bits of packed integer values from the source operand (second\n   operand) to the destination operand (first operand). This instruction can\n   be used to load an XMM register from a 128-bit memory location, to store\n   the contents of an XMM register into a 128-bit memory location, or to move\n   data between two XMM registers.\n\n   When the source or destination operand is a memory operand, the operand\n   must be aligned on a 16-byte boundary or a general-protection exception\n   (#GP) will be generated. To move integer data to and from unaligned memory\n   locations, use the VMOVDQU instruction.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding ZMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination register\n   are zeroed.\n"],
	["pmaxud:pmaxuq", "              PMAXUD/PMAXUQ \u2014 Maximum of Packed Unsigned Integers\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Compare packed unsigned    \n   66 0F 38 3F /r PMAXUD  A     V/V       SSE4_1   dword integers in xmm1 and \n   xmm1, xmm2/m128                                 xmm2/m128 and store packed \n                                                   maximum values in xmm1.    \n   VEX.128.66.0F38.WIG 3F                          Compare packed unsigned    \n   /r VPMAXUD xmm1, xmm2, B     V/V       AVX      dword integers in xmm2 and \n   xmm3/m128                                       xmm3/m128 and store packed \n                                                   maximum values in xmm1.    \n   VEX.256.66.0F38.WIG 3F                          Compare packed unsigned    \n   /r VPMAXUD ymm1, ymm2, B     V/V       AVX2     dword integers in ymm2 and \n   ymm3/m256                                       ymm3/m256 and store packed \n                                                   maximum values in ymm1.    \n                                                   Compare packed unsigned    \n   EVEX.128.66.0F38.W0 3F                          dword integers in xmm2 and \n   /r VPMAXUD xmm1        C     V/V       AVX512VL xmm3/m128/m32bcst and      \n   {k1}{z}, xmm2,                         AVX512F  store packed maximum       \n   xmm3/m128/m32bcst                               values in xmm1 under       \n                                                   writemask k1.              \n                                                   Compare packed unsigned    \n   EVEX.256.66.0F38.W0 3F                          dword integers in ymm2 and \n   /r VPMAXUD ymm1        C     V/V       AVX512VL ymm3/m256/m32bcst and      \n   {k1}{z}, ymm2,                         AVX512F  store packed maximum       \n   ymm3/m256/m32bcst                               values in ymm1 under       \n                                                   writemask k1.              \n                                                   Compare packed unsigned    \n   EVEX.512.66.0F38.W0 3F                          dword integers in zmm2 and \n   /r VPMAXUD zmm1        C     V/V       AVX512F  zmm3/m512/m32bcst and      \n   {k1}{z}, zmm2,                                  store packed maximum       \n   zmm3/m512/m32bcst                               values in zmm1 under       \n                                                   writemask k1.              \n                                                   Compare packed unsigned    \n   EVEX.128.66.0F38.W1 3F                          qword integers in xmm2 and \n   /r VPMAXUQ xmm1        C     V/V       AVX512VL xmm3/m128/m64bcst and      \n   {k1}{z}, xmm2,                         AVX512F  store packed maximum       \n   xmm3/m128/m64bcst                               values in xmm1 under       \n                                                   writemask k1.              \n                                                   Compare packed unsigned    \n   EVEX.256.66.0F38.W1 3F                          qword integers in ymm2 and \n   /r VPMAXUQ ymm1        C     V/V       AVX512VL ymm3/m256/m64bcst and      \n   {k1}{z}, ymm2,                         AVX512F  store packed maximum       \n   ymm3/m256/m64bcst                               values in ymm1 under       \n                                                   writemask k1.              \n                                                   Compare packed unsigned    \n   EVEX.512.66.0F38.W1 3F                          qword integers in zmm2 and \n   /r VPMAXUQ zmm1        C     V/V       AVX512F  zmm3/m512/m64bcst and      \n   {k1}{z}, zmm2,                                  store packed maximum       \n   zmm3/m512/m64bcst                               values in zmm1 under       \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv      ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv     ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed unsigned dword or qword integers in\n   the second source operand and the first source operand and returns the\n   maximum value for each pair of integers to the destination operand.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register; The\n   second source operand is a YMM register or 256-bit memory location. Bits\n   (MAXVL-1:256) of the corresponding destination register are zeroed.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register;\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n"],
	["roundss", "         ROUNDSS \u2014 Round Scalar Single Precision Floating-Point Values\n\n                                 64/32 bit CPUID                              \n   Opcode*/Instruction     Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Round the low packed       \n                                                   single precision           \n   66 0F 3A 0A /r ib                               floating-point value in    \n   ROUNDSS xmm1, xmm2/m32, RMI   V/V       SSE4_1  xmm2/m32 and place the     \n   imm8                                            result in xmm1. The        \n                                                   rounding mode is           \n                                                   determined by imm8.        \n                                                   Round the low packed       \n                                                   single precision           \n                                                   floating-point value in    \n                                                   xmm3/m32 and place the     \n   VEX.LIG.66.0F3A.WIG 0A                          result in xmm1. The        \n   /r ib VROUNDSS xmm1,    RVMI  V/V       AVX     rounding mode is           \n   xmm2, xmm3/m32, imm8                            determined by imm8. Also,  \n                                                   upper packed single        \n                                                   precision floating-point   \n                                                   values (bits[127:32]) from \n                                                   xmm2 are copied to         \n                                                   xmm1[127:32].              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3     Operand 4 \n   RMI   ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   RVMI  ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Round the single precision floating-point value in the lowest dword of the\n   source operand (second operand) using the rounding mode specified in the\n   immediate operand (third operand) and place the result in the destination\n   operand (first operand). The rounding process rounds a single precision\n   floating-point input to an integer value and returns the result as a\n   single precision floating-point value in the lowest position. The upper\n   three single precision floating-point values in the destination are\n   retained.\n\n   The immediate operand specifies control fields for the rounding operation,\n   three bit fields are defined and shown in Figure 4-24. Bit 3 of the\n   immediate byte controls processor behavior for a precision exception, bit\n   2 selects the source of rounding mode control. Bits 1:0 specify a\n   non-sticky rounding-mode value (Table 4-18 lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:32) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n"],
	["vpcompressd", "     VPCOMPRESSD \u2014 Store Sparse Packed Doubleword Integer Values Into Dense\n                                Memory/Register\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Compress packed         \n   EVEX.128.66.0F38.W0 8B /r                 AVX512VL doubleword integer      \n   VPCOMPRESSD xmm1/m128     A     V/V       AVX512F  values from xmm2 to     \n   {k1}{z}, xmm2                                      xmm1/m128 using control \n                                                      mask k1.                \n                                                      Compress packed         \n   EVEX.256.66.0F38.W0 8B /r                 AVX512VL doubleword integer      \n   VPCOMPRESSD ymm1/m256     A     V/V       AVX512F  values from ymm2 to     \n   {k1}{z}, ymm2                                      ymm1/m256 using control \n                                                      mask k1.                \n                                                      Compress packed         \n   EVEX.512.66.0F38.W0 8B /r                          doubleword integer      \n   VPCOMPRESSD zmm1/m512     A     V/V       AVX512F  values from zmm2 to     \n   {k1}{z}, zmm2                                      zmm1/m512 using control \n                                                      mask k1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\n  Description \u00b6\n\n   Compress (store) up to 16/8/4 doubleword integer values from the source\n   operand (second operand) to the destination operand (first operand). The\n   source operand is a ZMM/YMM/XMM register, the destination operand can be a\n   ZMM/YMM/XMM register or a 512/256/128-bit memory location.\n\n   The opmask register k1 selects the active elements (partial vector or\n   possibly non-contiguous if less than 16 active elements) from the source\n   operand to compress into a contiguous vector. The contiguous vector is\n   written to the destination starting from the low element of the\n   destination operand.\n\n   Memory destination version: Only the contiguous vector is written to the\n   destination memory location. EVEX.z must be zero.\n\n   Register destination version: If the vector length of the contiguous\n   vector is less than that of the input vector in the source operand, the\n   upper bits of the destination register are unmodified if EVEX.z is not\n   set, otherwise the upper bits are zeroed.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["movups", "     MOVUPS \u2014 Move Unaligned Packed Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Move unaligned packed      \n   NP 0F 10 /r MOVUPS      A    V/V       SSE      single precision           \n   xmm1, xmm2/m128                                 floating-point from        \n                                                   xmm2/mem to xmm1.          \n                                                   Move unaligned packed      \n   NP 0F 11 /r MOVUPS      B    V/V       SSE      single precision           \n   xmm2/m128, xmm1                                 floating-point from xmm1   \n                                                   to xmm2/mem.               \n                                                   Move unaligned packed      \n   VEX.128.0F.WIG 10 /r    A    V/V       AVX      single precision           \n   VMOVUPS xmm1, xmm2/m128                         floating-point from        \n                                                   xmm2/mem to xmm1.          \n                                                   Move unaligned packed      \n   VEX.128.0F.WIG 11 /r    B    V/V       AVX      single precision           \n   VMOVUPS xmm2/m128, xmm1                         floating-point from xmm1   \n                                                   to xmm2/mem.               \n                                                   Move unaligned packed      \n   VEX.256.0F.WIG 10 /r    A    V/V       AVX      single precision           \n   VMOVUPS ymm1, ymm2/m256                         floating-point from        \n                                                   ymm2/mem to ymm1.          \n                                                   Move unaligned packed      \n   VEX.256.0F.WIG 11 /r    B    V/V       AVX      single precision           \n   VMOVUPS ymm2/m256, ymm1                         floating-point from ymm1   \n                                                   to ymm2/mem.               \n                                                   Move unaligned packed      \n   EVEX.128.0F.W0 10 /r                   AVX512VL single precision           \n   VMOVUPS xmm1 {k1}{z},   C    V/V       AVX512F  floating-point values from \n   xmm2/m128                                       xmm2/m128 to xmm1 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.256.0F.W0 10 /r                   AVX512VL single precision           \n   VMOVUPS ymm1 {k1}{z},   C    V/V       AVX512F  floating-point values from \n   ymm2/m256                                       ymm2/m256 to ymm1 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.512.0F.W0 10 /r                            single precision           \n   VMOVUPS zmm1 {k1}{z},   C    V/V       AVX512F  floating-point values from \n   zmm2/m512                                       zmm2/m512 to zmm1 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.128.0F.W0 11 /r                   AVX512VL single precision           \n   VMOVUPS xmm2/m128       D    V/V       AVX512F  floating-point values from \n   {k1}{z}, xmm1                                   xmm1 to xmm2/m128 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.256.0F.W0 11 /r                   AVX512VL single precision           \n   VMOVUPS ymm2/m256       D    V/V       AVX512F  floating-point values from \n   {k1}{z}, ymm1                                   ymm1 to ymm2/m256 using    \n                                                   writemask k1.              \n                                                   Move unaligned packed      \n   EVEX.512.0F.W0 11 /r                            single precision           \n   VMOVUPS zmm2/m512       D    V/V       AVX512F  floating-point values from \n   {k1}{z}, zmm1                                   zmm1 to zmm2/m512 using    \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     N/A        ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   C     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Full Mem   ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n\nDescription \u00b6\n\n   Note: VEX.vvvv and EVEX.vvvv is reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   EVEX.512 encoded version:\n\n   Moves 512 bits of packed single precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a ZMM register from a\n   512-bit float32 memory location, to store the contents of a ZMM register\n   into memory. The destination operand is updated according to the\n   writemask.\n\n   VEX.256 and EVEX.256 encoded versions:\n\n   Moves 256 bits of packed single precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load a YMM register from a\n   256-bit memory location, to store the contents of a YMM register into a\n   256-bit memory location, or to move data between two YMM registers. Bits\n   (MAXVL-1:256) of the destination register are zeroed.\n\n   128-bit versions:\n\n   Moves 128 bits of packed single precision floating-point values from the\n   source operand (second operand) to the destination operand (first\n   operand). This instruction can be used to load an XMM register from a\n   128-bit memory location, to store the contents of an XMM register into a\n   128-bit memory location, or to move data between two XMM registers.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding\n   destination register remain unchanged.\n\n   When the source or destination operand is a memory operand, the operand\n   may be unaligned without causing a general-protection exception (#GP) to\n   be generated.\n\n   VEX.128 and EVEX.128 encoded versions: Bits (MAXVL-1:128) of the\n   destination register are zeroed.\n"],
	["kandw:kandb:kandq:kandd", "              KANDW/KANDB/KANDQ/KANDD \u2014 Bitwise Logical AND Masks\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Flag Description\n                                  Support   \n   VEX.L1.0F.W0 41 /r KANDW                              Bitwise AND 16 bits  \n   k1, k2, k3               RVR   V/V       AVX512F      masks k2 and k3 and  \n                                                         place result in k1.  \n   VEX.L1.66.0F.W0 41 /r                                 Bitwise AND 8 bits   \n   KANDB k1, k2, k3         RVR   V/V       AVX512DQ     masks k2 and k3 and  \n                                                         place result in k1.  \n   VEX.L1.0F.W1 41 /r KANDQ                              Bitwise AND 64 bits  \n   k1, k2, k3               RVR   V/V       AVX512BW     masks k2 and k3 and  \n                                                         place result in k1.  \n   VEX.L1.66.0F.W1 41 /r                                 Bitwise AND 32 bits  \n   KANDD k1, k2, k3         RVR   V/V       AVX512BW     masks k2 and k3 and  \n                                                         place result in k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3                              \n   RVR   ModRM:reg (w) VEX.1vvv (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Performs a bitwise AND between the vector mask k2 and the vector mask k3,\n   and writes the result into vector mask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vcomish", "          VCOMISH \u2014 Compare Scalar Ordered FP16 Values and Set EFLAGS\n\n   Description EVEX.LLIG.NP.MAP5.W0 2F /r A V/V                               \n   AVX512-FP16 VCOMISH xmm1, xmm2/m16 {sae}      \n   Description EVEX.LLIG.NP.MAP5.W0 2F /r A V/V  \n   AVX512-FP16 p/ 64/32 CPUID Feature            \n   Instruction En Bit Mode Flag Support          \n   Description EVEX.LLIG.NP.MAP5.W0 2F /r A V/V  \n   AVX512-FP16 Description EVEX.LLIG.NP.MAP5.W0  \n   2F /r A V/V AVX512-FP16 Instruction En Bit     Support  Description\n   Mode Flag Support Instruction En Bit Mode     \n   Flag Support 64/32 CPUID Feature Instruction  \n   En Bit Mode Flag CPUID Feature Instruction En \n   Bit Mode Flag Op/ 64/32 CPUID Feature         \n   Instruction En Bit Mode Flag 64/32 CPUID      \n   Feature Instruction En Bit Mode Flag CPUID    \n   Feature Instruction En Bit Mode Flag Op/      \n   64/32 CPUID Feature                           \n                                                           Compare low FP16   \n                                                           values in xmm1 and \n   VCOMISH xmm1, xmm2/m16 {sae}                            xmm2/m16, and set  \n                                                           the EFLAGS flags   \n                                                           accordingly.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction compares the FP16 values in the low word of operand 1\n   (first operand) and operand 2 (second operand), and sets the ZF, PF, and\n   CF flags in the EFLAGS register according to the result (unordered,\n   greater than, less than, or equal). The OF, SF and AF flags in the EFLAGS\n   register are set to 0. The unordered result is returned if either source\n   operand is a NaN (QNaN or SNaN).\n\n   Operand 1 is an XMM register; operand 2 can be an XMM register or a 16-bit\n   memory location.\n\n   The VCOMISH instruction differs from the VUCOMISH instruction in that it\n   signals a SIMD floating-point invalid operation exception (#I) when a\n   source operand is either a QNaN or SNaN. The VUCOMISH instruction signals\n   an invalid numeric exception only if a source operand is an SNaN.\n\n   The EFLAGS register is not updated if an unmasked SIMD floating-point\n   exception is generated. EVEX.vvvv is reserved and must be 1111b, otherwise\n   instructions will #UD.\n"],
	["packsswb:packssdw", "                PACKSSWB/PACKSSDW \u2014 Pack With Signed Saturation\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Converts 4 packed signed   \n                                                   word integers from mm1 and \n   NP 0F 63 /r^1 PACKSSWB A     V/V       MMX      from mm2/m64 into 8 packed \n   mm1, mm2/m64                                    signed byte integers in    \n                                                   mm1 using signed           \n                                                   saturation.                \n                                                   Converts 8 packed signed   \n                                                   word integers from xmm1    \n   66 0F 63 /r PACKSSWB   A     V/V       SSE2     and from xmm2/m128 into 16 \n   xmm1, xmm2/m128                                 packed signed byte         \n                                                   integers in xmm1 using     \n                                                   signed saturation.         \n                                                   Converts 2 packed signed   \n                                                   doubleword integers from   \n   NP 0F 6B /r^1 PACKSSDW A     V/V       MMX      mm1 and from mm2/m64 into  \n   mm1, mm2/m64                                    4 packed signed word       \n                                                   integers in mm1 using      \n                                                   signed saturation.         \n                                                   Converts 4 packed signed   \n                                                   doubleword integers from   \n   66 0F 6B /r PACKSSDW   A     V/V       SSE2     xmm1 and from xmm2/m128    \n   xmm1, xmm2/m128                                 into 8 packed signed word  \n                                                   integers in xmm1 using     \n                                                   signed saturation.         \n                                                   Converts 8 packed signed   \n   VEX.128.66.0F.WIG 63                            word integers from xmm2    \n   /r VPACKSSWB           B     V/V       AVX      and from xmm3/m128 into 16 \n   xmm1,xmm2, xmm3/m128                            packed signed byte         \n                                                   integers in xmm1 using     \n                                                   signed saturation.         \n                                                   Converts 4 packed signed   \n   VEX.128.66.0F.WIG 6B                            doubleword integers from   \n   /r VPACKSSDW           B     V/V       AVX      xmm2 and from xmm3/m128    \n   xmm1,xmm2, xmm3/m128                            into 8 packed signed word  \n                                                   integers in xmm1 using     \n                                                   signed saturation.         \n                                                   Converts 16 packed signed  \n   VEX.256.66.0F.WIG 63                            word integers from ymm2    \n   /r VPACKSSWB ymm1,     B     V/V       AVX2     and from ymm3/m256 into 32 \n   ymm2, ymm3/m256                                 packed signed byte         \n                                                   integers in ymm1 using     \n                                                   signed saturation.         \n                                                   Converts 8 packed signed   \n   VEX.256.66.0F.WIG 6B                            doubleword integers from   \n   /r VPACKSSDW ymm1,     B     V/V       AVX2     ymm2 and from ymm3/m256    \n   ymm2, ymm3/m256                                 into 16 packed signed word \n                                                   integers in ymm1using      \n                                                   signed saturation.         \n                                                   Converts packed signed     \n   EVEX.128.66.0F.WIG 63                           word integers from xmm2    \n   /r VPACKSSWB xmm1                      AVX512VL and from xmm3/m128 into    \n   {k1}{z}, xmm2,         C     V/V       AVX512BW packed signed byte         \n   xmm3/m128                                       integers in xmm1 using     \n                                                   signed saturation under    \n                                                   writemask k1.              \n                                                   Converts packed signed     \n   EVEX.256.66.0F.WIG 63                           word integers from ymm2    \n   /r VPACKSSWB ymm1                      AVX512VL and from ymm3/m256 into    \n   {k1}{z}, ymm2,         C     V/V       AVX512BW packed signed byte         \n   ymm3/m256                                       integers in ymm1 using     \n                                                   signed saturation under    \n                                                   writemask k1.              \n                                                   Converts packed signed     \n   EVEX.512.66.0F.WIG 63                           word integers from zmm2    \n   /r VPACKSSWB zmm1                               and from zmm3/m512 into    \n   {k1}{z}, zmm2,         C     V/V       AVX512BW packed signed byte         \n   zmm3/m512                                       integers in zmm1 using     \n                                                   signed saturation under    \n                                                   writemask k1.              \n                                                   Converts packed signed     \n                                                   doubleword integers from   \n   EVEX.128.66.0F.W0 6B                            xmm2 and from              \n   /r VPACKSSDW xmm1      D     V/V       AVX512VL xmm3/m128/m32bcst into     \n   {k1}{z}, xmm2,                         AVX512BW packed signed word         \n   xmm3/m128/m32bcst                               integers in xmm1 using     \n                                                   signed saturation under    \n                                                   writemask k1.              \n                                                   Converts packed signed     \n                                                   doubleword integers from   \n   EVEX.256.66.0F.W0 6B                            ymm2 and from              \n   /r VPACKSSDW ymm1      D     V/V       AVX512VL ymm3/m256/m32bcst into     \n   {k1}{z}, ymm2,                         AVX512BW packed signed word         \n   ymm3/m256/m32bcst                               integers in ymm1 using     \n                                                   signed saturation under    \n                                                   writemask k1.              \n                                                   Converts packed signed     \n                                                   doubleword integers from   \n   EVEX.512.66.0F.W0 6B                            zmm2 and from              \n   /r VPACKSSDW zmm1      D     V/V       AVX512BW zmm3/m512/m32bcst into     \n   {k1}{z}, zmm2,                                  packed signed word         \n   zmm3/m512/m32bcst                               integers in zmm1 using     \n                                                   signed saturation under    \n                                                   writemask k1.              \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Converts packed signed word integers into packed signed byte integers\n   (PACKSSWB) or converts packed signed doubleword integers into packed\n   signed word integers (PACKSSDW), using saturation to handle overflow\n   conditions. See Figure 4-6 for an example of the packing operation.\n\n   64-Bit SRC 64-Bit DEST C B A D\u2019 C\u2019 B\u2019 A\u2019 64-Bit DEST Figure 4-6. Operation\n   of the PACKSSDW Instruction Using 64-Bit Operands\n\n   PACKSSWB converts packed signed word integers in the first and second\n   source operands into packed signed byte integers using signed saturation\n   to handle overflow conditions beyond the range of signed byte integers. If\n   the signed word value is beyond the range of a signed byte value (i.e.,\n   greater than 7FH or less than 80H), the saturated signed byte integer\n   value of 7FH or 80H, respectively, is stored in the destination. PACKSSDW\n   converts packed signed doubleword integers in the first and second source\n   operands into packed signed word integers using signed saturation to\n   handle overflow conditions beyond 7FFFH and 8000H.\n\n   EVEX encoded PACKSSWB: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand is a ZMM/YMM/XMM register or a 512/256/128-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register,\n   updated conditional under the writemask k1.\n\n   EVEX encoded PACKSSDW: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 32-\n\n   bit memory location. The destination operand is a ZMM/YMM/XMM register,\n   updated conditional under the write-mask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding ZMM destination register\n   destination are unmodified.\n"],
	["rdpmc", "                  RDPMC \u2014 Read Performance-Monitoring Counters\n\n   Opcode* Instruction Op/En 64-Bit Compat/Leg Description                    \n                             Mode   Mode       \n                                               Read performance-monitoring    \n   0F 33   RDPMC       ZO    Valid  Valid      counter specified by ECX into  \n                                               EDX:EAX.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reads the contents of the performance monitoring counter (PMC) specified\n   in ECX register into registers EDX:EAX. (On processors that support the\n   Intel 64 architecture, the high-order 32 bits of RCX are ignored.) The EDX\n   register is loaded with the high-order 32 bits of the PMC and the EAX\n   register is loaded with the low-order 32 bits. (On processors that support\n   the Intel 64 architecture, the high-order 32 bits of each of RAX and RDX\n   are cleared.) If fewer than 64 bits are implemented in the PMC being read,\n   unimplemented bits returned to EDX:EAX will have value zero.\n\n   The width of PMCs on processors supporting architectural performance\n   monitoring (CPUID.0AH:EAX[7:0] =\u0338 0) are reported by CPUID.0AH:EAX[23:16].\n   On processors that do not support architectural performance monitoring\n   (CPUID.0AH:EAX[7:0]=0), the width of general-purpose performance PMCs is\n   40 bits, while the widths of special-purpose PMCs are implementation\n   specific.\n\n   Use of ECX to specify a PMC depends on whether the processor supports\n   architectural performance monitoring:\n\n     * If the processor does not support architectural performance monitoring\n       (CPUID.0AH:EAX[7:0]=0), ECX[30:0] specifies the index of the PMC to be\n       read. Setting ECX[31] selects \u201cfast\u201d read mode if supported. In this\n       mode, RDPMC returns bits 31:0 of the PMC in EAX while clearing EDX to\n       zero.\n     * If the processor does support architectural performance monitoring\n       (CPUID.0AH:EAX[7:0] =\u0338 0), ECX[31:16] specifies type of PMC while\n       ECX[15:0] specifies the index of the PMC to be read within that type.\n       The following PMC types are currently defined:\n          * General-purpose counters use type 0. The index x (to read\n            IA32_PMCx) must be less than the value enumerated by\n            CPUID.0AH.EAX[15:8] (thus ECX[15:8] must be zero).\n          * General-purpose counters use type 0. The index x (to read\n            IA32_PMCx) must be less than the value enumerated by\n            CPUID.0AH.EAX[15:8] (thus ECX[15:8] must be zero).\n          * Fixed-function counters use type 4000H. The index x (to read\n            IA32_FIXED_CTRx) can be used if either CPUID.0AH.EDX[4:0] > x or\n            CPUID.0AH.ECX[x] = 1 (thus ECX[15:5] must be 0).\n          * Fixed-function counters use type 4000H. The index x (to read\n            IA32_FIXED_CTRx) can be used if either CPUID.0AH.EDX[4:0] > x or\n            CPUID.0AH.ECX[x] = 1 (thus ECX[15:5] must be 0).\n          * Performance metrics use type 2000H. This type can be used only if\n            IA32_PERF_CAPABILITIES.PERF_MET-RICS_AVAILABLE[bit 15]=1. For\n            this type, the index in ECX[15:0] is implementation specific.\n          * Performance metrics use type 2000H. This type can be used only if\n            IA32_PERF_CAPABILITIES.PERF_MET-RICS_AVAILABLE[bit 15]=1. For\n            this type, the index in ECX[15:0] is implementation specific.\n\n   Specifying an unsupported PMC encoding will cause a general protection\n   exception #GP(0). For PMC details see Chapter 20, \u201cPerformance\n   Monitoring,\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3B.\n\n   When in protected or virtual 8086 mode, the Performance-monitoring\n   Counters Enabled (PCE) flag in register CR4 restricts the use of the RDPMC\n   instruction. When the PCE flag is set, the RDPMC instruction can be\n   executed at any privilege level; when the flag is clear, the instruction\n   can only be executed at privilege level 0. (When in real-address mode, the\n   RDPMC instruction is always enabled.) The PMCs can also be read with the\n   RDMSR instruction, when executing at privilege level 0.\n\n   The RDPMC instruction is not a serializing instruction; that is, it does\n   not imply that all the events caused by the preceding instructions have\n   been completed or that events caused by subsequent instructions have not\n   begun. If an exact event count is desired, software must insert a\n   serializing instruction (such as the CPUID instruction) before and/or\n   after the RDPMC instruction.\n\n   Performing back-to-back fast reads are not guaranteed to be monotonic. To\n   guarantee monotonicity on back-to-back reads, a serializing instruction\n   must be placed between the two RDPMC instructions.\n\n   The RDPMC instruction can execute in 16-bit addressing mode or\n   virtual-8086 mode; however, the full contents of the ECX register are used\n   to select the PMC, and the event count is stored in the full EAX and EDX\n   registers. The\n\n   RDPMC instruction was introduced into the IA-32 Architecture in the\n   Pentium Pro processor and the Pentium processor with MMX technology. The\n   earlier Pentium processors have PMCs, but they must be read with the RDMSR\n   instruction.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["testui", "                     TESTUI \u2014 Determine User Interrupt Flag\n\n   Opcode/Instruction Op/En 64/32 bit Mode CPUID        Description           \n                            Support        Feature Flag \n                                                        Copies the current    \n   F3 0F 01 ED TESTUI ZO    V/I            UINTR        value of UIF into     \n                                                        EFLAGS.CF.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A   N/A       N/A       N/A       N/A       \n\n   TESTUI copies the current value of the user interrupt flag (UIF) into\n   EFLAGS.CF. This instruction can be executed regardless of CPL.\n\n   TESTUI may be executed normally inside a transactional region.\n\nFlags Affected \u00b6\n\n   The ZF, OF, AF, PF, SF flags are cleared and the CF flags to the value of\n   the user interrupt flag.\n"],
	["mfence", "                             MFENCE \u2014 Memory Fence\n\n   Opcode /           Op/En 64/32 bit Mode CPUID Feature Description          \n   Instruction              Support        Flag          \n   NP 0F AE F0 MFENCE ZO    V/V            SSE2          Serializes load and  \n                                                         store operations.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Performs a serializing operation on all load-from-memory and\n   store-to-memory instructions that were issued prior the MFENCE\n   instruction. This serializing operation guarantees that every load and\n   store instruction that precedes the MFENCE instruction in program order\n   becomes globally visible before any load or store instruction that follows\n   the MFENCE instruction.^1 The MFENCE instruction is ordered with respect\n   to all load and store instructions, other MFENCE instructions, any LFENCE\n   and SFENCE instructions, and any serializing instructions (such as the\n   CPUID instruction). MFENCE does not serialize the instruction stream.\n\n     1. A load instruction is considered to become globally visible when the\n     value to be loaded into its destination register is determined.\n\n   Weakly ordered memory types can be used to achieve higher processor\n   performance through such techniques as out-of-order issue, speculative\n   reads, write-combining, and write-collapsing. The degree to which a\n   consumer of data recognizes or knows that the data is weakly ordered\n   varies among applications and may be unknown to the producer of this data.\n   The MFENCE instruction provides a performance-efficient way of ensuring\n   load and store ordering between routines that produce weakly-ordered\n   results and routines that consume that data.\n\n   Processors are free to fetch and cache data speculatively from regions of\n   system memory that use the WB, WC, and WT memory types. This speculative\n   fetching can occur at any time and is not tied to instruction execution.\n   Thus, it is not ordered with respect to executions of the MFENCE\n   instruction; data can be brought into the caches speculatively just\n   before, during, or after the execution of an MFENCE instruction.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\n   Specification of the instruction's opcode above indicates a ModR/M byte of\n   F0. For this instruction, the processor ignores the r/m field of the\n   ModR/M byte. Thus, MFENCE is encoded by any opcode of the form 0F AE Fx,\n   where x is in the range 0-7.\n\nExceptions (All Modes of Operation) \u00b6\n\n   #UD If CPUID.01H:EDX.SSE2[bit 26] = 0.\n\n   If the LOCK prefix is used.\n"],
	["vrsqrt14ps", " VRSQRT14PS \u2014 Compute Approximate Reciprocals of Square Roots of Packed Float32\n                                     Values\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Computes the approximate   \n                                                   reciprocal square roots of \n   EVEX.128.66.0F38.W0 4E                          the packed                 \n   /r VRSQRT14PS xmm1     A     V/V       AVX512VL single-precision           \n   {k1}{z},                               AVX512F  floating-point values in   \n   xmm2/m128/m32bcst                               xmm2/m128/m32bcst and      \n                                                   stores the results in      \n                                                   xmm1. Under writemask.     \n                                                   Computes the approximate   \n                                                   reciprocal square roots of \n   EVEX.256.66.0F38.W0 4E                          the packed                 \n   /r VRSQRT14PS ymm1     A     V/V       AVX512VL single-precision           \n   {k1}{z},                               AVX512F  floating-point values in   \n   ymm2/m256/m32bcst                               ymm2/m256/m32bcst and      \n                                                   stores the results in      \n                                                   ymm1. Under writemask.     \n                                                   Computes the approximate   \n                                                   reciprocal square roots of \n   EVEX.512.66.0F38.W0 4E                          the packed                 \n   /r VRSQRT14PS zmm1     A     V/V       AVX512F  single-precision           \n   {k1}{z},                                        floating-point values in   \n   zmm2/m512/m32bcst                               zmm2/m512/m32bcst and      \n                                                   stores the results in      \n                                                   zmm1. Under writemask.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD computation of the approximate\n   reciprocals of the square roots of 16 packed single-precision\n   floating-point values in the source operand (the second operand) and\n   stores the packed single-precision floating-point results in the\n   destination operand (the first operand) according to the writemask. The\n   maximum relative error for this approximation is less than 2^-14.\n\n   EVEX.512 encoded version: The source operand can be a ZMM register, a\n   512-bit memory location or a 512-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM register, conditionally\n   updated using writemask k1.\n\n   EVEX.256 encoded version: The source operand is a YMM register, a 256-bit\n   memory location, or a 256-bit vector broadcasted from a 32-bit memory\n   location. The destination operand is a YMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.128 encoded version: The source operand is a XMM register, a 128-bit\n   memory location, or a 128-bit vector broadcasted from a 32-bit memory\n   location. The destination operand is a XMM register, conditionally updated\n   using writemask k1.\n\n   The VRSQRT14PS instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. When the source operand is an +\u221e then +ZERO\n   value is returned. A denormal source value is treated as zero only if DAZ\n   bit is set in MXCSR. Otherwise it is treated correctly and performs the\n   approximation with the specified masked response. When a source value is a\n   negative value (other than 0.0) a floating-point QNaN_indefinite is\n   returned. When a source value is an SNaN or QNaN, the SNaN is converted to\n   a QNaN or the source QNaN is returned.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n\n  A numerically exact implementation of VRSQRT14xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["shufpd", " SHUFPD \u2014 Packed Interleave Shuffle of Pairs of Double Precision Floating-Point\n                                     Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Shuffle two pairs of       \n                                                   double precision           \n   66 0F C6 /r ib SHUFPD                           floating-point values from \n   xmm1, xmm2/m128, imm8   A    V/V       SSE2     xmm1 and xmm2/m128 using   \n                                                   imm8 to select from each   \n                                                   pair, interleaved result   \n                                                   is stored in xmm1.         \n                                                   Shuffle two pairs of       \n                                                   double precision           \n   VEX.128.66.0F.WIG C6 /r                         floating-point values from \n   ib VSHUFPD xmm1, xmm2,  B    V/V       AVX      xmm2 and xmm3/m128 using   \n   xmm3/m128, imm8                                 imm8 to select from each   \n                                                   pair, interleaved result   \n                                                   is stored in xmm1.         \n                                                   Shuffle four pairs of      \n                                                   double precision           \n   VEX.256.66.0F.WIG C6 /r                         floating-point values from \n   ib VSHUFPD ymm1, ymm2,  B    V/V       AVX      ymm2 and ymm3/m256 using   \n   ymm3/m256, imm8                                 imm8 to select from each   \n                                                   pair, interleaved result   \n                                                   is stored in xmm1.         \n                                                   Shuffle two pairs of       \n                                                   double precision           \n   EVEX.128.66.0F.W1 C6 /r                         floating-point values from \n   ib VSHUFPD xmm1{k1}{z},                AVX512VL xmm2 and xmm3/m128/m64bcst \n   xmm2,                   C    V/V       AVX512F  using imm8 to select from  \n   xmm3/m128/m64bcst, imm8                         each pair. store           \n                                                   interleaved results in     \n                                                   xmm1 subject to writemask  \n                                                   k1.                        \n                                                   Shuffle four pairs of      \n                                                   double precision           \n   EVEX.256.66.0F.W1 C6 /r                         floating-point values from \n   ib VSHUFPD ymm1{k1}{z},                AVX512VL ymm2 and ymm3/m256/m64bcst \n   ymm2,                   C    V/V       AVX512F  using imm8 to select from  \n   ymm3/m256/m64bcst, imm8                         each pair. store           \n                                                   interleaved results in     \n                                                   ymm1 subject to writemask  \n                                                   k1.                        \n                                                   Shuffle eight pairs of     \n                                                   double precision           \n   EVEX.512.66.0F.W1 C6 /r                         floating-point values from \n   ib VSHUFPD zmm1{k1}{z},                         zmm2 and zmm3/m512/m64bcst \n   zmm2,                   C    V/V       AVX512F  using imm8 to select from  \n   zmm3/m512/m64bcst, imm8                         each pair. store           \n                                                   interleaved results in     \n                                                   zmm1 subject to writemask  \n                                                   k1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Selects a double precision floating-point value of an input pair using a\n   bit control and move to a designated element of the destination operand.\n   The low-to-high order of double precision element of the destination\n   operand is interleaved between the first source operand and the second\n   source operand at the granularity of input pair of 128 bits. Each bit in\n   the imm8 byte, starting from bit 0, is the select control of the\n   corresponding element of the destination to received the shuffled result\n   of an input pair.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 64-bit\n   memory location The destination operand is a ZMM/YMM/XMM register updated\n   according to the writemask. The select controls are the lower 8/4/2 bits\n   of the imm8 byte.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. The select controls are the bit\n   3:0 of the imm8 byte, imm8[7:4) are ignored.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n\n   the corresponding ZMM register destination are zeroed. The select controls\n   are the bit 1:0 of the imm8 byte, imm8[7:2) are ignored.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination operand and the first source\n   operand is the same and is an XMM register. The upper bits (MAXVL-1:128)\n   of the corresponding ZMM register destination are unmodified. The select\n   controls are the bit 1:0 of the imm8 byte, imm8[7:2) are ignored.\n\n   X3 X2 X1 X0 SRC1 Y3 Y2 Y1 Y0 SRC2 DEST Y2 or Y3 X2 or X3 Y0 or Y1 X0 or X1\n   Figure 4-25. 256-bit VSHUFPD Operation of Four Pairs of Double Precision\n   Floating-Point Values\n"],
	["xor", "                           XOR \u2014 Logical Exclusive OR\n\n   Opcode   Instruction    Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   34 ib    XOR AL, imm8   I     Valid  Valid      AL XOR imm8.               \n   35 iw    XOR AX, imm16  I     Valid  Valid      AX XOR imm16.              \n   35 id    XOR EAX, imm32 I     Valid  Valid      EAX XOR imm32.             \n   REX.W +  XOR RAX, imm32 I     Valid  N.E.       RAX XOR imm32              \n   35 id                                           (sign-extended).           \n   80 /6 ib XOR r/m8, imm8 MI    Valid  Valid      r/m8 XOR imm8.             \n   REX + 80 XOR r/m8*,     MI    Valid  N.E.       r/m8 XOR imm8.             \n   /6 ib    imm8           \n   81 /6 iw XOR r/m16,     MI    Valid  Valid      r/m16 XOR imm16.           \n            imm16          \n   81 /6 id XOR r/m32,     MI    Valid  Valid      r/m32 XOR imm32.           \n            imm32          \n   REX.W +  XOR r/m64,     MI    Valid  N.E.       r/m64 XOR imm32            \n   81 /6 id imm32                                  (sign-extended).           \n   83 /6 ib XOR r/m16,     MI    Valid  Valid      r/m16 XOR imm8             \n            imm8                                   (sign-extended).           \n   83 /6 ib XOR r/m32,     MI    Valid  Valid      r/m32 XOR imm8             \n            imm8                                   (sign-extended).           \n   REX.W +  XOR r/m64,     MI    Valid  N.E.       r/m64 XOR imm8             \n   83 /6 ib imm8                                   (sign-extended).           \n   30 /r    XOR r/m8, r8   MR    Valid  Valid      r/m8 XOR r8.               \n   REX + 30 XOR r/m8*, r8* MR    Valid  N.E.       r/m8 XOR r8.               \n   /r       \n   31 /r    XOR r/m16, r16 MR    Valid  Valid      r/m16 XOR r16.             \n   31 /r    XOR r/m32, r32 MR    Valid  Valid      r/m32 XOR r32.             \n   REX.W +  XOR r/m64, r64 MR    Valid  N.E.       r/m64 XOR r64.             \n   31 /r    \n   32 /r    XOR r8, r/m8   RM    Valid  Valid      r8 XOR r/m8.               \n   REX + 32 XOR r8*, r/m8* RM    Valid  N.E.       r8 XOR r/m8.               \n   /r       \n   33 /r    XOR r16, r/m16 RM    Valid  Valid      r16 XOR r/m16.             \n   33 /r    XOR r32, r/m32 RM    Valid  Valid      r32 XOR r/m32.             \n   REX.W +  XOR r64, r/m64 RM    Valid  N.E.       r64 XOR r/m64.             \n   33 /r    \n\n     *\n     In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   I     AL/AX/EAX/RAX    imm8/16/32    N/A       N/A       \n   MI    ModRM:r/m (r, w) imm8/16/32    N/A       N/A       \n   MR    ModRM:r/m (r, w) ModRM:reg (r) N/A       N/A       \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs a bitwise exclusive OR (XOR) operation on the destination (first)\n   and source (second) operands and stores the result in the destination\n   operand location. The source operand can be an immediate, a register, or a\n   memory location; the destination operand can be a register or a memory\n   location. (However, two memory operands cannot be used in one\n   instruction.) Each bit of the result is 1 if the corresponding bits of the\n   operands are different; each bit is 0 if the corresponding bits are the\n   same.\n\n   This instruction can be used with a LOCK prefix to allow the instruction\n   to be executed atomically.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits access to\n   additional registers (R8-R15). Using a REX prefix in the form of REX.W\n   promotes operation to 64 bits. See the summary chart at the beginning of\n   this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   The OF and CF flags are cleared; the SF, ZF, and PF flags are set\n   according to the result. The state of the AF flag is undefined.\n"],
	["shrd", "                      SHRD \u2014 Double Precision Shift Right\n\n   Opcode*     Instruction Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n               SHRD r/m16,                         Shift r/m16 to right imm8  \n   0F AC /r ib r16, imm8   MRI   Valid  Valid      places while shifting bits \n                                                   from r16 in from the left. \n               SHRD r/m16,                         Shift r/m16 to right CL    \n   0F AD /r    r16, CL     MRC   Valid  Valid      places while shifting bits \n                                                   from r16 in from the left. \n               SHRD r/m32,                         Shift r/m32 to right imm8  \n   0F AC /r ib r32, imm8   MRI   Valid  Valid      places while shifting bits \n                                                   from r32 in from the left. \n   REX.W + 0F  SHRD r/m64,                         Shift r/m64 to right imm8  \n   AC /r ib    r64, imm8   MRI   Valid  N.E.       places while shifting bits \n                                                   from r64 in from the left. \n               SHRD r/m32,                         Shift r/m32 to right CL    \n   0F AD /r    r32, CL     MRC   Valid  Valid      places while shifting bits \n                                                   from r32 in from the left. \n   REX.W + 0F  SHRD r/m64,                         Shift r/m64 to right CL    \n   AD /r       r64, CL     MRC   Valid  N.E.       places while shifting bits \n                                                   from r64 in from the left. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MRI   ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   MRC   ModRM:r/m (w) ModRM:reg (r) CL        N/A       \n\nDescription \u00b6\n\n   The SHRD instruction is useful for multi-precision shifts of 64 bits or\n   more.\n\n   The instruction shifts the first operand (destination operand) to the\n   right the number of bits specified by the third operand (count operand).\n   The second operand (source operand) provides bits to shift in from the\n   left (starting with the most significant bit of the destination operand).\n\n   The destination operand can be a register or a memory location; the source\n   operand is a register. The count operand is an unsigned integer that can\n   be stored in an immediate byte or the CL register. If the count operand is\n   CL, the shift count is the logical AND of CL and a count mask. In\n   non-64-bit modes and default 64-bit mode, the width of the count mask is 5\n   bits. Only bits 0 through 4 of the count register are used (masking the\n   count to a value between 0 and 31). If the count is greater than the\n   operand size, the result is undefined.\n\n   If the count is 1 or greater, the CF flag is filled with the last bit\n   shifted out of the destination operand. For a 1-bit shift, the OF flag is\n   set if a sign change occurred; otherwise, it is cleared. If the count\n   operand is 0, flags are not affected.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits (upgrading the count mask to 6 bits). See the summary chart at the\n   beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   If the count is 1 or greater, the CF flag is filled with the last bit\n   shifted out of the destination operand and the SF, ZF, and PF flags are\n   set according to the value of the result. For a 1-bit shift, the OF flag\n   is set if a sign change occurred; otherwise, it is cleared. For shifts\n   greater than 1 bit, the OF flag is undefined. If a shift occurs, the AF\n   flag is undefined. If the count operand is 0, the flags are not affected.\n   If the count is greater than the operand size, the flags are undefined.\n"],
	["psadbw", "                  PSADBW \u2014 Compute Sum of Absolute Differences\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes the absolute     \n                                                    differences of the packed \n                                                    unsigned byte integers    \n   NP 0F F6 /r^1 PSADBW    A     V/V       SSE      from mm2 /m64 and mm1;    \n   mm1, mm2/m64                                     differences are then      \n                                                    summed to produce an      \n                                                    unsigned word integer     \n                                                    result.                   \n                                                    Computes the absolute     \n                                                    differences of the packed \n                                                    unsigned byte integers    \n   66 0F F6 /r PSADBW                               from xmm2 /m128 and xmm1; \n   xmm1, xmm2/m128         A     V/V       SSE2     the 8 low differences and \n                                                    8 high differences are    \n                                                    then summed separately to \n                                                    produce two unsigned word \n                                                    integer results.          \n                                                    Computes the absolute     \n                                                    differences of the packed \n                                                    unsigned byte integers    \n   VEX.128.66.0F.WIG F6 /r                          from xmm3 /m128 and xmm2; \n   VPSADBW xmm1, xmm2,     B     V/V       AVX      the 8 low differences and \n   xmm3/m128                                        8 high differences are    \n                                                    then summed separately to \n                                                    produce two unsigned word \n                                                    integer results.          \n                                                    Computes the absolute     \n                                                    differences of the packed \n                                                    unsigned byte integers    \n   VEX.256.66.0F.WIG F6 /r                          from ymm3 /m256 and ymm2; \n   VPSADBW ymm1, ymm2,     B     V/V       AVX2     then each consecutive 8   \n   ymm3/m256                                        differences are summed    \n                                                    separately to produce     \n                                                    four unsigned word        \n                                                    integer results.          \n                                                    Computes the absolute     \n                                                    differences of the packed \n                                                    unsigned byte integers    \n   EVEX.128.66.0F.WIG F6                   AVX512VL from xmm3 /m128 and xmm2; \n   /r VPSADBW xmm1, xmm2,  C     V/V       AVX512BW then each consecutive 8   \n   xmm3/m128                                        differences are summed    \n                                                    separately to produce two \n                                                    unsigned word integer     \n                                                    results.                  \n                                                    Computes the absolute     \n                                                    differences of the packed \n                                                    unsigned byte integers    \n   EVEX.256.66.0F.WIG F6                   AVX512VL from ymm3 /m256 and ymm2; \n   /r VPSADBW ymm1, ymm2,  C     V/V       AVX512BW then each consecutive 8   \n   ymm3/m256                                        differences are summed    \n                                                    separately to produce     \n                                                    four unsigned word        \n                                                    integer results.          \n                                                    Computes the absolute     \n                                                    differences of the packed \n                                                    unsigned byte integers    \n   EVEX.512.66.0F.WIG F6                            from zmm3 /m512 and zmm2; \n   /r VPSADBW zmm1, zmm2,  C     V/V       AVX512BW then each consecutive 8   \n   zmm3/m512                                        differences are summed    \n                                                    separately to produce     \n                                                    eight unsigned word       \n                                                    integer results.          \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv     ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Computes the absolute value of the difference of 8 unsigned byte integers\n   from the source operand (second operand) and from the destination operand\n   (first operand). These 8 differences are then summed to produce an\n   unsigned word integer result that is stored in the destination operand.\n   Figure 4-14 shows the operation of the PSADBW instruction when using\n   64-bit operands.\n\n   When operating on 64-bit operands, the word integer result is stored in\n   the low word of the destination operand, and the remaining bytes in the\n   destination operand are cleared to all 0s.\n\n   When operating on 128-bit operands, two packed results are computed. Here,\n   the 8 low-order bytes of the source and destination operands are operated\n   on to produce a word result that is stored in the low word of the\n   destination operand, and the 8 high-order bytes are operated on to produce\n   a word result that is stored in bits 64 through 79 of the destination\n   operand. The remaining bytes of the destination operand are cleared.\n\n   For 256-bit version, the third group of 8 differences are summed to\n   produce an unsigned word in bits[143:128] of the destination register and\n   the fourth group of 8 differences are summed to produce an unsigned word\n   in bits[207:192] of the destination register. The remaining words of the\n   destination are set to 0.\n\n   For 512-bit version, the fifth group result is stored in bits [271:256] of\n   the destination. The result from the sixth group is stored in bits\n   [335:320]. The results for the seventh and eighth group are stored\n   respectively in bits [399:384] and bits [463:447], respectively. The\n   remaining bits in the destination are set to 0.\n\n   In 64-bit mode and not encoded by VEX/EVEX prefix, using a REX prefix in\n   the form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version: The source operand can be an MMX technology register\n   or a 64-bit memory location. The destination operand is an MMX technology\n   register.\n\n   128-bit Legacy SSE version: The first source operand and destination\n   register are XMM registers. The second source operand is an XMM register\n   or a 128-bit memory location. Bits (MAXVL-1:128) of the corresponding ZMM\n   destination register remain unchanged.\n\n   VEX.128 and EVEX.128 encoded versions: The first source operand and\n   destination register are XMM registers. The second source operand is an\n   XMM register or a 128-bit memory location. Bits (MAXVL-1:128) of the\n   corresponding ZMM register are zeroed.\n\n   VEX.256 and EVEX.256 encoded versions: The first source operand and\n   destination register are YMM registers. The second source operand is an\n   YMM register or a 256-bit memory location. Bits (MAXVL-1:256) of the\n   corresponding ZMM register are zeroed.\n\n   EVEX.512 encoded version: The first source operand and destination\n   register are ZMM registers. The second source operand is a ZMM register or\n   a 512-bit memory location.\n\n   SRC X7 X6 X5 X4 X3 X2 X1 X0 DEST Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 TEMP ABS(X7:Y7)\n   ABS(X6:Y6) ABS(X5:Y5) ABS(X4:Y4) ABS(X3:Y3) ABS(X2:Y2) ABS(X1:Y1)\n   ABS(X0:Y0) DEST 00H 00H 00H 00H 00H 00H SUM(TEMP7...TEMP0) Figure 4-14.\n   PSADBW Instruction Operation Using 64-bit Operands\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vgatherpf1dps:vgatherpf1qps:vgatherpf1dpd:vgatherpf1qpd", "VGATHERPF1DPS/VGATHERPF1QPS/VGATHERPF1DPD/VGATHERPF1QPD \u2014 Sparse PrefetchPacked\n    SP/DP Data Values With Signed Dword, Signed Qword Indices Using T1 Hint\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Using signed dword         \n                                                   indices, prefetch sparse   \n   EVEX.512.66.0F38.W0 C6                          byte memory locations      \n   /2 /vsib VGATHERPF1DPS A     V/V       AVX512PF containing                 \n   vm32z {k1}                                      single-precision data      \n                                                   using opmask k1 and T1     \n                                                   hint.                      \n                                                   Using signed qword         \n                                                   indices, prefetch sparse   \n   EVEX.512.66.0F38.W0 C7                          byte memory locations      \n   /2 /vsib VGATHERPF1QPS A     V/V       AVX512PF containing                 \n   vm64z {k1}                                      single-precision data      \n                                                   using opmask k1 and T1     \n                                                   hint.                      \n                                                   Using signed dword         \n   EVEX.512.66.0F38.W1 C6                          indices, prefetch sparse   \n   /2 /vsib VGATHERPF1DPD A     V/V       AVX512PF byte memory locations      \n   vm32y {k1}                                      containing double          \n                                                   precision data using       \n                                                   opmask k1 and T1 hint.     \n                                                   Using signed qword         \n   EVEX.512.66.0F38.W1 C7                          indices, prefetch sparse   \n   /2 /vsib VGATHERPF1QPD A     V/V       AVX512PF byte memory locations      \n   vm64z {k1}                                      containing double          \n                                                   precision data using       \n                                                   opmask k1 and T1 hint.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1                   Operand 2 Operand 3 Operand 4 \n   A     Tuple1     BaseReg (R): VSIB:base,     N/A       N/A       N/A       \n         Scalar     VectorReg(R): VSIB:index    \n\n  Description \u00b6\n\n   The instruction conditionally prefetches up to sixteen 32-bit or eight\n   64-bit integer byte data elements. The elements are specified via the VSIB\n   (i.e., the index register is an zmm, holding packed indices). Elements\n   will only be prefetched if their corresponding mask bit is one.\n\n   Lines prefetched are loaded into to a location in the cache hierarchy\n   specified by a locality hint (T1):\n\n     * T1 (temporal data)\u2014prefetch data into the second level cache.\n\n   [PS data] For dword indices, the instruction will prefetch sixteen memory\n   locations. For qword indices, the instruction will prefetch eight values.\n\n   [PD data] For dword and qword indices, the instruction will prefetch eight\n   memory locations.\n\n   Note that:\n\n   (1) The prefetches may happen in any order (or not at all). The\n   instruction is a hint.\n\n   (2) The mask is left unchanged.\n\n   (3) Not valid with 16-bit effective addresses. Will deliver a #UD fault.\n\n   (4) No FP nor memory faults may be produced by this instruction.\n\n   (5) Prefetches do not handle cache line splits\n\n   (6) A #UD is signaled if the memory operand is encoded without the SIB\n   byte.\n"],
	["addsubps", "         ADDSUBPS \u2014 Packed Single Precision Floating-Point Add/Subtract\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Add/subtract single        \n   F2 0F D0 /r ADDSUBPS    RM    V/V       SSE3    precision floating-point   \n   xmm1, xmm2/m128                                 values from xmm2/m128 to   \n                                                   xmm1.                      \n                                                   Add/subtract single        \n   VEX.128.F2.0F.WIG D0 /r                         precision floating-point   \n   VADDSUBPS xmm1, xmm2,   RVM   V/V       AVX     values from xmm3/mem to    \n   xmm3/m128                                       xmm2 and stores result in  \n                                                   xmm1.                      \n                                                   Add / subtract single      \n   VEX.256.F2.0F.WIG D0 /r                         precision floating-point   \n   VADDSUBPS ymm1, ymm2,   RVM   V/V       AVX     values from ymm3/mem to    \n   ymm3/m256                                       ymm2 and stores result in  \n                                                   ymm1.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   RVM   ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds odd-numbered single precision floating-point values of the first\n   source operand (second operand) with the corresponding single precision\n   floating-point values from the second source operand (third operand);\n   stores the result in the odd-numbered values of the destination operand\n   (first operand). Subtracts the even-numbered single precision\n   floating-point values from the second source operand from the\n   corresponding single precision floating values in the first source\n   operand; stores the result into the even-numbered values of the\n   destination operand.\n\n   In 64-bit mode, using a REX prefix in the form of REX.R permits this\n   instruction to access additional registers (XMM8-XMM15).\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified. See Figure 3-4.\n\n   VEX.128 encoded version: the first source operand is an XMM register or\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   ADDSUBPS xmm1, xmm2/m128 xmm2/ [127:96] [95:64] [63:32] [31:0] m128\n   RESULT: xmm1[127:96] + xmm1[95:64] - xmm2/ xmm1[63:32] + xmm1[31:0] - xmm1\n   xmm2/m128[127:96] m128[95:64] xmm2/m128[63:32] xmm2/m128[31:0] [127:96]\n   [95:64] [63:32] [31:0] Figure 3-4. ADDSUBPS\u2014Packed Single Precision\n   Floating-Point Add/Subtract\n"],
	["swapgs", "                         SWAPGS \u2014 Swap GS Base Register\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                Exchanges the current GS base \n   0F 01 F8 SWAPGS      ZO    Valid  Invalid    register value with the value \n                                                contained in MSR address      \n                                                C0000102H.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   SWAPGS exchanges the current GS base register value with the value\n   contained in MSR address C0000102H (IA32_KERNEL_GS_BASE). The SWAPGS\n   instruction is a privileged instruction intended for use by system\n   software.\n\n   When using SYSCALL to implement system calls, there is no kernel stack at\n   the OS entry point. Neither is there a straightforward method to obtain a\n   pointer to kernel structures from which the kernel stack pointer could be\n   read. Thus, the kernel cannot save general purpose registers or reference\n   memory.\n\n   By design, SWAPGS does not require any general purpose registers or memory\n   operands. No registers need to be saved before using the instruction.\n   SWAPGS exchanges the CPL 0 data pointer from the IA32_KERNEL_GS_BASE MSR\n   with the GS base register. The kernel can then use the GS prefix on normal\n   memory references to access kernel data structures. Similarly, when the OS\n   kernel is entered using an interrupt or exception (where the kernel stack\n   is already set up), SWAPGS can be used to quickly get a pointer to the\n   kernel data structures.\n\n   The IA32_KERNEL_GS_BASE MSR itself is only accessible using RDMSR/WRMSR\n   instructions. Those instructions are only accessible at privilege level 0.\n   The WRMSR instruction ensures that the IA32_KERNEL_GS_BASE MSR contains a\n   canonical address.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfnmsub132ps:vfnmsub213ps:vfnmsub231ps", "   VFNMSUB132PS/VFNMSUB213PS/VFNMSUB231PS \u2014 Fused Negative Multiply-Subtract\n                ofPacked Single Precision Floating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed          \n                                                     single-precision         \n   VEX.128.66.0F38.W0 9E /r                          floating-point values    \n   VFNMSUB132PS xmm1, xmm2, A     V/V       FMA      from xmm1 and xmm3/mem,  \n   xmm3/m128                                         negate the               \n                                                     multiplication result    \n                                                     and subtract xmm2 and    \n                                                     put result in xmm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   VEX.128.66.0F38.W0 AE /r                          floating-point values    \n   VFNMSUB213PS xmm1, xmm2, A     V/V       FMA      from xmm1 and xmm2,      \n   xmm3/m128                                         negate the               \n                                                     multiplication result    \n                                                     and subtract xmm3/mem    \n                                                     and put result in xmm1.  \n                                                     Multiply packed          \n                                                     single-precision         \n   VEX.128.66.0F38.W0 BE /r                          floating-point values    \n   VFNMSUB231PS xmm1, xmm2, A     V/V       FMA      from xmm2 and xmm3/mem,  \n   xmm3/m128                                         negate the               \n                                                     multiplication result    \n                                                     and subtract xmm1 and    \n                                                     put result in xmm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   VEX.256.66.0F38.W0 9E /r                          floating-point values    \n   VFNMSUB132PS ymm1, ymm2, A     V/V       FMA      from ymm1 and ymm3/mem,  \n   ymm3/m256                                         negate the               \n                                                     multiplication result    \n                                                     and subtract ymm2 and    \n                                                     put result in ymm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   VEX.256.66.0F38.W0 AE /r                          floating-point values    \n   VFNMSUB213PS ymm1, ymm2, A     V/V       FMA      from ymm1 and ymm2,      \n   ymm3/m256                                         negate the               \n                                                     multiplication result    \n                                                     and subtract ymm3/mem    \n                                                     and put result in ymm1.  \n                                                     Multiply packed          \n                                                     single-precision         \n   VEX.256.66.0F38.0 BE /r                           floating-point values    \n   VFNMSUB231PS ymm1, ymm2, A     V/V       FMA      from ymm2 and ymm3/mem,  \n   ymm3/m256                                         negate the               \n                                                     multiplication result    \n                                                     and subtract ymm1 and    \n                                                     put result in ymm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.128.66.0F38.W0 9E                            floating-point values    \n   /r VFNMSUB132PS xmm1                     AVX512VL from xmm1 and            \n   {k1}{z}, xmm2,           B     V/V       AVX512F  xmm3/m128/m32bcst,       \n   xmm3/m128/m32bcst                                 negate the               \n                                                     multiplication result    \n                                                     and subtract xmm2 and    \n                                                     put result in xmm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.128.66.0F38.W0 AE                            floating-point values    \n   /r VFNMSUB213PS xmm1                     AVX512VL from xmm1 and xmm2,      \n   {k1}{z}, xmm2,           B     V/V       AVX512F  negate the               \n   xmm3/m128/m32bcst                                 multiplication result    \n                                                     and subtract             \n                                                     xmm3/m128/m32bcst and    \n                                                     put result in xmm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.128.66.0F38.W0 BE                            floating-point values    \n   /r VFNMSUB231PS xmm1                     AVX512VL from xmm2 and            \n   {k1}{z}, xmm2,           B     V/V       AVX512F  xmm3/m128/m32bcst,       \n   xmm3/m128/m32bcst                                 negate the               \n                                                     multiplication result    \n                                                     subtract add to xmm1 and \n                                                     put result in xmm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.256.66.0F38.W0 9E                            floating-point values    \n   /r VFNMSUB132PS ymm1                     AVX512VL from ymm1 and            \n   {k1}{z}, ymm2,           B     V/V       AVX512F  ymm3/m256/m32bcst,       \n   ymm3/m256/m32bcst                                 negate the               \n                                                     multiplication result    \n                                                     and subtract ymm2 and    \n                                                     put result in ymm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.256.66.0F38.W0 AE                            floating-point values    \n   /r VFNMSUB213PS ymm1                     AVX512VL from ymm1 and ymm2,      \n   {k1}{z}, ymm2,           B     V/V       AVX512F  negate the               \n   ymm3/m256/m32bcst                                 multiplication result    \n                                                     and subtract             \n                                                     ymm3/m256/m32bcst and    \n                                                     put result in ymm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.256.66.0F38.W0 BE                            floating-point values    \n   /r VFNMSUB231PS ymm1                     AVX512VL from ymm2 and            \n   {k1}{z}, ymm2,           B     V/V       AVX512F  ymm3/m256/m32bcst,       \n   ymm3/m256/m32bcst                                 negate the               \n                                                     multiplication result    \n                                                     subtract add to ymm1 and \n                                                     put result in ymm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.512.66.0F38.W0 9E                            floating-point values    \n   /r VFNMSUB132PS zmm1                              from zmm1 and            \n   {k1}{z}, zmm2,           B     V/V       AVX512F  zmm3/m512/m32bcst,       \n   zmm3/m512/m32bcst{er}                             negate the               \n                                                     multiplication result    \n                                                     and subtract zmm2 and    \n                                                     put result in zmm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.512.66.0F38.W0 AE                            floating-point values    \n   /r VFNMSUB213PS zmm1                              from zmm1 and zmm2,      \n   {k1}{z}, zmm2,           B     V/V       AVX512F  negate the               \n   zmm3/m512/m32bcst{er}                             multiplication result    \n                                                     and subtract             \n                                                     zmm3/m512/m32bcst and    \n                                                     put result in zmm1.      \n                                                     Multiply packed          \n                                                     single-precision         \n   EVEX.512.66.0F38.W0 BE                            floating-point values    \n   /r VFNMSUB231PS zmm1                              from zmm2 and            \n   {k1}{z}, zmm2,           B     V/V       AVX512F  zmm3/m512/m32bcst,       \n   zmm3/m512/m32bcst{er}                             negate the               \n                                                     multiplication result    \n                                                     subtract add to zmm1 and \n                                                     put result in zmm1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMSUB132PS: Multiplies the four, eight or sixteen packed\n   single-precision floating-point values from the first source operand to\n   the four, eight or sixteen packed single-precision floating-point values\n   in the third source operand. From negated infinite precision intermediate\n   results, subtracts the four, eight or sixteen packed single-precision\n   floating-point values in the second source operand, performs rounding and\n   stores the resulting four, eight or sixteen packed single-precision\n   floating-point values to the destination operand (first source operand).\n\n   VFNMSUB213PS: Multiplies the four, eight or sixteen packed\n   single-precision floating-point values from the second source operand to\n   the four, eight or sixteen packed single-precision floating-point values\n   in the first source operand. From negated infinite precision intermediate\n   results, subtracts the four, eight or sixteen packed single-precision\n   floating-point values in the third source operand, performs rounding and\n   stores the resulting four, eight or sixteen packed single-precision\n   floating-point values to the destination operand (first source operand).\n\n   VFNMSUB231PS: Multiplies the four, eight or sixteen packed\n   single-precision floating-point values from the second source to the four,\n   eight or sixteen packed single-precision floating-point values in the\n   third source operand. From negated infinite precision intermediate\n   results, subtracts the four, eight or sixteen packed single-precision\n   floating-point values in the first source operand, performs rounding and\n   stores the resulting four, eight or sixteen packed single-precision\n   floating-point values to the destination operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 32-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["vfmsub132sd:vfmsub213sd:vfmsub231sd", "    VFMSUB132SD/VFMSUB213SD/VFMSUB231SD \u2014 Fused Multiply-Subtract of Scalar\n                     DoublePrecision Floating-Point Values\n\n                              Op / 64/32 Bit CPUID                            \n   Opcode/Instruction         En   Mode      Feature Description\n                                   Support   Flag    \n                                                     Multiply scalar double   \n   VEX.LIG.66.0F38.W1 9B /r                          precision floating-point \n   VFMSUB132SD xmm1, xmm2,    A    V/V       FMA     value from xmm1 and      \n   xmm3/m64                                          xmm3/m64, subtract xmm2  \n                                                     and put result in xmm1.  \n                                                     Multiply scalar double   \n   VEX.LIG.66.0F38.W1 AB /r                          precision floating-point \n   VFMSUB213SD xmm1, xmm2,    A    V/V       FMA     value from xmm1 and      \n   xmm3/m64                                          xmm2, subtract xmm3/m64  \n                                                     and put result in xmm1.  \n                                                     Multiply scalar double   \n   VEX.LIG.66.0F38.W1 BB /r                          precision floating-point \n   VFMSUB231SD xmm1, xmm2,    A    V/V       FMA     value from xmm2 and      \n   xmm3/m64                                          xmm3/m64, subtract xmm1  \n                                                     and put result in xmm1.  \n                                                     Multiply scalar double   \n   EVEX.LLIG.66.0F38.W1 9B /r                        precision floating-point \n   VFMSUB132SD xmm1 {k1}{z},  B    V/V       AVX512F value from xmm1 and      \n   xmm2, xmm3/m64{er}                                xmm3/m64, subtract xmm2  \n                                                     and put result in xmm1.  \n                                                     Multiply scalar double   \n   EVEX.LLIG.66.0F38.W1 AB /r                        precision floating-point \n   VFMSUB213SD xmm1 {k1}{z},  B    V/V       AVX512F value from xmm1 and      \n   xmm2, xmm3/m64{er}                                xmm2, subtract xmm3/m64  \n                                                     and put result in xmm1.  \n                                                     Multiply scalar double   \n   EVEX.LLIG.66.0F38.W1 BB /r                        precision floating-point \n   VFMSUB231SD xmm1 {k1}{z},  B    V/V       AVX512F value from xmm2 and      \n   xmm2, xmm3/m64{er}                                xmm3/m64, subtract xmm1  \n                                                     and put result in xmm1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a SIMD multiply-subtract computation on the low packed double\n   precision floating-point values using three source operands and writes the\n   multiply-subtract result in the destination operand. The destination\n   operand is also the first source operand. The second operand must be a XMM\n   register. The third source operand can be a XMM register or a 64-bit\n   memory location.\n\n   VFMSUB132SD: Multiplies the low packed double precision floating-point\n   value from the first source operand to the low packed double precision\n   floating-point value in the third source operand. From the infinite\n   precision intermediate result, subtracts the low packed double precision\n   floating-point values in the second source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VFMSUB213SD: Multiplies the low packed double precision floating-point\n   value from the second source operand to the low packed double precision\n   floating-point value in the first source operand. From the infinite\n   precision intermediate result, subtracts the low packed double precision\n   floating-point value in the third source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VFMSUB231SD: Multiplies the low packed double precision floating-point\n   value from the second source to the low packed double precision\n   floating-point value in the third source operand. From the infinite\n   precision intermediate result, subtracts the low packed double precision\n   floating-point value in the first source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:64 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination is\n   updated according to the writemask.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["kaddw:kaddb:kaddq:kaddd", "                    KADDW/KADDB/KADDQ/KADDD \u2014 ADD Two Masks\n\n                                  64/32 bit    CPUID                          \n   Opcode/Instruction       Op/En Mode Support Feature  Description\n                                               Flag     \n   VEX.L1.0F.W0 4A /r KADDW                             Add 16 bits masks in  \n   k1, k2, k3               RVR   V/V          AVX512DQ k2 and k3 and place   \n                                                        result in k1.         \n   VEX.L1.66.0F.W0 4A /r                                Add 8 bits masks in   \n   KADDB k1, k2, k3         RVR   V/V          AVX512DQ k2 and k3 and place   \n                                                        result in k1.         \n   VEX.L1.0F.W1 4A /r KADDQ                             Add 64 bits masks in  \n   k1, k2, k3               RVR   V/V          AVX512BW k2 and k3 and place   \n                                                        result in k1.         \n   VEX.L1.66.0F.W1 4A /r                                Add 32 bits masks in  \n   KADDD k1, k2, k3         RVR   V/V          AVX512BW k2 and k3 and place   \n                                                        result in k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2    Operand 3                              \n   RVR   ModRM:reg (w) VEX.1vvv (r) ModRM:r/m (r, ModRM:[7:6] must be 11b) \n\nDescription \u00b6\n\n   Adds the vector mask k2 and the vector mask k3, and writes the result into\n   vector mask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["bndldx", "            BNDLDX \u2014 Load Extended Bounds Using Address Translation\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Load the bounds stored in  \n                                                   a bound table entry (BTE)  \n                                                   into bnd with address      \n   NP 0F 1A /r BNDLDX bnd, RM    V/V       MPX     translation using the base \n   mib                                             of mib and conditional on  \n                                                   the index of mib matching  \n                                                   the pointer value in the   \n                                                   BTE.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2                                    Operand 3 \n   RM    ModRM:reg (w) SIB.base (r): Address of pointer             N/A       \n                       SIB.index(r)                                 \n\nDescription \u00b6\n\n   BNDLDX uses the linear address constructed from the base register and\n   displacement of the SIB-addressing form of the memory operand (mib) to\n   perform address translation to access a bound table entry and\n   conditionally load the bounds in the BTE to the destination. The\n   destination register is updated with the bounds in the BTE, if the content\n   of the index register of mib matches the pointer value stored in the BTE.\n\n   If the pointer value comparison fails, the destination is updated with\n   INIT bounds (lb = 0x0, ub = 0x0) (note: as articulated earlier, the upper\n   bound is represented using 1's complement, therefore, the 0x0 value of\n   upper bound allows for access to full memory).\n\n   This instruction does not cause memory access to the linear address of mib\n   nor the effective address referenced by the base, and does not read or\n   write any flags.\n\n   Segment overrides apply to the linear address computation with the base of\n   mib, and are used during address translation to generate the address of\n   the bound table entry. By default, the address of the BTE is assumed to be\n   linear address. There are no segmentation checks performed on the base of\n   mib.\n\n   The base of mib will not be checked for canonical address violation as it\n   does not access memory.\n\n   Any encoding of this instruction that does not specify base or index\n   register will treat those registers as zero (constant). The reg-reg form\n   of this instruction will remain a NOP.\n\n   The scale field of the SIB byte has no effect on these instructions and is\n   ignored.\n\n   The bound register may be partially updated on memory faults. The order in\n   which memory operands are loaded is implementation specific.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpermq", "                      VPERMQ \u2014 Qwords Element Permutation\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n   VEX.256.66.0F3A.W1 00 /r                         Permute qwords in         \n   ib VPERMQ ymm1,          A    V/V       AVX2     ymm2/m256 using indices   \n   ymm2/m256, imm8                                  in imm8 and store the     \n                                                    result in ymm1.           \n   EVEX.256.66.0F3A.W1 00                           Permute qwords in         \n   /r ib VPERMQ ymm1        B    V/V       AVX512VL ymm2/m256/m64bcst using   \n   {k1}{z},                                AVX512F  indexes in imm8 and store \n   ymm2/m256/m64bcst, imm8                          the result in ymm1.       \n   EVEX.512.66.0F3A.W1 00                           Permute qwords in         \n   /r ib VPERMQ zmm1        B    V/V       AVX512F  zmm2/m512/m64bcst using   \n   {k1}{z},                                         indices in imm8 and store \n   zmm2/m512/m64bcst, imm8                          the result in zmm1.       \n   EVEX.256.66.0F38.W1 36                           Permute qwords in         \n   /r VPERMQ ymm1 {k1}{z},  C    V/V       AVX512VL ymm3/m256/m64bcst using   \n   ymm2, ymm3/m256/m64bcst                 AVX512F  indexes in ymm2 and store \n                                                    the result in ymm1.       \n   EVEX.512.66.0F38.W1 36                           Permute qwords in         \n   /r VPERMQ zmm1 {k1}{z},  C    V/V       AVX512F  zmm3/m512/m64bcst using   \n   zmm2, zmm3/m512/m64bcst                          indices in zmm2 and store \n                                                    the result in zmm1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) imm8          N/A       \n   C     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   The imm8 version: Copies quadwords from the source operand (the second\n   operand) to the destination operand (the first operand) according to the\n   indices specified by the immediate operand (the third operand). Each\n   two-bit value in the immediate byte selects a qword element in the source\n   operand.\n\n   VEX version: The source operand can be a YMM register or a memory\n   location. Bits (MAXVL-1:256) of the corresponding destination register are\n   zeroed.\n\n   In EVEX.512 encoded version, The elements in the destination are updated\n   using the writemask k1 and the imm8 bits are reused as control bits for\n   the upper 256-bit half when the control bits are coming from immediate.\n   The source operand can be a ZMM register, a 512-bit memory location or a\n   512-bit vector broadcasted from a 64-bit memory location.\n\n   Immediate control versions: VEX.vvvv and EVEX.vvvv are reserved and must\n   be 1111b otherwise instructions will #UD.\n\n   The vector control version: Copies quadwords from the second source\n   operand (the third operand) to the destination operand (the first operand)\n   according to the indices in the first source operand (the second operand).\n   The first 3 bits of each 64 bit element in the index operand selects which\n   quadword in the second source operand to copy. The first and second\n   operands are ZMM registers, the third operand can be a ZMM register, a\n   512-bit memory location or a 512-bit vector broadcasted from a 64-bit\n   memory location. The elements in the destination are updated using the\n   writemask k1.\n\n   Note that this instruction permits a qword in the source operand to be\n   copied to multiple locations in the destination operand.\n\n   If VPERMPQ is encoded with VEX.L= 0 or EVEX.128, an attempt to execute the\n   instruction will cause an #UD exception.\n"],
	["invlpg", "                        INVLPG \u2014 Invalidate TLB Entries\n\n   Opcode^1\n\n           Instruction Op/En 64-Bit Mode Compat/Leg Mode Description          \n                                                         Invalidate TLB       \n   0F 01/7                   Valid       Valid           entries for page     \n                                                         containing m.        \n\n   1. See the IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Invalidates any translation lookaside buffer (TLB) entries specified with\n   the source operand. The source operand is a memory address. The processor\n   determines the page that contains that address and flushes all TLB entries\n   for that page.^1\n\n   The INVLPG instruction is a privileged instruction. When the processor is\n   running in protected mode, the CPL must be 0 to execute this instruction.\n\n   The INVLPG instruction normally flushes TLB entries only for the specified\n   page; however, in some cases, it may flush more entries, even the entire\n   TLB. The instruction invalidates TLB entries associated with the current\n   PCID and may or may not do so for TLB entries associated with other PCIDs.\n   (If PCIDs are disabled \u2014 CR4.PCIDE = 0 \u2014 the current PCID is 000H.) The\n   instruction also invalidates any global TLB entries for the specified\n   page, regardless of PCID.\n\n   For more details on operations that flush the TLB, see \u201cMOV\u2014Move to/from\n   Control Registers\u201d in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 2B, and Section 4.10.4.1, \u201cOperations that\n   Invalidate TLBs and Paging-Structure Caches,\u201d in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3A.\n\n   This instruction\u2019s operation is the same in all non-64-bit modes. It also\n   operates the same in 64-bit mode, except if the memory address is in\n   non-canonical form. In this case, INVLPG is the same as a NOP.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The INVLPG instruction is implementation dependent, and its function may\n   be implemented differently on different families of Intel 64 or IA-32\n   processors. This instruction is not supported on IA-32 processors earlier\n   than the Intel486 processor.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vscalefph", "             VSCALEFPH \u2014 Scale Packed FP16 Values with FP16 Values\n\n   Instruction En bit Mode Flag                                               \n   Support Instruction En bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En bit    \n   Mode Flag CPUID Feature       \n   Instruction En bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En bit Mode Flag  \n   CPUID Feature Instruction En  \n   bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Scale the packed FP16  \n                                                       values in xmm2 using   \n   EVEX.128.66.MAP6.W0 2C /r               AVX512-FP16 values from            \n   VSCALEFPH xmm1{k1}{z}, xmm2,  A V/V     AVX512VL    xmm3/m128/m16bcst, and \n   xmm3/m128/m16bcst                                   store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Scale the packed FP16  \n                                                       values in ymm2 using   \n   EVEX.256.66.MAP6.W0 2C /r               AVX512-FP16 values from            \n   VSCALEFPH ymm1{k1}{z}, ymm2,  A V/V     AVX512VL    ymm3/m256/m16bcst, and \n   ymm3/m256/m16bcst                                   store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Scale the packed FP16  \n                                                       values in zmm2 using   \n   EVEX.512.66.MAP6.W0 2C /r                           values from            \n   VSCALEFPH zmm1{k1}{z}, zmm2,  A V/V     AVX512-FP16 zmm3/m512/m16bcst, and \n   zmm3/m512/m16bcst {er}                              store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a floating-point scale of the packed FP16 values\n   in the first source operand by multiplying it by 2 to the power of the\n   FP16 values in second source operand. The destination elements are updated\n   according to the writemask.\n\n   The equation of this operation is given by:\n\n   zmm1 := zmm2 * 2^floor(zmm3).\n\n   Floor(zmm3) means maximum integer value \u2264 zmm3.\n\n   If the result cannot be represented in FP16, then the proper overflow\n   response (for positive scaling operand), or the proper underflow response\n   (for negative scaling operand), is issued. The overflow and underflow\n   responses are dependent on the rounding mode (for IEEE-compliant\n   rounding), as well as on other settings in MXCSR (exception mask bits),\n   and on the SAE bit.\n\n   Handling of special-case input values are listed in Table 5-41 and Table\n   5-42.\n\n   Src1        Src2                                                     Set IE \n               \u00b1NaN       +INF            \u2212INF            0/Denorm/Norm \n                                                                        IF     \n                                                                        either \n   \u00b1QNaN       QNaN(Src1) +INF            +0              QNaN(Src1)    source \n                                                                        is     \n                                                                        SNaN   \n   \u00b1SNaN       QNaN(Src1) QNaN(Src1)      QNaN(Src1)      QNaN(Src1)    YES    \n                                                                        IF     \n                                                                        Src2   \n   \u00b1INF        QNaN(Src2) Src1            QNaN_Indefinite Src1          is     \n                                                                        SNaN   \n                                                                        or     \n                                                                        \u2212INF   \n                                                                        IF     \n                                                                        Src2   \n   \u00b10          QNaN(Src2) QNaN_Indefinite Src1            Src1          is     \n                                                                        SNaN   \n                                                                        or     \n                                                                        +INF   \n                                                                        IF     \n   Denorm/Norm QNaN(Src2) \u00b1INF (Src1      \u00b10 (Src1 sign)  Compute       Src2   \n                          sign)                           Result        is     \n                                                                        SNaN   \n\n   Table 5-41. VSCALEFPH/VSCALEFSH Special Cases\n\n   Special Case     Returned Value                                Faults    \n   |result| < 2^-24 \u00b10 or \u00b1Min-Denormal (Src1 sign)               Underflow \n   |result| \u2265 2^16  \u00b1INF (Src1 sign) or \u00b1Max-Denormal (Src1 sign) Overflow  \n\n   Table 5-42. Additional VSCALEFPH/VSCALEFSH Special Cases\n"],
	["pavgb:pavgw", "                     PAVGB/PAVGW \u2014 Average Packed Integers\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Average packed unsigned  \n   NP 0F E0 /r^1 PAVGB mm1, A     V/V       SSE      byte integers from       \n   mm2/m64                                           mm2/m64 and mm1 with     \n                                                     rounding.                \n                                                     Average packed unsigned  \n   66 0F E0, /r PAVGB xmm1, A     V/V       SSE2     byte integers from       \n   xmm2/m128                                         xmm2/m128 and xmm1 with  \n                                                     rounding.                \n                                                     Average packed unsigned  \n   NP 0F E3 /r^1 PAVGW mm1, A     V/V       SSE      word integers from       \n   mm2/m64                                           mm2/m64 and mm1 with     \n                                                     rounding.                \n                                                     Average packed unsigned  \n   66 0F E3 /r PAVGW xmm1,  A     V/V       SSE2     word integers from       \n   xmm2/m128                                         xmm2/m128 and xmm1 with  \n                                                     rounding.                \n   VEX.128.66.0F.WIG E0 /r                           Average packed unsigned  \n   VPAVGB xmm1, xmm2,       B     V/V       AVX      byte integers from       \n   xmm3/m128                                         xmm3/m128 and xmm2 with  \n                                                     rounding.                \n   VEX.128.66.0F.WIG E3 /r                           Average packed unsigned  \n   VPAVGW xmm1, xmm2,       B     V/V       AVX      word integers from       \n   xmm3/m128                                         xmm3/m128 and xmm2 with  \n                                                     rounding.                \n                                                     Average packed unsigned  \n   VEX.256.66.0F.WIG E0 /r                           byte integers from ymm2, \n   VPAVGB ymm1, ymm2,       B     V/V       AVX2     and ymm3/m256 with       \n   ymm3/m256                                         rounding and store to    \n                                                     ymm1.                    \n   VEX.256.66.0F.WIG E3 /r                           Average packed unsigned  \n   VPAVGW ymm1, ymm2,       B     V/V       AVX2     word integers from ymm2, \n   ymm3/m256                                         ymm3/m256 with rounding  \n                                                     to ymm1.                 \n                                                     Average packed unsigned  \n   EVEX.128.66.0F.WIG E0 /r                 AVX512VL byte integers from xmm2, \n   VPAVGB xmm1 {k1}{z},     C     V/V       AVX512BW and xmm3/m128 with       \n   xmm2, xmm3/m128                                   rounding and store to    \n                                                     xmm1 under writemask k1. \n                                                     Average packed unsigned  \n   EVEX.256.66.0F.WIG E0 /r                 AVX512VL byte integers from ymm2, \n   VPAVGB ymm1 {k1}{z},     C     V/V       AVX512BW and ymm3/m256 with       \n   ymm2, ymm3/m256                                   rounding and store to    \n                                                     ymm1 under writemask k1. \n                                                     Average packed unsigned  \n   EVEX.512.66.0F.WIG E0 /r                          byte integers from zmm2, \n   VPAVGB zmm1 {k1}{z},     C     V/V       AVX512BW and zmm3/m512 with       \n   zmm2, zmm3/m512                                   rounding and store to    \n                                                     zmm1 under writemask k1. \n                                                     Average packed unsigned  \n   EVEX.128.66.0F.WIG E3 /r                 AVX512VL word integers from xmm2, \n   VPAVGW xmm1 {k1}{z},     C     V/V       AVX512BW xmm3/m128 with rounding  \n   xmm2, xmm3/m128                                   to xmm1 under writemask  \n                                                     k1.                      \n                                                     Average packed unsigned  \n   EVEX.256.66.0F.WIG E3 /r                 AVX512VL word integers from ymm2, \n   VPAVGW ymm1 {k1}{z},     C     V/V       AVX512BW ymm3/m256 with rounding  \n   ymm2, ymm3/m256                                   to ymm1 under writemask  \n                                                     k1.                      \n                                                     Average packed unsigned  \n   EVEX.512.66.0F.WIG E3 /r                          word integers from zmm2, \n   VPAVGW zmm1 {k1}{z},     C     V/V       AVX512BW zmm3/m512 with rounding  \n   zmm2, zmm3/m512                                   to zmm1 under writemask  \n                                                     k1.                      \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2B, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD average of the packed unsigned integers from the source\n   operand (second operand) and the destination operand (first operand), and\n   stores the results in the destination operand. For each corresponding pair\n   of data elements in the first and second operands, the elements are added\n   together, a 1 is added to the temporary sum, and that result is shifted\n   right one bit position.\n\n   The (V)PAVGB instruction operates on packed unsigned bytes and the\n   (V)PAVGW instruction operates on packed unsigned words.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding register destination are\n   unmodified.\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand is a ZMM register or a 512-bit memory location. The\n   destination operand is a ZMM register.\n\n   VEX.256 and EVEX.256 encoded versions: The first source operand is a YMM\n   register. The second source operand is a YMM register or a 256-bit memory\n   location. The destination operand is a YMM register.\n\n   VEX.128 and EVEX.128 encoded versions: The first source operand is an XMM\n   register. The second source operand is an XMM register or 128-bit memory\n   location. The destination operand is an XMM register. The upper bits\n   (MAXVL-1:128) of the corresponding register destination are zeroed.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vblendmpd:vblendmps", "  VBLENDMPD/VBLENDMPS \u2014 Blend Float64/Float32 Vectors Using an OpMask Control\n\n                                64/32 Bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n                                                   Blend double precision     \n   EVEX.128.66.0F38.W1 65                          vector xmm2 and double     \n   /r VBLENDMPD xmm1      A     V/V       AVX512VL precision vector           \n   {k1}{z}, xmm2,                         AVX512F  xmm3/m128/m64bcst and      \n   xmm3/m128/m64bcst                               store the result in xmm1,  \n                                                   under control mask.        \n                                                   Blend double precision     \n   EVEX.256.66.0F38.W1 65                          vector ymm2 and double     \n   /r VBLENDMPD ymm1      A     V/V       AVX512VL precision vector           \n   {k1}{z}, ymm2,                         AVX512F  ymm3/m256/m64bcst and      \n   ymm3/m256/m64bcst                               store the result in ymm1,  \n                                                   under control mask.        \n                                                   Blend double precision     \n   EVEX.512.66.0F38.W1 65                          vector zmm2 and double     \n   /r VBLENDMPD zmm1      A     V/V       AVX512F  precision vector           \n   {k1}{z}, zmm2,                                  zmm3/m512/m64bcst and      \n   zmm3/m512/m64bcst                               store the result in zmm1,  \n                                                   under control mask.        \n                                                   Blend single precision     \n   EVEX.128.66.0F38.W0 65                          vector xmm2 and single     \n   /r VBLENDMPS xmm1      A     V/V       AVX512VL precision vector           \n   {k1}{z}, xmm2,                         AVX512F  xmm3/m128/m32bcst and      \n   xmm3/m128/m32bcst                               store the result in xmm1,  \n                                                   under control mask.        \n                                                   Blend single precision     \n   EVEX.256.66.0F38.W0 65                          vector ymm2 and single     \n   /r VBLENDMPS ymm1      A     V/V       AVX512VL precision vector           \n   {k1}{z}, ymm2,                         AVX512F  ymm3/m256/m32bcst and      \n   ymm3/m256/m32bcst                               store the result in ymm1,  \n                                                   under control mask.        \n                                                   Blend single precision     \n   EVEX.512.66.0F38.W0 65                          vector zmm2 and single     \n   /r VBLENDMPS zmm1      A     V/V       AVX512F  precision vector           \n   {k1}{z}, zmm2,                                  zmm3/m512/m32bcst using k1 \n   zmm3/m512/m32bcst                               as select control and      \n                                                   store the result in zmm1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs an element-by-element blending between float64/float32 elements\n   in the first source operand (the second operand) with the elements in the\n   second source operand (the third operand) using an opmask register as\n   select control. The blended result is written to the destination register.\n\n   The destination and first source operands are ZMM/YMM/XMM registers. The\n   second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 64-bit\n   memory location.\n\n   The opmask register is not used as a writemask for this instruction.\n   Instead, the mask is used as an element selector: every element of the\n   destination is conditionally selected between first source or second\n   source using the value of the related mask bit (0 for first source\n   operand, 1 for second source operand).\n\n   If EVEX.z is set, the elements with corresponding mask bit value of 0 in\n   the destination operand are zeroed.\n"],
	["emms", "                       EMMS \u2014 Empty MMX Technology State\n\n   Opcode   Instruction Op/En 64-Bit Mode Compat/Leg Mode Description         \n   NP 0F 77 EMMS        ZO    Valid       Valid           Set the x87 FPU tag \n                                                          word to empty.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Sets the values of all the tags in the x87 FPU tag word to empty (all 1s).\n   This operation marks the x87 FPU data registers (which are aliased to the\n   MMX technology registers) as available for use by x87 FPU floating-point\n   instructions. (See Figure 8-7 in the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 1, for the format of the x87 FPU tag\n   word.) All other MMX instructions (other than the EMMS instruction) set\n   all the tags in x87 FPU tag word to valid (all 0s).\n\n   The EMMS instruction must be used to clear the MMX technology state at the\n   end of all MMX technology procedures or subroutines and before calling\n   other procedures or subroutines that may execute x87 floating-point\n   instructions. If a floating-point instruction loads one of the registers\n   in the x87 FPU data register stack before the x87 FPU tag word has been\n   reset by the EMMS instruction, an x87 floating-point register stack\n   overflow can occur that will result in an x87 floating-point exception or\n   incorrect result.\n\n   EMMS operation is the same in non-64-bit modes and 64-bit mode.\n\nFlags Affected \u00b6\n\n   None\n"],
	["lldt", "                  LLDT \u2014 Load Local Descriptor Table Register\n\n   Opcode   Instruction Op/En 64-Bit Compat/Leg Mode Description              \n                              Mode   \n   0F 00 /2 LLDT r/m16  M     Valid  Valid           Load segment selector    \n                                                     r/m16 into LDTR.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the source operand into the segment selector field of the local\n   descriptor table register (LDTR). The source operand (a general-purpose\n   register or a memory location) contains a segment selector that points to\n   a local descriptor table (LDT). After the segment selector is loaded in\n   the LDTR, the processor uses the segment selector to locate the segment\n   descriptor for the LDT in the global descriptor table (GDT). It then loads\n   the segment limit and base address for the LDT from the segment descriptor\n   into the LDTR. The segment registers DS, ES, SS, FS, GS, and CS are not\n   affected by this instruction, nor is the LDTR field in the task state\n   segment (TSS) for the current task.\n\n   If bits 2-15 of the source operand are 0, LDTR is marked invalid and the\n   LLDT instruction completes silently. However, all subsequent references to\n   descriptors in the LDT (except by the LAR, VERR, VERW or LSL instructions)\n   cause a general protection exception (#GP).\n\n   The operand-size attribute has no effect on this instruction.\n\n   The LLDT instruction is provided for use in operating-system software; it\n   should not be used in application programs. This instruction can only be\n   executed in protected mode or 64-bit mode.\n\n   In 64-bit mode, the operand size is fixed at 16 bits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfmsubadd132ps:vfmsubadd213ps:vfmsubadd231ps", "              VFMSUBADD132PS/VFMSUBADD213PS/VFMSUBADD231PS \u2014 Fused\n   Multiply-AlternatingSubtract/Add of Packed Single Precision Floating-Point\n                                     Values\n\n                             Op 64/32 Bit CPUID                               \n   Opcode/Instruction        /  Mode      Feature  Description\n                             En Support   Flag     \n                                                   Multiply packed single     \n   VEX.128.66.0F38.W0 97 /r                        precision floating-point   \n   VFMSUBADD132PS xmm1,      A  V/V       FMA      values from xmm1 and       \n   xmm2, xmm3/m128                                 xmm3/mem, subtract/add     \n                                                   elements in xmm2 and put   \n                                                   result in xmm1.            \n                                                   Multiply packed single     \n   VEX.128.66.0F38.W0 A7 /r                        precision floating-point   \n   VFMSUBADD213PS xmm1,      A  V/V       FMA      values from xmm1 and xmm2, \n   xmm2, xmm3/m128                                 subtract/add elements in   \n                                                   xmm3/mem and put result in \n                                                   xmm1.                      \n                                                   Multiply packed single     \n   VEX.128.66.0F38.W0 B7 /r                        precision floating-point   \n   VFMSUBADD231PS xmm1,      A  V/V       FMA      values from xmm2 and       \n   xmm2, xmm3/m128                                 xmm3/mem, subtract/add     \n                                                   elements in xmm1 and put   \n                                                   result in xmm1.            \n                                                   Multiply packed single     \n   VEX.256.66.0F38.W0 97 /r                        precision floating-point   \n   VFMSUBADD132PS ymm1,      A  V/V       FMA      values from ymm1 and       \n   ymm2, ymm3/m256                                 ymm3/mem, subtract/add     \n                                                   elements in ymm2 and put   \n                                                   result in ymm1.            \n                                                   Multiply packed single     \n   VEX.256.66.0F38.W0 A7 /r                        precision floating-point   \n   VFMSUBADD213PS ymm1,      A  V/V       FMA      values from ymm1 and ymm2, \n   ymm2, ymm3/m256                                 subtract/add elements in   \n                                                   ymm3/mem and put result in \n                                                   ymm1.                      \n                                                   Multiply packed single     \n   VEX.256.66.0F38.W0 B7 /r                        precision floating-point   \n   VFMSUBADD231PS ymm1,      A  V/V       FMA      values from ymm2 and       \n   ymm2, ymm3/m256                                 ymm3/mem, subtract/add     \n                                                   elements in ymm1 and put   \n                                                   result in ymm1.            \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   EVEX.128.66.0F38.W0 97 /r                       values from xmm1 and       \n   VFMSUBADD132PS xmm1       B  V/V       AVX512VL xmm3/m128/m32bcst,         \n   {k1}{z}, xmm2,                         AVX512F  subtract/add elements in   \n   xmm3/m128/m32bcst                               xmm2 and put result in     \n                                                   xmm1 subject to writemask  \n                                                   k1.                        \n                                                   Multiply packed single     \n   EVEX.128.66.0F38.W0 A7 /r                       precision floating-point   \n   VFMSUBADD213PS xmm1                    AVX512VL values from xmm1 and xmm2, \n   {k1}{z}, xmm2,            B  V/V       AVX512F  subtract/add elements in   \n   xmm3/m128/m32bcst                               xmm3/m128/m32bcst and put  \n                                                   result in xmm1 subject to  \n                                                   writemask k1.              \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   EVEX.128.66.0F38.W0 B7 /r                       values from xmm2 and       \n   VFMSUBADD231PS xmm1       B  V/V       AVX512VL xmm3/m128/m32bcst,         \n   {k1}{z}, xmm2,                         AVX512F  subtract/add elements in   \n   xmm3/m128/m32bcst                               xmm1 and put result in     \n                                                   xmm1 subject to writemask  \n                                                   k1.                        \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   EVEX.256.66.0F38.W0 97 /r                       values from ymm1 and       \n   VFMSUBADD132PS ymm1       B  V/V       AVX512VL ymm3/m256/m32bcst,         \n   {k1}{z}, ymm2,                         AVX512F  subtract/add elements in   \n   ymm3/m256/m32bcst                               ymm2 and put result in     \n                                                   ymm1 subject to writemask  \n                                                   k1.                        \n                                                   Multiply packed single     \n   EVEX.256.66.0F38.W0 A7 /r                       precision floating-point   \n   VFMSUBADD213PS ymm1                    AVX512VL values from ymm1 and ymm2, \n   {k1}{z}, ymm2,            B  V/V       AVX512F  subtract/add elements in   \n   ymm3/m256/m32bcst                               ymm3/m256/m32bcst and put  \n                                                   result in ymm1 subject to  \n                                                   writemask k1.              \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   EVEX.256.66.0F38.W0 B7 /r                       values from ymm2 and       \n   VFMSUBADD231PS ymm1       B  V/V       AVX512VL ymm3/m256/m32bcst,         \n   {k1}{z}, ymm2,                         AVX512F  subtract/add elements in   \n   ymm3/m256/m32bcst                               ymm1 and put result in     \n                                                   ymm1 subject to writemask  \n                                                   k1.                        \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   EVEX.512.66.0F38.W0 97 /r                       values from zmm1 and       \n   VFMSUBADD132PS zmm1       B  V/V       AVX512F  zmm3/m512/m32bcst,         \n   {k1}{z}, zmm2,                                  subtract/add elements in   \n   zmm3/m512/m32bcst{er}                           zmm2 and put result in     \n                                                   zmm1 subject to writemask  \n                                                   k1.                        \n                                                   Multiply packed single     \n   EVEX.512.66.0F38.W0 A7 /r                       precision floating-point   \n   VFMSUBADD213PS zmm1                             values from zmm1 and zmm2, \n   {k1}{z}, zmm2,            B  V/V       AVX512F  subtract/add elements in   \n   zmm3/m512/m32bcst{er}                           zmm3/m512/m32bcst and put  \n                                                   result in zmm1 subject to  \n                                                   writemask k1.              \n                                                   Multiply packed single     \n                                                   precision floating-point   \n   EVEX.512.66.0F38.W0 B7 /r                       values from zmm2 and       \n   VFMSUBADD231PS zmm1       B  V/V       AVX512F  zmm3/m512/m32bcst,         \n   {k1}{z}, zmm2,                                  subtract/add elements in   \n   zmm3/m512/m32bcst{er}                           zmm1 and put result in     \n                                                   zmm1 subject to writemask  \n                                                   k1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFMSUBADD132PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the first source operand to the\n   corresponding packed single precision floating-point values in the third\n   source operand. From the infinite precision intermediate result, subtracts\n   the odd single precision floating-point elements and adds the even single\n   precision floating-point values in the second source operand, performs\n   rounding and stores the resulting packed single precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMSUBADD213PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the second source operand to the\n   corresponding packed single precision floating-point values in the first\n   source operand. From the infinite precision intermediate result, subtracts\n   the odd single precision floating-point elements and adds the even single\n   precision floating-point values in the third source operand, performs\n   rounding and stores the resulting packed single precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMSUBADD231PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the second source operand to the\n   corresponding packed single precision floating-point values in the third\n   source operand. From the infinite precision intermediate result, subtracts\n   the odd single precision floating-point elements and adds the even single\n   precision floating-point values in the first source operand, performs\n   rounding and stores the resulting packed single precision floating-point\n   values to the destination operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 32-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["cvtpd2ps", "   CVTPD2PS \u2014 Convert Packed Double Precision Floating-Point Values to Packed\n                     Single PrecisionFloating-Point Values\n\n                             Op / 64/32 bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     double precision         \n   66 0F 5A /r CVTPD2PS      A    V/V       SSE2     floating-point values in \n   xmm1, xmm2/m128                                   xmm2/mem to two single   \n                                                     precision floating-point \n                                                     values in xmm1.          \n                                                     Convert two packed       \n                                                     double precision         \n   VEX.128.66.0F.WIG 5A /r   A    V/V       AVX      floating-point values in \n   VCVTPD2PS xmm1, xmm2/m128                         xmm2/mem to two single   \n                                                     precision floating-point \n                                                     values in xmm1.          \n                                                     Convert four packed      \n                                                     double precision         \n   VEX.256.66.0F.WIG 5A /r   A    V/V       AVX      floating-point values in \n   VCVTPD2PS xmm1, ymm2/m256                         ymm2/mem to four single  \n                                                     precision floating-point \n                                                     values in xmm1.          \n                                                     Convert two packed       \n                                                     double precision         \n   EVEX.128.66.0F.W1 5A /r                  AVX512VL floating-point values in \n   VCVTPD2PS xmm1 {k1}{z},   B    V/V       AVX512F  xmm2/m128/m64bcst to two \n   xmm2/m128/m64bcst                                 single precision         \n                                                     floating-point values in \n                                                     xmm1with writemask k1.   \n                                                     Convert four packed      \n                                                     double precision         \n   EVEX.256.66.0F.W1 5A /r                  AVX512VL floating-point values in \n   VCVTPD2PS xmm1 {k1}{z},   B    V/V       AVX512F  ymm2/m256/m64bcst to     \n   ymm2/m256/m64bcst                                 four single precision    \n                                                     floating-point values in \n                                                     xmm1with writemask k1.   \n                                                     Convert eight packed     \n                                                     double precision         \n   EVEX.512.66.0F.W1 5A /r                           floating-point values in \n   VCVTPD2PS ymm1 {k1}{z},   B    V/V       AVX512F  zmm2/m512/m64bcst to     \n   zmm2/m512/m64bcst{er}                             eight single precision   \n                                                     floating-point values in \n                                                     ymm1with writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two, four or eight packed double precision floating-point values\n   in the source operand (second operand) to two, four or eight packed single\n   precision floating-point values in the destination operand (first\n   operand).\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 64-bit memory location. The destination operand is a YMM/XMM/XMM\n   (low 64-bits) register conditionally updated with writemask k1. The upper\n   bits (MAXVL-1:256/128/64) of the corresponding destination are zeroed.\n\n   VEX.256 encoded version: The source operand is a YMM register or 256- bit\n   memory location. The destination operand is an XMM register. The upper\n   bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   zeroed.\n\n   VEX.128 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a XMM register. The upper bits\n   (MAXVL-1:64) of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 128-\n   bit memory location. The destination operand is an XMM register.\n   Bits[127:64] of the destination XMM register are zeroed. However, the\n   upper Bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   SR X3 X2 X1 X0 DEST 0 X3 X2 X1 X0 Figure 3-13. VCVTPD2PS (VEX.256 encoded\n   version)\n"],
	["pmulhrsw", "              PMULHRSW \u2014 Packed Multiply High With Round and Scale\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Multiply 16-bit signed  \n   NP 0F 38 0B /r^1 PMULHRSW                          words, scale and round  \n   mm1, mm2/m64              A     V/V       SSSE3    signed doublewords,     \n                                                      pack high 16 bits to    \n                                                      mm1.                    \n                                                      Multiply 16-bit signed  \n   66 0F 38 0B /r PMULHRSW                            words, scale and round  \n   xmm1, xmm2/m128           A     V/V       SSSE3    signed doublewords,     \n                                                      pack high 16 bits to    \n                                                      xmm1.                   \n                                                      Multiply 16-bit signed  \n   VEX.128.66.0F38.WIG 0B /r                          words, scale and round  \n   VPMULHRSW xmm1, xmm2,     B     V/V       AVX      signed doublewords,     \n   xmm3/m128                                          pack high 16 bits to    \n                                                      xmm1.                   \n                                                      Multiply 16-bit signed  \n   VEX.256.66.0F38.WIG 0B /r                          words, scale and round  \n   VPMULHRSW ymm1, ymm2,     B     V/V       AVX2     signed doublewords,     \n   ymm3/m256                                          pack high 16 bits to    \n                                                      ymm1.                   \n                                                      Multiply 16-bit signed  \n   EVEX.128.66.0F38.WIG 0B                            words, scale and round  \n   /r VPMULHRSW xmm1         C     V/V       AVX512VL signed doublewords,     \n   {k1}{z}, xmm2, xmm3/m128                  AVX512BW pack high 16 bits to    \n                                                      xmm1 under writemask    \n                                                      k1.                     \n                                                      Multiply 16-bit signed  \n   EVEX.256.66.0F38.WIG 0B                            words, scale and round  \n   /r VPMULHRSW ymm1         C     V/V       AVX512VL signed doublewords,     \n   {k1}{z}, ymm2, ymm3/m256                  AVX512BW pack high 16 bits to    \n                                                      ymm1 under writemask    \n                                                      k1.                     \n                                                      Multiply 16-bit signed  \n   EVEX.512.66.0F38.WIG 0B                            words, scale and round  \n   /r VPMULHRSW zmm1         C     V/V       AVX512BW signed doublewords,     \n   {k1}{z}, zmm2, zmm3/m512                           pack high 16 bits to    \n                                                      zmm1 under writemask    \n                                                      k1.                     \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   PMULHRSW multiplies vertically each signed 16-bit integer from the\n   destination operand (first operand) with the corresponding signed 16-bit\n   integer of the source operand (second operand), producing intermediate,\n   signed 32-bit integers. Each intermediate 32-bit integer is truncated to\n   the 18 most significant bits. Rounding is always performed by adding 1 to\n   the least significant bit of the 18-bit intermediate result. The final\n   result is obtained by selecting the 16 bits immediately to the right of\n   the most significant bit of each 18-bit intermediate result and packed to\n   the destination operand.\n\n   When the source operand is a 128-bit memory operand, the operand must be\n   aligned on a 16-byte boundary or a general-protection exception (#GP) will\n   be generated.\n\n   In 64-bit mode and not encoded with VEX/EVEX, use the REX prefix to access\n   XMM8-XMM15 registers.\n\n   Legacy SSE version 64-bit operand: Both operands can be MMX registers. The\n   second source operand is an MMX register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n"],
	["wbinvd", "                    WBINVD \u2014 Write Back and Invalidate Cache\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Description                \n                                        Mode       \n                                                   Write back and flush       \n   0F 09  WBINVD      ZO    Valid       Valid      Internal caches; initiate  \n                                                   writing-back and flushing  \n                                                   of external caches.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Writes back all modified cache lines in the processor\u2019s internal cache to\n   main memory and invalidates (flushes) the internal caches. The instruction\n   then issues a special-function bus cycle that directs external caches to\n   also write back modified data and another bus cycle to indicate that the\n   external caches should be invalidated.\n\n   After executing this instruction, the processor does not wait for the\n   external caches to complete their write-back and flushing operations\n   before proceeding with instruction execution. It is the responsibility of\n   hardware to respond to the cache write-back and flush signals. The amount\n   of time or cycles for WBINVD to complete will vary due to size and other\n   factors of different cache hierarchies. As a consequence, the use of the\n   WBINVD instruction can have an impact on logical processor interrupt/event\n   response time. Additional information of WBINVD behavior in a cache\n   hierarchy with hierarchical sharing topology can be found in Chapter 2 of\n   the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n   3A.\n\n   The WBINVD instruction is a privileged instruction. When the processor is\n   running in protected mode, the CPL of a program or procedure must be 0 to\n   execute this instruction. This instruction is also a serializing\n   instruction (see \u201cSerializing Instructions\u201d in Chapter 9 of the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A).\n\n   In situations where cache coherency with main memory is not a concern,\n   software can use the INVD instruction.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The WBINVD instruction is implementation dependent, and its function may\n   be implemented differently on future Intel 64 and IA-32 processors. The\n   instruction is not supported on IA-32 processors earlier than the Intel486\n   processor.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["xorpd", "  XORPD \u2014 Bitwise Logical XOR of Packed Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Return the bitwise logical \n   66 0F 57/r XORPD xmm1,                          XOR of packed double       \n   xmm2/m128               A    V/V       SSE2     precision floating-point   \n                                                   values in xmm1 and         \n                                                   xmm2/mem.                  \n                                                   Return the bitwise logical \n   VEX.128.66.0F.WIG 57 /r                         XOR of packed double       \n   VXORPD xmm1,xmm2,       B    V/V       AVX      precision floating-point   \n   xmm3/m128                                       values in xmm2 and         \n                                                   xmm3/mem.                  \n                                                   Return the bitwise logical \n   VEX.256.66.0F.WIG 57 /r                         XOR of packed double       \n   VXORPD ymm1, ymm2,      B    V/V       AVX      precision floating-point   \n   ymm3/m256                                       values in ymm2 and         \n                                                   ymm3/mem.                  \n                                                   Return the bitwise logical \n   EVEX.128.66.0F.W1 57 /r                         XOR of packed double       \n   VXORPD xmm1 {k1}{z},    C    V/V       AVX512VL precision floating-point   \n   xmm2, xmm3/m128/m64bcst                AVX512DQ values in xmm2 and         \n                                                   xmm3/m128/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.256.66.0F.W1 57 /r                         XOR of packed double       \n   VXORPD ymm1 {k1}{z},    C    V/V       AVX512VL precision floating-point   \n   ymm2, ymm3/m256/m64bcst                AVX512DQ values in ymm2 and         \n                                                   ymm3/m256/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.512.66.0F.W1 57 /r                         XOR of packed double       \n   VXORPD zmm1 {k1}{z},    C    V/V       AVX512DQ precision floating-point   \n   zmm2, zmm3/m512/m64bcst                         values in zmm2 and         \n                                                   zmm3/m512/m64bcst subject  \n                                                   to writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a bitwise logical XOR of the two, four or eight packed double\n   precision floating-point values from the first source operand and the\n   second source operand, and stores the result in the destination operand.\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand can be a ZMM register or a vector memory location.\n   The destination operand is a ZMM register conditionally updated with\n   write-mask k1.\n\n   VEX.256 and EVEX.256 encoded versions: The first source operand is a YMM\n   register. The second source operand is a YMM register or a 256-bit memory\n   location. The destination operand is a YMM register (conditionally updated\n   with writemask k1 in case of EVEX). The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 and EVEX.128 encoded versions: The first source operand is an XMM\n   register. The second source operand is an XMM register or 128-bit memory\n   location. The destination operand is an XMM register (conditionally\n   updated with writemask k1 in case of EVEX). The upper bits (MAXVL-1:128)\n   of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["andps", "  ANDPS \u2014 Bitwise Logical AND of Packed Single Precision Floating-Point Values\n\n                        Op / 64/32 bit CPUID                                  \n   Opcode/Instruction   En   Mode      Feature  Description\n                             Support   Flag     \n                                                Return the bitwise logical    \n   NP 0F 54 /r ANDPS    A    V/V       SSE      AND of packed single          \n   xmm1, xmm2/m128                              precision floating-point      \n                                                values in xmm1 and xmm2/mem.  \n   VEX.128.0F 54 /r                             Return the bitwise logical    \n   VANDPS xmm1,xmm2,    B    V/V       AVX      AND of packed single          \n   xmm3/m128                                    precision floating-point      \n                                                values in xmm2 and xmm3/mem.  \n   VEX.256.0F 54 /r                             Return the bitwise logical    \n   VANDPS ymm1, ymm2,   B    V/V       AVX      AND of packed single          \n   ymm3/m256                                    precision floating-point      \n                                                values in ymm2 and ymm3/mem.  \n                                                Return the bitwise logical    \n   EVEX.128.0F.W0 54 /r                         AND of packed single          \n   VANDPS xmm1 {k1}{z}, C    V/V       AVX512VL precision floating-point      \n   xmm2,                               AVX512DQ values in xmm2 and            \n   xmm3/m128/m32bcst                            xmm3/m128/m32bcst subject to  \n                                                writemask k1.                 \n                                                Return the bitwise logical    \n   EVEX.256.0F.W0 54 /r                         AND of packed single          \n   VANDPS ymm1 {k1}{z}, C    V/V       AVX512VL precision floating-point      \n   ymm2,                               AVX512DQ values in ymm2 and            \n   ymm3/m256/m32bcst                            ymm3/m256/m32bcst subject to  \n                                                writemask k1.                 \n                                                Return the bitwise logical    \n   EVEX.512.0F.W0 54 /r                         AND of packed single          \n   VANDPS zmm1 {k1}{z}, C    V/V       AVX512DQ precision floating-point      \n   zmm2,                                        values in zmm2 and            \n   zmm3/m512/m32bcst                            zmm3/m512/m32bcst subject to  \n                                                writemask k1.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical AND of the four, eight or sixteen packed single\n   precision floating-point values from the first source operand and the\n   second source operand, and stores the result in the destination operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["vplzcntd:vplzcntq", "  VPLZCNTD/VPLZCNTQ \u2014 Count the Number of Leading Zero Bits for Packed Dword,\n                              Packed Qword Values\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                Support   Flag     \n   EVEX.128.66.0F38.W0 44                          Count the number of        \n   /r VPLZCNTD xmm1                       AVX512VL leading zero bits in each  \n   {k1}{z},               A     V/V       AVX512CD dword element of           \n   xmm2/m128/m32bcst                               xmm2/m128/m32bcst using    \n                                                   writemask k1.              \n   EVEX.256.66.0F38.W0 44                          Count the number of        \n   /r VPLZCNTD ymm1                       AVX512VL leading zero bits in each  \n   {k1}{z},               A     V/V       AVX512CD dword element of           \n   ymm2/m256/m32bcst                               ymm2/m256/m32bcst using    \n                                                   writemask k1.              \n   EVEX.512.66.0F38.W0 44                          Count the number of        \n   /r VPLZCNTD zmm1                                leading zero bits in each  \n   {k1}{z},               A     V/V       AVX512CD dword element of           \n   zmm2/m512/m32bcst                               zmm2/m512/m32bcst using    \n                                                   writemask k1.              \n   EVEX.128.66.0F38.W1 44                          Count the number of        \n   /r VPLZCNTQ xmm1                       AVX512VL leading zero bits in each  \n   {k1}{z},               A     V/V       AVX512CD qword element of           \n   xmm2/m128/m64bcst                               xmm2/m128/m64bcst using    \n                                                   writemask k1.              \n   EVEX.256.66.0F38.W1 44                          Count the number of        \n   /r VPLZCNTQ ymm1                       AVX512VL leading zero bits in each  \n   {k1}{z},               A     V/V       AVX512CD qword element of           \n   ymm2/m256/m64bcst                               ymm2/m256/m64bcst using    \n                                                   writemask k1.              \n   EVEX.512.66.0F38.W1 44                          Count the number of        \n   /r VPLZCNTQ zmm1                                leading zero bits in each  \n   {k1}{z},               A     V/V       AVX512CD qword element of           \n   zmm2/m512/m64bcst                               zmm2/m512/m64bcst using    \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Counts the number of leading most significant zero bits in each dword or\n   qword element of the source operand (the second operand) and stores the\n   results in the destination register (the first operand) according to the\n   writemask. If an element is zero, the result for that element is the\n   operand size of the element.\n\n   EVEX.512 encoded version: The source operand is a ZMM register, a 512-bit\n   memory location, or a 512-bit vector broadcasted from a 32/64-bit memory\n   location. The destination operand is a ZMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.256 encoded version: The source operand is a YMM register, a 256-bit\n   memory location, or a 256-bit vector broadcasted from a 32/64-bit memory\n   location. The destination operand is a YMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.128 encoded version: The source operand is a XMM register, a 128-bit\n   memory location, or a 128-bit vector broadcasted from a 32/64-bit memory\n   location. The destination operand is a XMM register, conditionally updated\n   using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["sttilecfg", "                      STTILECFG \u2014 Store Tile Configuration\n\n                                      64/32 bit CPUID                         \n   Opcode/Instruction           Op/En Mode      Feature Flag Description\n                                      Support   \n   VEX.128.66.0F38.W0 49                                     Store tile       \n   !(11):000:bbb STTILECFG m512 A     V/N.E.    AMX-TILE     configuration in \n                                                             m512.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2 Operand 3 Operand 4 \n   A     N/A   ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   The STTILECFG instruction takes a pointer to a 64-byte memory location\n   (described in Table 3-10 in the \u201cLDTILECFG\u2014Load Tile Configuration\u201d entry)\n   that will, after successful execution of this instruction, contain the\n   description of the tiles that were configured. In order to configure\n   tiles, the AMX-TILE bit in CPUID must be set and the operating system has\n   to have enabled the tiles architecture.\n\n   If the tiles are not configured, then STTILECFG stores 64B of zeros to the\n   indicated memory location.\n\n   Any attempt to execute the STTILECFG instruction inside an Intel TSX\n   transaction will result in a transaction abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["ret", "                          RET \u2014 Return From Procedure\n\n   Opcode* Instruction Op/En 64-Bit Mode Compat/Leg Description               \n                                         Mode       \n   C3      RET         ZO    Valid       Valid      Near return to calling    \n                                                    procedure.                \n   CB      RET         ZO    Valid       Valid      Far return to calling     \n                                                    procedure.                \n                                                    Near return to calling    \n   C2 iw   RET imm16   I     Valid       Valid      procedure and pop imm16   \n                                                    bytes from stack.         \n                                                    Far return to calling     \n   CA iw   RET imm16   I     Valid       Valid      procedure and pop imm16   \n                                                    bytes from stack.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n   I     imm16     N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Transfers program control to a return address located on the top of the\n   stack. The address is usually placed on the stack by a CALL instruction,\n   and the return is made to the instruction that follows the CALL\n   instruction.\n\n   The optional source operand specifies the number of stack bytes to be\n   released after the return address is popped; the default is none. This\n   operand can be used to release parameters from the stack that were passed\n   to the called procedure and are no longer needed. It must be used when the\n   CALL instruction used to switch to a new procedure uses a call gate with a\n   non-zero word count to access the new procedure. Here, the source operand\n   for the RET instruction must specify the same number of bytes as is\n   specified in the word count field of the call gate.\n\n   The RET instruction can be used to execute three different types of\n   returns:\n\n     * Near return \u2014 A return to a calling procedure within the current code\n       segment (the segment currently pointed to by the CS register),\n       sometimes referred to as an intrasegment return.\n     * Far return \u2014 A return to a calling procedure located in a different\n       segment than the current code segment, sometimes referred to as an\n       intersegment return.\n     * Inter-privilege-level far return \u2014 A far return to a different\n       privilege level than that of the currently executing program or\n       procedure.\n\n   The inter-privilege-level return type can only be executed in protected\n   mode. See the section titled \u201cCalling Procedures Using Call and RET\u201d in\n   Chapter 6 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 1, for detailed information on near, far, and\n   inter-privilege-level returns.\n\n   When executing a near return, the processor pops the return instruction\n   pointer (offset) from the top of the stack into the EIP register and\n   begins program execution at the new instruction pointer. The CS register\n   is unchanged.\n\n   When executing a far return, the processor pops the return instruction\n   pointer from the top of the stack into the EIP register, then pops the\n   segment selector from the top of the stack into the CS register. The\n   processor then begins program execution in the new code segment at the new\n   instruction pointer.\n\n   The mechanics of an inter-privilege-level far return are similar to an\n   intersegment return, except that the processor examines the privilege\n   levels and access rights of the code and stack segments being returned to\n   determine if the control transfer is allowed to be made. The DS, ES, FS,\n   and GS segment registers are cleared by the RET instruction during an\n   inter-privilege-level return if they refer to segments that are not\n   allowed to be accessed at the new privilege level. Since a stack switch\n   also occurs on an inter-privilege level return, the ESP and SS registers\n   are loaded from the stack.\n\n   If parameters are passed to the called procedure during an inter-privilege\n   level call, the optional source operand must be used with the RET\n   instruction to release the parameters on the return. Here, the parameters\n   are released both from the called procedure\u2019s stack and the calling\n   procedure\u2019s stack (that is, the stack being returned to).\n\n   In 64-bit mode, the default operation size of this instruction is the\n   stack-address size, i.e., 64 bits. This applies to near returns, not far\n   returns; the default operation size of far returns is 32 bits.\n\n   Refer to Chapter 6, \u201cProcedure Calls, Interrupts, and Exceptions\u201a\u201d and\n   Chapter 17, \u201cControl-flow Enforcement Technology (CET)\u201a\u201d in the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for CET\n   details.\n\n   Instruction ordering. Instructions following a far return may be fetched\n   from memory before earlier instructions complete execution, but they will\n   not execute (even speculatively) until all instructions prior to the far\n   return have completed execution (the later instructions may execute before\n   data stored by the earlier instructions have become globally visible).\n\n   Unlike near indirect CALL and near indirect JMP, the processor will not\n   speculatively execute the next sequential instruction after a near RET\n   unless that instruction is also the target of a jump or is a target in a\n   branch predictor.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfmadd132ps:vfmadd213ps:vfmadd231ps", "       VFMADD132PS/VFMADD213PS/VFMADD231PS \u2014 Fused Multiply-Add of Packed\n                     SinglePrecision Floating-Point Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Multiply packed single  \n   VEX.128.66.0F38.W0 98 /r                           precision               \n   VFMADD132PS xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm1 and xmm3/mem, \n                                                      add to xmm2 and put     \n                                                      result in xmm1.         \n                                                      Multiply packed single  \n   VEX.128.66.0F38.W0 A8 /r                           precision               \n   VFMADD213PS xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm1 and xmm2, add \n                                                      to xmm3/mem and put     \n                                                      result in xmm1.         \n                                                      Multiply packed single  \n   VEX.128.66.0F38.W0 B8 /r                           precision               \n   VFMADD231PS xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm2 and xmm3/mem, \n                                                      add to xmm1 and put     \n                                                      result in xmm1.         \n                                                      Multiply packed single  \n   VEX.256.66.0F38.W0 98 /r                           precision               \n   VFMADD132PS ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm1 and ymm3/mem, \n                                                      add to ymm2 and put     \n                                                      result in ymm1.         \n                                                      Multiply packed single  \n   VEX.256.66.0F38.W0 A8 /r                           precision               \n   VFMADD213PS ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm1 and ymm2, add \n                                                      to ymm3/mem and put     \n                                                      result in ymm1.         \n                                                      Multiply packed single  \n   VEX.256.66.0F38.0 B8 /r                            precision               \n   VFMADD231PS ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm2 and ymm3/mem, \n                                                      add to ymm1 and put     \n                                                      result in ymm1.         \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.128.66.0F38.W0 98 /r                 AVX512VL floating-point values   \n   VFMADD132PS xmm1 {k1}{z}, B     V/V       AVX512F  from xmm1 and           \n   xmm2, xmm3/m128/m32bcst                            xmm3/m128/m32bcst, add  \n                                                      to xmm2 and put result  \n                                                      in xmm1.                \n                                                      Multiply packed single  \n   EVEX.128.66.0F38.W0 A8 /r                          precision               \n   VFMADD213PS xmm1 {k1}{z}, B     V/V       AVX512VL floating-point values   \n   xmm2, xmm3/m128/m32bcst                   AVX512F  from xmm1 and xmm2, add \n                                                      to xmm3/m128/m32bcst    \n                                                      and put result in xmm1. \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.128.66.0F38.W0 B8 /r                 AVX512VL floating-point values   \n   VFMADD231PS xmm1 {k1}{z}, B     V/V       AVX512F  from xmm2 and           \n   xmm2, xmm3/m128/m32bcst                            xmm3/m128/m32bcst, add  \n                                                      to xmm1 and put result  \n                                                      in xmm1.                \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.256.66.0F38.W0 98 /r                 AVX512VL floating-point values   \n   VFMADD132PS ymm1 {k1}{z}, B     V/V       AVX512F  from ymm1 and           \n   ymm2, ymm3/m256/m32bcst                            ymm3/m256/m32bcst, add  \n                                                      to ymm2 and put result  \n                                                      in ymm1.                \n                                                      Multiply packed single  \n   EVEX.256.66.0F38.W0 A8 /r                          precision               \n   VFMADD213PS ymm1 {k1}{z}, B     V/V       AVX512VL floating-point values   \n   ymm2, ymm3/m256/m32bcst                   AVX512F  from ymm1 and ymm2, add \n                                                      to ymm3/m256/m32bcst    \n                                                      and put result in ymm1. \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.256.66.0F38.W0 B8 /r                 AVX512VL floating-point values   \n   VFMADD231PS ymm1 {k1}{z}, B     V/V       AVX512F  from ymm2 and           \n   ymm2, ymm3/m256/m32bcst                            ymm3/m256/m32bcst, add  \n                                                      to ymm1 and put result  \n                                                      in ymm1.                \n                                                      Multiply packed single  \n   EVEX.512.66.0F38.W0 98 /r                          precision               \n   VFMADD132PS zmm1 {k1}{z},                          floating-point values   \n   zmm2,                     B     V/V       AVX512F  from zmm1 and           \n   zmm3/m512/m32bcst{er}                              zmm3/m512/m32bcst, add  \n                                                      to zmm2 and put result  \n                                                      in zmm1.                \n                                                      Multiply packed single  \n   EVEX.512.66.0F38.W0 A8 /r                          precision               \n   VFMADD213PS zmm1 {k1}{z}, B     V/V       AVX512F  floating-point values   \n   zmm2,                                              from zmm1 and zmm2, add \n   zmm3/m512/m32bcst{er}                              to zmm3/m512/m32bcst    \n                                                      and put result in zmm1. \n                                                      Multiply packed single  \n   EVEX.512.66.0F38.W0 B8 /r                          precision               \n   VFMADD231PS zmm1 {k1}{z},                          floating-point values   \n   zmm2,                     B     V/V       AVX512F  from zmm2 and           \n   zmm3/m512/m32bcst{er}                              zmm3/m512/m32bcst, add  \n                                                      to zmm1 and put result  \n                                                      in zmm1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a set of SIMD multiply-add computation on packed single precision\n   floating-point values using three source operands and writes the\n   multiply-add results in the destination operand. The destination operand\n   is also the first source operand. The second operand must be a SIMD\n   register. The third source operand can be a SIMD register or a memory\n   location.\n\n   VFMADD132PS: Multiplies the four, eight or sixteen packed single precision\n   floating-point values from the first source operand to the four, eight or\n   sixteen packed single precision floating-point values in the third source\n   operand, adds the infinite precision intermediate result to the four,\n   eight or sixteen packed single precision floating-point values in the\n   second source operand, performs rounding and stores the resulting four,\n   eight or sixteen packed single precision floating-point values to the\n   destination operand (first source operand).\n\n   VFMADD213PS: Multiplies the four, eight or sixteen packed single precision\n   floating-point values from the second source operand to the four, eight or\n   sixteen packed single precision floating-point values in the first source\n   operand, adds the infinite precision intermediate result to the four,\n   eight or sixteen packed single precision floating-point values in the\n   third source operand, performs rounding and stores the resulting the four,\n   eight or sixteen packed single precision floating-point values to the\n   destination operand (first source operand).\n\n   VFMADD231PS: Multiplies the four, eight or sixteen packed single precision\n   floating-point values from the second source operand to the four, eight or\n   sixteen packed single precision floating-point values in the third source\n   operand, adds the infinite precision intermediate result to the four,\n   eight or sixteen packed single precision floating-point values in the\n   first source operand, performs rounding and stores the resulting four,\n   eight or sixteen packed single precision floating-point values to the\n   destination operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   is a ZMM register and encoded in reg_field. The second source operand is a\n   ZMM register and encoded in EVEX.vvvv. The third source operand is a ZMM\n   register, a 512-bit memory location, or a 512-bit vector broadcasted from\n   a 32-bit memory location. The destination operand is conditionally updated\n   with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["pclmulqdq", "                 PCLMULQDQ \u2014 Carry-Less Multiplication Quadword\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Flag Description\n                                 Support   \n                                                        Carry-less            \n                                                        multiplication of one \n                                                        quadword of xmm1 by   \n                                                        one quadword of       \n   66 0F 3A 44 /r ib                                    xmm2/m128, stores the \n   PCLMULQDQ xmm1,         A     V/V       PCLMULQDQ    128-bit result in     \n   xmm2/m128, imm8                                      xmm1. The immediate   \n                                                        is used to determine  \n                                                        which quadwords of    \n                                                        xmm1 and xmm2/m128    \n                                                        should be used.       \n                                                        Carry-less            \n                                                        multiplication of one \n                                                        quadword of xmm2 by   \n                                                        one quadword of       \n   VEX.128.66.0F3A.WIG 44                  PCLMULQDQ    xmm3/m128, stores the \n   /r ib VPCLMULQDQ xmm1,  B     V/V       AVX          128-bit result in     \n   xmm2, xmm3/m128, imm8                                xmm1. The immediate   \n                                                        is used to determine  \n                                                        which quadwords of    \n                                                        xmm2 and xmm3/m128    \n                                                        should be used.       \n                                                        Carry-less            \n                                                        multiplication of one \n                                                        quadword of ymm2 by   \n                                                        one quadword of       \n   VEX.256.66.0F3A.WIG 44                  VPCLMULQDQ   ymm3/m256, stores the \n   /r /ib VPCLMULQDQ ymm1, B     V/V       AVX          128-bit result in     \n   ymm2, ymm3/m256, imm8                                ymm1. The immediate   \n                                                        is used to determine  \n                                                        which quadwords of    \n                                                        ymm2 and ymm3/m256    \n                                                        should be used.       \n                                                        Carry-less            \n                                                        multiplication of one \n                                                        quadword of xmm2 by   \n                                                        one quadword of       \n   EVEX.128.66.0F3A.WIG 44                 VPCLMULQDQ   xmm3/m128, stores the \n   /r /ib VPCLMULQDQ xmm1, C     V/V       AVX512VL     128-bit result in     \n   xmm2, xmm3/m128, imm8                                xmm1. The immediate   \n                                                        is used to determine  \n                                                        which quadwords of    \n                                                        xmm2 and xmm3/m128    \n                                                        should be used.       \n                                                        Carry-less            \n                                                        multiplication of one \n                                                        quadword of ymm2 by   \n                                                        one quadword of       \n   EVEX.256.66.0F3A.WIG 44                 VPCLMULQDQ   ymm3/m256, stores the \n   /r /ib VPCLMULQDQ ymm1, C     V/V       AVX512VL     128-bit result in     \n   ymm2, ymm3/m256, imm8                                ymm1. The immediate   \n                                                        is used to determine  \n                                                        which quadwords of    \n                                                        ymm2 and ymm3/m256    \n                                                        should be used.       \n                                                        Carry-less            \n                                                        multiplication of one \n                                                        quadword of zmm2 by   \n                                                        one quadword of       \n   EVEX.512.66.0F3A.WIG 44                 VPCLMULQDQ   zmm3/m512, stores the \n   /r /ib VPCLMULQDQ zmm1, C     V/V       AVX512F      128-bit result in     \n   zmm2, zmm3/m512, imm8                                zmm1. The immediate   \n                                                        is used to determine  \n                                                        which quadwords of    \n                                                        zmm2 and zmm3/m512    \n                                                        should be used.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A      ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A      ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Full Mem ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8 (r)  \n\nDescription \u00b6\n\n   Performs a carry-less multiplication of two quadwords, selected from the\n   first source and second source operand according to the value of the\n   immediate byte. Bits 4 and 0 are used to select which 64-bit half of each\n   operand to use according to Table 4-13, other bits of the immediate byte\n   are ignored.\n\n   The EVEX encoded form of this instruction does not support memory fault\n   suppression.\n\n   Imm[4] Imm[0] PCLMULQDQ Operation                  \n   0      0      CL_MUL( SRC2^1[63:0], SRC1[63:0] )   \n   0      1      CL_MUL( SRC2[63:0], SRC1[127:64] )   \n   1      0      CL_MUL( SRC2[127:64], SRC1[63:0] )   \n   1      1      CL_MUL( SRC2[127:64], SRC1[127:64] ) \n\n   Table 4-13. PCLMULQDQ Quadword Selection of Immediate Byte\n\n     1. SRC2 denotes the second source operand, which can be a register or\n     memory; SRC1 denotes the first source and destination operand.\n\n   The first source operand and the destination operand are the same and must\n   be a ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register or a 512/256/128-bit memory location. Bits (VL_MAX-1:128) of the\n   corresponding YMM destination register remain unchanged.\n\n   Compilers and assemblers may implement the following pseudo-op syntax to\n   simplify programming and emit the required encoding for imm8.\n\n   Pseudo-Op               Imm8 Encoding \n   PCLMULLQLQDQ xmm1, xmm2 0000_0000B    \n   PCLMULHQLQDQ xmm1, xmm2 0000_0001B    \n   PCLMULLQHQDQ xmm1, xmm2 0001_0000B    \n   PCLMULHQHQDQ xmm1, xmm2 0001_0001B    \n\n   Table 4-14. Pseudo-Op and PCLMULQDQ Implementation\n"],
	["vprord:vprorvd:vprorq:vprorvq", "                VPRORD/VPRORVD/VPRORQ/VPRORVQ \u2014 Bit Rotate Right\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n   EVEX.128.66.0F38.W0 14                          Rotate doublewords in xmm2 \n   /r VPRORVD xmm1                        AVX512VL right by count in the      \n   {k1}{z}, xmm2,          B    V/V       AVX512F  corresponding element of   \n   xmm3/m128/m32bcst                               xmm3/m128/m32bcst, store   \n                                                   result using writemask k1. \n   EVEX.128.66.0F.W0 72 /0                         Rotate doublewords in      \n   ib VPRORD xmm1 {k1}{z}, A    V/V       AVX512VL xmm2/m128/m32bcst right by \n   xmm2/m128/m32bcst, imm8                AVX512F  imm8, store result using   \n                                                   writemask k1.              \n   EVEX.128.66.0F38.W1 14                          Rotate quadwords in xmm2   \n   /r VPRORVQ xmm1                        AVX512VL right by count in the      \n   {k1}{z}, xmm2,          B    V/V       AVX512F  corresponding element of   \n   xmm3/m128/m64bcst                               xmm3/m128/m64bcst, store   \n                                                   result using writemask k1. \n   EVEX.128.66.0F.W1 72 /0                         Rotate quadwords in        \n   ib VPRORQ xmm1 {k1}{z}, A    V/V       AVX512VL xmm2/m128/m64bcst right by \n   xmm2/m128/m64bcst, imm8                AVX512F  imm8, store result using   \n                                                   writemask k1.              \n   EVEX.256.66.0F38.W0 14                          Rotate doublewords in ymm2 \n   /r VPRORVD ymm1                        AVX512VL right by count in the      \n   {k1}{z}, ymm2,          B    V/V       AVX512F  corresponding element of   \n   ymm3/m256/m32bcst                               ymm3/m256/m32bcst, store   \n                                                   using result writemask k1. \n   EVEX.256.66.0F.W0 72 /0                         Rotate doublewords in      \n   ib VPRORD ymm1 {k1}{z}, A    V/V       AVX512VL ymm2/m256/m32bcst right by \n   ymm2/m256/m32bcst, imm8                AVX512F  imm8, store result using   \n                                                   writemask k1.              \n   EVEX.256.66.0F38.W1 14                          Rotate quadwords in ymm2   \n   /r VPRORVQ ymm1                        AVX512VL right by count in the      \n   {k1}{z}, ymm2,          B    V/V       AVX512F  corresponding element of   \n   ymm3/m256/m64bcst                               ymm3/m256/m64bcst, store   \n                                                   result using writemask k1. \n   EVEX.256.66.0F.W1 72 /0                         Rotate quadwords in        \n   ib VPRORQ ymm1 {k1}{z}, A    V/V       AVX512VL ymm2/m256/m64bcst right by \n   ymm2/m256/m64bcst, imm8                AVX512F  imm8, store result using   \n                                                   writemask k1.              \n   EVEX.512.66.0F38.W0 14                          Rotate doublewords in zmm2 \n   /r VPRORVD zmm1                                 right by count in the      \n   {k1}{z}, zmm2,          B    V/V       AVX512F  corresponding element of   \n   zmm3/m512/m32bcst                               zmm3/m512/m32bcst, store   \n                                                   result using writemask k1. \n   EVEX.512.66.0F.W0 72 /0                         Rotate doublewords in      \n   ib VPRORD zmm1 {k1}{z}, A    V/V       AVX512F  zmm2/m512/m32bcst right by \n   zmm2/m512/m32bcst, imm8                         imm8, store result using   \n                                                   writemask k1.              \n   EVEX.512.66.0F38.W1 14                          Rotate quadwords in zmm2   \n   /r VPRORVQ zmm1                                 right by count in the      \n   {k1}{z}, zmm2,          B    V/V       AVX512F  corresponding element of   \n   zmm3/m512/m64bcst                               zmm3/m512/m64bcst, store   \n                                                   result using writemask k1. \n   EVEX.512.66.0F.W1 72 /0                         Rotate quadwords in        \n   ib VPRORQ zmm1 {k1}{z}, A    V/V       AVX512F  zmm2/m512/m64bcst right by \n   zmm2/m512/m64bcst, imm8                         imm8, store result using   \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       VEX.vvvv (w)  ModRM:r/m (R) imm8          N/A       \n   B     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Rotates the bits in the individual data elements (doublewords, or\n   quadword) in the first source operand to the right by the number of bits\n   specified in the count operand. If the value specified by the count\n   operand is greater than 31 (for doublewords), or 63 (for a quadword), then\n   the count operand modulo the data size (32 or 64) is used.\n\n   EVEX.128 encoded version: The destination operand is a XMM register. The\n   source operand is a XMM register or a memory location (for immediate\n   form). The count operand can come either from an XMM register or a memory\n   location or an 8-bit immediate. Bits (MAXVL-1:128) of the corresponding\n   ZMM register are zeroed.\n\n   EVEX.256 encoded version: The destination operand is a YMM register. The\n   source operand is a YMM register or a memory location (for immediate\n   form). The count operand can come either from an XMM register or a memory\n   location or an 8-bit immediate. Bits (MAXVL-1:256) of the corresponding\n   ZMM register are zeroed.\n\n   EVEX.512 encoded version: The destination operand is a ZMM register\n   updated according to the writemask. For the count operand in immediate\n   form, the source operand can be a ZMM register, a 512-bit memory location\n   or a 512-bit vector broadcasted from a 32/64-bit memory location, the\n   count operand is an 8-bit immediate. For the count operand in variable\n   form, the first source operand (the second operand) is a ZMM register and\n   the counter operand (the third operand) is a ZMM register, a 512-bit\n   memory location or a 512-bit vector broadcasted from a 32/64-bit memory\n   location.\n"],
	["vpblendmb:vpblendmw", "     VPBLENDMB/VPBLENDMW \u2014 Blend Byte/Word Vectors Using an Opmask Control\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Blend byte integer      \n   EVEX.128.66.0F38.W0 66 /r                          vector xmm2 and byte    \n   VPBLENDMB xmm1 {k1}{z},   A     V/V       AVX512VL vector xmm3/m128 and    \n   xmm2, xmm3/m128                           AVX512BW store the result in     \n                                                      xmm1, under control     \n                                                      mask.                   \n                                                      Blend byte integer      \n   EVEX.256.66.0F38.W0 66 /r                          vector ymm2 and byte    \n   VPBLENDMB ymm1 {k1}{z},   A     V/V       AVX512VL vector ymm3/m256 and    \n   ymm2, ymm3/m256                           AVX512BW store the result in     \n                                                      ymm1, under control     \n                                                      mask.                   \n                                                      Blend byte integer      \n   EVEX.512.66.0F38.W0 66 /r                          vector zmm2 and byte    \n   VPBLENDMB zmm1 {k1}{z},   A     V/V       AVX512BW vector zmm3/m512 and    \n   zmm2, zmm3/m512                                    store the result in     \n                                                      zmm1, under control     \n                                                      mask.                   \n                                                      Blend word integer      \n   EVEX.128.66.0F38.W1 66 /r                          vector xmm2 and word    \n   VPBLENDMW xmm1 {k1}{z},   A     V/V       AVX512VL vector xmm3/m128 and    \n   xmm2, xmm3/m128                           AVX512BW store the result in     \n                                                      xmm1, under control     \n                                                      mask.                   \n                                                      Blend word integer      \n   EVEX.256.66.0F38.W1 66 /r                          vector ymm2 and word    \n   VPBLENDMW ymm1 {k1}{z},   A     V/V       AVX512VL vector ymm3/m256 and    \n   ymm2, ymm3/m256                           AVX512BW store the result in     \n                                                      ymm1, under control     \n                                                      mask.                   \n                                                      Blend word integer      \n   EVEX.512.66.0F38.W1 66 /r                          vector zmm2 and word    \n   VPBLENDMW zmm1 {k1}{z},   A     V/V       AVX512BW vector zmm3/m512 and    \n   zmm2, zmm3/m512                                    store the result in     \n                                                      zmm1, under control     \n                                                      mask.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs an element-by-element blending of byte/word elements between the\n   first source operand byte vector register and the second source operand\n   byte vector from memory or register, using the instruction mask as\n   selector. The result is written into the destination byte vector register.\n\n   The destination and first source operands are ZMM/YMM/XMM registers. The\n   second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit memory location.\n\n   The mask is not used as a writemask for this instruction. Instead, the\n   mask is used as an element selector: every element of the destination is\n   conditionally selected between first source or second source using the\n   value of the related mask bit (0 for first source, 1 for second source).\n"],
	["divps", "          DIVPS \u2014 Divide Packed Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Divide packed single       \n                                                   precision floating-point   \n   NP 0F 5E /r DIVPS xmm1, A    V/V       SSE      values in xmm1 by packed   \n   xmm2/m128                                       single precision           \n                                                   floating-point values in   \n                                                   xmm2/mem.                  \n                                                   Divide packed single       \n   VEX.128.0F.WIG 5E /r                            precision floating-point   \n   VDIVPS xmm1, xmm2,      B    V/V       AVX      values in xmm2 by packed   \n   xmm3/m128                                       single precision           \n                                                   floating-point values in   \n                                                   xmm3/mem.                  \n                                                   Divide packed single       \n   VEX.256.0F.WIG 5E /r                            precision floating-point   \n   VDIVPS ymm1, ymm2,      B    V/V       AVX      values in ymm2 by packed   \n   ymm3/m256                                       single precision           \n                                                   floating-point values in   \n                                                   ymm3/mem.                  \n                                                   Divide packed single       \n                                                   precision floating-point   \n   EVEX.128.0F.W0 5E /r                            values in xmm2 by packed   \n   VDIVPS xmm1 {k1}{z},    C    V/V       AVX512VL single precision           \n   xmm2, xmm3/m128/m32bcst                AVX512F  floating-point values in   \n                                                   xmm3/m128/m32bcst and      \n                                                   write results to xmm1      \n                                                   subject to writemask k1.   \n                                                   Divide packed single       \n                                                   precision floating-point   \n   EVEX.256.0F.W0 5E /r                            values in ymm2 by packed   \n   VDIVPS ymm1 {k1}{z},    C    V/V       AVX512VL single precision           \n   ymm2, ymm3/m256/m32bcst                AVX512F  floating-point values in   \n                                                   ymm3/m256/m32bcst and      \n                                                   write results to ymm1      \n                                                   subject to writemask k1.   \n                                                   Divide packed single       \n                                                   precision floating-point   \n   EVEX.512.0F.W0 5E /r                            values in zmm2 by packed   \n   VDIVPS zmm1 {k1}{z},    C    V/V       AVX512F  single precision           \n   zmm2,                                           floating-point values in   \n   zmm3/m512/m32bcst{er}                           zmm3/m512/m32bcst and      \n                                                   write results to zmm1      \n                                                   subject to writemask k1.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD divide of the four, eight or sixteen packed single\n   precision floating-point values in the first source operand (the second\n   operand) by the four, eight or sixteen packed single precision\n   floating-point values in the second source operand (the third operand).\n   Results are written to the destination operand (the first operand).\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["cvtps2pd", "   CVTPS2PD \u2014 Convert Packed Single Precision Floating-Point Values to Packed\n                     Double PrecisionFloating-Point Values\n\n                              Op 64/32 bit CPUID                              \n   Opcode/Instruction         /  Mode      Feature  Description\n                              En Support   Flag     \n                                                    Convert two packed single \n                                                    precision floating-point  \n   NP 0F 5A /r CVTPS2PD xmm1, A  V/V       SSE2     values in xmm2/m64 to two \n   xmm2/m64                                         packed double precision   \n                                                    floating-point values in  \n                                                    xmm1.                     \n                                                    Convert two packed single \n                                                    precision floating-point  \n   VEX.128.0F.WIG 5A /r       A  V/V       AVX      values in xmm2/m64 to two \n   VCVTPS2PD xmm1, xmm2/m64                         packed double precision   \n                                                    floating-point values in  \n                                                    xmm1.                     \n                                                    Convert four packed       \n                                                    single precision          \n   VEX.256.0F.WIG 5A /r                             floating-point values in  \n   VCVTPS2PD ymm1, xmm2/m128  A  V/V       AVX      xmm2/m128 to four packed  \n                                                    double precision          \n                                                    floating-point values in  \n                                                    ymm1.                     \n                                                    Convert two packed single \n                                                    precision floating-point  \n   EVEX.128.0F.W0 5A /r                    AVX512VL values in                 \n   VCVTPS2PD xmm1 {k1}{z},    B  V/V       AVX512F  xmm2/m64/m32bcst to       \n   xmm2/m64/m32bcst                                 packed double precision   \n                                                    floating-point values in  \n                                                    xmm1 with writemask k1.   \n                                                    Convert four packed       \n                                                    single precision          \n   EVEX.256.0F.W0 5A /r                    AVX512VL floating-point values in  \n   VCVTPS2PD ymm1 {k1}{z},    B  V/V       AVX512F  xmm2/m128/m32bcst to      \n   xmm2/m128/m32bcst                                packed double precision   \n                                                    floating-point values in  \n                                                    ymm1 with writemask k1.   \n                                                    Convert eight packed      \n                                                    single precision          \n   EVEX.512.0F.W0 5A /r                             floating-point values in  \n   VCVTPS2PD zmm1 {k1}{z},    B  V/V       AVX512F  ymm2/m256/b32bcst to      \n   ymm2/m256/m32bcst{sae}                           eight packed double       \n                                                    precision floating-point  \n                                                    values in zmm1 with       \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two, four or eight packed single precision floating-point values\n   in the source operand (second operand) to two, four or eight packed double\n   precision floating-point values in the destination operand (first\n   operand).\n\n   EVEX encoded versions: The source operand is a YMM/XMM/XMM (low 64-bits)\n   register, a 256/128/64-bit memory location or a 256/128/64-bit vector\n   broadcasted from a 32-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a YMM register. Bits\n   (MAXVL-1:256) of the corresponding destination ZMM register are zeroed.\n\n   VEX.128 encoded version: The source operand is an XMM register or 64- bit\n   memory location. The destination operand is a XMM register. The upper Bits\n   (MAXVL-1:128) of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 64-\n   bit memory location. The destination operand is an XMM register. The upper\n   Bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   X3 X2 X1 X0 SRC X3 X2 X1 X0 DEST Figure 3-14. CVTPS2PD (VEX.256 encoded\n   version)\n"],
	["xchg", "                 XCHG \u2014 Exchange Register/Memory With Register\n\n   Opcode     Instruction     Op/En 64-Bit Compat/Leg Description             \n                                    Mode   Mode       \n   90+rw      XCHG AX, r16    O     Valid  Valid      Exchange r16 with AX.   \n   90+rw      XCHG r16, AX    O     Valid  Valid      Exchange AX with r16.   \n   90+rd      XCHG EAX, r32   O     Valid  Valid      Exchange r32 with EAX.  \n   REX.W +    XCHG RAX, r64   O     Valid  N.E.       Exchange r64 with RAX.  \n   90+rd      \n   90+rd      XCHG r32, EAX   O     Valid  Valid      Exchange EAX with r32.  \n   REX.W +    XCHG r64, RAX   O     Valid  N.E.       Exchange RAX with r64.  \n   90+rd      \n                                                      Exchange r8 (byte       \n   86 /r      XCHG r/m8, r8   MR    Valid  Valid      register) with byte     \n                                                      from r/m8.              \n   REX + 86                                           Exchange r8 (byte       \n   /r         XCHG r/m8*, r8* MR    Valid  N.E.       register) with byte     \n                                                      from r/m8.              \n                                                      Exchange byte from r/m8 \n   86 /r      XCHG r8, r/m8   RM    Valid  Valid      with r8 (byte           \n                                                      register).              \n   REX + 86                                           Exchange byte from r/m8 \n   /r         XCHG r8*, r/m8* RM    Valid  N.E.       with r8 (byte           \n                                                      register).              \n   87 /r      XCHG r/m16, r16 MR    Valid  Valid      Exchange r16 with word  \n                                                      from r/m16.             \n   87 /r      XCHG r16, r/m16 RM    Valid  Valid      Exchange word from      \n                                                      r/m16 with r16.         \n   87 /r      XCHG r/m32, r32 MR    Valid  Valid      Exchange r32 with       \n                                                      doubleword from r/m32.  \n   REX.W + 87 XCHG r/m64, r64 MR    Valid  N.E.       Exchange r64 with       \n   /r                                                 quadword from r/m64.    \n   87 /r      XCHG r32, r/m32 RM    Valid  Valid      Exchange doubleword     \n                                                      from r/m32 with r32.    \n   REX.W + 87 XCHG r64, r/m64 RM    Valid  N.E.       Exchange quadword from  \n   /r                                                 r/m64 with r64.         \n\n     *\n     In64-bitmode,r/m8cannotbeencodedtoaccessthefollowingbyteregistersifaREXprefixisused:AH,BH,CH,DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1          Operand 2          Operand 3 Operand 4 \n   O     AX/EAX/RAX (r, w)  opcode + rd (r, w) N/A       N/A       \n   O     opcode + rd (r, w) AX/EAX/RAX (r, w)  N/A       N/A       \n   MR    ModRM:r/m (r, w)   ModRM:reg (r)      N/A       N/A       \n   RM    ModRM:reg (w)      ModRM:r/m (r)      N/A       N/A       \n\nDescription \u00b6\n\n   Exchanges the contents of the destination (first) and source (second)\n   operands. The operands can be two general-purpose registers or a register\n   and a memory location. If a memory operand is referenced, the processor\u2019s\n   locking protocol is automatically implemented for the duration of the\n   exchange operation, regardless of the presence or absence of the LOCK\n   prefix or of the value of the IOPL. (See the LOCK prefix description in\n   this chapter for more information on the locking protocol.)\n\n   This instruction is useful for implementing semaphores or similar data\n   structures for process synchronization. (See \u201cBus Locking\u201d in Chapter 9 of\n   the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume\n   3A, for more information on bus locking.)\n\n   The XCHG instruction can also be used instead of the BSWAP instruction for\n   16-bit operands.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits. See the summary chart at the beginning of this section for encoding\n   data and limits.\n\n     XCHG (E)AX, (E)AX (encoded instruction byte is 90H) is an alias for NOP\n     regardless of data size prefixes, including REX.W.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["shld", "                       SHLD \u2014 Double Precision Shift Left\n\n   Opcode*     Instruction Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n                                                   Shift r/m16 to left imm8   \n   0F A4 /r ib SHLD r/m16, MRI   Valid  Valid      places while shifting bits \n               r16, imm8                           from r16 in from the       \n                                                   right.                     \n                                                   Shift r/m16 to left CL     \n   0F A5 /r    SHLD r/m16, MRC   Valid  Valid      places while shifting bits \n               r16, CL                             from r16 in from the       \n                                                   right.                     \n                                                   Shift r/m32 to left imm8   \n   0F A4 /r ib SHLD r/m32, MRI   Valid  Valid      places while shifting bits \n               r32, imm8                           from r32 in from the       \n                                                   right.                     \n                                                   Shift r/m64 to left imm8   \n   REX.W + 0F  SHLD r/m64, MRI   Valid  N.E.       places while shifting bits \n   A4 /r ib    r64, imm8                           from r64 in from the       \n                                                   right.                     \n                                                   Shift r/m32 to left CL     \n   0F A5 /r    SHLD r/m32, MRC   Valid  Valid      places while shifting bits \n               r32, CL                             from r32 in from the       \n                                                   right.                     \n                                                   Shift r/m64 to left CL     \n   REX.W + 0F  SHLD r/m64, MRC   Valid  N.E.       places while shifting bits \n   A5 /r       r64, CL                             from r64 in from the       \n                                                   right.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MRI   ModRM:r/m (w) ModRM:reg (r) imm8      N/A       \n   MRC   ModRM:r/m (w) ModRM:reg (r) CL        N/A       \n\nDescription \u00b6\n\n   The SHLD instruction is used for multi-precision shifts of 64 bits or\n   more.\n\n   The instruction shifts the first operand (destination operand) to the left\n   the number of bits specified by the third operand (count operand). The\n   second operand (source operand) provides bits to shift in from the right\n   (starting with bit 0 of the destination operand).\n\n   The destination operand can be a register or a memory location; the source\n   operand is a register. The count operand is an unsigned integer that can\n   be stored in an immediate byte or in the CL register. If the count operand\n   is CL, the shift count is the logical AND of CL and a count mask. In\n   non-64-bit modes and default 64-bit mode; only bits 0 through 4 of the\n   count are used. This masks the count to a value between 0 and 31. If a\n   count is greater than the operand size, the result is undefined.\n\n   If the count is 1 or greater, the CF flag is filled with the last bit\n   shifted out of the destination operand. For a 1-bit shift, the OF flag is\n   set if a sign change occurred; otherwise, it is cleared. If the count\n   operand is 0, flags are not affected.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Using\n   a REX prefix in the form of REX.R permits access to additional registers\n   (R8-R15). Using a REX prefix in the form of REX.W promotes operation to 64\n   bits (upgrading the count mask to 6 bits). See the summary chart at the\n   beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   If the count is 1 or greater, the CF flag is filled with the last bit\n   shifted out of the destination operand and the SF, ZF, and PF flags are\n   set according to the value of the result. For a 1-bit shift, the OF flag\n   is set if a sign change occurred; otherwise, it is cleared. For shifts\n   greater than 1 bit, the OF flag is undefined. If a shift occurs, the AF\n   flag is undefined. If the count operand is 0, the flags are not affected.\n   If the count is greater than the operand size, the flags are undefined.\n"],
	["sqrtpd", "         SQRTPD \u2014 Square Root of Double Precision Floating-Point Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes Square Roots of  \n                                                    the packed double         \n   66 0F 51 /r SQRTPD xmm1, A    V/V       SSE2     precision floating-point  \n   xmm2/m128                                        values in xmm2/m128 and   \n                                                    stores the result in      \n                                                    xmm1.                     \n                                                    Computes Square Roots of  \n                                                    the packed double         \n   VEX.128.66.0F.WIG 51 /r  A    V/V       AVX      precision floating-point  \n   VSQRTPD xmm1, xmm2/m128                          values in xmm2/m128 and   \n                                                    stores the result in      \n                                                    xmm1.                     \n                                                    Computes Square Roots of  \n                                                    the packed double         \n   VEX.256.66.0F.WIG 51 /r  A    V/V       AVX      precision floating-point  \n   VSQRTPD ymm1, ymm2/m256                          values in ymm2/m256 and   \n                                                    stores the result in      \n                                                    ymm1.                     \n                                                    Computes Square Roots of  \n                                                    the packed double         \n   EVEX.128.66.0F.W1 51 /r                 AVX512VL precision floating-point  \n   VSQRTPD xmm1 {k1}{z},    B    V/V       AVX512F  values in                 \n   xmm2/m128/m64bcst                                xmm2/m128/m64bcst and     \n                                                    stores the result in xmm1 \n                                                    subject to writemask k1.  \n                                                    Computes Square Roots of  \n                                                    the packed double         \n   EVEX.256.66.0F.W1 51 /r                 AVX512VL precision floating-point  \n   VSQRTPD ymm1 {k1}{z},    B    V/V       AVX512F  values in                 \n   ymm2/m256/m64bcst                                ymm2/m256/m64bcst and     \n                                                    stores the result in ymm1 \n                                                    subject to writemask k1.  \n                                                    Computes Square Roots of  \n                                                    the packed double         \n   EVEX.512.66.0F.W1 51 /r                          precision floating-point  \n   VSQRTPD zmm1 {k1}{z},    B    V/V       AVX512F  values in                 \n   zmm2/m512/m64bcst{er}                            zmm2/m512/m64bcst and     \n                                                    stores the result in zmm1 \n                                                    subject to writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Performs a SIMD computation of the square roots of the two, four or eight\n   packed double precision floating-point values in the source operand (the\n   second operand) stores the packed double precision floating-point results\n   in the destination operand (the first operand).\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 64-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register updated according to the writemask.\n\n   VEX.256 encoded version: The source operand is a YMM register or a 256-bit\n   memory location. The destination operand is a YMM register. The upper bits\n   (MAXVL-1:256) of the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: the source operand second source operand or a\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["vcvtph2uqq", "     VCVTPH2UQQ \u2014 Convert Packed FP16 Values to Unsigned Quadword Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert two packed    \n                                                        FP16 values in        \n   EVEX.128.66.MAP5.W0 79 /r                            xmm2/m32/m16bcst to   \n   VCVTPH2UQQ xmm1{k1}{z},        A V/V     AVX512-FP16 two unsigned quadword \n   xmm2/m32/m16bcst                         AVX512VL    integers, and store   \n                                                        the result in xmm1    \n                                                        subject to writemask  \n                                                        k1.                   \n                                                        Convert four packed   \n                                                        FP16 values in        \n   EVEX.256.66.MAP5.W0 79 /r                            xmm2/m64/m16bcst to   \n   VCVTPH2UQQ ymm1{k1}{z},        A V/V     AVX512-FP16 four unsigned         \n   xmm2/m64/m16bcst                         AVX512VL    quadword integers,    \n                                                        and store the result  \n                                                        in ymm1 subject to    \n                                                        writemask k1.         \n                                                        Convert eight packed  \n                                                        FP16 values in        \n   EVEX.512.66.MAP5.W0 79 /r                            xmm2/m128/m16bcst to  \n   VCVTPH2UQQ zmm1{k1}{z},        A V/V     AVX512-FP16 eight unsigned        \n   xmm2/m128/m16bcst {er}                               quadword integers,    \n                                                        and store the result  \n                                                        in zmm1 subject to    \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Quarter ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   unsigned quadword integers in destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["mov", "                                   MOV \u2014 Move\n\n   Opcode    Instruction      Op/En 64-Bit Compat/Leg Description             \n                                    Mode   Mode       \n   88 /r     MOV r/m8, r8     MR    Valid  Valid      Move r8 to r/m8.        \n   REX + 88  MOV r/m8^1, r8^1 MR    Valid  N.E.       Move r8 to r/m8.        \n   /r        \n   89 /r     MOV r/m16, r16   MR    Valid  Valid      Move r16 to r/m16.      \n   89 /r     MOV r/m32, r32   MR    Valid  Valid      Move r32 to r/m32.      \n   REX.W +   MOV r/m64, r64   MR    Valid  N.E.       Move r64 to r/m64.      \n   89 /r     \n   8A /r     MOV r8, r/m8     RM    Valid  Valid      Move r/m8 to r8.        \n   REX + 8A  MOV r8^1, r/m8^1 RM    Valid  N.E.       Move r/m8 to r8.        \n   /r        \n   8B /r     MOV r16, r/m16   RM    Valid  Valid      Move r/m16 to r16.      \n   8B /r     MOV r32, r/m32   RM    Valid  Valid      Move r/m32 to r32.      \n   REX.W +   MOV r64, r/m64   RM    Valid  N.E.       Move r/m64 to r64.      \n   8B /r     \n   8C /r     MOV r/m16,       MR    Valid  Valid      Move segment register   \n             Sreg^2                                   to r/m16.               \n             MOV r16/r32/m16,                         Move zero extended      \n   8C /r     Sreg^2           MR    Valid  Valid      16-bit segment register \n                                                      to r16/r32/m16.         \n   REX.W +   MOV r64/m16,                             Move zero extended      \n   8C /r     Sreg^2           MR    Valid  Valid      16-bit segment register \n                                                      to r64/m16.             \n   8E /r     MOV Sreg,        RM    Valid  Valid      Move r/m16 to segment   \n             r/m16^2                                  register.               \n   REX.W +   MOV Sreg,                                Move lower 16 bits of   \n   8E /r     r/m64^2          RM    Valid  Valid      r/m64 to segment        \n                                                      register.               \n   A0        MOV AL, moffs8^3 FD    Valid  Valid      Move byte at            \n                                                      (seg:offset) to AL.     \n   REX.W +   MOV AL, moffs8^3 FD    Valid  N.E.       Move byte at (offset)   \n   A0                                                 to AL.                  \n   A1        MOV AX,          FD    Valid  Valid      Move word at            \n             moffs16^3                                (seg:offset) to AX.     \n   A1        MOV EAX,         FD    Valid  Valid      Move doubleword at      \n             moffs32^3                                (seg:offset) to EAX.    \n   REX.W +   MOV RAX,         FD    Valid  N.E.       Move quadword at        \n   A1        moffs64^3                                (offset) to RAX.        \n   A2        MOV moffs8, AL   TD    Valid  Valid      Move AL to              \n                                                      (seg:offset).           \n   REX.W +   MOV moffs8^1, AL TD    Valid  N.E.       Move AL to (offset).    \n   A2        \n   A3        MOV moffs16^3,   TD    Valid  Valid      Move AX to              \n             AX                                       (seg:offset).           \n   A3        MOV moffs32^3,   TD    Valid  Valid      Move EAX to             \n             EAX                                      (seg:offset).           \n   REX.W +   MOV moffs64^3,   TD    Valid  N.E.       Move RAX to (offset).   \n   A3        RAX              \n   B0+ rb ib MOV r8, imm8     OI    Valid  Valid      Move imm8 to r8.        \n   REX + B0+ MOV r8^1, imm8   OI    Valid  N.E.       Move imm8 to r8.        \n   rb ib     \n   B8+ rw iw MOV r16, imm16   OI    Valid  Valid      Move imm16 to r16.      \n   B8+ rd id MOV r32, imm32   OI    Valid  Valid      Move imm32 to r32.      \n   REX.W +   MOV r64, imm64   OI    Valid  N.E.       Move imm64 to r64.      \n   B8+ rd io \n   C6 /0 ib  MOV r/m8, imm8   MI    Valid  Valid      Move imm8 to r/m8.      \n   REX + C6  MOV r/m8^1, imm8 MI    Valid  N.E.       Move imm8 to r/m8.      \n   /0 ib     \n   C7 /0 iw  MOV r/m16, imm16 MI    Valid  Valid      Move imm16 to r/m16.    \n   C7 /0 id  MOV r/m32, imm32 MI    Valid  Valid      Move imm32 to r/m32.    \n   REX.W +                                            Move imm32 sign         \n   C7 /0 id  MOV r/m64, imm32 MI    Valid  N.E.       extended to 64-bits to  \n                                                      r/m64.                  \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if a REX prefix is used: AH, BH, CH, DH.\n\n   2. In 32-bit mode, the assembler may insert the 16-bit operand-size prefix\n   with this instruction (see the following \u201cDescription\u201d section for further\n   information).\n\n   3. The moffs8, moffs16, moffs32, and moffs64 operands specify a simple\n   offset relative to the segment base, where 8, 16, 32, and 64 refer to the\n   size of the data. The address-size attribute of the instruction determines\n   the size of the offset, either 16, 32, or 64 bits.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1       Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w)   ModRM:reg (r) N/A       N/A       \n   RM    ModRM:reg (w)   ModRM:r/m (r) N/A       N/A       \n   FD    AL/AX/EAX/RAX   Moffs         N/A       N/A       \n   TD    Moffs (w)       AL/AX/EAX/RAX N/A       N/A       \n   OI    opcode + rd (w) imm8/16/32/64 N/A       N/A       \n   MI    ModRM:r/m (w)   imm8/16/32/64 N/A       N/A       \n\nDescription \u00b6\n\n   Copies the second operand (source operand) to the first operand\n   (destination operand). The source operand can be an immediate value,\n   general-purpose register, segment register, or memory location; the\n   destination register can be a general-purpose register, segment register,\n   or memory location. Both operands must be the same size, which can be a\n   byte, a word, a doubleword, or a quadword.\n\n   The MOV instruction cannot be used to load the CS register. Attempting to\n   do so results in an invalid opcode exception (#UD). To load the CS\n   register, use the far JMP, CALL, or RET instruction.\n\n   If the destination operand is a segment register (DS, ES, FS, GS, or SS),\n   the source operand must be a valid segment selector. In protected mode,\n   moving a segment selector into a segment register automatically causes the\n   segment descriptor information associated with that segment selector to be\n   loaded into the hidden (shadow) part of the segment register. While\n   loading this information, the segment selector and segment descriptor\n   information is validated (see the \u201cOperation\u201d algorithm below). The\n   segment descriptor data is obtained from the GDT or LDT entry for the\n   specified segment selector.\n\n   A NULL segment selector (values 0000-0003) can be loaded into the DS, ES,\n   FS, and GS registers without causing a protection exception. However, any\n   subsequent attempt to reference a segment whose corresponding segment\n   register is loaded with a NULL value causes a general protection exception\n   (#GP) and no memory reference occurs.\n\n   Loading the SS register with a MOV instruction suppresses or inhibits some\n   debug exceptions and inhibits interrupts on the following instruction\n   boundary. (The inhibition ends after delivery of an exception or the\n   execution of the next instruction.) This behavior allows a stack pointer\n   to be loaded into the ESP register with the next instruction (MOV ESP,\n   stack-pointer value) before an event can be delivered. See Section 6.8.3,\n   \u201cMasking Exceptions and Interrupts When Switching Stacks,\u201d in the Intel^\u00ae\n   64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A. Intel\n   recommends that software use the LSS instruction to load the SS register\n   and ESP together.\n\n   When executing MOV Reg, Sreg, the processor copies the content of Sreg to\n   the 16 least significant bits of the general-purpose register. The upper\n   bits of the destination register are zero for most IA-32 processors\n   (Pentium Pro processors and later) and all Intel 64 processors, with the\n   exception that bits 31:16 are undefined for Intel Quark X1000 processors,\n   Pentium, and earlier processors.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["endbr64", "             ENDBR64 \u2014 Terminate an Indirect Branch in 64-bit Mode\n\n   Opcode/Instruction  Op / En 64/32 bit    CPUID        Description          \n                               Mode Support Feature Flag \n                                                         Terminate indirect   \n   F3 0F 1E FA ENDBR64 ZO      V/V          CET_IBT      branch in 64-bit     \n                                                         mode.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A        N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Terminate an indirect branch in 64 bit mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpmultishiftqb", "      VPMULTISHIFTQB \u2014 Select Packed Unaligned Bytes From Quadword Sources\n\n                                   64/32    CPUID                             \n   Opcode / Instruction      Op/En bit Mode Feature Flag Description\n                                   Support  \n                                                         Select unaligned     \n   EVEX.128.66.0F38.W1 83 /r                             bytes from qwords in \n   VPMULTISHIFTQB xmm1                      AVX512_VBMI  xmm3/m128/m64bcst    \n   {k1}{z},                  A     V/V      AVX512VL     using control bytes  \n   xmm2,xmm3/m128/m64bcst                                in xmm2, write byte  \n                                                         results to xmm1      \n                                                         under k1.            \n                                                         Select unaligned     \n   EVEX.256.66.0F38.W1 83 /r                             bytes from qwords in \n   VPMULTISHIFTQB ymm1                      AVX512_VBMI  ymm3/m256/m64bcst    \n   {k1}{z},                  A     V/V      AVX512VL     using control bytes  \n   ymm2,ymm3/m256/m64bcst                                in ymm2, write byte  \n                                                         results to ymm1      \n                                                         under k1.            \n                                                         Select unaligned     \n   EVEX.512.66.0F38.W1 83 /r                             bytes from qwords in \n   VPMULTISHIFTQB zmm1                                   zmm3/m512/m64bcst    \n   {k1}{z},                  A     V/V      AVX512_VBMI  using control bytes  \n   zmm2,zmm3/m512/m64bcst                                in zmm2, write byte  \n                                                         results to zmm1      \n                                                         under k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full       ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction selects eight unaligned bytes from each input qword\n   element of the second source operand (the third operand) and writes eight\n   assembled bytes for each qword element in the destination operand (the\n   first operand). Each byte result is selected using a byte-granular shift\n   control within the corresponding qword element of the first source operand\n   (the second operand). Each byte result in the destination operand is\n   updated under the writemask k1.\n\n   Only the low 6 bits of each control byte are used to select an 8-bit slot\n   to extract the output byte from the qword data in the second source\n   operand. The starting bit of the 8-bit slot can be unaligned relative to\n   any byte boundary and is extracted from the input qword source at the\n   location specified in the low 6-bit of the control byte. If the 8-bit slot\n   would exceed the qword boundary, the out-of-bound portion of the 8-bit\n   slot is wrapped back to start from bit 0 of the input qword element.\n\n   The first source operand is a ZMM/YMM/XMM register. The second source\n   operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location\n   or a 512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is a ZMM/YMM/XMM register.\n"],
	["ptwrite", "                PTWRITE \u2014 Write Data to a Processor Trace Packet\n\n                             64/32 bit    CPUID                               \n   Opcode/Instruction  Op/En Mode Support Feature Description\n                                          Flag    \n                                                  Reads the data from r64/m64 \n   F3 REX.W 0F AE /4   RM    V/N.E        PTWRITE to encode into a PTW packet \n   PTWRITE r64/m64                                if dependencies are met     \n                                                  (see details below).        \n                                                  Reads the data from r32/m32 \n   F3 0F AE /4 PTWRITE RM    V/V          PTWRITE to encode into a PTW packet \n   r32/m32                                        if dependencies are met     \n                                                  (see details below).        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1    Operand 2 Operand 3 Operand 4 \n   RM    ModRM:rm (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   This instruction reads data in the source operand and sends it to the\n   Intel Processor Trace hardware to be encoded in a PTW packet if TriggerEn,\n   ContextEn, FilterEn, and PTWEn are all set to 1. For more details on these\n   values, see Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s\n   Manual, Volume 3C, Section 33.2.2, \u201cSoftware Trace Instrumentation with\n   PTWRITE.\u201d The size of data is 64-bit if using REX.W in 64-bit mode,\n   otherwise 32-bits of data are copied from the source operand.\n\n   Note: The instruction will #UD if prefix 66H is used.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fcom:fcomp:fcompp", "               FCOM/FCOMP/FCOMPP \u2014 Compare Floating-Point Values\n\n   Opcode  Instruction 64-Bit Mode Compat/Leg Mode Description                \n   D8 /2   FCOM m32fp  Valid       Valid           Compare ST(0) with m32fp.  \n   DC /2   FCOM m64fp  Valid       Valid           Compare ST(0) with m64fp.  \n   D8 D0+i FCOM ST(i)  Valid       Valid           Compare ST(0) with ST(i).  \n   D8 D1   FCOM        Valid       Valid           Compare ST(0) with ST(1).  \n   D8 /3   FCOMP m32fp Valid       Valid           Compare ST(0) with m32fp   \n                                                   and pop register stack.    \n   DC /3   FCOMP m64fp Valid       Valid           Compare ST(0) with m64fp   \n                                                   and pop register stack.    \n   D8 D8+i FCOMP ST(i) Valid       Valid           Compare ST(0) with ST(i)   \n                                                   and pop register stack.    \n   D8 D9   FCOMP       Valid       Valid           Compare ST(0) with ST(1)   \n                                                   and pop register stack.    \n                                                   Compare ST(0) with ST(1)   \n   DE D9   FCOMPP      Valid       Valid           and pop register stack     \n                                                   twice.                     \n\nDescription \u00b6\n\n   Compares the contents of register ST(0) and source value and sets\n   condition code flags C0, C2, and C3 in the FPU status word according to\n   the results (see the table below). The source operand can be a data\n   register or a memory location. If no source operand is given, the value in\n   ST(0) is compared with the value in ST(1). The sign of zero is ignored, so\n   that \u20130.0 is equal to +0.0.\n\n   Condition   C3 C2 C0 \n   ST(0) > SRC 0  0  0  \n   ST(0) < SRC 0  0  1  \n   ST(0) = SRC 1  0  0  \n   Unordered*  1  1  1  \n\n   Table 3-21. FCOM/FCOMP/FCOMPP Results\n\n     *\n     Flagsnotsetifunmaskedinvalid-arithmetic-operand(#IA)exceptionisgenerated.\n\n   This instruction checks the class of the numbers being compared (see\n   \u201cFXAM\u2014Examine Floating-Point\u201d in this chapter). If either operand is a NaN\n   or is in an unsupported format, an invalid-arithmetic-operand exception\n   (#IA) is raised and, if the exception is masked, the condition flags are\n   set to \u201cunordered.\u201d If the invalid-arithmetic-operand exception is\n   unmasked, the condition code flags are not set.\n\n   The FCOMP instruction pops the register stack following the comparison\n   operation and the FCOMPP instruction pops the register stack twice\n   following the comparison operation. To pop the register stack, the\n   processor marks the ST(0) register as empty and increments the stack\n   pointer (TOP) by 1.\n\n   The FCOM instructions perform the same operation as the FUCOM\n   instructions. The only difference is how they handle QNaN operands. The\n   FCOM instructions raise an invalid-arithmetic-operand exception (#IA) when\n   either or both of the operands is a NaN value or is in an unsupported\n   format. The FUCOM instructions perform the same operation as the FCOM\n   instructions, except that they do not generate an\n   invalid-arithmetic-operand exception for QNaNs.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0.                   \n   C0, C2, C3 See table on previous page. \n"],
	["fcomi:fcomip:fucomi:fucomip", "   FCOMI/FCOMIP/FUCOMI/FUCOMIP \u2014 Compare Floating-Point Values and Set EFLAGS\n\n   Opcode  Instruction      64-Bit Compat/Leg Description                     \n                            Mode   Mode       \n   DB F0+i FCOMI ST, ST(i)  Valid  Valid      Compare ST(0) with ST(i) and    \n                                              set status flags accordingly.   \n                                              Compare ST(0) with ST(i), set   \n   DF F0+i FCOMIP ST, ST(i) Valid  Valid      status flags accordingly, and   \n                                              pop register stack.             \n                                              Compare ST(0) with ST(i), check \n   DB E8+i FUCOMI ST, ST(i) Valid  Valid      for ordered values, and set     \n                                              status flags accordingly.       \n                                              Compare ST(0) with ST(i), check \n   DF E8+i FUCOMIP ST,      Valid  Valid      for ordered values, set status  \n           ST(i)                              flags accordingly, and pop      \n                                              register stack.                 \n\nDescription \u00b6\n\n   Performs an unordered comparison of the contents of registers ST(0) and\n   ST(i) and sets the status flags ZF, PF, and CF in the EFLAGS register\n   according to the results (see the table below). The sign of zero is\n   ignored for comparisons, so that \u20130.0 is equal to +0.0.\n\n   Comparison Results* ZF PF CF \n   ST0 > ST(i)         0  0  0  \n   ST0 < ST(i)         0  0  1  \n   ST0 = ST(i)         1  0  0  \n   Unordered**         1  1  1  \n\n   Table 3-22. FCOMI/FCOMIP/ FUCOMI/FUCOMIP Results\n\n     * SeetheIA-32ArchitectureCompatibilitysectionbelow.\n\n     ** Flags not set if unmasked invalid-arithmetic-operand (#IA) exception\n     is generated.\n\n   An unordered comparison checks the class of the numbers being compared\n   (see \u201cFXAM\u2014Examine Floating-Point\u201d in this chapter). The FUCOMI/FUCOMIP\n   instructions perform the same operations as the FCOMI/FCOMIP instructions.\n   The only difference is that the FUCOMI/FUCOMIP instructions raise the\n   invalid-arithmetic-operand exception (#IA) only when either or both\n   operands are an SNaN or are in an unsupported format; QNaNs cause the\n   condition code flags to be set to unordered, but do not cause an exception\n   to be generated. The FCOMI/FCOMIP instructions raise an invalid-operation\n   exception when either or both of the operands are a NaN value of any kind\n   or are in an unsupported format.\n\n   If the operation results in an invalid-arithmetic-operand exception being\n   raised, the status flags in the EFLAGS register are set only if the\n   exception is masked.\n\n   The FCOMI/FCOMIP and FUCOMI/FUCOMIP instructions set the OF, SF, and AF\n   flags to zero in the EFLAGS register (regardless of whether an\n   invalid-operation exception is detected).\n\n   The FCOMIP and FUCOMIP instructions also pop the register stack following\n   the comparison operation. To pop the register stack, the processor marks\n   the ST(0) register as empty and increments the stack pointer (TOP) by 1.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The FCOMI/FCOMIP/FUCOMI/FUCOMIP instructions were introduced to the IA-32\n   Architecture in the P6 family processors and are not available in earlier\n   IA-32 processors.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0.     \n   C0, C2, C3 Not affected. \n"],
	["ecreate", "            ECREATE \u2014 Create an SECS page in the Enclave Page Cache\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n   EAX = 00H                                     This leaf function begins an \n   ENCLS[ECREATE]     IR    V/V          SGX1    enclave build by creating an \n                                                 SECS page in EPC.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX          RBX                   RCX                               \n   IR    ECREATE (In) Address of a PAGEINFO Address of the destination SECS   \n                      (In)                  page (In)                         \n\n  Description \u00b6\n\n   ENCLS[ECREATE] is the first instruction executed in the enclave build\n   process. ECREATE copies an SECS structure outside the EPC into an SECS\n   page inside the EPC. The internal structure of SECS is not accessible to\n   software.\n\n   ECREATE will set up fields in the protected SECS and mark the page as\n   valid inside the EPC. ECREATE initializes or checks unused fields.\n\n   Software sets the following fields in the source structure: SECS:BASEADDR,\n   SECS:SIZE in bytes, ATTRIBUTES, CONFIGID, and CONFIGSVN. SECS:BASEADDR\n   must be naturally aligned on an SECS.SIZE boundary. SECS.SIZE must be at\n   least 2 pages (8192).\n\n   The source operand RBX contains an effective address of a PAGEINFO\n   structure. PAGEINFO contains an effective address of a source SECS and an\n   effective address of an SECINFO. The SECS field in PAGEINFO is not used.\n\n   The RCX register is the effective address of the destination SECS. It is\n   an address of an empty slot in the EPC. The SECS structure must be page\n   aligned. SECINFO flags must specify the page as an SECS page.\n\nECREATE Memory Parameter Semantics \u00b6\n\n   PAGEINFO          PAGEINFO.SRCPGE       PAGEINFO.SECINFO      EPCPAGE      \n   Read access       Read access permitted Read access permitted Write access \n   permitted by Non  by Non Enclave        by Non Enclave        permitted by \n   Enclave                                                       Enclave      \n\n   ECREATE will fault if the SECS target page is in use; already valid;\n   outside the EPC. It will also fault if addresses are not aligned; unused\n   PAGEINFO fields are not zero.\n\n   If the amount of space needed to store the SSA frame is greater than the\n   amount specified in SECS.SSAFRAMESIZE, a #GP(0) results. The amount of\n   space needed for an SSA frame is computed based on\n   DS:TMP_SECS.ATTRIBUTES.XFRM size. Details of computing the size can be\n   found Section 39.7.\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                           Parameter     Base Concurrency Restrictions\n                                                       On Conflict      \n   ECREATE ECREATE SECS [DS:RCX]                \n   Exclusive #GP ECREATE SECS     SECS [DS:RCX]\n   [DS:RCX]                       \n\n   Table 38-15. Base Concurrency Restrictions of ECREATE\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT, EACCEPTCOPY, vs. vs. EADD,                 \n                     EADD, EEXTEND, EINIT vs.      EEXTEND, EINIT            \n                     ETRACK, ETRACKC Access vs.    vs. EADD,      vs. ETRACK,\n                     ETRACK, ETRACKC Access On     EEXTEND, EINIT ETRACKC\n   Leaf    Parameter Conflict Access vs. ETRACK,   vs. ETRACK,  \n                     ETRACKC Access On Conflict    ETRACKC      \n                     EMODPE, EMODPR, EMODT      \n                     Access On Conflict Access  \n                     On Conflict Access Access  \n                     On Conflict Access On      \n                     Conflict                   \n   ECREATE SECS      Concurrent                    Concurrent     Concurrent \n           [DS:RCX]  \n\n   Table 38-16. Additional Concurrency Restrictions of ECREATE\n\n  Flags Affected \u00b6\n\n   None\n"],
	["vgatherdps:vgatherqps", "  VGATHERDPS/VGATHERQPS \u2014 Gather Packed Single Precision Floating-Point Values\n                        UsingSigned Dword/Qword Indices\n\n                               64/32 Bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                               Support   Flag    \n                                                 Using dword indices          \n                                                 specified in vm32x, gather   \n                                                 single-precision             \n   VEX.128.66.0F38.W0 92                         floating-point values from   \n   /r VGATHERDPS xmm1,   A     V/V       AVX2    memory conditioned on mask   \n   vm32x, xmm2                                   specified by xmm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 xmm1.                        \n                                                 Using qword indices          \n                                                 specified in vm64x, gather   \n                                                 single-precision             \n   VEX.128.66.0F38.W0 93                         floating-point values from   \n   /r VGATHERQPS xmm1,   A     V/V       AVX2    memory conditioned on mask   \n   vm64x, xmm2                                   specified by xmm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 xmm1.                        \n                                                 Using dword indices          \n                                                 specified in vm32y, gather   \n                                                 single-precision             \n   VEX.256.66.0F38.W0 92                         floating-point values from   \n   /r VGATHERDPS ymm1,   A     V/V       AVX2    memory conditioned on mask   \n   vm32y, ymm2                                   specified by ymm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 ymm1.                        \n                                                 Using qword indices          \n                                                 specified in vm64y, gather   \n                                                 single-precision             \n   VEX.256.66.0F38.W0 93                         floating-point values from   \n   /r VGATHERQPS xmm1,   A     V/V       AVX2    memory conditioned on mask   \n   vm64y, xmm2                                   specified by xmm2.           \n                                                 Conditionally gathered       \n                                                 elements are merged into     \n                                                 xmm1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1       Operand 2                  Operand 3       Operand 4 \n   A     ModRM:reg (r,w) BaseReg (R): VSIB:base,    VEX.vvvv (r, w) N/A       \n                         VectorReg(R): VSIB:index   \n\nDescription \u00b6\n\n   The instruction conditionally loads up to 4 or 8 single-precision\n   floating-point values from memory addresses specified by the memory\n   operand (the second operand) and using dword indices. The memory operand\n   uses the VSIB form of the SIB byte to specify a general purpose register\n   operand as the common base, a vector register for an array of indices\n   relative to the base and a constant scale factor.\n\n   The mask operand (the third operand) specifies the conditional load\n   operation from each memory address and the corresponding update of each\n   data element of the destination operand (the first operand).\n   Conditionality is specified by the most significant bit of each data\n   element of the mask register. If an element\u2019s mask bit is not set, the\n   corresponding element of the destination register is left unchanged. The\n   width of data element in the destination register and mask register are\n   identical. The entire mask register will be set to zero by this\n   instruction unless the instruction causes an exception.\n\n   Using qword indices, the instruction conditionally loads up to 2 or 4\n   single-precision floating-point values from the VSIB addressing memory\n   operand, and updates the lower half of the destination register. The upper\n   128 or 256 bits of the destination register are zero\u2019ed with qword\n   indices.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask operand are partially updated; those\n   elements that have been gathered are placed into the destination register\n   and have their mask bits set to zero. If any traps or interrupts are\n   pending from already gathered elements, they will be delivered in lieu of\n   the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data size and index size are different, part of the destination\n   register and part of the mask register do not correspond to any elements\n   being gathered. This instruction sets those parts to zero. It may do this\n   to one or both of those registers even if the instruction triggers an\n   exception, and even if the instruction triggers the exception before\n   gathering any elements.\n\n   VEX.128 version: For dword indices, the instruction will gather four\n   single-precision floating-point values. For qword indices, the instruction\n   will gather two values and zero the upper 64 bits of the destination.\n\n   VEX.256 version: For dword indices, the instruction will gather eight\n   single-precision floating-point values. For qword indices, the instruction\n   will gather four values and zero the upper 128 bits of the destination.\n\n   Note that:\n\n     * If any pair of the index, mask, or destination registers are the same,\n       this instruction results a UD fault.\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination will be completed (and non-faulting). Individual\n       elements closer to the MSB may or may not be completed. If a given\n       element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to-left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * This instruction will cause a #UD if the address size attribute is\n       16-bit.\n     * This instruction will cause a #UD if the memory operand is encoded\n       without the SIB byte.\n     * This instruction should not be used to access memory mapped I/O as the\n       ordering of the individual loads it does is implementation specific,\n       and some implementations may use loads larger than the data element\n       size or load elements an indeterminate number of times.\n     * The scaled index may require more bits to represent than the address\n       bits used by the processor (e.g., in 32-bit mode, if the scale is\n       greater than one). In this case, the most significant bits beyond the\n       number of address bits are ignored.\n"],
	["gf2p8mulb", "                    GF2P8MULB \u2014 Galois Field Multiply Bytes\n\n                                           64/32 bit CPUID                    \n   Opcode/Instruction                Op/En Mode      Feature  Description\n                                           Support   Flag     \n                                                              Multiplies      \n   66 0F38 CF /r GF2P8MULB xmm1,     A     V/V       GFNI     elements in the \n   xmm2/m128                                                  finite field    \n                                                              GF(2^8).        \n                                                              Multiplies      \n   VEX.128.66.0F38.W0 CF /r          B     V/V       AVX GFNI elements in the \n   VGF2P8MULB xmm1, xmm2, xmm3/m128                           finite field    \n                                                              GF(2^8).        \n                                                              Multiplies      \n   VEX.256.66.0F38.W0 CF /r          B     V/V       AVX GFNI elements in the \n   VGF2P8MULB ymm1, ymm2, ymm3/m256                           finite field    \n                                                              GF(2^8).        \n   EVEX.128.66.0F38.W0 CF /r                                  Multiplies      \n   VGF2P8MULB xmm1{k1}{z}, xmm2,     C     V/V       AVX512VL elements in the \n   xmm3/m128                                         GFNI     finite field    \n                                                              GF(2^8).        \n   EVEX.256.66.0F38.W0 CF /r                                  Multiplies      \n   VGF2P8MULB ymm1{k1}{z}, ymm2,     C     V/V       AVX512VL elements in the \n   ymm3/m256                                         GFNI     finite field    \n                                                              GF(2^8).        \n   EVEX.512.66.0F38.W0 CF /r                                  Multiplies      \n   VGF2P8MULB zmm1{k1}{z}, zmm2,     C     V/V       AVX512F  elements in the \n   zmm3/m512                                         GFNI     finite field    \n                                                              GF(2^8).        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A      ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A      ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   The instruction multiplies elements in the finite field GF(2^8), operating\n   on a byte (field element) in the first source operand and the\n   corresponding byte in a second source operand. The field GF(2^8) is\n   represented in polynomial representation with the reduction polynomial x^8\n   + x^4 + x^3 + x + 1.\n\n   This instruction does not support broadcasting.\n\n   The EVEX encoded form of this instruction supports memory fault\n   suppression. The SSE encoded forms of the instruction require16B alignment\n   on their memory operations.\n"],
	["aesimc", "              AESIMC \u2014 Perform the AES InvMixColumn Transformation\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature  Description\n                                          Flag     \n                                                   Perform the InvMixColumn   \n   66 0F 38 DB /r AESIMC                           transformation on a        \n   xmm1, xmm2/m128        RM    V/V       AES      128-bit round key from     \n                                                   xmm2/m128 and store the    \n                                                   result in xmm1.            \n                                                   Perform the InvMixColumn   \n   VEX.128.66.0F38.WIG DB                 Both AES transformation on a        \n   /r VAESIMC xmm1,       RM    V/V       and AVX  128-bit round key from     \n   xmm2/m128                              flags    xmm2/m128 and store the    \n                                                   result in xmm1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Perform the InvMixColumns transformation on the source operand and store\n   the result in the destination operand. The destination operand is an XMM\n   register. The source operand can be an XMM register or a 128-bit memory\n   location.\n\n   Note: the AESIMC instruction should be applied to the expanded AES round\n   keys (except for the first and last round key) in order to prepare them\n   for decryption using the \u201cEquivalent Inverse Cipher\u201d (defined in FIPS\n   197).\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n"],
	["vpbroadcastb:vpbroadcastw:vpbroadcastd:vpbroadcastq", "   VPBROADCASTB/VPBROADCASTW/VPBROADCASTD/VPBROADCASTQ \u2014 Load With Broadcast\n                   Integer Data From General Purpose Register\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Broadcast an 8-bit      \n   EVEX.128.66.0F38.W0 7A /r                 AVX512VL value from a GPR to all \n   VPBROADCASTB xmm1         A     V/V       AVX512BW bytes in the 128-bit    \n   {k1}{z}, reg                                       destination subject to  \n                                                      writemask k1.           \n                                                      Broadcast an 8-bit      \n   EVEX.256.66.0F38.W0 7A /r                 AVX512VL value from a GPR to all \n   VPBROADCASTB ymm1         A     V/V       AVX512BW bytes in the 256-bit    \n   {k1}{z}, reg                                       destination subject to  \n                                                      writemask k1.           \n                                                      Broadcast an 8-bit      \n   EVEX.512.66.0F38.W0 7A /r                          value from a GPR to all \n   VPBROADCASTB zmm1         A     V/V       AVX512BW bytes in the 512-bit    \n   {k1}{z}, reg                                       destination subject to  \n                                                      writemask k1.           \n                                                      Broadcast a 16-bit      \n   EVEX.128.66.0F38.W0 7B /r                 AVX512VL value from a GPR to all \n   VPBROADCASTW xmm1         A     V/V       AVX512BW words in the 128-bit    \n   {k1}{z}, reg                                       destination subject to  \n                                                      writemask k1.           \n                                                      Broadcast a 16-bit      \n   EVEX.256.66.0F38.W0 7B /r                 AVX512VL value from a GPR to all \n   VPBROADCASTW ymm1         A     V/V       AVX512BW words in the 256-bit    \n   {k1}{z}, reg                                       destination subject to  \n                                                      writemask k1.           \n                                                      Broadcast a 16-bit      \n   EVEX.512.66.0F38.W0 7B /r                          value from a GPR to all \n   VPBROADCASTW zmm1         A     V/V       AVX512BW words in the 512-bit    \n   {k1}{z}, reg                                       destination subject to  \n                                                      writemask k1.           \n                                                      Broadcast a 32-bit      \n   EVEX.128.66.0F38.W0 7C /r                          value from a GPR to all \n   VPBROADCASTD xmm1         A     V/V       AVX512VL doublewords in the      \n   {k1}{z}, r32                              AVX512F  128-bit destination     \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Broadcast a 32-bit      \n   EVEX.256.66.0F38.W0 7C /r                          value from a GPR to all \n   VPBROADCASTD ymm1         A     V/V       AVX512VL doublewords in the      \n   {k1}{z}, r32                              AVX512F  256-bit destination     \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Broadcast a 32-bit      \n   EVEX.512.66.0F38.W0 7C /r                          value from a GPR to all \n   VPBROADCASTD zmm1         A     V/V       AVX512F  doublewords in the      \n   {k1}{z}, r32                                       512-bit destination     \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Broadcast a 64-bit      \n   EVEX.128.66.0F38.W1 7C /r                          value from a GPR to all \n   VPBROADCASTQ xmm1         A     V/N.E.^1  AVX512VL quadwords in the        \n   {k1}{z}, r64                              AVX512F  128-bit destination     \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Broadcast a 64-bit      \n   EVEX.256.66.0F38.W1 7C /r                          value from a GPR to all \n   VPBROADCASTQ ymm1         A     V/N.E.^1  AVX512VL quadwords in the        \n   {k1}{z}, r64                              AVX512F  256-bit destination     \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Broadcast a 64-bit      \n   EVEX.512.66.0F38.W1 7C /r                          value from a GPR to all \n   VPBROADCASTQ zmm1         A     V/N.E.^1  AVX512F  quadwords in the        \n   {k1}{z}, r64                                       512-bit destination     \n                                                      subject to writemask    \n                                                      k1.                     \n\n     1. EVEX.W in non-64 bit is ignored; the instruction behaves as if the W0\n     version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Broadcasts a 8-bit, 16-bit, 32-bit or 64-bit value from a general-purpose\n   register (the second operand) to all the locations in the destination\n   vector register (the first operand) using the writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n"],
	["egetkey", "                    EGETKEY \u2014 Retrieves a Cryptographic Key\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n   EAX = 01H          IR    V/V          SGX1    This leaf function retrieves \n   ENCLU[EGETKEY]                                a cryptographic key.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                       RBX             RCX                        \n   IR    EGETKEY (In) Return error Address to a    Address of the OUTPUTDATA  \n                      code (Out)   KEYREQUEST (In) (In)                       \n\n  Description \u00b6\n\n   The ENCLU[EGETKEY] instruction returns a 128-bit secret key from the\n   processor specific key hierarchy. The register RBX contains the effective\n   address of a KEYREQUEST structure, which the instruction interprets to\n   determine the key being requested. The Requesting Keys section below\n   provides a description of the keys that can be requested. The RCX register\n   contains the effective address where the key will be returned. Both the\n   addresses in RBX & RCX should be locations inside the enclave.\n\n   EGETKEY derives keys using a processor unique value to create a specific\n   key based on a number of possible inputs. This instruction leaf can only\n   be executed inside an enclave.\n\nEEGETKEY Memory Parameter Semantics \u00b6\n\n   KEYREQUEST          OUTPUTDATA           \n   Enclave read access Enclave write access \n\n   After validating the operands, the instruction determines which key is to\n   be produced and performs the following actions:\n\n     * The instruction assembles the derivation data for the key based on the\n       Table 38-66.\n     * Computes derived key using the derivation data and package specific\n       value.\n     * Outputs the calculated key to the address in RCX.\n\n   The instruction fails with #GP(0) if the operands are not properly\n   aligned. Successful completion of the instruction will clear RFLAGS.{ZF,\n   CF, AF, OF, SF, PF}. The instruction returns an error code if the user\n   tries to request a key based on an invalid CPUSVN or ISVSVN (when the user\n   request is accepted, see the table below), requests a key for which it has\n   not been granted the attribute to request, or requests a key that is not\n   supported by the hardware. These checks may be performed in any order.\n   Thus, an indication by error number of one cause (for example, invalid\n   attribute) does not imply that there are not also other errors. Different\n   processors may thus give different error numbers for the same Enclave. The\n   correctness of software should not rely on the order resulting from the\n   checks documented in this section. In such cases the ZF flag is set and\n   the corresponding error bit (SGX_INVALID_SVN, SGX_INVALID_ATTRIBUTE,\n   SGX_INVALID_KEYNAME) is set in RAX and the data at the address specified\n   by RCX is unmodified.\n\n   Requesting Keys\n\n   The KEYREQUEST structure (see Section 35.18.1) identifies the key to be\n   provided. The Keyrequest.KeyName field identifies which type of key is\n   requested.\n\n   Deriving Keys\n\n   Key derivation is based on a combination of the enclave specific values\n   (see Table 38-66) and a processor key. Depending on the key being\n   requested a field may either be included by definition or the value may be\n   included from the KeyRequest. A \u201cyes\u201d in Table 38-66 indicates the value\n   for the field is included from its default location, identified in the\n   source row, and a \u201crequest\u201d indicates the values for the field is included\n   from its corresponding KeyRequest field.\n\n             Key Name  Attributes      Owner  CPU SVN   ISV SVN ISV     ISVEXT  ISVFAM  MRENCLAVE MRSIGNER CONFIG  CONFIGS RAND    \n                                       Epoch                    PRODID  PRODID  ILYID                      ID      VN      \n                       Y :=                                                                                                        \n                       SECS.ATTRIBUTES                                                                                             \n                       and                    Y :=                                      \n                       SECS.MISCSELECT        CPUSVN\n                       and                    Register;\n                       SECS.CET_ATTRIB \n             Key       UTES;           CR_SGX           R :=    SECS.   SECS.IS SECS.IS SECS.     SECS.    SECS.CO SECS.CO Req.\nSource       Dependent R := AttribMask OWNER            Req.ISV ISVID   VEXTPR  VFAMIL  MRENCLAVE MRSIGNER NFIGID  NFIGSVN KEYID\n             Constant  &               EPOCH            SVN;            ODID    YID\n                       SECS.ATTRIBUTES        R :=      \n                       and                    Req.CPU\n                       SECS.MISCSELECT        SVN;\n                       and             \n                       SECS.CET_ATTRIB \n                       UTES;           \nEINITTOKEN   Yes       Request         Yes    Request   Request Yes     No      No      No        Yes      No      No      Request \nReport       Yes       Yes             Yes    Yes       No      No      No      No      Yes       No       Yes     Yes     Request \nSeal         Yes       Request         Yes    Request   Request Request Request Request Request   Request  Request Request Request \nProvisioning Yes       Request         No     Request   Request Yes     No      No      No        Yes      No      No      Yes     \nProvisioning Yes       Request         No     Request   Request Request Request Request No        Yes      Request Request Yes     \nSeal         \n\n   Table 38-66. Key Derivation\n\n   Keys that permit the specification of a CPU or ISV's code's, or enclave\n   configuration's SVNs have additional requirements. The caller may not\n   request a key for an SVN beyond the current CPU, ISV or enclave\n   configuration's SVN, respectively.\n\n   Several keys are access controlled. Access to the Provisioning Key and\n   Provisioning Seal key requires the enclave's ATTRIBUTES.PROVISIONKEY be\n   set. The EINITTOKEN Key requires ATTRIBUTES.EINITTOKEN_KEY be set and\n   SECS.MRSIGNER equal IA32_SGXLEPUBKEYHASH.\n\n   Some keys are derived based on a hardcode PKCS padding constant (352 byte\n   string):\n\n   HARDCODED_PKCS1_5_PADDING[15:0] := 0100H;\n\n   HARDCODED_PKCS1_5_PADDING[2655:16] := SignExtend330Byte(-1); // 330 bytes\n   of 0FFH\n\n   HARDCODED_PKCS1_5_PADDING[2815:2656] :=\n   2004000501020403650148866009060D30313000H;\n\n   The error codes are:\n\n   Error Code (see Table 38-4) Value Description                              \n   No Error                    0     EGETKEY successful.                      \n   SGX_INVALID_ATTRIBUTE             The KEYREQUEST contains a KEYNAME for    \n                                     which the enclave is not authorized.     \n   SGX_INVALID_CPUSVN                If KEYREQUEST.CPUSVN is an unsupported   \n                                     platforms CPUSVN value.                  \n                                     If KEYREQUEST software SVN (ISVSVN or    \n   SGX_INVALID_ISVSVN                CONFIGSVN) is greater than the enclave's \n                                     corresponding SVN.                       \n   SGX_INVALID_KEYNAME               If KEYREQUEST.KEYNAME is an unsupported  \n                                     value.                                   \n\n   Table 38-67. EGETKEY Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                      Base Concurrency Restrictions\n   Leaf    Parameter  Access     On Conflict SGX_CONFLICT VM Exit             \n                                             Qualification                    \n           KEYREQUEST Concurrent \n   EGETKEY [DS:RBX]   \n           OUTPUTDATA Concurrent \n           [DS:RCX]   \n\n   Table 38-68. Base Concurrency Restrictions of EGETKEY\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT,                                       \n                     EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\n  Leaf    Parameter  EMODPE, EMODPR,     EINIT\n                     EMODT      \n                     Access     On       Access     On       Access     On       \n                                Conflict            Conflict            Conflict \n          KEYREQUEST Concurrent          Concurrent          Concurrent \n  EGETKEY [DS:RBX]   \n          OUTPUTDATA Concurrent          Concurrent          Concurrent \n          [DS:RCX]   \n\n   Table 38-69. Additional Concurrency Restrictions of EGETKEY\n\n  Flags Affected \u00b6\n\n   ZF is cleared if successful, otherwise ZF is set. CF, PF, AF, OF, SF are\n   cleared.\n"],
	["bndcl", "                           BNDCL \u2014 Check Lower Bound\n\n                                64/32 bit    CPUID                            \n   Opcode/Instruction     Op/En Mode Support Feature Description\n                                             Flag    \n                                                     Generate a #BR if the    \n   F3 0F 1A /r BNDCL bnd, RM    N.E./V       MPX     address in r/m32 is      \n   r/m32                                             lower than the lower     \n                                                     bound in bnd.LB.         \n                                                     Generate a #BR if the    \n   F3 0F 1A /r BNDCL bnd, RM    V/N.E.       MPX     address in r/m64 is      \n   r/m64                                             lower than the lower     \n                                                     bound in bnd.LB.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Compare the address in the second operand with the lower bound in bnd. The\n   second operand can be either a register or memory operand. If the address\n   is lower than the lower bound in bnd.LB, it will set BNDSTATUS to 01H and\n   signal a #BR exception.\n\n   This instruction does not cause any memory access, and does not read or\n   write any flags.\n\nFlags Affected \u00b6\n\n   None\n"],
	["vpshldv", "       VPSHLDV \u2014 Concatenate and Variable Shift Packed Data Left Logical\n\n                                  64/32 bit CPUID Feature                     \n   Opcode/Instruction       Op/En Mode      Flag          Description\n                                  Support   \n                                                          Concatenate xmm1    \n   EVEX.128.66.0F38.W1 70                                 and xmm2, extract   \n   /r VPSHLDVW xmm1{k1}{z}, A     V/V       AVX512_VBMI2  result shifted to   \n   xmm2, xmm3/m128                          AVX512VL      the left by value   \n                                                          in xmm3/m128 into   \n                                                          xmm1.               \n                                                          Concatenate ymm1    \n   EVEX.256.66.0F38.W1 70                                 and ymm2, extract   \n   /r VPSHLDVW ymm1{k1}{z}, A     V/V       AVX512_VBMI2  result shifted to   \n   ymm2, ymm3/m256                          AVX512VL      the left by value   \n                                                          in xmm3/m256 into   \n                                                          ymm1.               \n                                                          Concatenate zmm1    \n   EVEX.512.66.0F38.W1 70                                 and zmm2, extract   \n   /r VPSHLDVW zmm1{k1}{z}, A     V/V       AVX512_VBMI2  result shifted to   \n   zmm2, zmm3/m512                                        the left by value   \n                                                          in zmm3/m512 into   \n                                                          zmm1.               \n                                                          Concatenate xmm1    \n   EVEX.128.66.0F38.W0 71                                 and xmm2, extract   \n   /r VPSHLDVD xmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   xmm2, xmm3/m128/m32bcst                  AVX512VL      the left by value   \n                                                          in xmm3/m128 into   \n                                                          xmm1.               \n                                                          Concatenate ymm1    \n   EVEX.256.66.0F38.W0 71                                 and ymm2, extract   \n   /r VPSHLDVD ymm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   ymm2, ymm3/m256/m32bcst                  AVX512VL      the left by value   \n                                                          in xmm3/m256 into   \n                                                          ymm1.               \n                                                          Concatenate zmm1    \n   EVEX.512.66.0F38.W0 71                                 and zmm2, extract   \n   /r VPSHLDVD zmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   zmm2, zmm3/m512/m32bcst                                the left by value   \n                                                          in zmm3/m512 into   \n                                                          zmm1.               \n                                                          Concatenate xmm1    \n   EVEX.128.66.0F38.W1 71                                 and xmm2, extract   \n   /r VPSHLDVQ xmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   xmm2, xmm3/m128/m64bcst                  AVX512VL      the left by value   \n                                                          in xmm3/m128 into   \n                                                          xmm1.               \n                                                          Concatenate ymm1    \n   EVEX.256.66.0F38.W1 71                                 and ymm2, extract   \n   /r VPSHLDVQ ymm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   ymm2, ymm3/m256/m64bcst                  AVX512VL      the left by value   \n                                                          in xmm3/m256 into   \n                                                          ymm1.               \n                                                          Concatenate zmm1    \n   EVEX.512.66.0F38.W1 71                                 and zmm2, extract   \n   /r VPSHLDVQ zmm1{k1}{z}, B     V/V       AVX512_VBMI2  result shifted to   \n   zmm2, zmm3/m512/m64bcst                                the left by value   \n                                                          in zmm3/m512 into   \n                                                          zmm1.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full Mem ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   B     Full     ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Concatenate packed data, extract result shifted to the left by variable\n   value.\n\n   This instruction supports memory fault suppression.\n"],
	["vcvttps2uqq", "  VCVTTPS2UQQ \u2014 Convert With Truncation Packed Single Precision Floating-Point\n                Values toPacked Unsigned Quadword Integer Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Convert two packed      \n                                                      single precision        \n                                                      floating-point values   \n   EVEX.128.66.0F.W0 78 /r                   AVX512VL from xmm2/m64/m32bcst   \n   VCVTTPS2UQQ xmm1 {k1}{z}, A     V/V       AVX512DQ to two packed unsigned  \n   xmm2/m64/m32bcst                                   quadword values in xmm1 \n                                                      using truncation        \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Convert four packed     \n                                                      single precision        \n                                                      floating-point values   \n   EVEX.256.66.0F.W0 78 /r                   AVX512VL from xmm2/m128/m32bcst  \n   VCVTTPS2UQQ ymm1 {k1}{z}, A     V/V       AVX512DQ to four packed unsigned \n   xmm2/m128/m32bcst                                  quadword values in ymm1 \n                                                      using truncation        \n                                                      subject to writemask    \n                                                      k1.                     \n                                                      Convert eight packed    \n                                                      single precision        \n                                                      floating-point values   \n   EVEX.512.66.0F.W0 78 /r                            from ymm2/m256/m32bcst  \n   VCVTTPS2UQQ zmm1 {k1}{z}, A     V/V       AVX512DQ to eight packed         \n   ymm2/m256/m32bcst{sae}                             unsigned quadword       \n                                                      values in zmm1 using    \n                                                      truncation subject to   \n                                                      writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation up to eight packed single precision\n   floating-point values in the source operand to unsigned quadword integers\n   in the destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   EVEX encoded versions: The source operand is a YMM/XMM/XMM (low 64 bits)\n   register or a 256/128/64-bit memory location. The destination operation is\n   a vector register conditionally updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n"],
	["andnpd", "   ANDNPD \u2014 Bitwise Logical AND NOT of Packed Double Precision Floating-Point\n                                     Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Return the bitwise logical \n   66 0F 55 /r ANDNPD                              AND NOT of packed double   \n   xmm1, xmm2/m128         A    V/V       SSE2     precision floating-point   \n                                                   values in xmm1 and         \n                                                   xmm2/mem.                  \n                                                   Return the bitwise logical \n   VEX.128.66.0F 55 /r                             AND NOT of packed double   \n   VANDNPD xmm1, xmm2,     B    V/V       AVX      precision floating-point   \n   xmm3/m128                                       values in xmm2 and         \n                                                   xmm3/mem.                  \n                                                   Return the bitwise logical \n   VEX.256.66.0F 55/r                              AND NOT of packed double   \n   VANDNPD ymm1, ymm2,     B    V/V       AVX      precision floating-point   \n   ymm3/m256                                       values in ymm2 and         \n                                                   ymm3/mem.                  \n                                                   Return the bitwise logical \n   EVEX.128.66.0F.W1 55 /r                         AND NOT of packed double   \n   VANDNPD xmm1 {k1}{z},   C    V/V       AVX512VL precision floating-point   \n   xmm2, xmm3/m128/m64bcst                AVX512DQ values in xmm2 and         \n                                                   xmm3/m128/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.256.66.0F.W1 55 /r                         AND NOT of packed double   \n   VANDNPD ymm1 {k1}{z},   C    V/V       AVX512VL precision floating-point   \n   ymm2, ymm3/m256/m64bcst                AVX512DQ values in ymm2 and         \n                                                   ymm3/m256/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.512.66.0F.W1 55 /r                         AND NOT of packed double   \n   VANDNPD zmm1 {k1}{z},   C    V/V       AVX512DQ precision floating-point   \n   zmm2, zmm3/m512/m64bcst                         values in zmm2 and         \n                                                   zmm3/m512/m64bcst subject  \n                                                   to writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical AND NOT of the two, four or eight packed double\n   precision floating-point values from the first source operand and the\n   second source operand, and stores the result in the destination operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["lock", "                       LOCK \u2014 Assert LOCK# Signal Prefix\n\n   Opcode^1\n\n      Instruction Op/En 64-Bit Mode Compat/Leg Mode Description               \n                                                    Asserts LOCK# signal for  \n   F0 LOCK        ZO    Valid       Valid           duration of the           \n                                                    accompanying instruction. \n\n     1. See IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Causes the processor\u2019s LOCK# signal to be asserted during execution of the\n   accompanying instruction (turns the instruction into an atomic\n   instruction). In a multiprocessor environment, the LOCK# signal ensures\n   that the processor has exclusive use of any shared memory while the signal\n   is asserted.\n\n   In most IA-32 and all Intel 64 processors, locking may occur without the\n   LOCK# signal being asserted. See the \u201cIA-32 Architecture Compatibility\u201d\n   section below for more details.\n\n   The LOCK prefix can be prepended only to the following instructions and\n   only to those forms of the instructions where the destination operand is a\n   memory operand: ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B,\n   CMPXCHG16B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG. If the\n   LOCK prefix is used with one of these instructions and the source operand\n   is a memory operand, an undefined opcode exception (#UD) may be generated.\n   An undefined opcode exception will also be generated if the LOCK prefix is\n   used with any instruction not in the above list. The XCHG instruction\n   always asserts the LOCK# signal regardless of the presence or absence of\n   the LOCK prefix.\n\n   The LOCK prefix is typically used with the BTS instruction to perform a\n   read-modify-write operation on a memory location in shared memory\n   environment.\n\n   The integrity of the LOCK prefix is not affected by the alignment of the\n   memory field. Memory locking is observed for arbitrarily misaligned\n   fields.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   Beginning with the P6 family processors, when the LOCK prefix is prefixed\n   to an instruction and the memory area being accessed is cached internally\n   in the processor, the LOCK# signal is generally not asserted. Instead,\n   only the processor\u2019s cache is locked. Here, the processor\u2019s cache\n   coherency mechanism ensures that the operation is carried out atomically\n   with regards to memory. See \u201cEffects of a Locked Operation on Internal\n   Processor Caches\u201d in Chapter 9 of Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3A, the for more information on\n   locking of caches.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["bzhi", "           BZHI \u2014 Zero High Bits Starting with Specified Bit Position\n\n                                64/32-bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                          Flag    \n   VEX.LZ.0F38.W0 F5 /r                           Zero bits in r/m32 starting \n   BZHI r32a, r/m32, r32b RMV   V/V       BMI2    with the position in r32b,  \n                                                  write result to r32a.       \n   VEX.LZ.0F38.W1 F5 /r                           Zero bits in r/m64 starting \n   BZHI r64a, r/m64, r64b RMV   V/N.E.    BMI2    with the position in r64b,  \n                                                  write result to r64a.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3    Operand 4 \n   RMV   ModRM:reg (w) ModRM:r/m (r) VEX.vvvv (r) N/A       \n\nDescription \u00b6\n\n   BZHI copies the bits of the first source operand (the second operand) into\n   the destination operand (the first operand) and clears the higher bits in\n   the destination according to the INDEX value specified by the second\n   source operand (the third operand). The INDEX is specified by bits 7:0 of\n   the second source operand. The INDEX value is saturated at the value of\n   OperandSize -1. CF is set, if the number contained in the 8 low bits of\n   the third operand is greater than OperandSize -1.\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   ZF and SF flags are updated based on the result. CF flag is set as\n   specified in the Operation section. OF flag is cleared. AF and PF flags\n   are undefined.\n"],
	["eremove", "                      EREMOVE \u2014 Remove a page from the EPC\n\n                                  64/32 bit    CPUID                          \n   Opcode/Instruction       Op/En Mode Support Feature Description\n                                               Flag    \n                                                       This leaf function     \n   EAX = 03H ENCLS[EREMOVE] IR    V/V          SGX1    removes a page from    \n                                                       the EPC.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                                  RCX                             \n   IR    EREMOVE (In) Return error code (Out) Effective address of the EPC    \n                                              page (In)                       \n\n  Description \u00b6\n\n   This leaf function causes an EPC page to be un-associated with its SECS\n   and be marked as unused. This instruction leaf can only be executed when\n   the current privilege level is 0.\n\n   The content of RCX is an effective address of an EPC page. The DS segment\n   is used to create linear address. Segment override is not supported.\n\n   The instruction fails if the operand is not properly aligned or does not\n   refer to an EPC page or the page is in use by another thread, or other\n   threads are running in the enclave to which the page belongs. In addition\n   the instruction fails if the operand refers to an SECS with associations.\n\nEREMOVE Memory Parameter Semantics \u00b6\n\n   EPCPAGE                           \n   Write access permitted by Enclave \n\n   The instruction faults if any of the following:\n\nEREMOVE Faulting Conditions \u00b6\n\n   The memory operand is not properly  The memory operand does not resolve in \n   aligned.                            an EPC page.                           \n   Refers to an invalid SECS.          Refers to an EPC page that is locked   \n                                       by another thread.                     \n   Another Intel SGX instruction is    RCX does not contain an effective      \n   accessing the EPC page.             address of an EPC page.                \n   the EPC page refers to an SECS with \n   associations.                       \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EREMOVE successful.                            \n   SGX_CHILD_PRESENT           If the SECS still have enclave pages loaded    \n                               into EPC.                                      \n   SGX_ENCLAVE_ACT             If there are still logical processors          \n                               executing inside the enclave.                  \n\n   Table 38-42. EREMOVE Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                         Parameter       Base Concurrency Restrictions\n                                                       On Conflict      \n   EREMOVE EREMOVE Target                       \n   [DS:RCX] Exclusive #GP       Target [DS:RCX]\n   EREMOVE Target [DS:RCX]      \n\n   Table 38-43. Base Concurrency Restrictions of EREMOVE\n\n                     Additional Concurrency Restrictions\n                     vs. EACCEPT, EACCEPTCOPY, vs. vs. EADD,                 \n                     EADD, EEXTEND, EINIT vs.      EEXTEND, EINIT            \n                     ETRACK, ETRACKC Access vs.    vs. EADD,      vs. ETRACK,\n                     ETRACK, ETRACKC Access On     EEXTEND, EINIT ETRACKC\n   Leaf    Parameter Conflict Access vs. ETRACK,   vs. ETRACK,  \n                     ETRACKC Access On Conflict    ETRACKC      \n                     EMODPE, EMODPR, EMODT      \n                     Access On Conflict Access  \n                     On Conflict Access Access  \n                     On Conflict Access On      \n                     Conflict                   \n   EREMOVE Target    Concurrent                    Concurrent     Concurrent \n           [DS:RCX]  \n\n   Table 38-44. Additional Concurrency Restrictions of EREMOVE\n\n  Flags Affected \u00b6\n\n   Sets ZF if unsuccessful, otherwise cleared and RAX returns error code.\n   Clears CF, PF, AF, OF, SF.\n"],
	["cvttpd2dq", "   CVTTPD2DQ \u2014 Convert with Truncation Packed Double Precision Floating-Point\n                      Values toPacked Doubleword Integers\n\n                              Op 64/32 bit CPUID                              \n   Opcode/Instruction         /  Mode      Feature  Description\n                              En Support   Flag     \n                                                    Convert two packed double \n                                                    precision floating-point  \n   66 0F E6 /r CVTTPD2DQ      A  V/V       SSE2     values in xmm2/mem to two \n   xmm1, xmm2/m128                                  signed doubleword         \n                                                    integers in xmm1 using    \n                                                    truncation.               \n                                                    Convert two packed double \n                                                    precision floating-point  \n   VEX.128.66.0F.WIG E6 /r    A  V/V       AVX      values in xmm2/mem to two \n   VCVTTPD2DQ xmm1, xmm2/m128                       signed doubleword         \n                                                    integers in xmm1 using    \n                                                    truncation.               \n                                                    Convert four packed       \n                                                    double precision          \n   VEX.256.66.0F.WIG E6 /r    A  V/V       AVX      floating-point values in  \n   VCVTTPD2DQ xmm1, ymm2/m256                       ymm2/mem to four signed   \n                                                    doubleword integers in    \n                                                    xmm1 using truncation.    \n                                                    Convert two packed double \n                                                    precision floating-point  \n   EVEX.128.66.0F.W1 E6 /r                          values in                 \n   VCVTTPD2DQ xmm1 {k1}{z},   B  V/V       AVX512VL xmm2/m128/m64bcst to two  \n   xmm2/m128/m64bcst                       AVX512F  signed doubleword         \n                                                    integers in xmm1 using    \n                                                    truncation subject to     \n                                                    writemask k1.             \n                                                    Convert four packed       \n                                                    double precision          \n   EVEX.256.66.0F.W1 E6 /r                          floating-point values in  \n   VCVTTPD2DQ xmm1 {k1}{z},   B  V/V       AVX512VL ymm2/m256/m64bcst to four \n   ymm2/m256/m64bcst                       AVX512F  signed doubleword         \n                                                    integers in xmm1 using    \n                                                    truncation subject to     \n                                                    writemask k1.             \n                                                    Convert eight packed      \n                                                    double precision          \n   EVEX.512.66.0F.W1 E6 /r                          floating-point values in  \n   VCVTTPD2DQ ymm1 {k1}{z},   B  V/V       AVX512F  zmm2/m512/m64bcst to      \n   zmm2/m512/m64bcst{sae}                           eight signed doubleword   \n                                                    integers in ymm1 using    \n                                                    truncation subject to     \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two, four or eight packed double precision floating-point values\n   in the source operand (second operand) to two, four or eight packed signed\n   doubleword integers in the destination operand (first operand).\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result is larger than the maximum signed\n   doubleword integer, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (80000000H) is\n   returned.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location, or a 512/256/128-bit vector broadcasted\n   from a 64-bit memory location. The destination operand is a YMM/XMM/XMM\n   (low 64 bits) register conditionally updated with writemask k1. The upper\n   bits (MAXVL-1:256) of the corresponding destination are zeroed.\n\n   VEX.256 encoded version: The source operand is a YMM register or 256- bit\n   memory location. The destination operand is an XMM register. The upper\n   bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   zeroed.\n\n   VEX.128 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a XMM register. The upper bits\n   (MAXVL-1:64) of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 128-\n   bit memory location. The destination operand is an XMM register. The upper\n   bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   SR X3 X2 X1 X0 DEST 0 X3 X2 X1 X0 Figure 3-15. VCVTTPD2DQ (VEX.256 encoded\n   version)\n"],
	["xorps", "  XORPS \u2014 Bitwise Logical XOR of Packed Single Precision Floating-Point Values\n\n                        Op / 64/32 bit CPUID                                  \n   Opcode/Instruction   En   Mode      Feature  Description\n                             Support   Flag     \n                                                Return the bitwise logical    \n   NP 0F 57 /r XORPS                            XOR of packed                 \n   xmm1, xmm2/m128      A    V/V       SSE      single-precision              \n                                                floating-point values in xmm1 \n                                                and xmm2/mem.                 \n                                                Return the bitwise logical    \n   VEX.128.0F.WIG 57 /r                         XOR of packed                 \n   VXORPS xmm1,xmm2,    B    V/V       AVX      single-precision              \n   xmm3/m128                                    floating-point values in xmm2 \n                                                and xmm3/mem.                 \n                                                Return the bitwise logical    \n   VEX.256.0F.WIG 57 /r                         XOR of packed                 \n   VXORPS ymm1, ymm2,   B    V/V       AVX      single-precision              \n   ymm3/m256                                    floating-point values in ymm2 \n                                                and ymm3/mem.                 \n                                                Return the bitwise logical    \n   EVEX.128.0F.W0 57 /r                         XOR of packed                 \n   VXORPS xmm1 {k1}{z}, C    V/V       AVX512VL single-precision              \n   xmm2,                               AVX512DQ floating-point values in xmm2 \n   xmm3/m128/m32bcst                            and xmm3/m128/m32bcst subject \n                                                to writemask k1.              \n                                                Return the bitwise logical    \n   EVEX.256.0F.W0 57 /r                         XOR of packed                 \n   VXORPS ymm1 {k1}{z}, C    V/V       AVX512VL single-precision              \n   ymm2,                               AVX512DQ floating-point values in ymm2 \n   ymm3/m256/m32bcst                            and ymm3/m256/m32bcst subject \n                                                to writemask k1.              \n                                                Return the bitwise logical    \n   EVEX.512.0F.W0 57 /r                         XOR of packed                 \n   VXORPS zmm1 {k1}{z}, C    V/V       AVX512DQ single-precision              \n   zmm2,                                        floating-point values in zmm2 \n   zmm3/m512/m32bcst                            and zmm3/m512/m32bcst subject \n                                                to writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a bitwise logical XOR of the four, eight or sixteen packed\n   single-precision floating-point values from the first source operand and\n   the second source operand, and stores the result in the destination\n   operand\n\n   EVEX.512 encoded version: The first source operand is a ZMM register. The\n   second source operand can be a ZMM register or a vector memory location.\n   The destination operand is a ZMM register conditionally updated with\n   write-mask k1.\n\n   VEX.256 and EVEX.256 encoded versions: The first source operand is a YMM\n   register. The second source operand is a YMM register or a 256-bit memory\n   location. The destination operand is a YMM register (conditionally updated\n   with writemask k1 in case of EVEX). The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 and EVEX.128 encoded versions: The first source operand is an XMM\n   register. The second source operand is an XMM register or 128-bit memory\n   location. The destination operand is an XMM register (conditionally\n   updated with writemask k1 in case of EVEX). The upper bits (MAXVL-1:128)\n   of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["pmulld:pmullq", "         PMULLD/PMULLQ \u2014 Multiply Packed Integers and Store Low Result\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature   Description\n                                Support   Flag      \n                                                    Multiply the packed dword \n   66 0F 38 40 /r PMULLD                            signed integers in xmm1   \n   xmm1, xmm2/m128        A     V/V       SSE4_1    and xmm2/m128 and store   \n                                                    the low 32 bits of each   \n                                                    product in xmm1.          \n                                                    Multiply the packed dword \n   VEX.128.66.0F38.WIG 40                           signed integers in xmm2   \n   /r VPMULLD xmm1, xmm2, B     V/V       AVX       and xmm3/m128 and store   \n   xmm3/m128                                        the low 32 bits of each   \n                                                    product in xmm1.          \n                                                    Multiply the packed dword \n   VEX.256.66.0F38.WIG 40                           signed integers in ymm2   \n   /r VPMULLD ymm1, ymm2, B     V/V       AVX2      and ymm3/m256 and store   \n   ymm3/m256                                        the low 32 bits of each   \n                                                    product in ymm1.          \n                                                    Multiply the packed dword \n   EVEX.128.66.0F38.W0 40                           signed integers in xmm2   \n   /r VPMULLD xmm1        C     V/V       AVX512VL  and xmm3/m128/m32bcst and \n   {k1}{z}, xmm2,                         AVX512F   store the low 32 bits of  \n   xmm3/m128/m32bcst                                each product in xmm1      \n                                                    under writemask k1.       \n                                                    Multiply the packed dword \n   EVEX.256.66.0F38.W0 40                           signed integers in ymm2   \n   /r VPMULLD ymm1        C     V/V       AVX512VL  and ymm3/m256/m32bcst and \n   {k1}{z}, ymm2,                         AVX512F   store the low 32 bits of  \n   ymm3/m256/m32bcst                                each product in ymm1      \n                                                    under writemask k1.       \n                                                    Multiply the packed dword \n   EVEX.512.66.0F38.W0 40                           signed integers in zmm2   \n   /r VPMULLD zmm1        C     V/V       AVX512F   and zmm3/m512/m32bcst and \n   {k1}{z}, zmm2,                                   store the low 32 bits of  \n   zmm3/m512/m32bcst                                each product in zmm1      \n                                                    under writemask k1.       \n                                                    Multiply the packed qword \n   EVEX.128.66.0F38.W1 40                           signed integers in xmm2   \n   /r VPMULLQ xmm1        C     V/V       AVX512VL  and xmm3/m128/m64bcst and \n   {k1}{z}, xmm2,                         AVX512DQ  store the low 64 bits of  \n   xmm3/m128/m64bcst                                each product in xmm1      \n                                                    under writemask k1.       \n                                                    Multiply the packed qword \n   EVEX.256.66.0F38.W1 40                           signed integers in ymm2   \n   /r VPMULLQ ymm1        C     V/V       AVX512VLA and ymm3/m256/m64bcst and \n   {k1}{z}, ymm2,                         VX512DQ   store the low 64 bits of  \n   ymm3/m256/m64bcst                                each product in ymm1      \n                                                    under writemask k1.       \n                                                    Multiply the packed qword \n   EVEX.512.66.0F38.W1 40                           signed integers in zmm2   \n   /r VPMULLQ zmm1        C     V/V       AVX512DQ  and zmm3/m512/m64bcst and \n   {k1}{z}, zmm2,                                   store the low 64 bits of  \n   zmm3/m512/m64bcst                                each product in zmm1      \n                                                    under writemask k1.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD signed multiply of the packed signed dword/qword integers\n   from each element of the first source operand with the corresponding\n   element in the second source operand. The low 32/64 bits of each\n   64/128-bit intermediate results are stored to the destination operand.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding ZMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding ZMM register are\n   zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register; The\n   second source operand is a YMM register or 256-bit memory location. Bits\n   (MAXVL-1:256) of the corresponding destination ZMM register are zeroed.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32/64-bit\n   memory location. The destination operand is conditionally updated based on\n   writemask k1.\n"],
	["fild", "                              FILD \u2014 Load Integer\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n   DF /0  FILD m16int Valid       Valid           Push m16int onto the FPU    \n                                                  register stack.             \n   DB /0  FILD m32int Valid       Valid           Push m32int onto the FPU    \n                                                  register stack.             \n   DF /5  FILD m64int Valid       Valid           Push m64int onto the FPU    \n                                                  register stack.             \n\nDescription \u00b6\n\n   Converts the signed-integer source operand into double extended-precision\n   floating-point format and pushes the value onto the FPU register stack.\n   The source operand can be a word, doubleword, or quadword integer. It is\n   loaded without rounding errors. The sign of the source operand is\n   preserved.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 1 if stack overflow occurred; set to 0 otherwise. \n   C0, C2, C3 Undefined.                                               \n"],
	["vcvtsh2sd", "              VCVTSH2SD \u2014 Convert Low FP16 Value to an FP64 Value\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert the low FP16 \n                                                         value in xmm3/m16 to \n                                                         an FP64 value and    \n   EVEX.LLIG.F3.MAP5.W0 5A /r                            store the result in  \n   VCVTSH2SD xmm1{k1}{z}, xmm2,    A V/V     AVX512-FP16 the low element of   \n   xmm3/m16 {sae}                                        xmm1 subject to      \n                                                         writemask k1. Bits   \n                                                         127:64 of xmm2 are   \n                                                         copied to            \n                                                         xmm1[127:64].        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP16 element in the second source\n   operand to a FP64 element in the low element of the destination operand.\n\n   Bits 127:64 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP64 element of the destination is updated\n   according to the writemask.\n"],
	["fsincos", "                           FSINCOS \u2014 Sine and Cosine\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Compute the sine and cosine \n                                                  of ST(0); replace ST(0)     \n   D9 FB  FSINCOS     Valid       Valid           with the approximate sine,  \n                                                  and push the approximate    \n                                                  cosine onto the register    \n                                                  stack.                      \n\nDescription \u00b6\n\n   Computes both the approximate sine and the cosine of the source operand in\n   register ST(0), stores the sine in ST(0), and pushes the cosine onto the\n   top of the FPU register stack. (This instruction is faster than executing\n   the FSIN and FCOS instructions in succession.)\n\n   The source operand must be given in radians and must be within the range\n   \u22122^63 to +2^63. The following table shows the results obtained when taking\n   the sine and cosine of various classes of numbers, assuming that underflow\n   does not occur.\n\n   SRC   DEST         \n   ST(0) ST(1) Cosine ST(0) Sine \n   \u2212\u221e    *            *          \n   \u2212F    \u2212 1 to + 1   \u2212 1 to + 1 \n   \u22120    +1           \u22120         \n   +0    +1           +0         \n   +F    \u2212 1 to + 1   \u2212 1 to + 1 \n   +\u221e    *            *          \n   NaN   NaN          NaN        \n\n   Table 3-36. FSINCOS Results\n\n     F Meansfinitefloating-pointvalue.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   If the source operand is outside the acceptable range, the C2 flag in the\n   FPU status word is set, and the value in register ST(0) remains unchanged.\n   The instruction does not raise an exception when the source operand is out\n   of range. It is up to the program to check the C2 flag for out-of-range\n   conditions. Source values outside the range \u2212 2^63 to +2^63 can be reduced\n   to the range of the instruction by subtracting an appropriate integer\n   multiple of 2\u03c0. However, even within the range -2^63 to +2^63, inaccurate\n   results can occur because the finite approximation of \u03c0 used internally\n   for argument reduction is not sufficient in all cases. Therefore, for\n   accurate results it is safe to apply FSINCOS only to arguments reduced\n   accurately in software, to a value smaller in absolute value than 3\u03c0/8.\n   See the sections titled \u201cApproximation of Pi\u201d and \u201cTranscendental\n   Instruction Accuracy\u201d in Chapter 8 of the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 1, for a discussion of\n   the proper value to use for \u03c0 in performing such reductions.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n          Set to 0 if stack underflow occurred; set to 1 of stack overflow    \n          occurs.                                                             \n   C1     Set if result was rounded up; cleared otherwise.                    \n          Set to 1 if outside range (\u2212263 < source operand < +263);           \n          otherwise, set to 0.                                                \n   C2     \n   C0, C3 Undefined.                                                          \n"],
	["andpd", "  ANDPD \u2014 Bitwise Logical AND of Packed Double Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Return the bitwise logical \n   66 0F 54 /r ANDPD xmm1,                         AND of packed double       \n   xmm2/m128               A    V/V       SSE2     precision floating-point   \n                                                   values in xmm1 and         \n                                                   xmm2/mem.                  \n                                                   Return the bitwise logical \n   VEX.128.66.0F 54 /r                             AND of packed double       \n   VANDPD xmm1, xmm2,      B    V/V       AVX      precision floating-point   \n   xmm3/m128                                       values in xmm2 and         \n                                                   xmm3/mem.                  \n                                                   Return the bitwise logical \n   VEX.256.66.0F 54 /r                             AND of packed double       \n   VANDPD ymm1, ymm2,      B    V/V       AVX      precision floating-point   \n   ymm3/m256                                       values in ymm2 and         \n                                                   ymm3/mem.                  \n                                                   Return the bitwise logical \n   EVEX.128.66.0F.W1 54 /r                         AND of packed double       \n   VANDPD xmm1 {k1}{z},    C    V/V       AVX512VL precision floating-point   \n   xmm2, xmm3/m128/m64bcst                AVX512DQ values in xmm2 and         \n                                                   xmm3/m128/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.256.66.0F.W1 54 /r                         AND of packed double       \n   VANDPD ymm1 {k1}{z},    C    V/V       AVX512VL precision floating-point   \n   ymm2, ymm3/m256/m64bcst                AVX512DQ values in ymm2 and         \n                                                   ymm3/m256/m64bcst subject  \n                                                   to writemask k1.           \n                                                   Return the bitwise logical \n   EVEX.512.66.0F.W1 54 /r                         AND of packed double       \n   VANDPD zmm1 {k1}{z},    C    V/V       AVX512DQ precision floating-point   \n   zmm2, zmm3/m512/m64bcst                         values in zmm2 and         \n                                                   zmm3/m512/m64bcst subject  \n                                                   to writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a bitwise logical AND of the two, four or eight packed double\n   precision floating-point values from the first source operand and the\n   second source operand, and stores the result in the destination operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 64-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["aesencwide256kl", "AESENCWIDE256KL \u2014 Perform 14 Rounds of AES Encryption Flow With Key Locker on 8\n                            BlocksUsing 256-Bit Key\n\n                               64/32-bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature Description\n                                         Flag    \n   F3 0F 38 D8                                   Encrypt XMM0-7 using 256-bit \n   !(11):010:bbb                         AESKLE  AES key indicated by handle  \n   AESENCWIDE256KL m512, A     V/V       WIDE_KL at m512 and store each       \n   <XMM0-7>                                      resultant block back to its  \n                                                 corresponding register.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operands 2\u20149           \n   A     N/A   ModRM:r/m (r) Implicit XMM0-7 (r, w) \n\nDescription \u00b6\n\n   The AESENCWIDE256KL^1 instruction performs 14 rounds of AES to encrypt\n   each of the eight blocks in XMM0-7 using the 256-bit key indicated by the\n   handle from the second operand. It replaces each input block in XMM0-7\n   with its corresponding encrypted block if the operation succeeds (e.g.,\n   does not run into a handle violation failure).\n\nFlags Affected \u00b6\n\n   ZF is set to 0 if the operation succeeded and set to 1 if the operation\n   failed due to a handle violation. The other arithmetic flags (OF, SF, AF,\n   PF, CF) are cleared to 0.\n"],
	["subss", "         SUBSS \u2014 Subtract Scalar Single Precision Floating-Point Value\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Subtract the low single    \n   F3 0F 5C /r SUBSS xmm1,                         precision floating-point   \n   xmm2/m32                 A    V/V       SSE     value in xmm2/m32 from     \n                                                   xmm1 and store the result  \n                                                   in xmm1.                   \n                                                   Subtract the low single    \n   VEX.LIG.F3.0F.WIG 5C /r                         precision floating-point   \n   VSUBSS xmm1,xmm2,        B    V/V       AVX     value in xmm3/m32 from     \n   xmm3/m32                                        xmm2 and store the result  \n                                                   in xmm1.                   \n                                                   Subtract the low single    \n   EVEX.LLIG.F3.0F.W0 5C /r                        precision floating-point   \n   VSUBSS xmm1 {k1}{z},     C    V/V       AVX512F value in xmm3/m32 from     \n   xmm2, xmm3/m32{er}                              xmm2 and store the result  \n                                                   in xmm1 under writemask    \n                                                   k1.                        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Subtract the low single precision floating-point value from the second\n   source operand and the first source operand and store the double precision\n   floating-point result in the low doubleword of the destination operand.\n\n   The second source operand can be an XMM register or a 32-bit memory\n   location. The first source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The destination and first source operand are\n   the same. Bits (MAXVL-1:32) of the corresponding destination register\n   remain unchanged.\n\n   VEX.128 and EVEX encoded versions: Bits (127:32) of the XMM register\n   destination are copied from corresponding bits in the first source\n   operand. Bits (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX encoded version: The low doubleword element of the destination\n   operand is updated according to the write-mask.\n\n   Software should ensure VSUBSS is encoded with VEX.L=0. Encoding VSUBSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["palignr", "                          PALIGNR \u2014 Packed Align Right\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Concatenate destination \n   NP 0F 3A 0F /r ib^1                                and source operands,    \n   PALIGNR mm1, mm2/m64,     A     V/V       SSSE3    extract byte-aligned    \n   imm8                                               result shifted to the   \n                                                      right by constant value \n                                                      in imm8 into mm1.       \n                                                      Concatenate destination \n                                                      and source operands,    \n   66 0F 3A 0F /r ib PALIGNR A     V/V       SSSE3    extract byte-aligned    \n   xmm1, xmm2/m128, imm8                              result shifted to the   \n                                                      right by constant value \n                                                      in imm8 into xmm1.      \n                                                      Concatenate xmm2 and    \n                                                      xmm3/m128, extract byte \n   VEX.128.66.0F3A.WIG 0F /r                          aligned result shifted  \n   ib VPALIGNR xmm1, xmm2,   B     V/V       AVX      to the right by         \n   xmm3/m128, imm8                                    constant value in imm8  \n                                                      and result is stored in \n                                                      xmm1.                   \n                                                      Concatenate pairs of 16 \n                                                      bytes in ymm2 and       \n                                                      ymm3/m256 into 32-byte  \n                                                      intermediate result,    \n   VEX.256.66.0F3A.WIG 0F /r                          extract byte-aligned,   \n   ib VPALIGNR ymm1, ymm2,   B     V/V       AVX2     16-byte result shifted  \n   ymm3/m256, imm8                                    to the right by         \n                                                      constant values in imm8 \n                                                      from each intermediate  \n                                                      result, and two 16-byte \n                                                      results are stored in   \n                                                      ymm1.                   \n                                                      Concatenate xmm2 and    \n                                                      xmm3/m128 into a        \n   EVEX.128.66.0F3A.WIG 0F                            32-byte intermediate    \n   /r ib VPALIGNR xmm1                       AVX512VL result, extract byte    \n   {k1}{z}, xmm2, xmm3/m128, C     V/V       AVX512BW aligned result shifted  \n   imm8                                               to the right by         \n                                                      constant value in imm8  \n                                                      and result is stored in \n                                                      xmm1.                   \n                                                      Concatenate pairs of 16 \n                                                      bytes in ymm2 and       \n                                                      ymm3/m256 into 32-byte  \n                                                      intermediate result,    \n   EVEX.256.66.0F3A.WIG 0F                            extract byte-aligned,   \n   /r ib VPALIGNR ymm1       C     V/V       AVX512VL 16-byte result shifted  \n   {k1}{z}, ymm2, ymm3/m256,                 AVX512BW to the right by         \n   imm8                                               constant values in imm8 \n                                                      from each intermediate  \n                                                      result, and two 16-byte \n                                                      results are stored in   \n                                                      ymm1.                   \n                                                      Concatenate pairs of 16 \n                                                      bytes in zmm2 and       \n                                                      zmm3/m512 into 32-byte  \n                                                      intermediate result,    \n   EVEX.512.66.0F3A.WIG 0F                            extract byte-aligned,   \n   /r ib VPALIGNR zmm1       C     V/V       AVX512BW 16-byte result shifted  \n   {k1}{z}, zmm2, zmm3/m512,                          to the right by         \n   imm8                                               constant values in imm8 \n                                                      from each intermediate  \n                                                      result, and four        \n                                                      16-byte results are     \n                                                      stored in zmm1.         \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   (V)PALIGNR concatenates the destination operand (the first operand) and\n   the source operand (the second operand) into an intermediate composite,\n   shifts the composite at byte granularity to the right by a constant\n   immediate, and extracts the right-aligned result into the destination. The\n   first and the second operands can be an MMX, XMM or a YMM register. The\n   immediate value is considered unsigned. Immediate shift counts larger than\n   the 2L (i.e., 32 for 128-bit operands, or 16 for 64-bit operands) produce\n   a zero result. Both operands can be MMX registers, XMM registers or YMM\n   registers. When the source operand is a 128-bit memory operand, the\n   operand must be aligned on a 16-byte boundary or a general-protection\n   exception (#GP) will be generated.\n\n   In 64-bit mode and not encoded by VEX/EVEX prefix, use the REX prefix to\n   access additional registers.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   EVEX.512 encoded version: The first source operand is a ZMM register and\n   contains four 16-byte blocks. The second source operand is a ZMM register\n   or a 512-bit memory location containing four 16-byte block. The\n   destination operand is a ZMM register and contain four 16-byte results.\n   The imm8[7:0] is the common shift count\n\n   used for each of the four successive 16-byte block sources. The low\n   16-byte block of the two source operands produce the low 16-byte result of\n   the destination operand, the high 16-byte block of the two source operands\n   produce the high 16-byte result of the destination operand and so on for\n   the blocks in the middle.\n\n   VEX.256 and EVEX.256 encoded versions: The first source operand is a YMM\n   register and contains two 16-byte blocks. The second source operand is a\n   YMM register or a 256-bit memory location containing two 16-byte block.\n   The destination operand is a YMM register and contain two 16-byte results.\n   The imm8[7:0] is the common shift count used for the two lower 16-byte\n   block sources and the two upper 16-byte block sources. The low 16-byte\n   block of the two source operands produce the low 16-byte result of the\n   destination operand, the high 16-byte block of the two source operands\n   produce the high 16-byte result of the destination operand. The upper bits\n   (MAXVL-1:256) of the corresponding ZMM register destination are zeroed.\n\n   VEX.128 and EVEX.128 encoded versions: The first source operand is an XMM\n   register. The second source operand is an XMM register or 128-bit memory\n   location. The destination operand is an XMM register. The upper bits\n   (MAXVL-1:128) of the corresponding ZMM register destination are zeroed.\n\n   Concatenation is done with 128-bit data in the first and second source\n   operand for both 128-bit and 256-bit instructions. The high 128-bits of\n   the intermediate composite 256-bit result came from the 128-bit data from\n   the first source operand; the low 128-bits of the intermediate result came\n   from the 128-bit data of the second source operand.\n\n   0 127 0 127\n\n   SRC1 SRC2 Imm8[7:0]*8 128 255 128 255 SRC1 SRC2 Imm8[7:0]*8 128 127 0 255\n   DEST DEST Figure 4-7. 256-bit VPALIGN Instruction Operation\n"],
	["vgetmantss", " VGETMANTSS \u2014 Extract Float32 Vector of Normalized Mantissa From Float32 Scalar\n\n                                 64/32 Bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Extract the normalized     \n                                                   mantissa from the low      \n                                                   float32 element of         \n   EVEX.LLIG.66.0F3A.W0 27                         xmm3/m32 using imm8 for    \n   /r ib VGETMANTSS xmm1   A     V/V       AVX512F sign control and mantissa  \n   {k1}{z}, xmm2,                                  interval normalization,    \n   xmm3/m32{sae}, imm8                             store the mantissa to xmm1 \n                                                   under the writemask k1 and \n                                                   merge with the other       \n                                                   elements of xmm2.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Convert the single-precision floating values in the low doubleword element\n   of the second source operand (the third operand) to single-precision\n   floating-point value with the mantissa normalization and sign control\n   specified by the imm8 byte, see Figure 5-15. The converted result is\n   written to the low doubleword element of the destination operand (the\n   first operand) using writemask k1. Bits (127:32) of the XMM register\n   destination are copied from corresponding bits in the first source\n   operand. The normalized mantissa is specified by interv (imm8[1:0]) and\n   the sign control (sc) is specified by bits 3:2 of the immediate byte.\n\n   The conversion operation is:\n\n   GetMant(x) = \u00b12^k|x.significand|\n\n   where:\n\n   1 <= |x.significand| < 2\n\n   Unbiased exponent k can be either 0 or -1, depending on the interval range\n   defined by interv, the range of the significand and whether the exponent\n   of the source is even or odd. The sign of the final result is determined\n   by sc and the source sign. The encoded value of imm8[1:0] and sign control\n   are shown in Figure 5-15.\n\n   The converted single-precision floating-point result is encoded according\n   to the sign control, the unbiased exponent k (adding bias) and a mantissa\n   normalized to the range specified by interv.\n\n   The GetMant() function follows Table 5-18 when dealing with floating-point\n   special numbers.\n\n   If writemasking is used, the low doubleword element of the destination\n   operand is conditionally updated depending on the value of writemask\n   register k1. If writemasking is not used, the low doubleword element of\n   the destination operand is unconditionally updated.\n"],
	["pmaxsb:pmaxsw:pmaxsd:pmaxsq", "        PMAXSB/PMAXSW/PMAXSD/PMAXSQ \u2014 Maximum of Packed Signed Integers\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature  Description\n                                 Support   Flag     \n                                                    Compare signed word       \n   NP 0F EE /r^1 PMAXSW     A    V/V       SSE      integers in mm2/m64 and   \n   mm1, mm2/m64                                     mm1 and return maximum    \n                                                    values.                   \n                                                    Compare packed signed     \n   66 0F 38 3C /r PMAXSB                            byte integers in xmm1 and \n   xmm1, xmm2/m128          A    V/V       SSE4_1   xmm2/m128 and store       \n                                                    packed maximum values in  \n                                                    xmm1.                     \n                                                    Compare packed signed     \n   66 0F EE /r PMAXSW xmm1,                         word integers in          \n   xmm2/m128                A    V/V       SSE2     xmm2/m128 and xmm1 and    \n                                                    stores maximum packed     \n                                                    values in xmm1.           \n                                                    Compare packed signed     \n   66 0F 38 3D /r PMAXSD                            dword integers in xmm1    \n   xmm1, xmm2/m128          A    V/V       SSE4_1   and xmm2/m128 and store   \n                                                    packed maximum values in  \n                                                    xmm1.                     \n                                                    Compare packed signed     \n   VEX.128.66.0F38.WIG 3C                           byte integers in xmm2 and \n   /r VPMAXSB xmm1, xmm2,   B    V/V       AVX      xmm3/m128 and store       \n   xmm3/m128                                        packed maximum values in  \n                                                    xmm1.                     \n                                                    Compare packed signed     \n   VEX.128.66.0F.WIG EE /r                          word integers in          \n   VPMAXSW xmm1, xmm2,      B    V/V       AVX      xmm3/m128 and xmm2 and    \n   xmm3/m128                                        store packed maximum      \n                                                    values in xmm1.           \n                                                    Compare packed signed     \n   VEX.128.66.0F38.WIG 3D                           dword integers in xmm2    \n   /r VPMAXSD xmm1, xmm2,   B    V/V       AVX      and xmm3/m128 and store   \n   xmm3/m128                                        packed maximum values in  \n                                                    xmm1.                     \n                                                    Compare packed signed     \n   VEX.256.66.0F38.WIG 3C                           byte integers in ymm2 and \n   /r VPMAXSB ymm1, ymm2,   B    V/V       AVX2     ymm3/m256 and store       \n   ymm3/m256                                        packed maximum values in  \n                                                    ymm1.                     \n                                                    Compare packed signed     \n   VEX.256.66.0F.WIG EE /r                          word integers in          \n   VPMAXSW ymm1, ymm2,      B    V/V       AVX2     ymm3/m256 and ymm2 and    \n   ymm3/m256                                        store packed maximum      \n                                                    values in ymm1.           \n                                                    Compare packed signed     \n   VEX.256.66.0F38.WIG 3D                           dword integers in ymm2    \n   /r VPMAXSD ymm1, ymm2,   B    V/V       AVX2     and ymm3/m256 and store   \n   ymm3/m256                                        packed maximum values in  \n                                                    ymm1.                     \n                                                    Compare packed signed     \n   EVEX.128.66.0F38.WIG 3C                 AVX512VL byte integers in xmm2 and \n   /r VPMAXSB xmm1{k1}{z},  C    V/V       AVX512BW xmm3/m128 and store       \n   xmm2, xmm3/m128                                  packed maximum values in  \n                                                    xmm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.256.66.0F38.WIG 3C                 AVX512VL byte integers in ymm2 and \n   /r VPMAXSB ymm1{k1}{z},  C    V/V       AVX512BW ymm3/m256 and store       \n   ymm2, ymm3/m256                                  packed maximum values in  \n                                                    ymm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.512.66.0F38.WIG 3C                          byte integers in zmm2 and \n   /r VPMAXSB zmm1{k1}{z},  C    V/V       AVX512BW zmm3/m512 and store       \n   zmm2, zmm3/m512                                  packed maximum values in  \n                                                    zmm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.128.66.0F.WIG EE /r                AVX512VL word integers in xmm2 and \n   VPMAXSW xmm1{k1}{z},     C    V/V       AVX512BW xmm3/m128 and store       \n   xmm2, xmm3/m128                                  packed maximum values in  \n                                                    xmm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.256.66.0F.WIG EE /r                AVX512VL word integers in ymm2 and \n   VPMAXSW ymm1{k1}{z},     C    V/V       AVX512BW ymm3/m256 and store       \n   ymm2, ymm3/m256                                  packed maximum values in  \n                                                    ymm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.512.66.0F.WIG EE /r                         word integers in zmm2 and \n   VPMAXSW zmm1{k1}{z},     C    V/V       AVX512BW zmm3/m512 and store       \n   zmm2, zmm3/m512                                  packed maximum values in  \n                                                    zmm1 under writemask k1.  \n                                                    Compare packed signed     \n   EVEX.128.66.0F38.W0 3D                           dword integers in xmm2    \n   /r VPMAXSD xmm1 {k1}{z}, D    V/V       AVX512VL and xmm3/m128/m32bcst and \n   xmm2, xmm3/m128/m32bcst                 AVX512F  store packed maximum      \n                                                    values in xmm1 using      \n                                                    writemask k1.             \n                                                    Compare packed signed     \n   EVEX.256.66.0F38.W0 3D                           dword integers in ymm2    \n   /r VPMAXSD ymm1 {k1}{z}, D    V/V       AVX512VL and ymm3/m256/m32bcst and \n   ymm2, ymm3/m256/m32bcst                 AVX512F  store packed maximum      \n                                                    values in ymm1 using      \n                                                    writemask k1.             \n                                                    Compare packed signed     \n   EVEX.512.66.0F38.W0 3D                           dword integers in zmm2    \n   /r VPMAXSD zmm1 {k1}{z}, D    V/V       AVX512F  and zmm3/m512/m32bcst and \n   zmm2, zmm3/m512/m32bcst                          store packed maximum      \n                                                    values in zmm1 using      \n                                                    writemask k1.             \n                                                    Compare packed signed     \n   EVEX.128.66.0F38.W1 3D                           qword integers in xmm2    \n   /r VPMAXSQ xmm1 {k1}{z}, D    V/V       AVX512VL and xmm3/m128/m64bcst and \n   xmm2, xmm3/m128/m64bcst                 AVX512F  store packed maximum      \n                                                    values in xmm1 using      \n                                                    writemask k1.             \n                                                    Compare packed signed     \n   EVEX.256.66.0F38.W1 3D                           qword integers in ymm2    \n   /r VPMAXSQ ymm1 {k1}{z}, D    V/V       AVX512VL and ymm3/m256/m64bcst and \n   ymm2, ymm3/m256/m64bcst                 AVX512F  store packed maximum      \n                                                    values in ymm1 using      \n                                                    writemask k1.             \n                                                    Compare packed signed     \n   EVEX.512.66.0F38.W1 3D                           qword integers in zmm2    \n   /r VPMAXSQ zmm1 {k1}{z}, D    V/V       AVX512F  and zmm3/m512/m64bcst and \n   zmm2, zmm3/m512/m64bcst                          store packed maximum      \n                                                    values in zmm1 using      \n                                                    writemask k1.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD compare of the packed signed byte, word, dword or qword\n   integers in the second source operand and the first source operand and\n   returns the maximum value for each pair of integers to the destination\n   operand.\n\n   Legacy SSE version PMAXSW: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   XMM registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding YMM destination\n   register remain unchanged.\n\n   VEX.128 encoded version: The first source and destination operands are XMM\n   registers. The second source operand is an XMM register or a 128-bit\n   memory location. Bits (MAXVL-1:128) of the corresponding destination\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand can be an YMM register\n   or a 256-bit memory location. The first source and destination operands\n   are YMM registers. Bits (MAXVL-1:256) of the corresponding destination\n   register are zeroed.\n\n   EVEX encoded VPMAXSD/Q: The first source operand is a ZMM/YMM/XMM\n   register; The second source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location or a 512/256/128-bit vector broadcasted\n   from a 32/64-bit memory location. The destination operand is conditionally\n   updated based on writemask k1.\n\n   EVEX encoded VPMAXSB/W: The first source operand is a ZMM/YMM/XMM\n   register; The second source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location. The destination operand is conditionally\n   updated based on writemask k1.\n"],
	["pmuludq", "             PMULUDQ \u2014 Multiply Packed Unsigned Doubleword Integers\n\n                               64/32 bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature  Description\n                               Support   Flag     \n                                                  Multiply unsigned           \n                                                  doubleword integer in mm1   \n   NP 0F F4 /r^1 PMULUDQ A     V/V       SSE2     by unsigned doubleword      \n   mm1, mm2/m64                                   integer in mm2/m64, and     \n                                                  store the quadword result   \n                                                  in mm1.                     \n                                                  Multiply packed unsigned    \n                                                  doubleword integers in xmm1 \n   66 0F F4 /r PMULUDQ   A     V/V       SSE2     by packed unsigned          \n   xmm1, xmm2/m128                                doubleword integers in      \n                                                  xmm2/m128, and store the    \n                                                  quadword results in xmm1.   \n                                                  Multiply packed unsigned    \n   VEX.128.66.0F.WIG F4                           doubleword integers in xmm2 \n   /r VPMULUDQ xmm1,     B     V/V       AVX      by packed unsigned          \n   xmm2, xmm3/m128                                doubleword integers in      \n                                                  xmm3/m128, and store the    \n                                                  quadword results in xmm1.   \n                                                  Multiply packed unsigned    \n   VEX.256.66.0F.WIG F4                           doubleword integers in ymm2 \n   /r VPMULUDQ ymm1,     B     V/V       AVX2     by packed unsigned          \n   ymm2, ymm3/m256                                doubleword integers in      \n                                                  ymm3/m256, and store the    \n                                                  quadword results in ymm1.   \n                                                  Multiply packed unsigned    \n   EVEX.128.66.0F.W1 F4                           doubleword integers in xmm2 \n   /r VPMULUDQ xmm1                      AVX512VL by packed unsigned          \n   {k1}{z}, xmm2,        C     V/V       AVX512F  doubleword integers in      \n   xmm3/m128/m64bcst                              xmm3/m128/m64bcst, and      \n                                                  store the quadword results  \n                                                  in xmm1 under writemask k1. \n                                                  Multiply packed unsigned    \n   EVEX.256.66.0F.W1 F4                           doubleword integers in ymm2 \n   /r VPMULUDQ ymm1                      AVX512VL by packed unsigned          \n   {k1}{z}, ymm2,        C     V/V       AVX512F  doubleword integers in      \n   ymm3/m256/m64bcst                              ymm3/m256/m64bcst, and      \n                                                  store the quadword results  \n                                                  in ymm1 under writemask k1. \n                                                  Multiply packed unsigned    \n   EVEX.512.66.0F.W1 F4                           doubleword integers in zmm2 \n   /r VPMULUDQ zmm1                               by packed unsigned          \n   {k1}{z}, zmm2,        C     V/V       AVX512F  doubleword integers in      \n   zmm3/m512/m64bcst                              zmm3/m512/m64bcst, and      \n                                                  store the quadword results  \n                                                  in zmm1 under writemask k1. \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Multiplies the first operand (destination operand) by the second operand\n   (source operand) and stores the result in the destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The source operand can be an unsigned\n   doubleword integer stored in the low doubleword of an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   unsigned doubleword integer stored in the low doubleword an MMX technology\n   register. The result is an unsigned\n\n   quadword integer stored in the destination an MMX technology register.\n   When a quadword result is too large to be represented in 64 bits\n   (overflow), the result is wrapped around and the low 64 bits are written\n   to the destination element (that is, the carry is ignored).\n\n   For 64-bit memory operands, 64 bits are fetched from memory, but only the\n   low doubleword is used in the computation.\n\n   128-bit Legacy SSE version: The second source operand is two packed\n   unsigned doubleword integers stored in the first (low) and third\n   doublewords of an XMM register or a 128-bit memory location. For 128-bit\n   memory operands, 128 bits are fetched from memory, but only the first and\n   third doublewords are used in the computation. The first source operand is\n   two packed unsigned doubleword integers stored in the first and third\n   doublewords of an XMM register. The destination contains two packed\n   unsigned quadword integers stored in an XMM register. Bits (MAXVL-1:128)\n   of the corresponding YMM destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand is two packed unsigned\n   doubleword integers stored in the first (low) and third doublewords of an\n   XMM register or a 128-bit memory location. For 128-bit memory operands,\n   128 bits are fetched from memory, but only the first and third doublewords\n   are used in the computation. The first source operand is two packed\n   unsigned doubleword integers stored in the first and third doublewords of\n   an XMM register. The destination contains two packed unsigned quadword\n   integers stored in an XMM register. Bits (MAXVL-1:128) of the destination\n   YMM register are zeroed.\n\n   VEX.256 encoded version: The second source operand is four packed unsigned\n   doubleword integers stored in the first (low), third, fifth, and seventh\n   doublewords of a YMM register or a 256-bit memory location. For 256-bit\n   memory operands, 256 bits are fetched from memory, but only the first,\n   third, fifth, and seventh doublewords are used in the computation. The\n   first source operand is four packed unsigned doubleword integers stored in\n   the first, third, fifth, and seventh doublewords of an YMM register. The\n   destination contains four packed unaligned quadword integers stored in an\n   YMM register.\n\n   EVEX encoded version: The input unsigned doubleword integers are taken\n   from the even-numbered elements of the source operands. The first source\n   operand is a ZMM/YMM/XMM registers. The second source operand can be an\n   ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination is a ZMM/YMM/XMM register, and updated according to the\n   writemask at 64-bit granularity.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["lahf", "                   LAHF \u2014 Load Status Flags Into AH Register\n\n   Opcode  En Mode Leg Mode Description                               \n   9F                       Load: AH := EFLAGS(SF:ZF:0:AF:0:PF:1:CF). \n\n   1. Valid in specific steppings; see Description section.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   This instruction executes as described above in compatibility mode and\n   legacy mode. It is valid in 64-bit mode only if\n   CPUID.80000001H:ECX.LAHF-SAHF[bit 0] = 1.\n\nFlags Affected \u00b6\n\n   None. The state of the flags in the EFLAGS register is not affected.\n"],
	["vcvtsi2sh", "   VCVTSI2SH \u2014 Convert a Signed Doubleword/Quadword Integer to an FP16 Value\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En Bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Convert the signed  \n                                                          doubleword integer  \n   EVEX.LLIG.F3.MAP5.W0 2A /r                             in r32/m32 to an    \n   VCVTSI2SH xmm1, xmm2, r32/m32    A V/V^1   AVX512-FP16 FP16 value and      \n   {er}                                                   store the result in \n                                                          xmm1. Bits 127:16   \n                                                          of xmm2 are copied  \n                                                          to xmm1[127:16].    \n                                                          Convert the signed  \n                                                          quadword integer in \n   EVEX.LLIG.F3.MAP5.W1 2A /r                             r64/m64 to an FP16  \n   VCVTSI2SH xmm1, xmm2, r64/m64    A V/N.E.  AVX512-FP16 value and store the \n   {er}                                                   result in xmm1.     \n                                                          Bits 127:16 of xmm2 \n                                                          are copied to       \n                                                          xmm1[127:16].       \n\n     1. Outside of 64b mode, the EVEX.W field is ignored. The instruction\n     behaves as if W=0 was used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction converts a signed doubleword integer (or signed quadword\n   integer if operand size is 64 bits) in the second source operand to an\n   FP16 value in the destination operand. The result is stored in the low\n   word of the destination operand. When conversion is inexact, the value\n   returned is rounded according to the rounding control bits in the MXCSR\n   register or embedded rounding controls.\n\n   The second source operand can be a general-purpose register or a 32/64-bit\n   memory location. The first source and destination operands are XMM\n   registers. Bits 127:16 of the XMM register destination are copied from\n   corresponding bits in the first source operand. Bits MAXVL-1:128 of the\n   destination register are zeroed.\n\n   If the result of the convert operation is overflow and MXCSR.OM=0 then a\n   SIMD exception will be raised with OE=1, PE=1.\n"],
	["fxtract", "                   FXTRACT \u2014 Extract Exponent and Significand\n\n   Opcode/Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Separate value in ST(0)     \n                                                  into exponent and           \n   D9 F4 FXTRACT      Valid       Valid           significand, store exponent \n                                                  in ST(0), and push the      \n                                                  significand onto the        \n                                                  register stack.             \n\nDescription \u00b6\n\n   Separates the source value in the ST(0) register into its exponent and\n   significand, stores the exponent in ST(0), and pushes the significand onto\n   the register stack. Following this operation, the new top-of-stack\n   register ST(0) contains the value of the original significand expressed as\n   a floating-point value. The sign and significand of this value are the\n   same as those found in the source operand, and the exponent is 3FFFH\n   (biased value for a true exponent of zero). The ST(1) register contains\n   the value of the original operand\u2019s true (unbiased) exponent expressed as\n   a floating-point value. (The operation performed by this instruction is a\n   superset of the IEEE-recommended logb(x) function.)\n\n   This instruction and the F2XM1 instruction are useful for performing power\n   and range scaling operations. The FXTRACT instruction is also useful for\n   converting numbers in double extended-precision floating-point format to\n   decimal representations (e.g., for printing or displaying).\n\n   If the floating-point zero-divide exception (#Z) is masked and the source\n   operand is zero, an exponent value of \u2013\u221e is stored in register ST(1) and 0\n   with the sign of the source operand is stored in register ST(0).\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred; set to 1 if stack         \n              overflow occurred.                                              \n   C0, C2, C3 Undefined.                                                      \n"],
	["vpexpandq", "       VPEXPANDQ \u2014 Load Sparse Packed Quadword Integer Values From Dense\n                                Memory/Register\n\n                                   64/32 bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n   EVEX.128.66.0F38.W1 89 /r                          Expand packed quad-word \n   VPEXPANDQ xmm1 {k1}{z},   A     V/V       AVX512VL integer values from     \n   xmm2/m128                                 AVX512F  xmm2/m128 to xmm1 using \n                                                      writemask k1.           \n   EVEX.256.66.0F38.W1 89 /r                          Expand packed quad-word \n   VPEXPANDQ ymm1 {k1}{z},   A     V/V       AVX512VL integer values from     \n   ymm2/m256                                 AVX512F  ymm2/m256 to ymm1 using \n                                                      writemask k1.           \n   EVEX.512.66.0F38.W1 89 /r                          Expand packed quad-word \n   VPEXPANDQ zmm1 {k1}{z},   A     V/V       AVX512F  integer values from     \n   zmm2/m512                                          zmm2/m512 to zmm1 using \n                                                      writemask k1.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Expand (load) up to 8 quadword integer values from the source operand (the\n   second operand) to sparse elements in the destination operand (the first\n   operand), selected by the writemask k1. The destination operand is a ZMM\n   register, the source operand can be a ZMM register or memory location.\n\n   The input vector starts from the lowest element in the source operand. The\n   opmask register k1 selects the destination elements (a partial vector or\n   sparse elements if less than 8 elements) to be replaced by the ascending\n   elements in the input vector. Destination elements not selected by the\n   writemask k1 are either unmodified or zeroed, depending on EVEX.z.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n\n   Note that the compressed displacement assumes a pre-scaling (N)\n   corresponding to the size of one single element instead of the size of the\n   full vector.\n"],
	["mov-1", "                      MOV \u2014 Move to/from Control Registers\n\n   Opcode/Instruction       Op/En 64-Bit Compat/Leg Description               \n                                  Mode   Mode       \n   0F 20/r MOV r32, CR0\u2013CR7 MR    N.E.   Valid      Move control register to  \n                                                    r32.                      \n   0F 20/r MOV r64, CR0\u2013CR7 MR    Valid  N.E.       Move extended control     \n                                                    register to r64.          \n   REX.R + 0F 20 /0 MOV     MR    Valid  N.E.       Move extended CR8 to      \n   r64, CR8                                         r64.^1                    \n   0F 22 /r MOV CR0\u2013CR7,    RM    N.E.   Valid      Move r32 to control       \n   r32                                              register.                 \n   0F 22 /r MOV CR0\u2013CR7,    RM    Valid  N.E.       Move r64 to extended      \n   r64                                              control register.         \n   REX.R + 0F 22 /0 MOV     RM    Valid  N.E.       Move r64 to extended      \n   CR8, r64                                         CR8.^1                    \n\n     1. MOV CR* instructions, except for MOV CR8, are serializing\n     instructions. MOV CR8 is not architecturally defined as a serializing\n     instruction. For more information, see Chapter 9 in the Intel^\u00ae 64 and\n     IA-32 Architectures Software Developer\u2019s Manual, Volume 3A.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) N/A       N/A       \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Moves the contents of a control register (CR0, CR2, CR3, CR4, or CR8) to a\n   general-purpose register or the contents of a general-purpose register to\n   a control register. The operand size for these instructions is always 32\n   bits in non-64-bit modes, regardless of the operand-size attribute. On a\n   64-bit capable processor, an execution of MOV to CR outside of 64-bit mode\n   zeros the upper 32 bits of the control register. (See \u201cControl Registers\u201d\n   in Chapter 2 of the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 3A, for a detailed description of the flags and\n   fields in the control registers.) This instruction can be executed only\n   when the current privilege level is 0.\n\n   At the opcode level, the reg field within the ModR/M byte specifies which\n   of the control registers is loaded or read. The 2 bits in the mod field\n   are ignored. The r/m field specifies the general-purpose register loaded\n   or read. Some of the bits in CR0, CR3, and CR4 are reserved and must be\n   written with zeros. Attempting to set any reserved bits in CR0[31:0] is\n   ignored. Attempting to set any reserved bits in CR0[63:32] results in a\n   general-protection exception, #GP(0). When PCIDs are not enabled, bits 2:0\n   and bits 11:5 of CR3 are not used and attempts to set them are ignored.\n   Attempting to set any reserved bits in CR3[63:MAXPHYADDR] results in\n   #GP(0). Attempting to set any reserved bits in CR4 results in #GP(0). On\n   Pentium 4, Intel Xeon and P6 family processors, CR0.ET remains set after\n   any load of CR0; attempts to clear this bit have no impact.\n\n   In certain cases, these instructions have the side effect of invalidating\n   entries in the TLBs and the paging-structure caches. See Section 4.10.4.1,\n   \u201cOperations that Invalidate TLBs and Paging-Structure Caches,\u201d in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 3A,\n   for details.\n\n   The following side effects are implementation-specific for the Pentium 4,\n   Intel Xeon, and P6 processor family: when modifying PE or PG in register\n   CR0, or PSE or PAE in register CR4, all TLB entries are flushed, including\n   global entries. Software should not depend on this functionality in all\n   Intel 64 or IA-32 processors.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 64 bits. The\n   REX.R prefix must be used to access CR8. Use of REX.B permits access to\n   additional registers (R8-R15). Use of the REX.W prefix or 66H prefix is\n   ignored. Use\n\n   of the REX.R prefix to specify a register other than CR8 causes an\n   invalid-opcode exception. See the summary chart at the beginning of this\n   section for encoding data and limits.\n\n   If CR4.PCIDE = 1, bit 63 of the source operand to MOV to CR3 determines\n   whether the instruction invalidates entries in the TLBs and the\n   paging-structure caches (see Section 4.10.4.1, \u201cOperations that Invalidate\n   TLBs and Paging-Structure Caches,\u201d in the Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3A). The instruction\n   does not modify bit 63 of CR3, which is reserved and always 0.\n\n   See \u201cChanges to Instruction Behavior in VMX Non-Root Operation\u201d in Chapter\n   26 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3C, for more information about the behavior of this instruction in\n   VMX non-root operation.\n\nFlags Affected \u00b6\n\n   The OF, SF, ZF, AF, PF, and CF flags are undefined.\n"],
	["psubb:psubw:psubd", "                  PSUBB/PSUBW/PSUBD \u2014 Subtract Packed Integers\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Subtract packed byte      \n   NP 0F F8 /r^1 PSUBB mm, A     V/V       MMX      integers in mm/m64 from   \n   mm/m64                                           packed byte integers in   \n                                                    mm.                       \n                                                    Subtract packed byte      \n   66 0F F8 /r PSUBB xmm1, A     V/V       SSE2     integers in xmm2/m128     \n   xmm2/m128                                        from packed byte integers \n                                                    in xmm1.                  \n                                                    Subtract packed word      \n   NP 0F F9 /r^1 PSUBW mm, A     V/V       MMX      integers in mm/m64 from   \n   mm/m64                                           packed word integers in   \n                                                    mm.                       \n                                                    Subtract packed word      \n   66 0F F9 /r PSUBW xmm1, A     V/V       SSE2     integers in xmm2/m128     \n   xmm2/m128                                        from packed word integers \n                                                    in xmm1.                  \n                                                    Subtract packed           \n   NP 0F FA /r^1 PSUBD mm,                          doubleword integers in    \n   mm/m64                  A     V/V       MMX      mm/m64 from packed        \n                                                    doubleword integers in    \n                                                    mm.                       \n                                                    Subtract packed           \n   66 0F FA /r PSUBD xmm1,                          doubleword integers in    \n   xmm2/m128               A     V/V       SSE2     xmm2/mem128 from packed   \n                                                    doubleword integers in    \n                                                    xmm1.                     \n   VEX.128.66.0F.WIG F8 /r                          Subtract packed byte      \n   VPSUBB xmm1, xmm2,      B     V/V       AVX      integers in xmm3/m128     \n   xmm3/m128                                        from xmm2.                \n   VEX.128.66.0F.WIG F9 /r                          Subtract packed word      \n   VPSUBW xmm1, xmm2,      B     V/V       AVX      integers in xmm3/m128     \n   xmm3/m128                                        from xmm2.                \n   VEX.128.66.0F.WIG FA /r                          Subtract packed           \n   VPSUBD xmm1, xmm2,      B     V/V       AVX      doubleword integers in    \n   xmm3/m128                                        xmm3/m128 from xmm2.      \n   VEX.256.66.0F.WIG F8 /r                          Subtract packed byte      \n   VPSUBB ymm1, ymm2,      B     V/V       AVX2     integers in ymm3/m256     \n   ymm3/m256                                        from ymm2.                \n   VEX.256.66.0F.WIG F9 /r                          Subtract packed word      \n   VPSUBW ymm1, ymm2,      B     V/V       AVX2     integers in ymm3/m256     \n   ymm3/m256                                        from ymm2.                \n   VEX.256.66.0F.WIG FA /r                          Subtract packed           \n   VPSUBD ymm1, ymm2,      B     V/V       AVX2     doubleword integers in    \n   ymm3/m256                                        ymm3/m256 from ymm2.      \n   EVEX.128.66.0F.WIG F8                            Subtract packed byte      \n   /r VPSUBB xmm1 {k1}{z}, C     V/V       AVX512VL integers in xmm3/m128     \n   xmm2, xmm3/m128                         AVX512BW from xmm2 and store in    \n                                                    xmm1 using writemask k1.  \n   EVEX.256.66.0F.WIG F8                            Subtract packed byte      \n   /r VPSUBB ymm1 {k1}{z}, C     V/V       AVX512VL integers in ymm3/m256     \n   ymm2, ymm3/m256                         AVX512BW from ymm2 and store in    \n                                                    ymm1 using writemask k1.  \n   EVEX.512.66.0F.WIG F8                            Subtract packed byte      \n   /r VPSUBB zmm1 {k1}{z}, C     V/V       AVX512BW integers in zmm3/m512     \n   zmm2, zmm3/m512                                  from zmm2 and store in    \n                                                    zmm1 using writemask k1.  \n   EVEX.128.66.0F.WIG F9                            Subtract packed word      \n   /r VPSUBW xmm1 {k1}{z}, C     V/V       AVX512VL integers in xmm3/m128     \n   xmm2, xmm3/m128                         AVX512BW from xmm2 and store in    \n                                                    xmm1 using writemask k1.  \n   EVEX.256.66.0F.WIG F9                            Subtract packed word      \n   /r VPSUBW ymm1 {k1}{z}, C     V/V       AVX512VL integers in ymm3/m256     \n   ymm2, ymm3/m256                         AVX512BW from ymm2 and store in    \n                                                    ymm1 using writemask k1.  \n   EVEX.512.66.0F.WIG F9                            Subtract packed word      \n   /r VPSUBW zmm1 {k1}{z}, C     V/V       AVX512BW integers in zmm3/m512     \n   zmm2, zmm3/m512                                  from zmm2 and store in    \n                                                    zmm1 using writemask k1.  \n                                                    Subtract packed           \n   EVEX.128.66.0F.W0 FA /r                 AVX512VL doubleword integers in    \n   VPSUBD xmm1 {k1}{z},    D     V/V       AVX512F  xmm3/m128/m32bcst from    \n   xmm2, xmm3/m128/m32bcst                          xmm2 and store in xmm1    \n                                                    using writemask k1.       \n                                                    Subtract packed           \n   EVEX.256.66.0F.W0 FA /r                 AVX512VL doubleword integers in    \n   VPSUBD ymm1 {k1}{z},    D     V/V       AVX512F  ymm3/m256/m32bcst from    \n   ymm2, ymm3/m256/m32bcst                          ymm2 and store in ymm1    \n                                                    using writemask k1.       \n                                                    Subtract packed           \n   EVEX.512.66.0F.W0 FA /r                          doubleword integers in    \n   VPSUBD zmm1 {k1}{z},    D     V/V       AVX512F  zmm3/m512/m32bcst from    \n   zmm2, zmm3/m512/m32bcst                          zmm2 and store in zmm1    \n                                                    using writemask k1        \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD subtract of the packed integers of the source operand\n   (second operand) from the packed integers of the destination operand\n   (first operand), and stores the packed integer results in the destination\n   operand. See Figure 9-4 in the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1, for an illustration of a SIMD operation.\n   Overflow is handled with wraparound, as described in the following\n   paragraphs.\n\n   The (V)PSUBB instruction subtracts packed byte integers. When an\n   individual result is too large or too small to be represented in a byte,\n   the result is wrapped around and the low 8 bits are written to the\n   destination element.\n\n   The (V)PSUBW instruction subtracts packed word integers. When an\n   individual result is too large or too small to be represented in a word,\n   the result is wrapped around and the low 16 bits are written to the\n   destination element.\n\n   The (V)PSUBD instruction subtracts packed doubleword integers. When an\n   individual result is too large or too small to be represented in a\n   doubleword, the result is wrapped around and the low 32 bits are written\n   to the destination element.\n\n   Note that the (V)PSUBB, (V)PSUBW, and (V)PSUBD instructions can operate on\n   either unsigned or signed (two's complement notation) packed integers;\n   however, it does not set bits in the EFLAGS register to indicate overflow\n   and/or a carry. To prevent undetected overflow conditions, software must\n   control the ranges of values upon which it operates.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE version 64-bit operand: The destination operand must be an MMX\n   technology register and the source operand can be either an MMX technology\n   register or a 64-bit memory location.\n\n   128-bit Legacy SSE version: The second source operand is an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand is an XMM register or a\n   128-bit memory location. The first source operand and destination operands\n   are XMM registers. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded versions: The second source operand is an YMM register or\n   an 256-bit memory location. The first source operand and destination\n   operands are YMM registers. Bits (MAXVL-1:256) of the corresponding ZMM\n   register are zeroed.\n\n   EVEX encoded VPSUBD: The second source operand is a ZMM/YMM/XMM register,\n   a 512/256/128-bit memory location or a 512/256/128-bit vector broadcasted\n   from a 32/64-bit memory location. The first source operand and destination\n   operands are ZMM/YMM/XMM registers. The destination is conditionally\n   updated with writemask k1.\n\n   EVEX encoded VPSUBB/W: The second source operand is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location. The first source operand and\n   destination operands are ZMM/YMM/XMM registers. The destination is\n   conditionally updated with writemask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["sha256msg1", "   SHA256MSG1 \u2014 Perform an Intermediate Calculation for the Next Four SHA256\n                                 MessageDwords\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Description\n                            Support   Flag    \n                                              Performs an intermediate        \n   NP 0F 38 CC /r                             calculation for the next four   \n   SHA256MSG1 xmm1,   RM    V/V       SHA     SHA256 message dwords using     \n   xmm2/m128                                  previous message dwords from    \n                                              xmm1 and xmm2/m128, storing the \n                                              result in xmm1.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   The SHA256MSG1 instruction is one of two SHA256 message scheduling\n   instructions. The instruction performs an intermediate calculation for the\n   next four SHA256 message dwords.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["addss", "           ADDSS \u2014 Add Scalar Single Precision Floating-Point Values\n\n                            Op / 64/32 bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Add the low single         \n   F3 0F 58 /r ADDSS xmm1,                         precision floating-point   \n   xmm2/m32                 A    V/V       SSE     value from xmm2/mem to     \n                                                   xmm1 and store the result  \n                                                   in xmm1.                   \n                                                   Add the low single         \n   VEX.LIG.F3.0F.WIG 58 /r                         precision floating-point   \n   VADDSS xmm1,xmm2,        B    V/V       AVX     value from xmm3/mem to     \n   xmm3/m32                                        xmm2 and store the result  \n                                                   in xmm1.                   \n                                                   Add the low single         \n   EVEX.LLIG.F3.0F.W0 58 /r                        precision floating-point   \n   VADDSS xmm1{k1}{z},      C    V/V       AVX512F value from xmm3/m32 to     \n   xmm2, xmm3/m32{er}                              xmm2 and store the result  \n                                                   in xmm1with writemask k1.  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds the low single precision floating-point values from the second source\n   operand and the first source operand, and stores the double precision\n   floating-point result in the destination operand.\n\n   The second source operand can be an XMM register or a 64-bit memory\n   location. The first source and destination operands are XMM registers.\n\n   128-bit Legacy SSE version: The first source and destination operands are\n   the same. Bits (MAXVL-1:32) of the corresponding the destination register\n   remain unchanged.\n\n   EVEX and VEX.128 encoded version: The first source operand is encoded by\n   EVEX.vvvv/VEX.vvvv. Bits (127:32) of the XMM register destination are\n   copied from corresponding bits in the first source operand. Bits\n   (MAXVL-1:128) of the destination register are zeroed.\n\n   EVEX version: The low doubleword element of the destination is updated\n   according to the writemask.\n\n   Software should ensure VADDSS is encoded with VEX.L=0. Encoding VADDSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["sahf", "                           SAHF \u2014 Store AH Into Flags\n\n   Opcode^1\n\n      Instruction Op/En 64-Bit Mode Compat/Leg Mode Description               \n                                                    Loads SF, ZF, AF, PF, and \n   9E SAHF        ZO    Invalid*    Valid           CF from AH into the       \n                                                    EFLAGS register.          \n\n     1. Valid in specific steppings. See Description section.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the SF, ZF, AF, PF, and CF flags of the EFLAGS register with values\n   from the corresponding bits in the AH register (bits 7, 6, 4, 2, and 0,\n   respectively). Bits 1, 3, and 5 of register AH are ignored; the\n   corresponding reserved bits (1, 3, and 5) in the EFLAGS register remain as\n   shown in the \u201cOperation\u201d section below.\n\n   This instruction executes as described above in compatibility mode and\n   legacy mode. It is valid in 64-bit mode only if\n   CPUID.80000001H:ECX.LAHF-SAHF[bit 0] = 1.\n\nFlags Affected \u00b6\n\n   The SF, ZF, AF, PF, and CF flags are loaded with values from the AH\n   register. Bits 1, 3, and 5 of the EFLAGS register are unaffected, with the\n   values remaining 1, 0, and 0, respectively.\n"],
	["bound", "                    BOUND \u2014 Check Array Index Against Bounds\n\n   Opcode Instruction Op/En 64-bit Mode Compat/Leg Description                \n                                        Mode       \n          BOUND r16,                               Check if r16 (array index) \n   62 /r  m16&16      RM    Invalid     Valid      is within bounds specified \n                                                   by m16&16.                 \n          BOUND r32,                               Check if r32 (array index) \n   62 /r  m32&32      RM    Invalid     Valid      is within bounds specified \n                                                   by m32&32.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   BOUND determines if the first operand (array index) is within the bounds\n   of an array specified the second operand (bounds operand). The array index\n   is a signed integer located in a register. The bounds operand is a memory\n   location that contains a pair of signed doubleword-integers (when the\n   operand-size attribute is 32) or a pair of signed word-integers (when the\n   operand-size attribute is 16). The first doubleword (or word) is the lower\n   bound of the array and the second doubleword (or word) is the upper bound\n   of the array. The array index must be greater than or equal to the lower\n   bound and less than or equal to the upper bound plus the operand size in\n   bytes. If the index is not within bounds, a BOUND range exceeded exception\n   (#BR) is signaled. When this exception is generated, the saved return\n   instruction pointer points to the BOUND instruction.\n\n   The bounds limit data structure (two words or doublewords containing the\n   lower and upper limits of the array) is usually placed just before the\n   array itself, making the limits addressable via a constant offset from the\n   beginning of the array. Because the address of the array already will be\n   present in a register, this practice avoids extra bus cycles to obtain the\n   effective address of the array bounds.\n\n   This instruction executes as described in compatibility mode and legacy\n   mode. It is not valid in 64-bit mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vmread", "           VMREAD \u2014 Read Field from Virtual-Machine Control Structure\n\n   Opcode/Instruction         Op/En Description                               \n   NP 0F 78 VMREAD r/m64, r64 MR    Reads a specified VMCS field (in 64-bit   \n                                    mode).                                    \n   NP 0F 78 VMREAD r/m32, r32 MR    Reads a specified VMCS field (outside     \n                                    64-bit mode).                             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   MR    ModRM:r/m (w) ModRM:reg (r) NA        NA        \n\nDescription \u00b6\n\n   Reads a specified field from a VMCS and stores it into a specified\n   destination operand (register or memory). In VMX root operation, the\n   instruction reads from the current VMCS. If executed in VMX non-root\n   operation, the instruction reads from the VMCS referenced by the VMCS link\n   pointer field in the current VMCS.\n\n   The VMCS field is specified by the VMCS-field encoding contained in the\n   register source operand. Outside IA-32e mode, the source operand has 32\n   bits, regardless of the value of CS.D. In 64-bit mode, the source operand\n   has 64 bits.\n\n   The effective size of the destination operand, which may be a register or\n   in memory, is always 32 bits outside IA-32e mode (the setting of CS.D is\n   ignored with respect to operand size) and 64 bits in 64-bit mode. If the\n   VMCS field specified by the source operand is shorter than this effective\n   operand size, the high bits of the destination operand are cleared to 0.\n   If the VMCS field is longer, then the high bits of the field are not read.\n\n   Note that any faults resulting from accessing a memory destination operand\n   can occur only after determining, in the operation section below, that the\n   relevant VMCS pointer is valid and that the specified VMCS field is\n   supported.\n\nFlags Affected \u00b6\n\n   See the operation section and Section 31.2.\n"],
	["psrlw:psrld:psrlq", "              PSRLW/PSRLD/PSRLQ \u2014 Shift Packed Data Right Logical\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Shift words in mm right   \n   NP 0F D1 /r^1 PSRLW mm, A     V/V       MMX      by amount specified in    \n   mm/m64                                           mm/m64 while shifting in  \n                                                    0s.                       \n                                                    Shift words in xmm1 right \n   66 0F D1 /r PSRLW xmm1, A     V/V       SSE2     by amount specified in    \n   xmm2/m128                                        xmm2/m128 while shifting  \n                                                    in 0s.                    \n   NP 0F 71 /2 ib^1 PSRLW                           Shift words in mm right   \n   mm, imm8                B     V/V       MMX      by imm8 while shifting in \n                                                    0s.                       \n   66 0F 71 /2 ib PSRLW                             Shift words in xmm1 right \n   xmm1, imm8              B     V/V       SSE2     by imm8 while shifting in \n                                                    0s.                       \n                                                    Shift doublewords in mm   \n   NP 0F D2 /r^1 PSRLD mm, A     V/V       MMX      right by amount specified \n   mm/m64                                           in mm/m64 while shifting  \n                                                    in 0s.                    \n                                                    Shift doublewords in xmm1 \n   66 0F D2 /r PSRLD xmm1, A     V/V       SSE2     right by amount specified \n   xmm2/m128                                        in xmm2 /m128 while       \n                                                    shifting in 0s.           \n   NP 0F 72 /2 ib^1 PSRLD                           Shift doublewords in mm   \n   mm, imm8                B     V/V       MMX      right by imm8 while       \n                                                    shifting in 0s.           \n   66 0F 72 /2 ib PSRLD                             Shift doublewords in xmm1 \n   xmm1, imm8              B     V/V       SSE2     right by imm8 while       \n                                                    shifting in 0s.           \n   NP 0F D3 /r^1 PSRLQ mm,                          Shift mm right by amount  \n   mm/m64                  A     V/V       MMX      specified in mm/m64 while \n                                                    shifting in 0s.           \n                                                    Shift quadwords in xmm1   \n   66 0F D3 /r PSRLQ xmm1, A     V/V       SSE2     right by amount specified \n   xmm2/m128                                        in xmm2/m128 while        \n                                                    shifting in 0s.           \n   NP 0F 73 /2 ib^1 PSRLQ  B     V/V       MMX      Shift mm right by imm8    \n   mm, imm8                                         while shifting in 0s.     \n   66 0F 73 /2 ib PSRLQ                             Shift quadwords in xmm1   \n   xmm1, imm8              B     V/V       SSE2     right by imm8 while       \n                                                    shifting in 0s.           \n   VEX.128.66.0F.WIG D1 /r                          Shift words in xmm2 right \n   VPSRLW xmm1, xmm2,      C     V/V       AVX      by amount specified in    \n   xmm3/m128                                        xmm3/m128 while shifting  \n                                                    in 0s.                    \n   VEX.128.66.0F.WIG 71 /2                          Shift words in xmm2 right \n   ib VPSRLW xmm1, xmm2,   D     V/V       AVX      by imm8 while shifting in \n   imm8                                             0s.                       \n   VEX.128.66.0F.WIG D2 /r                          Shift doublewords in xmm2 \n   VPSRLD xmm1, xmm2,      C     V/V       AVX      right by amount specified \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.128.66.0F.WIG 72 /2                          Shift doublewords in xmm2 \n   ib VPSRLD xmm1, xmm2,   D     V/V       AVX      right by imm8 while       \n   imm8                                             shifting in 0s.           \n   VEX.128.66.0F.WIG D3 /r                          Shift quadwords in xmm2   \n   VPSRLQ xmm1, xmm2,      C     V/V       AVX      right by amount specified \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.128.66.0F.WIG 73 /2                          Shift quadwords in xmm2   \n   ib VPSRLQ xmm1, xmm2,   D     V/V       AVX      right by imm8 while       \n   imm8                                             shifting in 0s.           \n   VEX.256.66.0F.WIG D1 /r                          Shift words in ymm2 right \n   VPSRLW ymm1, ymm2,      C     V/V       AVX2     by amount specified in    \n   xmm3/m128                                        xmm3/m128 while shifting  \n                                                    in 0s.                    \n   VEX.256.66.0F.WIG 71 /2                          Shift words in ymm2 right \n   ib VPSRLW ymm1, ymm2,   D     V/V       AVX2     by imm8 while shifting in \n   imm8                                             0s.                       \n   VEX.256.66.0F.WIG D2 /r                          Shift doublewords in ymm2 \n   VPSRLD ymm1, ymm2,      C     V/V       AVX2     right by amount specified \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.256.66.0F.WIG 72 /2                          Shift doublewords in ymm2 \n   ib VPSRLD ymm1, ymm2,   D     V/V       AVX2     right by imm8 while       \n   imm8                                             shifting in 0s.           \n   VEX.256.66.0F.WIG D3 /r                          Shift quadwords in ymm2   \n   VPSRLQ ymm1, ymm2,      C     V/V       AVX2     right by amount specified \n   xmm3/m128                                        in xmm3/m128 while        \n                                                    shifting in 0s.           \n   VEX.256.66.0F.WIG 73 /2                          Shift quadwords in ymm2   \n   ib VPSRLQ ymm1, ymm2,   D     V/V       AVX2     right by imm8 while       \n   imm8                                             shifting in 0s.           \n   EVEX.128.66.0F.WIG D1                            Shift words in xmm2 right \n   /r VPSRLW xmm1 {k1}{z}, G     V/V       AVX512VL by amount specified in    \n   xmm2, xmm3/m128                         AVX512BW xmm3/m128 while shifting  \n                                                    in 0s using writemask k1. \n   EVEX.256.66.0F.WIG D1                            Shift words in ymm2 right \n   /r VPSRLW ymm1 {k1}{z}, G     V/V       AVX512VL by amount specified in    \n   ymm2, xmm3/m128                         AVX512BW xmm3/m128 while shifting  \n                                                    in 0s using writemask k1. \n   EVEX.512.66.0F.WIG D1                            Shift words in zmm2 right \n   /r VPSRLW zmm1 {k1}{z}, G     V/V       AVX512BW by amount specified in    \n   zmm2, xmm3/m128                                  xmm3/m128 while shifting  \n                                                    in 0s using writemask k1. \n   EVEX.128.66.0F.WIG 71                            Shift words in xmm2/m128  \n   /2 ib VPSRLW xmm1       E     V/V       AVX512VL right by imm8 while       \n   {k1}{z}, xmm2/m128,                     AVX512BW shifting in 0s using      \n   imm8                                             writemask k1.             \n   EVEX.256.66.0F.WIG 71                            Shift words in ymm2/m256  \n   /2 ib VPSRLW ymm1       E     V/V       AVX512VL right by imm8 while       \n   {k1}{z}, ymm2/m256,                     AVX512BW shifting in 0s using      \n   imm8                                             writemask k1.             \n   EVEX.512.66.0F.WIG 71                            Shift words in zmm2/m512  \n   /2 ib VPSRLW zmm1       E     V/V       AVX512BW right by imm8 while       \n   {k1}{z}, zmm2/m512,                              shifting in 0s using      \n   imm8                                             writemask k1.             \n                                                    Shift doublewords in xmm2 \n   EVEX.128.66.0F.W0 D2 /r                 AVX512VL right by amount specified \n   VPSRLD xmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   xmm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift doublewords in ymm2 \n   EVEX.256.66.0F.W0 D2 /r                 AVX512VL right by amount specified \n   VPSRLD ymm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   ymm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift doublewords in zmm2 \n   EVEX.512.66.0F.W0 D2 /r                          right by amount specified \n   VPSRLD zmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   zmm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n   EVEX.128.66.0F.W0 72 /2                          Shift doublewords in      \n   ib VPSRLD xmm1 {k1}{z}, F     V/V       AVX512VL xmm2/m128/m32bcst right   \n   xmm2/m128/m32bcst, imm8                 AVX512F  by imm8 while shifting in \n                                                    0s using writemask k1.    \n   EVEX.256.66.0F.W0 72 /2                          Shift doublewords in      \n   ib VPSRLD ymm1 {k1}{z}, F     V/V       AVX512VL ymm2/m256/m32bcst right   \n   ymm2/m256/m32bcst, imm8                 AVX512F  by imm8 while shifting in \n                                                    0s using writemask k1.    \n   EVEX.512.66.0F.W0 72 /2                          Shift doublewords in      \n   ib VPSRLD zmm1 {k1}{z}, F     V/V       AVX512F  zmm2/m512/m32bcst right   \n   zmm2/m512/m32bcst, imm8                          by imm8 while shifting in \n                                                    0s using writemask k1.    \n                                                    Shift quadwords in xmm2   \n   EVEX.128.66.0F.W1 D3 /r                 AVX512VL right by amount specified \n   VPSRLQ xmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   xmm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift quadwords in ymm2   \n   EVEX.256.66.0F.W1 D3 /r                 AVX512VL right by amount specified \n   VPSRLQ ymm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   ymm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n                                                    Shift quadwords in zmm2   \n   EVEX.512.66.0F.W1 D3 /r                          right by amount specified \n   VPSRLQ zmm1 {k1}{z},    G     V/V       AVX512F  in xmm3/m128 while        \n   zmm2, xmm3/m128                                  shifting in 0s using      \n                                                    writemask k1.             \n   EVEX.128.66.0F.W1 73 /2                          Shift quadwords in        \n   ib VPSRLQ xmm1 {k1}{z}, F     V/V       AVX512VL xmm2/m128/m64bcst right   \n   xmm2/m128/m64bcst, imm8                 AVX512F  by imm8 while shifting in \n                                                    0s using writemask k1.    \n   EVEX.256.66.0F.W1 73 /2                          Shift quadwords in        \n   ib VPSRLQ ymm1 {k1}{z}, F     V/V       AVX512VL ymm2/m256/m64bcst right   \n   ymm2/m256/m64bcst, imm8                 AVX512F  by imm8 while shifting in \n                                                    0s using writemask k1.    \n   EVEX.512.66.0F.W1 73 /2                          Shift quadwords in        \n   ib VPSRLQ zmm1 {k1}{z}, F     V/V       AVX512F  zmm2/m512/m64bcst right   \n   zmm2/m512/m64bcst, imm8                          by imm8 while shifting in \n                                                    0s using writemask k1.    \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:r/m (r, w) imm8          N/A           N/A       \n   C     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   D     N/A        VEX.vvvv (w)     ModRM:r/m (r) imm8          N/A       \n   E     Full Mem   EVEX.vvvv (w)    ModRM:r/m (r) imm8          N/A       \n   F     Full       EVEX.vvvv (w)    ModRM:r/m (r) imm8          N/A       \n   G     Mem128     ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Shifts the bits in the individual data elements (words, doublewords, or\n   quadword) in the destination operand (first operand) to the right by the\n   number of bits specified in the count operand (second operand). As the\n   bits in the data elements are shifted right, the empty high-order bits are\n   cleared (set to 0). If the value specified by the count operand is greater\n   than 15 (for words), 31 (for doublewords), or 63 (for a quadword), then\n   the destination operand is set to all 0s. Figure 4-19 gives an example of\n   shifting words in a 64-bit operand.\n\n   Note that only the low 64-bits of a 128-bit count operand are checked to\n   compute the count.\n\n   Pre-Shift X3 X2 X1 X0 DEST Shift Right with Zero Extension Post-Shift X0\n   >> COUNT X3 >> COUNT X2 >> COUNT X1 >> COUNT DEST Figure 4-19. PSRLW,\n   PSRLD, and PSRLQ Instruction Operation Using 64-bit Operand\n\n   The (V)PSRLW instruction shifts each of the words in the destination\n   operand to the right by the number of bits specified in the count operand;\n   the (V)PSRLD instruction shifts each of the doublewords in the destination\n   operand; and the PSRLQ instruction shifts the quadword (or quadwords) in\n   the destination operand.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instruction 64-bit operand: The destination operand is an MMX\n   technology register; the count operand can be either an MMX technology\n   register or an 64-bit memory location.\n\n   128-bit Legacy SSE version: The destination operand is an XMM register;\n   the count operand can be either an XMM register or a 128-bit memory\n   location, or an 8-bit immediate. If the count operand is a memory address,\n   128 bits are loaded but the upper 64 bits are ignored. Bits (MAXVL-1:128)\n   of the corresponding YMM destination register remain unchanged.\n\n   VEX.128 encoded version: The destination operand is an XMM register; the\n   count operand can be either an XMM register or a 128-bit memory location,\n   or an 8-bit immediate. If the count operand is a memory address, 128 bits\n   are loaded but the upper 64 bits are ignored. Bits (MAXVL-1:128) of the\n   destination YMM register are zeroed.\n\n   VEX.256 encoded version: The destination operand is a YMM register. The\n   source operand is a YMM register or a memory location. The count operand\n   can come either from an XMM register or a memory location or an 8-bit\n   immediate. Bits (MAXVL-1:256) of the corresponding ZMM register are\n   zeroed.\n\n   EVEX encoded versions: The destination operand is a ZMM register updated\n   according to the writemask. The count operand is either an 8-bit immediate\n   (the immediate count version) or an 8-bit value from an XMM register or a\n   memory location (the variable count version). For the immediate count\n   version, the source operand (the second operand) can be a ZMM register, a\n   512-bit memory location or a 512-bit vector broadcasted from a 32/64-bit\n   memory location. For the variable count version, the first source operand\n   (the second operand) is a ZMM register, the second source operand (the\n   third operand, 8-bit variable count) can be an XMM register or a memory\n   location.\n\n   Note: In VEX/EVEX encoded versions of shifts with an immediate count, vvvv\n   of VEX/EVEX encode the destination register, and VEX.B/EVEX.B + ModRM.r/m\n   encodes the source register.\n\n   Note: For shifts with an immediate count (VEX.128.66.0F 71-73 /2, or\n   EVEX.128.66.0F 71-73 /2), VEX.vvvv/EVEX.vvvv encodes the destination\n   register.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vfmsub132ph:vfnmsub132ph:vfmsub213ph:vfnmsub213ph:vfmsub231ph:vfnmsub231ph", "  VFMSUB132PH/VFNMSUB132PH/VFMSUB213PH/VFNMSUB213PH/VFMSUB231PH/VFNMSUB231PH \u2014\n                 Fused Multiply-Subtract of Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit    \n   Mode Flag Support 64/32 CPUID \n   Feature Instruction En Bit    \n   Mode Flag CPUID Feature       \n   Instruction En Bit Mode Flag  \n   Op/ 64/32 CPUID Feature         Support             Description\n   Instruction En Bit Mode Flag  \n   64/32 CPUID Feature           \n   Instruction En Bit Mode Flag  \n   CPUID Feature Instruction En  \n   Bit Mode Flag Op/ 64/32 CPUID \n   Feature                       \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 9A /r               AVX512-FP16 xmm3/m128/m16bcst,     \n   VFMSUB132PH xmm1{k1}{z},      A V/V     AVX512VL    subtract xmm2, and     \n   xmm2, xmm3/m128/m16bcst                             store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 9A /r               AVX512-FP16 ymm3/m256/m16bcst,     \n   VFMSUB132PH ymm1{k1}{z},      A V/V     AVX512VL    subtract ymm2, and     \n   ymm2, ymm3/m256/m16bcst                             store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 9A /r                           zmm3/m512/m16bcst,     \n   VFMSUB132PH zmm1{k1}{z},      A V/V     AVX512-FP16 subtract zmm2, and     \n   zmm2, zmm3/m512/m16bcst {er}                        store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n   EVEX.128.66.MAP6.W0 AA /r               AVX512-FP16 xmm2, subtract         \n   VFMSUB213PH xmm1{k1}{z},      A V/V     AVX512VL    xmm3/m128/m16bcst, and \n   xmm2, xmm3/m128/m16bcst                             store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n   EVEX.256.66.MAP6.W0 AA /r               AVX512-FP16 ymm2, subtract         \n   VFMSUB213PH ymm1{k1}{z},      A V/V     AVX512VL    ymm3/m256/m16bcst, and \n   ymm2, ymm3/m256/m16bcst                             store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n   EVEX.512.66.MAP6.W0 AA /r                           zmm2, subtract         \n   VFMSUB213PH zmm1{k1}{z},      A V/V     AVX512-FP16 zmm3/m512/m16bcst, and \n   zmm2, zmm3/m512/m16bcst {er}                        store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from xmm2 and   \n   EVEX.128.66.MAP6.W0 BA /r               AVX512-FP16 xmm3/m128/m16bcst,     \n   VFMSUB231PH xmm1{k1}{z},      A V/V     AVX512VL    subtract xmm1, and     \n   xmm2, xmm3/m128/m16bcst                             store the result in    \n                                                       xmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from ymm2 and   \n   EVEX.256.66.MAP6.W0 BA /r               AVX512-FP16 ymm3/m256/m16bcst,     \n   VFMSUB231PH ymm1{k1}{z},      A V/V     AVX512VL    subtract ymm1, and     \n   ymm2, ymm3/m256/m16bcst                             store the result in    \n                                                       ymm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from zmm2 and   \n   EVEX.512.66.MAP6.W0 BA /r                           zmm3/m512/m16bcst,     \n   VFMSUB231PH zmm1{k1}{z},      A V/V     AVX512-FP16 subtract zmm1, and     \n   zmm2, zmm3/m512/m16bcst {er}                        store the result in    \n                                                       zmm1 subject to        \n                                                       writemask k1.          \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n                                                       xmm3/m128/m16bcst, and \n   EVEX.128.66.MAP6.W0 9E /r               AVX512-FP16 negate the value.      \n   VFNMSUB132PH xmm1{k1}{z},     A V/V     AVX512VL    Subtract xmm2 from     \n   xmm2, xmm3/m128/m16bcst                             this value, and store  \n                                                       the result in xmm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n                                                       ymm3/m256/m16bcst, and \n   EVEX.256.66.MAP6.W0 9E /r               AVX512-FP16 negate the value.      \n   VFNMSUB132PH ymm1{k1}{z},     A V/V     AVX512VL    Subtract ymm2 from     \n   ymm2, ymm3/m256/m16bcst                             this value, and store  \n                                                       the result in ymm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n                                                       zmm3/m512/m16bcst, and \n   EVEX.512.66.MAP6.W0 9E /r                           negate the value.      \n   VFNMSUB132PH zmm1{k1}{z},     A V/V     AVX512-FP16 Subtract zmm2 from     \n   zmm2, zmm3/m512/m16bcst {er}                        this value, and store  \n                                                       the result in zmm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from xmm1 and   \n                                                       xmm2, and negate the   \n   EVEX.128.66.MAP6.W0 AE /r               AVX512-FP16 value. Subtract        \n   VFNMSUB213PH xmm1{k1}{z},     A V/V     AVX512VL    xmm3/m128/m16bcst from \n   xmm2, xmm3/m128/m16bcst                             this value, and store  \n                                                       the result in xmm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from ymm1 and   \n                                                       ymm2, and negate the   \n   EVEX.256.66.MAP6.W0 AE /r               AVX512-FP16 value. Subtract        \n   VFNMSUB213PH ymm1{k1}{z},     A V/V     AVX512VL    ymm3/m256/m16bcst from \n   ymm2, ymm3/m256/m16bcst                             this value, and store  \n                                                       the result in ymm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from zmm1 and   \n                                                       zmm2, and negate the   \n   EVEX.512.66.MAP6.W0 AE /r                           value. Subtract        \n   VFNMSUB213PH zmm1{k1}{z},     A V/V     AVX512-FP16 zmm3/m512/m16bcst from \n   zmm2, zmm3/m512/m16bcst {er}                        this value, and store  \n                                                       the result in zmm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from xmm2 and   \n                                                       xmm3/m128/m16bcst, and \n   EVEX.128.66.MAP6.W0 BE /r               AVX512-FP16 negate the value.      \n   VFNMSUB231PH xmm1{k1}{z},     A V/V     AVX512VL    Subtract xmm1 from     \n   xmm2, xmm3/m128/m16bcst                             this value, and store  \n                                                       the result in xmm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from ymm2 and   \n                                                       ymm3/m256/m16bcst, and \n   EVEX.256.66.MAP6.W0 BE /r               AVX512-FP16 negate the value.      \n   VFNMSUB231PH ymm1{k1}{z},     A V/V     AVX512VL    Subtract ymm1 from     \n   ymm2, ymm3/m256/m16bcst                             this value, and store  \n                                                       the result in ymm1     \n                                                       subject to writemask   \n                                                       k1.                    \n                                                       Multiply packed FP16   \n                                                       values from zmm2 and   \n                                                       zmm3/m512/m16bcst, and \n   EVEX.512.66.MAP6.W0 BE /r                           negate the value.      \n   VFNMSUB231PH zmm1{k1}{z},     A V/V     AVX512-FP16 Subtract zmm1 from     \n   zmm2, zmm3/m512/m16bcst {er}                        this value, and store  \n                                                       the result in zmm1     \n                                                       subject to writemask   \n                                                       k1.                    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1        Operand 2    Operand 3     Operand 4 \n   A     Full  ModRM:reg (r, w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a packed multiply-subtract or a negated\n   multiply-subtract computation on FP16 values using three source operands\n   and writes the results in the destination operand. The destination operand\n   is also the first source operand. The \u201cN\u201d (negated) forms of this\n   instruction subtract the remaining operand from the negated infinite\n   precision intermediate product. The notation\u2019 \u201c132\u201d, \u201c213\u201d and \u201c231\u201d\n   indicate the use of the operands in \u00b1A * B \u2212 C, where each digit\n   corresponds to the operand number, with the destination being operand 1;\n   see Table 5-6.\n\n   The destination elements are updated according to the writemask.\n\n   Notation Operands                \n   132      dest = \u00b1 dest*src3-src2 \n   231      dest = \u00b1 src2*src3-dest \n   213      dest = \u00b1 src2*dest-src3 \n\n   Table 5-6. VF[,N]MSUB[132,213,231]PH Notation for Operands\n"],
	["edbgrd", "                       EDBGRD \u2014 Read From a Debug Enclave\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   This leaf function reads a \n   EAX = 04H ENCLS[EDBGRD] IR    V/V       SGX1    dword/quadword from a      \n                                                   debug enclave.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                      RBX                 RCX                     \n   IR    EDBGRD (In) Return error Data read from a    Address of source       \n                     code (Out)   debug enclave (Out) memory in the EPC (In)  \n\n  Description \u00b6\n\n   This leaf function copies a quadword/doubleword from an EPC page belonging\n   to a debug enclave into the RBX register. Eight bytes are read in 64-bit\n   mode, four bytes are read in non-64-bit modes. The size of data read\n   cannot be overridden.\n\n   The effective address of the source location inside the EPC is provided in\n   the register RCX.\n\nEDBGRD Memory Parameter Semantics \u00b6\n\n   EPCQW                            \n   Read access permitted by Enclave \n\n   The error codes are:\n\n   Error Code (see Table 38-4) Description                                    \n   No Error                    EDBGRD successful.                             \n   SGX_PAGE_NOT_DEBUGGABLE     The EPC page cannot be accessed because it is  \n                               in the PENDING or MODIFIED state.              \n\n   Table 38-17. EDBGRD Return Value in RAX\n\n   The instruction faults if any of the following:\n\nEDBGRD Faulting Conditions \u00b6\n\n   RCX points into a page that is RCX does not resolve to a naturally aligned \n   an SECS.                       linear address.                             \n   RCX points to a page that does RCX points to a location inside a TCS that  \n   not belong to an enclave that  is beyond the architectural size of the TCS \n   is in debug mode.              (SGX_TCS_LIMIT).                            \n   An operand causing any segment May page fault.                             \n   violation.                     \n   CPL > 0.                       \n\n   This instruction ignores the EPCM RWX attributes on the enclave page.\n   Consequently, violation of EPCM RWX attributes via EDBGRD does not result\n   in a #GP.\n\n  Concurrency Restrictions \u00b6\n\n   Leaf                         Parameter       Base Concurrency Restrictions\n                                                       On Conflict      \n   EDBGRD EDBGRD Target                         \n   [DS:RCX] Shared EDBGRD       Target [DS:RCX]\n   Target [DS:RCX]              \n\n   Table 38-18. Base Concurrency Restrictions of EDBGRD\n\n                    Additional Concurrency Restrictions\n                    vs. EACCEPT, EACCEPTCOPY, vs.  vs. EADD,                 \n                    EADD, EEXTEND, EINIT vs.       EEXTEND, EINIT            \n                    ETRACK, ETRACKC Access vs.     vs. EADD,      vs. ETRACK,\n                    ETRACK, ETRACKC Access On      EEXTEND, EINIT ETRACKC\n   Leaf   Parameter Conflict Access vs. ETRACK,    vs. ETRACK,  \n                    ETRACKC Access On Conflict     ETRACKC      \n                    EMODPE, EMODPR, EMODT       \n                    Access On Conflict Access   \n                    On Conflict Access Access   \n                    On Conflict Access On       \n                    Conflict                    \n   EDBGRD Target    Concurrent                     Concurrent     Concurrent \n          [DS:RCX]  \n\n   Table 38-19. Additional Concurrency Restrictions of EDBGRD\n\n  Flags Affected \u00b6\n\n   ZF is set if the page is MODIFIED or PENDING; RAX contains the error code.\n   Otherwise ZF is cleared and RAX is set to 0. CF, PF, AF, OF, SF are\n   cleared.\n"],
	["cmpss", "          CMPSS \u2014 Compare Scalar Single Precision Floating-Point Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Compare low single          \n   F3 0F C2 /r ib CMPSS                           precision floating-point    \n   xmm1, xmm2/m32, imm8    A    V/V       SSE     value in xmm2/m32 and xmm1  \n                                                  using bits 2:0 of imm8 as   \n                                                  comparison predicate.       \n                                                  Compare low single          \n   VEX.LIG.F3.0F.WIG C2 /r                        precision floating-point    \n   ib VCMPSS xmm1, xmm2,   B    V/V       AVX     value in xmm3/m32 and xmm2  \n   xmm3/m32, imm8                                 using bits 4:0 of imm8 as   \n                                                  comparison predicate.       \n                                                  Compare low single          \n   EVEX.LLIG.F3.0F.W0 C2                          precision floating-point    \n   /r ib VCMPSS k1 {k2},                          value in xmm3/m32 and xmm2  \n   xmm2, xmm3/m32{sae},    C    V/V       AVX512F using bits 4:0 of imm8 as   \n   imm8                                           comparison predicate with   \n                                                  writemask k2 and leave the  \n                                                  result in mask register k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Compares the low single precision floating-point values in the second\n   source operand and the first source operand and returns the result of the\n   comparison to the destination operand. The comparison predicate operand\n   (immediate operand) specifies the type of comparison performed.\n\n   128-bit Legacy SSE version: The first source and destination operand\n   (first operand) is an XMM register. The second source operand (second\n   operand) can be an XMM register or 32-bit memory location. Bits\n   (MAXVL-1:32) of the corresponding YMM destination register remain\n   unchanged. The comparison result is a doubleword mask of all 1s\n   (comparison true) or all 0s (comparison false).\n\n   VEX.128 encoded version: The first source operand (second operand) is an\n   XMM register. The second source operand (third operand) can be an XMM\n   register or a 32-bit memory location. The result is stored in the low 32\n   bits of the destination operand; bits 127:32 of the destination operand\n   are copied from the first source operand. Bits (MAXVL-1:128) of the\n   destination ZMM register are zeroed. The comparison result is a doubleword\n   mask of all 1s (comparison true) or all 0s (comparison false).\n\n   EVEX encoded version: The first source operand (second operand) is an XMM\n   register. The second source operand can be a XMM register or a 32-bit\n   memory location. The destination operand (first operand) is an opmask\n   register. The comparison result is a single mask bit of 1 (comparison\n   true) or 0 (comparison false), written to the destination starting from\n   the LSB according to the writemask k2. Bits (MAX_KL-1:128) of the\n   destination register are cleared.\n\n   The comparison predicate operand is an 8-bit immediate:\n\n     * For instructions encoded using the VEX prefix, bits 4:0 define the\n       type of comparison to be performed (see Table 3-1). Bits 5 through 7\n       of the immediate are reserved.\n     * For instruction encodings that do not use VEX prefix, bits 2:0 define\n       the type of comparison to be made (see the first 8 rows of Table 3-1).\n       Bits 3 through 7 of the immediate are reserved.\n\n   The unordered relationship is true when at least one of the two source\n   operands being compared is a NaN; the ordered relationship is true when\n   neither source operand is a NaN.\n\n   A subsequent computational instruction that uses the mask result in the\n   destination operand as an input operand will not generate an exception,\n   because a mask of all 0s corresponds to a floating-point value of +0.0 and\n   a mask of all 1s corresponds to a QNaN.\n\n   Note that processors with \u201cCPUID.1H:ECX.AVX =0\u201d do not implement the\n   \u201cgreater-than\u201d, \u201cgreater-than-or-equal\u201d, \u201cnot-greater than\u201d, and\n   \u201cnot-greater-than-or-equal relations\u201d predicates. These comparisons can be\n   made either by using the inverse relationship (that is, use the\n   \u201cnot-less-than-or-equal\u201d to make a \u201cgreater-than\u201d comparison) or by using\n   software emulation. When using software emulation, the program must swap\n   the operands (copying registers when necessary to protect the data that\n   will now be in the destination), and then perform the compare using a\n   different predicate. The predicate to be used for these emulations is\n   listed in the first 8 rows of Table 3-7 (Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 2A) under the heading\n   Emulation.\n\n   Compilers and assemblers may implement the following two-operand\n   pseudo-ops in addition to the three-operand CMPSS instruction, for\n   processors with \u201cCPUID.1H:ECX.AVX =0\u201d. See Table 3-8. The compiler should\n   treat reserved imm8 values as illegal syntax.\n\n   Pseudo-Op             CMPSS Implementation \n   CMPEQSS xmm1, xmm2    CMPSS xmm1, xmm2, 0  \n   CMPLTSS xmm1, xmm2    CMPSS xmm1, xmm2, 1  \n   CMPLESS xmm1, xmm2    CMPSS xmm1, xmm2, 2  \n   CMPUNORDSS xmm1, xmm2 CMPSS xmm1, xmm2, 3  \n   CMPNEQSS xmm1, xmm2   CMPSS xmm1, xmm2, 4  \n   CMPNLTSS xmm1, xmm2   CMPSS xmm1, xmm2, 5  \n   CMPNLESS xmm1, xmm2   CMPSS xmm1, xmm2, 6  \n   CMPORDSS xmm1, xmm2   CMPSS xmm1, xmm2, 7  \n\n   Table 3-8. Pseudo-Op and CMPSS Implementation\n\n   The greater-than relations that the processor does not implement require\n   more than one instruction to emulate in software and therefore should not\n   be implemented as pseudo-ops. (For these, the programmer should reverse\n   the operands of the corresponding less than relations and use move\n   instructions to ensure that the mask is moved to the correct destination\n   register and that the source operand is left intact.)\n\n   Processors with \u201cCPUID.1H:ECX.AVX =1\u201d implement the full complement of 32\n   predicates shown in Table 3-7, software emulation is no longer needed.\n   Compilers and assemblers may implement the following three-operand\n   pseudo-ops in addition to the four-operand VCMPSS instruction. See Table\n   3-9, where the notations of reg1 reg2, and reg3 represent either XMM\n   registers or YMM registers. The compiler should treat reserved imm8 values\n   as illegal syntax. Alternately, intrinsics can map the pseudo-ops to\n   pre-defined constants to support a simpler intrinsic interface. Compilers\n   and assemblers may implement three-operand pseudo-ops for EVEX encoded\n   VCMPSS instructions in a similar fashion by extending the syntax listed in\n   Table 3-9.\n\n   Pseudo-Op                    CMPSS Implementation         \n   VCMPEQSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 0   \n   VCMPLTSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 1   \n   VCMPLESS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 2   \n   VCMPUNORDSS reg1, reg2, reg3 VCMPSS reg1, reg2, reg3, 3   \n   VCMPNEQSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 4   \n   VCMPNLTSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 5   \n   VCMPNLESS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 6   \n   VCMPORDSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 7   \n   VCMPEQ_UQSS reg1, reg2, reg3 VCMPSS reg1, reg2, reg3, 8   \n   VCMPNGESS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 9   \n   VCMPNGTSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 0AH \n   VCMPFALSESS reg1, reg2, reg3 VCMPSS reg1, reg2, reg3, 0BH \n\n   Table 3-9. Pseudo-Op and VCMPSS Implementation\n\n   Pseudo-Op                       CMPSS Implementation         \n   VCMPNEQ_OQSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 0CH \n   VCMPGESS reg1, reg2, reg3       VCMPSS reg1, reg2, reg3, 0DH \n   VCMPGTSS reg1, reg2, reg3       VCMPSS reg1, reg2, reg3, 0EH \n   VCMPTRUESS reg1, reg2, reg3     VCMPSS reg1, reg2, reg3, 0FH \n   VCMPEQ_OSSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 10H \n   VCMPLT_OQSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 11H \n   VCMPLE_OQSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 12H \n   VCMPUNORD_SSS reg1, reg2, reg3  VCMPSS reg1, reg2, reg3, 13H \n   VCMPNEQ_USSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 14H \n   VCMPNLT_UQSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 15H \n   VCMPNLE_UQSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 16H \n   VCMPORD_SSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 17H \n   VCMPEQ_USSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 18H \n   VCMPNGE_UQSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 19H \n   VCMPNGT_UQSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 1AH \n   VCMPFALSE_OSSS reg1, reg2, reg3 VCMPSS reg1, reg2, reg3, 1BH \n   VCMPNEQ_OSSS reg1, reg2, reg3   VCMPSS reg1, reg2, reg3, 1CH \n   VCMPGE_OQSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 1DH \n   VCMPGT_OQSS reg1, reg2, reg3    VCMPSS reg1, reg2, reg3, 1EH \n   VCMPTRUE_USSS reg1, reg2, reg3  VCMPSS reg1, reg2, reg3, 1FH \n\n   Table 3-9. Pseudo-Op and VCMPSS Implementation\n\n   Software should ensure VCMPSS is encoded with VEX.L=0. Encoding VCMPSS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["addps", "           ADDPS \u2014 Add Packed Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Add packed single          \n   NP 0F 58 /r ADDPS xmm1,                         precision floating-point   \n   xmm2/m128               A    V/V       SSE      values from xmm2/m128 to   \n                                                   xmm1 and store result in   \n                                                   xmm1.                      \n                                                   Add packed single          \n   VEX.128.0F.WIG 58 /r                            precision floating-point   \n   VADDPS xmm1,xmm2,       B    V/V       AVX      values from xmm3/m128 to   \n   xmm3/m128                                       xmm2 and store result in   \n                                                   xmm1.                      \n                                                   Add packed single          \n   VEX.256.0F.WIG 58 /r                            precision floating-point   \n   VADDPS ymm1, ymm2,      B    V/V       AVX      values from ymm3/m256 to   \n   ymm3/m256                                       ymm2 and store result in   \n                                                   ymm1.                      \n                                                   Add packed single          \n   EVEX.128.0F.W0 58 /r                            precision floating-point   \n   VADDPS xmm1 {k1}{z},    C    V/V       AVX512VL values from                \n   xmm2, xmm3/m128/m32bcst                AVX512F  xmm3/m128/m32bcst to xmm2  \n                                                   and store result in xmm1   \n                                                   with writemask k1.         \n                                                   Add packed single          \n   EVEX.256.0F.W0 58 /r                            precision floating-point   \n   VADDPS ymm1 {k1}{z},    C    V/V       AVX512VL values from                \n   ymm2, ymm3/m256/m32bcst                AVX512F  ymm3/m256/m32bcst to ymm2  \n                                                   and store result in ymm1   \n                                                   with writemask k1.         \n                                                   Add packed single          \n   EVEX.512.0F.W0 58 /r                            precision floating-point   \n   VADDPS zmm1 {k1}{z},    C    V/V       AVX512F  values from                \n   zmm2, zmm3/m512/m32bcst                         zmm3/m512/m32bcst to zmm2  \n   {er}                                            and store result in zmm1   \n                                                   with writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Adds four, eight or sixteen packed single precision floating-point values\n   from the first source operand with the second source operand, and stores\n   the packed single precision floating-point result in the destination\n   operand.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand can be a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location or a 512/256/128-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM/YMM/XMM register\n   conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. The upper bits (MAXVL-1:256) of\n   the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: the first source operand is a XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper Bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["vcvtsh2usi", "            VCVTSH2USI \u2014 Convert Low FP16 Value to Unsigned Integer\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode     \n   Flag Support 64/32 CPUID Feature    \n   Instruction En Bit Mode Flag CPUID  \n   Feature Instruction En Bit Mode     \n   Flag Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag 64/32  \n   CPUID Feature Instruction En Bit    \n   Mode Flag CPUID Feature Instruction \n   En Bit Mode Flag Op/ 64/32 CPUID    \n   Feature                             \n                                                             Convert the low  \n                                                             FP16 element in  \n   EVEX.LLIG.F3.MAP5.W0 79 /r          A V/V^1   AVX512-FP16 xmm1/m16 to an   \n   VCVTSH2USI r32, xmm1/m16 {er}                             unsigned integer \n                                                             and store the    \n                                                             result in r32.   \n                                                             Convert the low  \n                                                             FP16 element in  \n   EVEX.LLIG.F3.MAP5.W1 79 /r          A V/N.E.  AVX512-FP16 xmm1/m16 to an   \n   VCVTSH2USI r64, xmm1/m16 {er}                             unsigned integer \n                                                             and store the    \n                                                             result in r64.   \n\n     1. Outside of 64b mode, the EVEX.W field is ignored. The instruction\n     behaves as if W=0 was used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP16 element in the source operand to an\n   unsigned integer in the destination general purpose register.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer indefinite value is returned.\n"],
	["invd", "                       INVD \u2014 Invalidate Internal Caches\n\n   Opcode^1\n\n         Instruction Op/En 64-Bit Mode Compat/Leg Mode Description            \n                                                       Flush internal caches; \n   0F 08 INVD        ZO    Valid       Valid           initiate flushing of   \n                                                       external caches.       \n\n     1. See the IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Invalidates (flushes) the processor\u2019s internal caches and issues a\n   special-function bus cycle that directs external caches to also flush\n   themselves. Data held in internal caches is not written back to main\n   memory.\n\n   After executing this instruction, the processor does not wait for the\n   external caches to complete their flushing operation before proceeding\n   with instruction execution. It is the responsibility of hardware to\n   respond to the cache flush signal.\n\n   The INVD instruction is a privileged instruction. When the processor is\n   running in protected mode, the CPL of a program or procedure must be 0 to\n   execute this instruction.\n\n   The INVD instruction may be used when the cache is used as temporary\n   memory and the cache contents need to be invalidated rather than written\n   back to memory. When the cache is used as temporary memory, no external\n   device should be actively writing data to main memory.\n\n   Use this instruction with care. Data cached internally and not written\n   back to main memory will be lost. Note that any data from an external\n   device to main memory (for example, via a PCIWrite) can be temporarily\n   stored in the caches; these data can be lost when an INVD instruction is\n   executed. Unless there is a specific requirement or benefit to flushing\n   caches without writing back modified cache lines (for example, temporary\n   memory, testing, or fault recovery where cache coherency with main memory\n   is not a concern), software should instead use the WBINVD instruction.\n\n   On processors that support processor reserved memory, the INVD instruction\n   cannot be executed when processor reserved memory protections are\n   activated. See Section 36.5, \u201cEPC and Management of EPC Pages,\u201d in the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 3D.\n\n   Some processors prevent execution of INVD after BIOS execution is\n   complete. They report this by enumerating CPUID.(EAX=07H,ECX=1H):EAX[bit\n   30] as 1. On such processors, INVD cannot be executed if bit 0 of\n   SR_BIOS_DONE (MSR address 151H) is 1.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The INVD instruction is implementation dependent; it may be implemented\n   differently on different families of Intel 64 or IA-32 processors. This\n   instruction is not supported on IA-32 processors earlier than the Intel486\n   processor.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["das", "                   DAS \u2014 Decimal Adjust AL After Subtraction\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n   2F     DAS         ZO    Invalid     Valid           Decimal adjust AL     \n                                                        after subtraction.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Adjusts the result of the subtraction of two packed BCD values to create a\n   packed BCD result. The AL register is the implied source and destination\n   operand. The DAS instruction is only useful when it follows a SUB\n   instruction that subtracts (binary subtraction) one 2-digit, packed BCD\n   value from another and stores a byte result in the AL register. The DAS\n   instruction then adjusts the contents of the AL register to contain the\n   correct 2-digit, packed BCD result. If a decimal borrow is detected, the\n   CF and AF flags are set accordingly.\n\n   This instruction executes as described above in compatibility mode and\n   legacy mode. It is not valid in 64-bit mode.\n\nExample \u00b6\n\n   SUB AL, BL Before: AL = 35H, BL = 47H, EFLAGS(OSZAPC) = XXXXXX\n\n   After: AL = EEH, BL = 47H, EFLAGS(0SZAPC) = 010111\n\n   DAA Before: AL = EEH, BL = 47H, EFLAGS(OSZAPC) = 010111\n\n   After: AL = 88H, BL = 47H, EFLAGS(0SZAPC) = X10111\n\nFlags Affected \u00b6\n\n   The CF and AF flags are set if the adjustment of the value results in a\n   decimal borrow in either digit of the result (see the \u201cOperation\u201d section\n   above). The SF, ZF, and PF flags are set according to the result. The OF\n   flag is undefined.\n"],
	["vcvtuqq2ps", "    VCVTUQQ2PS \u2014 Convert Packed Unsigned Quadword Integers to Packed Single\n                         PrecisionFloating-Point Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     unsigned quadword        \n   EVEX.128.F2.0F.W1 7A /r                  AVX512VL integers from            \n   VCVTUQQ2PS xmm1 {k1}{z}, A     V/V       AVX512DQ xmm2/m128/m64bcst to     \n   xmm2/m128/m64bcst                                 packed single precision  \n                                                     floating-point values in \n                                                     zmm1 with writemask k1.  \n                                                     Convert four packed      \n                                                     unsigned quadword        \n   EVEX.256.F2.0F.W1 7A /r                  AVX512VL integers from            \n   VCVTUQQ2PS xmm1 {k1}{z}, A     V/V       AVX512DQ ymm2/m256/m64bcst to     \n   ymm2/m256/m64bcst                                 packed single precision  \n                                                     floating-point values in \n                                                     xmm1 with writemask k1.  \n                                                     Convert eight packed     \n                                                     unsigned quadword        \n   EVEX.512.F2.0F.W1 7A /r                           integers from            \n   VCVTUQQ2PS ymm1 {k1}{z}, A     V/V       AVX512DQ zmm2/m512/m64bcst to     \n   zmm2/m512/m64bcst{er}                             eight packed single      \n                                                     precision floating-point \n                                                     values in zmm1 with      \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts packed unsigned quadword integers in the source operand (second\n   operand) to single precision floating-point values in the destination\n   operand (first operand).\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register or a\n   512/256/128-bit memory location. The destination operand is a YMM/XMM/XMM\n   (low 64 bits) register conditionally updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b, otherwise instructions will\n   #UD.\n"],
	["pshufb", "                         PSHUFB \u2014 Packed Shuffle Bytes\n\n                                    64/32 bit CPUID                           \n   Opcode/Instruction         Op/En Mode      Feature  Description\n                                    Support   Flag     \n   NP 0F 38 00 /r^1 PSHUFB                             Shuffle bytes in mm1   \n   mm1, mm2/m64               A     V/V       SSSE3    according to contents  \n                                                       of mm2/m64.            \n   66 0F 38 00 /r PSHUFB                               Shuffle bytes in xmm1  \n   xmm1, xmm2/m128            A     V/V       SSSE3    according to contents  \n                                                       of xmm2/m128.          \n   VEX.128.66.0F38.WIG 00 /r                           Shuffle bytes in xmm2  \n   VPSHUFB xmm1, xmm2,        B     V/V       AVX      according to contents  \n   xmm3/m128                                           of xmm3/m128.          \n   VEX.256.66.0F38.WIG 00 /r                           Shuffle bytes in ymm2  \n   VPSHUFB ymm1, ymm2,        B     V/V       AVX2     according to contents  \n   ymm3/m256                                           of ymm3/m256.          \n   EVEX.128.66.0F38.WIG 00 /r                          Shuffle bytes in xmm2  \n   VPSHUFB xmm1 {k1}{z},      C     V/V       AVX512VL according to contents  \n   xmm2, xmm3/m128                            AVX512BW of xmm3/m128 under     \n                                                       write mask k1.         \n   EVEX.256.66.0F38.WIG 00 /r                          Shuffle bytes in ymm2  \n   VPSHUFB ymm1 {k1}{z},      C     V/V       AVX512VL according to contents  \n   ymm2, ymm3/m256                            AVX512BW of ymm3/m256 under     \n                                                       write mask k1.         \n   EVEX.512.66.0F38.WIG 00 /r                          Shuffle bytes in zmm2  \n   VPSHUFB zmm1 {k1}{z},      C     V/V       AVX512BW according to contents  \n   zmm2, zmm3/m512                                     of zmm3/m512 under     \n                                                       write mask k1.         \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   PSHUFB performs in-place shuffles of bytes in the destination operand (the\n   first operand) according to the shuffle control mask in the source operand\n   (the second operand). The instruction permutes the data in the destination\n   operand, leaving the shuffle mask unaffected. If the most significant bit\n   (bit[7]) of each byte of the shuffle control mask is set, then constant\n   zero is written in the result byte. Each byte in the shuffle control mask\n   forms an index to permute the corresponding byte in the destination\n   operand. The value of each index is the least significant 4 bits (128-bit\n   operation) or 3 bits (64-bit operation) of the shuffle control byte. When\n   the source operand is a 128-bit memory operand, the operand must be\n   aligned on a 16-byte boundary or a general-protection exception (#GP) will\n   be generated.\n\n   In 64-bit mode and not encoded with VEX/EVEX, use the REX prefix to access\n   XMM8-XMM15 registers.\n\n   Legacy SSE version 64-bit operand: Both operands can be MMX registers.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand are the same. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: The destination operand is the first operand, the\n   first source operand is the second operand, the second source operand is\n   the third operand. Bits (MAXVL-1:128) of the destination YMM register are\n   zeroed.\n\n   VEX.256 encoded version: Bits (255:128) of the destination YMM register\n   stores the 16-byte shuffle result of the upper 16 bytes of the first\n   source operand, using the upper 16-bytes of the second source operand as\n   control mask.\n\n   The value of each index is for the high 128-bit lane is the least\n   significant 4 bits of the respective shuffle control byte. The index value\n   selects a source data element within each 128-bit lane.\n\n   EVEX encoded version: The second source operand is an ZMM/YMM/XMM register\n   or an 512/256/128-bit memory location. The first source operand and\n   destination operands are ZMM/YMM/XMM registers. The destination is\n   conditionally updated with writemask k1.\n\n   EVEX and VEX encoded version: Four/two in-lane 128-bit shuffles.\n"],
	["fprem1", "                           FPREM1 \u2014 Partial Remainder\n\n   Opcode Instruction 64-Bit Mode Compat/Leg Mode Description                 \n                                                  Replace ST(0) with the IEEE \n   D9 F5  FPREM1      Valid       Valid           remainder obtained from     \n                                                  dividing ST(0) by ST(1).    \n\nDescription \u00b6\n\n   Computes the IEEE remainder obtained from dividing the value in the ST(0)\n   register (the dividend) by the value in the ST(1) register (the divisor or\n   modulus), and stores the result in ST(0). The remainder represents the\n   following value:\n\n   Remainder := ST(0) \u2212 (Q \u2217 ST(1))\n\n   Here, Q is an integer value that is obtained by rounding the\n   floating-point number quotient of [ST(0) / ST(1)] toward the nearest\n   integer value. The magnitude of the remainder is less than or equal to\n   half the magnitude of the modulus, unless a partial remainder was computed\n   (as described below).\n\n   This instruction produces an exact result; the precision (inexact)\n   exception does not occur and the rounding control has no effect. The\n   following table shows the results obtained when computing the remainder of\n   various classes of numbers, assuming that underflow does not occur.\n\n   ST(1) \n             \u2212\u221e    \u2212F         \u22120  +0  +F         +\u221e    NaN \n         \u2212\u221e  *     *          *   *   *          *     NaN \n         \u2212F  ST(0) \u00b1F or \u22120   *   *   \u00b1 F or \u2212 0 ST(0) NaN \n   ST(0) \u22120  \u22120    \u22120         *   *   \u22120         -0    NaN \n         +0  +0    +0         *   *   +0         +0    NaN \n         +F  ST(0) \u00b1 F or + 0 *   *   \u00b1 F or + 0 ST(0) NaN \n         +\u221e  *     *          *   *   *          *     NaN \n         NaN NaN   NaN        NaN NaN NaN        NaN   NaN \n\n   Table 3-32. FPREM1 Results\n\n     F Means finite floating-point value.\n\n     * Indicatesfloating-pointinvalid-arithmetic-operand(#IA)exception.\n\n   When the result is 0, its sign is the same as that of the dividend. When\n   the modulus is \u221e, the result is equal to the value in ST(0).\n\n   The FPREM1 instruction computes the remainder specified in IEEE Standard\n   754. This instruction operates differently from the FPREM instruction in\n   the way that it rounds the quotient of ST(0) divided by ST(1) to an\n   integer (see the \u201cOperation\u201d section below).\n\n   Like the FPREM instruction, FPREM1 computes the remainder through\n   iterative subtraction, but can reduce the exponent of ST(0) by no more\n   than 63 in one execution of the instruction. If the instruction succeeds\n   in producing a remainder that is less than one half the modulus, the\n   operation is complete and the C2 flag in the FPU status word is cleared.\n   Otherwise, C2 is set, and the result in ST(0) is called the partial\n   remainder. The exponent of the partial remainder will be less than the\n   exponent of the original dividend by at least 32. Software can re-execute\n   the instruction (using the partial remainder in ST(0) as the dividend)\n   until C2 is cleared. (Note that while executing such a\n   remainder-computation loop, a higher-priority interrupting routine that\n   needs the FPU can force a context switch in-between the instructions in\n   the loop.)\n\n   An important use of the FPREM1 instruction is to reduce the arguments of\n   periodic functions. When reduction is complete, the instruction stores the\n   three least-significant bits of the quotient in the C3, C1, and C0 flags\n   of the FPU status word. This information is important in argument\n   reduction for the tangent function (using a modulus of \u03c0/4), because it\n   locates the original angle in the correct one of eight sectors of the unit\n   circle.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C0 Set to bit 2 (Q2) of the quotient.                                      \n   C1 Set to 0 if stack underflow occurred; otherwise, set to least           \n      significant bit of quotient (Q0).                                       \n   C2 Set to 0 if reduction complete; set to 1 if incomplete.                 \n   C3 Set to bit 1 (Q1) of the quotient.                                      \n"],
	["comiss", " COMISS \u2014 Compare Scalar Ordered Single Precision Floating-Point Values and Set\n                                     EFLAGS\n\n                          Op / 64/32 bit CPUID                                \n   Opcode/Instruction     En   Mode      Feature Description\n                               Support   Flag    \n                                                 Compare low single precision \n   NP 0F 2F /r COMISS                            floating-point values in     \n   xmm1, xmm2/m32         A    V/V       SSE     xmm1 and xmm2/mem32 and set  \n                                                 the EFLAGS flags             \n                                                 accordingly.                 \n                                                 Compare low single precision \n   VEX.LIG.0F.WIG 2F /r                          floating-point values in     \n   VCOMISS xmm1, xmm2/m32 A    V/V       AVX     xmm1 and xmm2/mem32 and set  \n                                                 the EFLAGS flags             \n                                                 accordingly.                 \n                                                 Compare low single precision \n   EVEX.LLIG.0F.W0 2F /r                         floating-point values in     \n   VCOMISS xmm1,          B    V/V       AVX512F xmm1 and xmm2/mem32 and set  \n   xmm2/m32{sae}                                 the EFLAGS flags             \n                                                 accordingly.                 \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Compares the single precision floating-point values in the low quadwords\n   of operand 1 (first operand) and operand 2 (second operand), and sets the\n   ZF, PF, and CF flags in the EFLAGS register according to the result\n   (unordered, greater than, less than, or equal). The OF, SF, and AF flags\n   in the EFLAGS register are set to 0. The unordered result is returned if\n   either source operand is a NaN (QNaN or SNaN).\n\n   Operand 1 is an XMM register; operand 2 can be an XMM register or a 32 bit\n   memory location.\n\n   The COMISS instruction differs from the UCOMISS instruction in that it\n   signals a SIMD floating-point invalid operation exception (#I) when a\n   source operand is either a QNaN or SNaN. The UCOMISS instruction signals\n   an invalid operation exception only if a source operand is an SNaN.\n\n   The EFLAGS register is not updated if an unmasked SIMD floating-point\n   exception is generated.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCOMISS is encoded with VEX.L=0. Encoding VCOMISS\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["cldemote", "                          CLDEMOTE \u2014 Cache Line Demote\n\n                              64/32 bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Flag Description\n                              Support   \n                                                     Hint to hardware to move \n                                                     the cache line           \n   NP 0F 1C /0 CLDEMOTE A     V/V       CLDEMOTE     containing m8 to a more  \n   m8                                                distant level of the     \n                                                     cache without writing    \n                                                     back to memory.          \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. The Mod field of the ModR/M byte cannot have value 11B.\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   A     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Hints to hardware that the cache line that contains the linear address\n   specified with the memory operand should be moved (\u201cdemoted\u201d) from the\n   cache(s) closest to the processor core to a level more distant from the\n   processor core. This may accelerate subsequent accesses to the line by\n   other cores in the same coherence domain, especially if the line was\n   written by the core that demotes the line. Moving the line in such a\n   manner is a performance optimization, i.e., it is a hint which does not\n   modify architectural state. Hardware may choose which level in the cache\n   hierarchy to retain the line (e.g., L3 in typical server designs). The\n   source operand is a byte memory location.\n\n   The availability of the CLDEMOTE instruction is indicated by the presence\n   of the CPUID feature flag CLDEMOTE (bit 25 of the ECX register in sub-leaf\n   07H, see \u201cCPUID\u2014CPU Identification\u201d). On processors which do not support\n   the CLDEMOTE instruction (including legacy hardware) the instruction will\n   be treated as a NOP.\n\n   A CLDEMOTE instruction is ordered with respect to stores to the same cache\n   line, but unordered with respect to other instructions including memory\n   fences, CLDEMOTE, CLWB or CLFLUSHOPT instructions to a different cache\n   line. Since CLDEMOTE will retire in order with respect to stores to the\n   same cache line, software should ensure that after issuing CLDEMOTE the\n   line is not accessed again immediately by the same core to avoid cache\n   data movement penalties.\n\n   The effective memory type of the page containing the affected line\n   determines the effect; cacheable types are likely to generate a data\n   movement operation, while uncacheable types may cause the instruction to\n   be ignored.\n\n   Speculative fetching can occur at any time and is not tied to instruction\n   execution. The CLDEMOTE instruction is not ordered with respect to\n   PREFETCHh instructions or any of the speculative fetching mechanisms. That\n   is, data can be speculatively loaded into a cache line just before,\n   during, or after the execution of a CLDEMOTE instruction that references\n   the cache line.\n\n   Unlike CLFLUSH, CLFLUSHOPT, and CLWB instructions, CLDEMOTE is not\n   guaranteed to write back modified data to memory.\n\n   The CLDEMOTE instruction may be ignored by hardware in certain cases and\n   is not a guarantee.\n\n   The CLDEMOTE instruction can be used at all privilege levels. In certain\n   processor implementations the CLDEMOTE instruction may set the A bit but\n   not the D bit in the page tables.\n\n   If the line is not found in the cache, the instruction will be treated as\n   a NOP.\n\n   In some implementations, the CLDEMOTE instruction may always cause a\n   transactional abort with Transactional Synchronization Extensions (TSX).\n   However, programmers must not rely on CLDEMOTE instruction to force a\n   transactional abort.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cmovcc", "                           CMOVcc \u2014 Conditional Move\n\n   Opcode     Instruction  Op/En 64-Bit Compat/Leg Description                \n                                 Mode   Mode       \n   0F 47 /r   CMOVA r16,   RM    Valid  Valid      Move if above (CF=0 and    \n              r/m16                                ZF=0).                     \n   0F 47 /r   CMOVA r32,   RM    Valid  Valid      Move if above (CF=0 and    \n              r/m32                                ZF=0).                     \n   REX.W + 0F CMOVA r64,   RM    Valid  N.E.       Move if above (CF=0 and    \n   47 /r      r/m64                                ZF=0).                     \n   0F 43 /r   CMOVAE r16,  RM    Valid  Valid      Move if above or equal     \n              r/m16                                (CF=0).                    \n   0F 43 /r   CMOVAE r32,  RM    Valid  Valid      Move if above or equal     \n              r/m32                                (CF=0).                    \n   REX.W + 0F CMOVAE r64,  RM    Valid  N.E.       Move if above or equal     \n   43 /r      r/m64                                (CF=0).                    \n   0F 42 /r   CMOVB r16,   RM    Valid  Valid      Move if below (CF=1).      \n              r/m16        \n   0F 42 /r   CMOVB r32,   RM    Valid  Valid      Move if below (CF=1).      \n              r/m32        \n   REX.W + 0F CMOVB r64,   RM    Valid  N.E.       Move if below (CF=1).      \n   42 /r      r/m64        \n   0F 46 /r   CMOVBE r16,  RM    Valid  Valid      Move if below or equal     \n              r/m16                                (CF=1 or ZF=1).            \n   0F 46 /r   CMOVBE r32,  RM    Valid  Valid      Move if below or equal     \n              r/m32                                (CF=1 or ZF=1).            \n   REX.W + 0F CMOVBE r64,  RM    Valid  N.E.       Move if below or equal     \n   46 /r      r/m64                                (CF=1 or ZF=1).            \n   0F 42 /r   CMOVC r16,   RM    Valid  Valid      Move if carry (CF=1).      \n              r/m16        \n   0F 42 /r   CMOVC r32,   RM    Valid  Valid      Move if carry (CF=1).      \n              r/m32        \n   REX.W + 0F CMOVC r64,   RM    Valid  N.E.       Move if carry (CF=1).      \n   42 /r      r/m64        \n   0F 44 /r   CMOVE r16,   RM    Valid  Valid      Move if equal (ZF=1).      \n              r/m16        \n   0F 44 /r   CMOVE r32,   RM    Valid  Valid      Move if equal (ZF=1).      \n              r/m32        \n   REX.W + 0F CMOVE r64,   RM    Valid  N.E.       Move if equal (ZF=1).      \n   44 /r      r/m64        \n   0F 4F /r   CMOVG r16,   RM    Valid  Valid      Move if greater (ZF=0 and  \n              r/m16                                SF=OF).                    \n   0F 4F /r   CMOVG r32,   RM    Valid  Valid      Move if greater (ZF=0 and  \n              r/m32                                SF=OF).                    \n   REX.W + 0F CMOVG r64,   RM    V/N.E. N/A        Move if greater (ZF=0 and  \n   4F /r      r/m64                                SF=OF).                    \n   0F 4D /r   CMOVGE r16,  RM    Valid  Valid      Move if greater or equal   \n              r/m16                                (SF=OF).                   \n   0F 4D /r   CMOVGE r32,  RM    Valid  Valid      Move if greater or equal   \n              r/m32                                (SF=OF).                   \n   REX.W + 0F CMOVGE r64,  RM    Valid  N.E.       Move if greater or equal   \n   4D /r      r/m64                                (SF=OF).                   \n   0F 4C /r   CMOVL r16,   RM    Valid  Valid      Move if less (SF=\u0338 OF).    \n              r/m16        \n   0F 4C /r   CMOVL r32,   RM    Valid  Valid      Move if less (SF=\u0338 OF).    \n              r/m32        \n   REX.W + 0F CMOVL r64,   RM    Valid  N.E.       Move if less (SF=\u0338 OF).    \n   4C /r      r/m64        \n   0F 4E /r   CMOVLE r16,  RM    Valid  Valid      Move if less or equal      \n              r/m16                                (ZF=1 or SF=\u0338 OF).         \n   0F 4E /r   CMOVLE r32,  RM    Valid  Valid      Move if less or equal      \n              r/m32                                (ZF=1 or SF=\u0338 OF).         \n   REX.W + 0F CMOVLE r64,  RM    Valid  N.E.       Move if less or equal      \n   4E /r      r/m64                                (ZF=1 or SF=\u0338 OF).         \n   0F 46 /r   CMOVNA r16,  RM    Valid  Valid      Move if not above (CF=1 or \n              r/m16                                ZF=1).                     \n   0F 46 /r   CMOVNA r32,  RM    Valid  Valid      Move if not above (CF=1 or \n              r/m32                                ZF=1).                     \n   REX.W + 0F CMOVNA r64,  RM    Valid  N.E.       Move if not above (CF=1 or \n   46 /r      r/m64                                ZF=1).                     \n   0F 42 /r   CMOVNAE r16, RM    Valid  Valid      Move if not above or equal \n              r/m16                                (CF=1).                    \n   0F 42 /r   CMOVNAE r32, RM    Valid  Valid      Move if not above or equal \n              r/m32                                (CF=1).                    \n   REX.W + 0F CMOVNAE r64, RM    Valid  N.E.       Move if not above or equal \n   42 /r      r/m64                                (CF=1).                    \n   0F 43 /r   CMOVNB r16,  RM    Valid  Valid      Move if not below (CF=0).  \n              r/m16        \n   0F 43 /r   CMOVNB r32,  RM    Valid  Valid      Move if not below (CF=0).  \n              r/m32        \n   REX.W + 0F CMOVNB r64,  RM    Valid  N.E.       Move if not below (CF=0).  \n   43 /r      r/m64        \n   0F 47 /r   CMOVNBE r16, RM    Valid  Valid      Move if not below or equal \n              r/m16                                (CF=0 and ZF=0).           \n   0F 47 /r   CMOVNBE r32, RM    Valid  Valid      Move if not below or equal \n              r/m32                                (CF=0 and ZF=0).           \n   REX.W + 0F CMOVNBE r64, RM    Valid  N.E.       Move if not below or equal \n   47 /r      r/m64                                (CF=0 and ZF=0).           \n   0F 43 /r   CMOVNC r16,  RM    Valid  Valid      Move if not carry (CF=0).  \n              r/m16        \n   0F 43 /r   CMOVNC r32,  RM    Valid  Valid      Move if not carry (CF=0).  \n              r/m32        \n   REX.W + 0F CMOVNC r64,  RM    Valid  N.E.       Move if not carry (CF=0).  \n   43 /r      r/m64        \n   0F 45 /r   CMOVNE r16,  RM    Valid  Valid      Move if not equal (ZF=0).  \n              r/m16        \n   0F 45 /r   CMOVNE r32,  RM    Valid  Valid      Move if not equal (ZF=0).  \n              r/m32        \n   REX.W + 0F CMOVNE r64,  RM    Valid  N.E.       Move if not equal (ZF=0).  \n   45 /r      r/m64        \n   0F 4E /r   CMOVNG r16,  RM    Valid  Valid      Move if not greater (ZF=1  \n              r/m16                                or SF=\u0338 OF).               \n   0F 4E /r   CMOVNG r32,  RM    Valid  Valid      Move if not greater (ZF=1  \n              r/m32                                or SF=\u0338 OF).               \n   REX.W + 0F CMOVNG r64,  RM    Valid  N.E.       Move if not greater (ZF=1  \n   4E /r      r/m64                                or SF=\u0338 OF).               \n   0F 4C /r   CMOVNGE r16, RM    Valid  Valid      Move if not greater or     \n              r/m16                                equal (SF=\u0338 OF).           \n   0F 4C /r   CMOVNGE r32, RM    Valid  Valid      Move if not greater or     \n              r/m32                                equal (SF=\u0338 OF).           \n   REX.W + 0F CMOVNGE r64, RM    Valid  N.E.       Move if not greater or     \n   4C /r      r/m64                                equal (SF=\u0338 OF).           \n   0F 4D /r   CMOVNL r16,  RM    Valid  Valid      Move if not less (SF=OF).  \n              r/m16        \n   0F 4D /r   CMOVNL r32,  RM    Valid  Valid      Move if not less (SF=OF).  \n              r/m32        \n   REX.W + 0F CMOVNL r64,  RM    Valid  N.E.       Move if not less (SF=OF).  \n   4D /r      r/m64        \n   0F 4F /r   CMOVNLE r16, RM    Valid  Valid      Move if not less or equal  \n              r/m16                                (ZF=0 and SF=OF).          \n   0F 4F /r   CMOVNLE r32, RM    Valid  Valid      Move if not less or equal  \n              r/m32                                (ZF=0 and SF=OF).          \n   REX.W + 0F CMOVNLE r64, RM    Valid  N.E.       Move if not less or equal  \n   4F /r      r/m64                                (ZF=0 and SF=OF).          \n   0F 41 /r   CMOVNO r16,  RM    Valid  Valid      Move if not overflow       \n              r/m16                                (OF=0).                    \n   0F 41 /r   CMOVNO r32,  RM    Valid  Valid      Move if not overflow       \n              r/m32                                (OF=0).                    \n   REX.W + 0F CMOVNO r64,  RM    Valid  N.E.       Move if not overflow       \n   41 /r      r/m64                                (OF=0).                    \n   0F 4B /r   CMOVNP r16,  RM    Valid  Valid      Move if not parity (PF=0). \n              r/m16        \n   0F 4B /r   CMOVNP r32,  RM    Valid  Valid      Move if not parity (PF=0). \n              r/m32        \n   REX.W + 0F CMOVNP r64,  RM    Valid  N.E.       Move if not parity (PF=0). \n   4B /r      r/m64        \n   0F 49 /r   CMOVNS r16,  RM    Valid  Valid      Move if not sign (SF=0).   \n              r/m16        \n   0F 49 /r   CMOVNS r32,  RM    Valid  Valid      Move if not sign (SF=0).   \n              r/m32        \n   REX.W + 0F CMOVNS r64,  RM    Valid  N.E.       Move if not sign (SF=0).   \n   49 /r      r/m64        \n   0F 45 /r   CMOVNZ r16,  RM    Valid  Valid      Move if not zero (ZF=0).   \n              r/m16        \n   0F 45 /r   CMOVNZ r32,  RM    Valid  Valid      Move if not zero (ZF=0).   \n              r/m32        \n   REX.W + 0F CMOVNZ r64,  RM    Valid  N.E.       Move if not zero (ZF=0).   \n   45 /r      r/m64        \n   0F 40 /r   CMOVO r16,   RM    Valid  Valid      Move if overflow (OF=1).   \n              r/m16        \n   0F 40 /r   CMOVO r32,   RM    Valid  Valid      Move if overflow (OF=1).   \n              r/m32        \n   REX.W + 0F CMOVO r64,   RM    Valid  N.E.       Move if overflow (OF=1).   \n   40 /r      r/m64        \n   0F 4A /r   CMOVP r16,   RM    Valid  Valid      Move if parity (PF=1).     \n              r/m16        \n   0F 4A /r   CMOVP r32,   RM    Valid  Valid      Move if parity (PF=1).     \n              r/m32        \n   REX.W + 0F CMOVP r64,   RM    Valid  N.E.       Move if parity (PF=1).     \n   4A /r      r/m64        \n   0F 4A /r   CMOVPE r16,  RM    Valid  Valid      Move if parity even        \n              r/m16                                (PF=1).                    \n   0F 4A /r   CMOVPE r32,  RM    Valid  Valid      Move if parity even        \n              r/m32                                (PF=1).                    \n   REX.W + 0F CMOVPE r64,  RM    Valid  N.E.       Move if parity even        \n   4A /r      r/m64                                (PF=1).                    \n   0F 4B /r   CMOVPO r16,  RM    Valid  Valid      Move if parity odd (PF=0). \n              r/m16        \n   0F 4B /r   CMOVPO r32,  RM    Valid  Valid      Move if parity odd (PF=0). \n              r/m32        \n   REX.W + 0F CMOVPO r64,  RM    Valid  N.E.       Move if parity odd (PF=0). \n   4B /r      r/m64        \n   0F 48 /r   CMOVS r16,   RM    Valid  Valid      Move if sign (SF=1).       \n              r/m16        \n   0F 48 /r   CMOVS r32,   RM    Valid  Valid      Move if sign (SF=1).       \n              r/m32        \n   REX.W + 0F CMOVS r64,   RM    Valid  N.E.       Move if sign (SF=1).       \n   48 /r      r/m64        \n   0F 44 /r   CMOVZ r16,   RM    Valid  Valid      Move if zero (ZF=1).       \n              r/m16        \n   0F 44 /r   CMOVZ r32,   RM    Valid  Valid      Move if zero (ZF=1).       \n              r/m32        \n   REX.W + 0F CMOVZ r64,   RM    Valid  N.E.       Move if zero (ZF=1).       \n   44 /r      r/m64        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Each of the CMOVcc instructions performs a move operation if the status\n   flags in the EFLAGS register (CF, OF, PF, SF, and ZF) are in a specified\n   state (or condition). A condition code (cc) is associated with each\n   instruction to indicate the condition being tested for. If the condition\n   is not satisfied, a move is not performed and execution continues with the\n   instruction following the CMOVcc instruction.\n\n   Specifically, CMOVcc loads data from its source operand into a temporary\n   register unconditionally (regardless of the condition code and the status\n   flags in the EFLAGS register). If the condition code associated with the\n   instruction (cc) is satisfied, the data in the temporary register is then\n   copied into the instruction's destination operand.\n\n   These instructions can move 16-bit, 32-bit or 64-bit values from memory to\n   a general-purpose register or from one general-purpose register to\n   another. Conditional moves of 8-bit register operands are not supported.\n\n   The condition for each CMOVcc mnemonic is given in the description column\n   of the above table. The terms \u201cless\u201d and \u201cgreater\u201d are used for\n   comparisons of signed integers and the terms \u201cabove\u201d and \u201cbelow\u201d are used\n   for unsigned integers.\n\n   Because a particular state of the status flags can sometimes be\n   interpreted in two ways, two mnemonics are defined for some opcodes. For\n   example, the CMOVA (conditional move if above) instruction and the CMOVNBE\n   (conditional move if not below or equal) instruction are alternate\n   mnemonics for the opcode 0F 47H.\n\n   The CMOVcc instructions were introduced in P6 family processors; however,\n   these instructions may not be supported by all IA-32 processors. Software\n   can determine if the CMOVcc instructions are supported by checking the\n   processor\u2019s feature information with the CPUID instruction (see \u201cCPUID\u2014CPU\n   Identification\u201d in this chapter).\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bits. See the summary chart\n   at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["cvtdq2ps", "    CVTDQ2PS \u2014 Convert Packed Doubleword Integers to Packed Single Precision\n                              Floating-PointValues\n\n                             Op / 64/32 bit CPUID                             \n   Opcode Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert four packed      \n                                                     signed doubleword        \n   NP 0F 5B /r CVTDQ2PS      A    V/V       SSE2     integers from xmm2/mem   \n   xmm1, xmm2/m128                                   to four packed single    \n                                                     precision floating-point \n                                                     values in xmm1.          \n                                                     Convert four packed      \n                                                     signed doubleword        \n   VEX.128.0F.WIG 5B /r      A    V/V       AVX      integers from xmm2/mem   \n   VCVTDQ2PS xmm1, xmm2/m128                         to four packed single    \n                                                     precision floating-point \n                                                     values in xmm1.          \n                                                     Convert eight packed     \n                                                     signed doubleword        \n   VEX.256.0F.WIG 5B /r      A    V/V       AVX      integers from ymm2/mem   \n   VCVTDQ2PS ymm1, ymm2/m256                         to eight packed single   \n                                                     precision floating-point \n                                                     values in ymm1.          \n                                                     Convert four packed      \n                                                     signed doubleword        \n   EVEX.128.0F.W0 5B /r                              integers from            \n   VCVTDQ2PS xmm1 {k1}{z},   B    V/V       AVX512VL xmm2/m128/m32bcst to     \n   xmm2/m128/m32bcst                        AVX512F  four packed single       \n                                                     precision floating-point \n                                                     values in xmm1with       \n                                                     writemask k1.            \n                                                     Convert eight packed     \n                                                     signed doubleword        \n   EVEX.256.0F.W0 5B /r                              integers from            \n   VCVTDQ2PS ymm1 {k1}{z},   B    V/V       AVX512VL ymm2/m256/m32bcst to     \n   ymm2/m256/m32bcst                        AVX512F  eight packed single      \n                                                     precision floating-point \n                                                     values in ymm1with       \n                                                     writemask k1.            \n                                                     Convert sixteen packed   \n                                                     signed doubleword        \n   EVEX.512.0F.W0 5B /r                              integers from            \n   VCVTDQ2PS zmm1 {k1}{z},   B    V/V       AVX512F  zmm2/m512/m32bcst to     \n   zmm2/m512/m32bcst{er}                             sixteen packed single    \n                                                     precision floating-point \n                                                     values in zmm1with       \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts four, eight or sixteen packed signed doubleword integers in the\n   source operand to four, eight or sixteen packed single precision\n   floating-point values in the destination operand.\n\n   EVEX encoded versions: The source operand can be a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location or a 512/256/128-bit vector broadcasted\n   from a 32-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The source operand is a YMM register or 256- bit\n   memory location. The destination operand is a YMM register. Bits\n   (MAXVL-1:256) of the corresponding register destination are zeroed.\n\n   VEX.128 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a XMM register. The upper bits\n   (MAXVL-1:128) of the corresponding register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 128-\n   bit memory location. The destination operand is an XMM register. The upper\n   Bits (MAXVL-1:128) of the corresponding register destination are\n   unmodified.\n\n   VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n"],
	["vfpclasssh", "                 VFPCLASSSH \u2014 Test Types of Scalar FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En Bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Test the input for  \n                                                          the following       \n                                                          categories: NaN,    \n                                                          +0, -0, +Infinity,  \n                                                          -Infinity,          \n                                                          denormal, finite    \n   EVEX.LLIG.NP.0F3A.W0 67 /r /ib                         negative. The       \n   VFPCLASSSH k1{k2}, xmm1/m16,     A V/V     AVX512-FP16 immediate field     \n   imm8                                                   provides a mask bit \n                                                          for each of these   \n                                                          category tests. The \n                                                          masked test results \n                                                          are OR-ed together  \n                                                          to form a mask      \n                                                          result.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Scalar ModRM:reg (w) ModRM:r/m (r) imm8 (r)  N/A       \n\n  Description \u00b6\n\n   This instruction checks the low FP16 value in the source operand for\n   special categories, specified by the set bits in the imm8 byte. Each set\n   bit in imm8 specifies a category of floating-point values that the input\n   data element is classified against; see Table 5-9 for the categories. The\n   classified results of all specified categories of an input value are ORed\n   together to form the final boolean result for the input element. The\n   result is written to the low bit in the destination mask register\n   according to the writemask. The other bits in the destination mask\n   register are zeroed.\n"],
	["sidt", "                SIDT \u2014 Store Interrupt Descriptor Table Register\n\n   Opcode^1\n\n            Instruction Op/En 64-Bit Mode Compat/Leg Mode Description      \n   0F 01 /1                   Valid       Valid           Store IDTR to m. \n\n   1. See the IA-32 Architecture Compatibility section below.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (w) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Stores the content the interrupt descriptor table register (IDTR) in the\n   destination operand. The destination operand specifies a 6-byte memory\n   location.\n\n   In non-64-bit modes, the 16-bit limit field of the register is stored in\n   the low 2 bytes of the memory location and the 32-bit base address is\n   stored in the high 4 bytes.\n\n   In 64-bit mode, the operand size fixed at 8+2 bytes. The instruction\n   stores 8-byte base and 2-byte limit values.\n\n   SIDT is only useful in operating-system software; however, it can be used\n   in application programs without causing an exception to be generated if\n   CR4.UMIP = 0. See \u201cLGDT/LIDT\u2014Load Global/Interrupt Descriptor Table\n   Register\u201d in Chapter 3, Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 2A, for information on loading the GDTR and\n   IDTR.\n\nIA-32 Architecture Compatibility \u00b6\n\n   The 16-bit form of SIDT is compatible with the Intel 286 processor if the\n   upper 8 bits are not referenced. The Intel 286 processor fills these bits\n   with 1s; processor generations later than the Intel 286 processor fill\n   these bits with 0s.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fst:fstp", "                     FST/FSTP \u2014 Store Floating-Point Value\n\n   Opcode  Instruction 64-Bit Mode Compat/Leg Mode Description                \n   D9 /2   FST m32fp   Valid       Valid           Copy ST(0) to m32fp.       \n   DD /2   FST m64fp   Valid       Valid           Copy ST(0) to m64fp.       \n   DD D0+i FST ST(i)   Valid       Valid           Copy ST(0) to ST(i).       \n   D9 /3   FSTP m32fp  Valid       Valid           Copy ST(0) to m32fp and    \n                                                   pop register stack.        \n   DD /3   FSTP m64fp  Valid       Valid           Copy ST(0) to m64fp and    \n                                                   pop register stack.        \n   DB /7   FSTP m80fp  Valid       Valid           Copy ST(0) to m80fp and    \n                                                   pop register stack.        \n   DD D8+i FSTP ST(i)  Valid       Valid           Copy ST(0) to ST(i) and    \n                                                   pop register stack.        \n\nDescription \u00b6\n\n   The FST instruction copies the value in the ST(0) register to the\n   destination operand, which can be a memory location or another register in\n   the FPU register stack. When storing the value in memory, the value is\n   converted to single precision or double precision floating-point format.\n\n   The FSTP instruction performs the same operation as the FST instruction\n   and then pops the register stack. To pop the register stack, the processor\n   marks the ST(0) register as empty and increments the stack pointer (TOP)\n   by 1. The FSTP instruction can also store values in memory in double\n   extended-precision floating-point format.\n\n   If the destination operand is a memory location, the operand specifies the\n   address where the first byte of the destination value is to be stored. If\n   the destination operand is a register, the operand specifies a register in\n   the register stack relative to the top of the stack.\n\n   If the destination size is single precision or double precision, the\n   significand of the value being stored is rounded to the width of the\n   destination (according to the rounding mode specified by the RC field of\n   the FPU control word), and the exponent is converted to the width and bias\n   of the destination format. If the value being stored is too large for the\n   destination format, a numeric overflow exception (#O) is generated and, if\n   the exception is unmasked, no value is stored in the destination operand.\n   If the value being stored is a denormal value, the denormal exception (#D)\n   is not generated. This condition is simply signaled as a numeric underflow\n   exception (#U) condition.\n\n   If the value being stored is \u00b10, \u00b1\u221e, or a NaN, the least-significant bits\n   of the significand and the exponent are truncated to fit the destination\n   format. This operation preserves the value\u2019s identity as a 0, \u221e, or NaN.\n\n   If the destination operand is a non-empty register, the invalid-operation\n   exception is not generated.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n              Set to 0 if stack underflow occurred.                           \n   C1         Indicates rounding direction of if the floating-point inexact   \n              exception (#P) is generated: 0 := not roundup; 1 := roundup.    \n   C0, C2, C3 Undefined.                                                      \n"],
	["cvttps2pi", "   CVTTPS2PI \u2014 Convert With Truncation Packed Single Precision Floating-Point\n                         Values to PackedDword Integers\n\n   Opcode/Instruction    Op/En 64-Bit Compat/Leg Description                  \n                               Mode   Mode       \n                                                 Convert two single precision \n   NP 0F 2C /r CVTTPS2PI                         floating-point values from   \n   mm, xmm/m64           RM    Valid  Valid      xmm/m64 to two signed        \n                                                 doubleword signed integers   \n                                                 in mm using truncation.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts two packed single precision floating-point values in the source\n   operand (second operand) to two packed signed doubleword integers in the\n   destination operand (first operand). The source operand can be an XMM\n   register or a 64-bit memory location. The destination operand is an MMX\n   technology register. When the source operand is an XMM register, the two\n   single precision floating-point values are contained in the low quadword\n   of the register.\n\n   When a conversion is inexact, a truncated (round toward zero) result is\n   returned. If a converted result is larger than the maximum signed\n   doubleword integer, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (80000000H) is\n   returned.\n\n   This instruction causes a transition from x87 FPU to MMX technology\n   operation (that is, the x87 FPU top-of-stack pointer is set to 0 and the\n   x87 FPU tag word is set to all 0s [valid]). If this instruction is\n   executed while an x87 FPU floating-point exception is pending, the\n   exception is handled before the CVTTPS2PI instruction is executed.\n\n   In 64-bit mode, use of the REX.R prefix permits this instruction to access\n   additional registers (XMM8-XMM15).\n"],
	["vrcp28ss", "     VRCP28SS \u2014 Approximation to the Reciprocal of Scalar Single Precision\n            Floating-Point ValueWith Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes the approximate  \n                                                    reciprocal ( < 2^-28      \n                                                    relative error) of the    \n                                                    scalar single-precision   \n   EVEX.LLIG.66.0F38.W0 CB                          floating-point value in   \n   /r VRCP28SS xmm1                                 xmm3/m32 and stores the   \n   {k1}{z}, xmm2, xmm3/m32 A     V/V       AVX512ER results in xmm1. Under    \n   {sae}                                            writemask. Also, upper 3  \n                                                    single-precision          \n                                                    floating-point values     \n                                                    (bits[127:32]) from xmm2  \n                                                    is copied to              \n                                                    xmm1[127:32].             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4      \n   A Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   Computes the reciprocal approximation of the low float32 value in the\n   second source operand (the third operand) and store the result to the\n   destination operand (the first operand). The approximate reciprocal is\n   evaluated with less than 2^-28 of maximum relative error prior to final\n   rounding. The final result is rounded to < 2^-23 relative error before\n   written into the low float32 element of the destination according to\n   writemask k1. Bits 127:32 of the destination is copied from the\n   corresponding bits of the first source operand (the second operand).\n\n   A denormal input value is treated as zero and does not signal #DE,\n   irrespective of MXCSR.DAZ. A denormal result is flushed to zero and does\n   not signal #UE, irrespective of MXCSR.FTZ.\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. If any source element is \u00b1\u221e, \u00b10.0 is returned for that\n   element. Also, if any source element is \u00b10.0, \u00b1\u221e is returned for that\n   element.\n\n   The first source operand is an XMM register. The second source operand is\n   an XMM register or a 32-bit memory location. The destination operand is a\n   XMM register, conditionally updated using writemask k1.\n\n  A numerically exact implementation of VRCP28xx can be found at\n  https://software.intel.com/en-us/articles/refer- \u00b6\n\n  ence-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["cvttss2si", "CVTTSS2SI \u2014 Convert With Truncation Scalar Single Precision Floating-Point Value\n                                   to Integer\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Convert one single          \n   F3 0F 2C /r CVTTSS2SI                          precision floating-point    \n   r32, xmm1/m32           A    V/V       SSE     value from xmm1/m32 to one  \n                                                  signed doubleword integer   \n                                                  in r32 using truncation.    \n                                                  Convert one single          \n   F3 REX.W 0F 2C /r                              precision floating-point    \n   CVTTSS2SI r64, xmm1/m32 A    V/N.E.    SSE     value from xmm1/m32 to one  \n                                                  signed quadword integer in  \n                                                  r64 using truncation.       \n                                                  Convert one single          \n   VEX.LIG.F3.0F.W0 2C /r                         precision floating-point    \n   ^1 VCVTTSS2SI r32,      A    V/V       AVX     value from xmm1/m32 to one  \n   xmm1/m32                                       signed doubleword integer   \n                                                  in r32 using truncation.    \n                                                  Convert one single          \n   VEX.LIG.F3.0F.W1 2C /r                         precision floating-point    \n   ^1 VCVTTSS2SI r64,      A    V/N.E.^2  AVX     value from xmm1/m32 to one  \n   xmm1/m32                                       signed quadword integer in  \n                                                  r64 using truncation.       \n                                                  Convert one single          \n   EVEX.LLIG.F3.0F.W0 2C                          precision floating-point    \n   /r VCVTTSS2SI r32,      B    V/V       AVX512F value from xmm1/m32 to one  \n   xmm1/m32{sae}                                  signed doubleword integer   \n                                                  in r32 using truncation.    \n                                                  Convert one single          \n   EVEX.LLIG.F3.0F.W1 2C                          precision floating-point    \n   /r VCVTTSS2SI r64,      B    V/N.E.^2  AVX512F value from xmm1/m32 to one  \n   xmm1/m32{sae}                                  signed quadword integer in  \n                                                  r64 using truncation.       \n\n     1. Software should ensure VCVTTSS2SI is encoded with VEX.L=0. Encoding\n     VCVTTSS2SI with VEX.L=1 may encounter unpredictable behavior across\n     different processor generations.\n\n     2. For this specific instruction, VEX.W/EVEX.W in non-64 bit is ignored;\n     the instructions behaves as if the W0 version is used.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type   Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A          ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Fixed ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts a single precision floating-point value in the source operand\n   (the second operand) to a signed doubleword integer (or signed quadword\n   integer if operand size is 64 bits) in the destination operand (the first\n   operand). The source operand can be an XMM register or a 32-bit memory\n   location. The destination operand is a general purpose register. When the\n   source operand is an XMM register, the single precision floating-point\n   value is contained in the low doubleword of the register.\n\n   When a conversion is inexact, a truncated (round toward zero) result is\n   returned. If a converted result is larger than the maximum signed\n   doubleword integer, the floating-point invalid exception is raised. If\n   this exception is masked, the indefinite integer value (80000000H or\n   80000000_00000000H if operand size is 64 bits) is returned.\n\n   Legacy SSE instructions: In 64-bit mode, Use of the REX.W prefix promotes\n   the instruction to 64-bit operation. See the summary chart at the\n   beginning of this section for encoding data and limits.\n\n   VEX.W1 and EVEX.W1 versions: promotes the instruction to produce 64-bit\n   data in 64-bit mode.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b, otherwise\n   instructions will #UD.\n\n   Software should ensure VCVTTSS2SI is encoded with VEX.L=0. Encoding\n   VCVTTSS2SI with VEX.L=1 may encounter unpredictable behavior across\n   different processor generations.\n"],
	["vbroadcast", "              VBROADCAST \u2014 Load with Broadcast Floating-Point Data\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Broadcast single         \n   VEX.128.66.0F38.W0 18 /r A     V/V       AVX      precision floating-point \n   VBROADCASTSS xmm1, m32                            element in mem to four   \n                                                     locations in xmm1.       \n                                                     Broadcast single         \n   VEX.256.66.0F38.W0 18 /r A     V/V       AVX      precision floating-point \n   VBROADCASTSS ymm1, m32                            element in mem to eight  \n                                                     locations in ymm1.       \n                                                     Broadcast double         \n   VEX.256.66.0F38.W0 19 /r A     V/V       AVX      precision floating-point \n   VBROADCASTSD ymm1, m64                            element in mem to four   \n                                                     locations in ymm1.       \n   VEX.256.66.0F38.W0 1A /r                          Broadcast 128 bits of    \n   VBROADCASTF128 ymm1,     A     V/V       AVX      floating-point data in   \n   m128                                              mem to low and high      \n                                                     128-bits in ymm1.        \n                                                     Broadcast the low single \n   VEX.128.66.0F38.W0 18/r                           precision floating-point \n   VBROADCASTSS xmm1, xmm2  A     V/V       AVX2     element in the source    \n                                                     operand to four          \n                                                     locations in xmm1.       \n                                                     Broadcast low single     \n   VEX.256.66.0F38.W0 18 /r                          precision floating-point \n   VBROADCASTSS ymm1, xmm2  A     V/V       AVX2     element in the source    \n                                                     operand to eight         \n                                                     locations in ymm1.       \n                                                     Broadcast low double     \n   VEX.256.66.0F38.W0 19 /r                          precision floating-point \n   VBROADCASTSD ymm1, xmm2  A     V/V       AVX2     element in the source    \n                                                     operand to four          \n                                                     locations in ymm1.       \n                                                     Broadcast low double     \n   EVEX.256.66.0F38.W1 19                   AVX512VL precision floating-point \n   /r VBROADCASTSD ymm1     B     V/V       AVX512F  element in xmm2/m64 to   \n   {k1}{z}, xmm2/m64                                 four locations in ymm1   \n                                                     using writemask k1.      \n                                                     Broadcast low double     \n   EVEX.512.66.0F38.W1 19                            precision floating-point \n   /r VBROADCASTSD zmm1     B     V/V       AVX512F  element in xmm2/m64 to   \n   {k1}{z}, xmm2/m64                                 eight locations in zmm1  \n                                                     using writemask k1.      \n                                                     Broadcast two single     \n   EVEX.256.66.0F38.W0 19                   AVX512VL precision floating-point \n   /r VBROADCASTF32X2 ymm1  C     V/V       AVX512DQ elements in xmm2/m64 to  \n   {k1}{z}, xmm2/m64                                 locations in ymm1 using  \n                                                     writemask k1.            \n                                                     Broadcast two single     \n   EVEX.512.66.0F38.W0 19                            precision floating-point \n   /r VBROADCASTF32X2 zmm1  C     V/V       AVX512DQ elements in xmm2/m64 to  \n   {k1}{z}, xmm2/m64                                 locations in zmm1 using  \n                                                     writemask k1.            \n                                                     Broadcast low single     \n   EVEX.128.66.0F38.W0 18                   AVX512VL precision floating-point \n   /r VBROADCASTSS xmm1     B     V/V       AVX512F  element in xmm2/m32 to   \n   {k1}{z}, xmm2/m32                                 all locations in xmm1    \n                                                     using writemask k1.      \n                                                     Broadcast low single     \n   EVEX.256.66.0F38.W0 18                   AVX512VL precision floating-point \n   /r VBROADCASTSS ymm1     B     V/V       AVX512F  element in xmm2/m32 to   \n   {k1}{z}, xmm2/m32                                 all locations in ymm1    \n                                                     using writemask k1.      \n                                                     Broadcast low single     \n   EVEX.512.66.0F38.W0 18                            precision floating-point \n   /r VBROADCASTSS zmm1     B     V/V       AVX512F  element in xmm2/m32 to   \n   {k1}{z}, xmm2/m32                                 all locations in zmm1    \n                                                     using writemask k1.      \n                                                     Broadcast 128 bits of 4  \n   EVEX.256.66.0F38.W0 1A                   AVX512VL single precision         \n   /r VBROADCASTF32X4 ymm1  D     V/V       AVX512F  floating-point data in   \n   {k1}{z}, m128                                     mem to locations in ymm1 \n                                                     using writemask k1.      \n                                                     Broadcast 128 bits of 4  \n   EVEX.512.66.0F38.W0 1A                            single precision         \n   /r VBROADCASTF32X4 zmm1  D     V/V       AVX512F  floating-point data in   \n   {k1}{z}, m128                                     mem to locations in zmm1 \n                                                     using writemask k1.      \n                                                     Broadcast 128 bits of 2  \n   EVEX.256.66.0F38.W1 1A                   AVX512VL double precision         \n   /r VBROADCASTF64X2 ymm1  C     V/V       AVX512DQ floating-point data in   \n   {k1}{z}, m128                                     mem to locations in ymm1 \n                                                     using writemask k1.      \n                                                     Broadcast 128 bits of 2  \n   EVEX.512.66.0F38.W1 1A                            double precision         \n   /r VBROADCASTF64X2 zmm1  C     V/V       AVX512DQ floating-point data in   \n   {k1}{z}, m128                                     mem to locations in zmm1 \n                                                     using writemask k1.      \n                                                     Broadcast 256 bits of 8  \n   EVEX.512.66.0F38.W0 1B                            single precision         \n   /r VBROADCASTF32X8 zmm1  E     V/V       AVX512DQ floating-point data in   \n   {k1}{z}, m256                                     mem to locations in zmm1 \n                                                     using writemask k1.      \n                                                     Broadcast 256 bits of 4  \n   EVEX.512.66.0F38.W1 1B                            double precision         \n   /r VBROADCASTF64X4 zmm1  D     V/V       AVX512F  floating-point data in   \n   {k1}{z}, m256                                     mem to locations in zmm1 \n                                                     using writemask k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A           ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Tuple1 Scalar ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   C     Tuple2        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   D     Tuple4        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   E     Tuple8        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   VBROADCASTSD/VBROADCASTSS/VBROADCASTF128 load floating-point values as one\n   tuple from the source operand (second operand) in memory and broadcast to\n   all elements of the destination operand (first operand).\n\n   VEX256-encoded versions: The destination operand is a YMM register. The\n   source operand is either a 32-bit, 64-bit, or 128-bit memory location.\n   Register source encodings are reserved and will #UD. Bits (MAXVL-1:256) of\n   the destination register are zeroed.\n\n   EVEX-encoded versions: The destination operand is a ZMM/YMM/XMM register\n   and updated according to the writemask k1. The source operand is either a\n   32-bit, 64-bit memory location or the low doubleword/quadword element of\n   an XMM register.\n\n   VBROADCASTF32X2/VBROADCASTF32X4/VBROADCASTF64X2/VBROADCASTF32X8/VBROADCASTF64X4\n   load floating-point values as tuples from the source operand (the second\n   operand) in memory or register and broadcast to all elements of the\n   destination operand (the first operand). The destination operand is a\n   YMM/ZMM register updated according to the writemask k1. The source operand\n   is either a register or 64-bit/128-bit/256-bit memory location.\n\n   VBROADCASTSD and VBROADCASTF128,F32x4 and F64x2 are only supported as\n   256-bit and 512-bit wide versions and up. VBROADCASTSS is supported in\n   128-bit, 256-bit and 512-bit wide versions. F32x8 and F64x4 are only\n   supported as 512-bit wide versions.\n\n   VBROADCASTF32X2/VBROADCASTF32X4/VBROADCASTF32X8 have 32-bit granularity.\n   VBROADCASTF64X2 and VBROADCASTF64X4 have 64-bit granularity.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n\n   If VBROADCASTSD or VBROADCASTF128 is encoded with VEX.L= 0, an attempt to\n   execute the instruction encoded with VEX.L= 0 will cause an #UD exception.\n\n   X0 m32 DEST X0 X0 X0 X0 X0 X0 X0 X0 Figure 5-1. VBROADCASTSS Operation\n   (VEX.256 encoded version) X0 m32 DEST 0 0 0 0 X0 X0 X0 X0 Figure 5-2.\n   VBROADCASTSS Operation (VEX.128-bit version) m64 X0 DEST X0 X0 X0 X0\n   Figure 5-3. VBROADCASTSD Operation (VEX.256-bit version) m128 X0 DEST X0\n   X0 Figure 5-4. VBROADCASTF128 Operation (VEX.256-bit version) m256 X0 DEST\n   X0 X0 Figure 5-5. VBROADCASTF64X4 Operation (512-bit version with\n   writemask all 1s)\n"],
	["fincstp", "                     FINCSTP \u2014 Increment Stack-Top Pointer\n\n   Opcode  Mode Leg Mode Description                                         \n   D9 F7                 Increment the TOP field in the FPU status register. \n\nDescription \u00b6\n\n   Adds one to the TOP field of the FPU status word (increments the\n   top-of-stack pointer). If the TOP field contains a 7, it is set to 0. The\n   effect of this instruction is to rotate the stack by one position. The\n   contents of the FPU data registers and tag register are not affected. This\n   operation is not equivalent to popping the stack, because the tag for the\n   previous top-of-stack register is not marked empty.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   The C1 flag is set to 0. The C0, C2, and C3 flags are undefined.\n"],
	["packusdw", "                    PACKUSDW \u2014 Pack With Unsigned Saturation\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Convert 4 packed signed    \n                                                   doubleword integers from   \n                                                   xmm1 and 4 packed signed   \n   66 0F 38 2B /r PACKUSDW A    V/V       SSE4_1   doubleword integers from   \n   xmm1, xmm2/m128                                 xmm2/m128 into 8 packed    \n                                                   unsigned word integers in  \n                                                   xmm1 using unsigned        \n                                                   saturation.                \n                                                   Convert 4 packed signed    \n                                                   doubleword integers from   \n   VEX.128.66.0F38 2B /r                           xmm2 and 4 packed signed   \n   VPACKUSDW xmm1,xmm2,    B    V/V       AVX      doubleword integers from   \n   xmm3/m128                                       xmm3/m128 into 8 packed    \n                                                   unsigned word integers in  \n                                                   xmm1 using unsigned        \n                                                   saturation.                \n                                                   Convert 8 packed signed    \n                                                   doubleword integers from   \n   VEX.256.66.0F38 2B /r                           ymm2 and 8 packed signed   \n   VPACKUSDW ymm1, ymm2,   B    V/V       AVX2     doubleword integers from   \n   ymm3/m256                                       ymm3/m256 into 16 packed   \n                                                   unsigned word integers in  \n                                                   ymm1 using unsigned        \n                                                   saturation.                \n                                                   Convert packed signed      \n                                                   doubleword integers from   \n   EVEX.128.66.0F38.W0 2B                          xmm2 and packed signed     \n   /r VPACKUSDW                           AVX512VL doubleword integers from   \n   xmm1{k1}{z}, xmm2,      C    V/V       AVX512BW xmm3/m128/m32bcst into     \n   xmm3/m128/m32bcst                               packed unsigned word       \n                                                   integers in xmm1 using     \n                                                   unsigned saturation under  \n                                                   writemask k1.              \n                                                   Convert packed signed      \n                                                   doubleword integers from   \n   EVEX.256.66.0F38.W0 2B                          ymm2 and packed signed     \n   /r VPACKUSDW                           AVX512VL doubleword integers from   \n   ymm1{k1}{z}, ymm2,      C    V/V       AVX512BW ymm3/m256/m32bcst into     \n   ymm3/m256/m32bcst                               packed unsigned word       \n                                                   integers in ymm1 using     \n                                                   unsigned saturation under  \n                                                   writemask k1.              \n                                                   Convert packed signed      \n                                                   doubleword integers from   \n   EVEX.512.66.0F38.W0 2B                          zmm2 and packed signed     \n   /r VPACKUSDW                                    doubleword integers from   \n   zmm1{k1}{z}, zmm2,      C    V/V       AVX512BW zmm3/m512/m32bcst into     \n   zmm3/m512/m32bcst                               packed unsigned word       \n                                                   integers in zmm1 using     \n                                                   unsigned saturation under  \n                                                   writemask k1.              \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Converts packed signed doubleword integers in the first and second source\n   operands into packed unsigned word integers using unsigned saturation to\n   handle overflow conditions. If the signed doubleword value is beyond the\n   range of an unsigned word (that is, greater than FFFFH or less than\n   0000H), the saturated unsigned word integer value of FFFFH or 0000H,\n   respectively, is stored in the destination.\n\n   EVEX encoded versions: The first source operand is a ZMM/YMM/XMM register.\n   The second source operand is a ZMM/YMM/XMM register, a 512/256/128-bit\n   memory location, or a 512/256/128-bit vector broadcasted from a 32-bit\n   memory location. The destination operand is a ZMM register, updated\n   conditionally under the writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register. The upper bits (MAXVL-1:256) of the\n   corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The first source operand is an XMM register. The\n   second source operand is an XMM register or 128-bit memory location. The\n   destination operand is an XMM register. The upper bits (MAXVL-1:128) of\n   the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The first source operand is an XMM register.\n   The second operand can be an XMM register or an 128-bit memory location.\n   The destination is not distinct from the first source XMM register and the\n   upper bits (MAXVL-1:128) of the corresponding destination register\n   destination are unmodified.\n"],
	["vcvtss2sh", "              VCVTSS2SH \u2014 Convert Low FP32 Value to an FP16 Value\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode  \n   Flag Support 64/32 CPUID Feature \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID          Support             Description\n   Feature Instruction En Bit Mode  \n   Flag 64/32 CPUID Feature         \n   Instruction En Bit Mode Flag     \n   CPUID Feature Instruction En Bit \n   Mode Flag Op/ 64/32 CPUID        \n   Feature                          \n                                                          Convert low FP32    \n                                                          value in xmm3/m32   \n                                                          to an FP16 value    \n   EVEX.LLIG.NP.MAP5.W0 1D /r                             and store in the    \n   VCVTSS2SH xmm1{k1}{z}, xmm2,     A V/V     AVX512-FP16 low element of xmm1 \n   xmm3/m32 {er}                                          subject to          \n                                                          writemask k1. Bits  \n                                                          127:16 from xmm2    \n                                                          are copied to       \n                                                          xmm1[127:16].       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple  Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction converts the low FP32 value in the second source operand\n   to a FP16 value in the low element of the destination operand.\n\n   When the conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register.\n\n   Bits 127:16 of the destination operand are copied from the corresponding\n   bits of the first source operand. Bits MAXVL-1:128 of the destination\n   operand are zeroed. The low FP16 element of the destination is updated\n   according to the writemask.\n"],
	["eacceptcopy", "                    EACCEPTCOPY \u2014 Initialize a Pending Page\n\n                            64/32 bit    CPUID                                \n   Opcode/Instruction Op/En Mode Support Feature Description\n                                         Flag    \n                                                 This leaf function           \n   EAX = 07H          IR    V/V          SGX2    initializes a dynamically    \n   ENCLU[EACCEPTCOPY]                            allocated EPC page from      \n                                                 another page in the EPC.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX                    RBX          RCX                   RDX        \n                     Return                  Address of the        Address of \n   IR    EACCEPTCOPY Error Code Address of a destination EPC page  the source \n         (In)        (Out)      SECINFO (In) (In)                  EPC page   \n                                                                   (In)       \n\n  Description \u00b6\n\n   This leaf function copies the contents of an existing EPC page into an\n   uninitialized EPC page (created by EAUG). After initialization, the\n   instruction may also modify the access rights associated with the\n   destination EPC page. This instruction leaf can only be executed when\n   inside the enclave.\n\n   RBX contains the effective address of a SECINFO structure while RCX and\n   RDX each contain the effective address of an EPC page. The table below\n   provides additional information on the memory parameter of the EACCEPTCOPY\n   leaf function.\n\nEACCEPTCOPY Memory Parameter Semantics \u00b6\n\n   SECINFO               EPCPAGE (Destination)          EPCPAGE (Source)      \n   Read access permitted Read/Write access permitted by Read access permitted \n   by Non Enclave        Enclave                        by Enclave            \n\n   The instruction faults if any of the following:\n\nEACCEPTCOPY Faulting Conditions \u00b6\n\n   The operands are not        If security attributes of the SECINFO page     \n   properly aligned.           make the page inaccessible.                    \n   The EPC page is locked by   If security attributes of the source EPC page  \n   another thread.             make the page inaccessible.                    \n   The EPC page is not valid.  RBX does not contain an effective address in   \n                               an EPC page in the running enclave.            \n   SECINFO contains an invalid RCX/RDX does not contain an effective address  \n   request.                    of an EPC page in the running enclave.         \n\n   The error codes are:\n\n   Error Code (see Table 38-4)  Description                                   \n   No Error                     EACCEPTCOPY successful.                       \n   SGX_PAGE_ATTRIBUTES_MISMATCH The attributes of the target EPC page do not  \n                                match the expected values.                    \n\n   Table 38-57. EACCEPTCOPY Return Value in RAX\n\n  Concurrency Restrictions \u00b6\n\n                                Base Concurrency Restrictions\n   Leaf        Parameter        Access     On Conflict SGX_CONFLICT VM Exit   \n                                                       Qualification          \n               Target [DS:RCX]  Concurrent \n   EACCEPTCOPY Source [DS:RDX]  Concurrent \n               SECINFO [DS:RBX] Concurrent \n\n   Table 38-58. Base Concurrency Restrictions of EACCEPTCOPY\n\n                      Additional Concurrency Restrictions\n                      vs. EACCEPT,                                       \n                      EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\nLeaf        Parameter EMODPE, EMODPR,     EINIT\n                      EMODT      \n                      Access     On       Access     On       Access     On       \n                                 Conflict            Conflict            Conflict \n            Target    Exclusive  #GP      Concurrent          Concurrent \n            [DS:RCX]  \nEACCEPTCOPY Source    Concurrent          Concurrent          Concurrent \n            [DS:RDX]  \n            SECINFO   Concurrent          Concurrent          Concurrent \n            [DS:RBX]  \n\n   Table 38-59. Additional Concurrency Restrictions of EACCEPTCOPY\n\n  Flags Affected \u00b6\n\n   Sets ZF if page is not modifiable, otherwise cleared. Clears CF, PF, AF,\n   OF, SF.\n"],
	["punpckhbw:punpckhwd:punpckhdq:punpckhqdq", "          PUNPCKHBW/PUNPCKHWD/PUNPCKHDQ/PUNPCKHQDQ \u2014 Unpack High Data\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   NP 0F 68 /r^1 PUNPCKHBW                          Unpack and interleave     \n   mm, mm/m64              A     V/V       MMX      high-order bytes from mm  \n                                                    and mm/m64 into mm.       \n                                                    Unpack and interleave     \n   66 0F 68 /r PUNPCKHBW   A     V/V       SSE2     high-order bytes from     \n   xmm1, xmm2/m128                                  xmm1 and xmm2/m128 into   \n                                                    xmm1.                     \n   NP 0F 69 /r^1 PUNPCKHWD                          Unpack and interleave     \n   mm, mm/m64              A     V/V       MMX      high-order words from mm  \n                                                    and mm/m64 into mm.       \n                                                    Unpack and interleave     \n   66 0F 69 /r PUNPCKHWD   A     V/V       SSE2     high-order words from     \n   xmm1, xmm2/m128                                  xmm1 and xmm2/m128 into   \n                                                    xmm1.                     \n                                                    Unpack and interleave     \n   NP 0F 6A /r^1 PUNPCKHDQ A     V/V       MMX      high-order doublewords    \n   mm, mm/m64                                       from mm and mm/m64 into   \n                                                    mm.                       \n                                                    Unpack and interleave     \n   66 0F 6A /r PUNPCKHDQ   A     V/V       SSE2     high-order doublewords    \n   xmm1, xmm2/m128                                  from xmm1 and xmm2/m128   \n                                                    into xmm1.                \n                                                    Unpack and interleave     \n   66 0F 6D /r PUNPCKHQDQ  A     V/V       SSE2     high-order quadwords from \n   xmm1, xmm2/m128                                  xmm1 and xmm2/m128 into   \n                                                    xmm1.                     \n   VEX.128.66.0F.WIG 68/r                           Interleave high-order     \n   VPUNPCKHBW xmm1,xmm2,   B     V/V       AVX      bytes from xmm2 and       \n   xmm3/m128                                        xmm3/m128 into xmm1.      \n   VEX.128.66.0F.WIG 69/r                           Interleave high-order     \n   VPUNPCKHWD xmm1,xmm2,   B     V/V       AVX      words from xmm2 and       \n   xmm3/m128                                        xmm3/m128 into xmm1.      \n   VEX.128.66.0F.WIG 6A/r                           Interleave high-order     \n   VPUNPCKHDQ xmm1, xmm2,  B     V/V       AVX      doublewords from xmm2 and \n   xmm3/m128                                        xmm3/m128 into xmm1.      \n   VEX.128.66.0F.WIG 6D/r                           Interleave high-order     \n   VPUNPCKHQDQ xmm1, xmm2, B     V/V       AVX      quadword from xmm2 and    \n   xmm3/m128                                        xmm3/m128 into xmm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 68 /r                          Interleave high-order     \n   VPUNPCKHBW ymm1, ymm2,  B     V/V       AVX2     bytes from ymm2 and       \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 69 /r                          Interleave high-order     \n   VPUNPCKHWD ymm1, ymm2,  B     V/V       AVX2     words from ymm2 and       \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 6A /r                          Interleave high-order     \n   VPUNPCKHDQ ymm1, ymm2,  B     V/V       AVX2     doublewords from ymm2 and \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   VEX.256.66.0F.WIG 6D /r                          Interleave high-order     \n   VPUNPCKHQDQ ymm1, ymm2, B     V/V       AVX2     quadword from ymm2 and    \n   ymm3/m256                                        ymm3/m256 into ymm1       \n                                                    register.                 \n   EVEX.128.66.0F.WIG 68                            Interleave high-order     \n   /r VPUNPCKHBW xmm1                      AVX512VL bytes from xmm2 and       \n   {k1}{z}, xmm2,          C     V/V       AVX512BW xmm3/m128 into xmm1       \n   xmm3/m128                                        register using k1 write   \n                                                    mask.                     \n   EVEX.128.66.0F.WIG 69                            Interleave high-order     \n   /r VPUNPCKHWD xmm1                      AVX512VL words from xmm2 and       \n   {k1}{z}, xmm2,          C     V/V       AVX512BW xmm3/m128 into xmm1       \n   xmm3/m128                                        register using k1 write   \n                                                    mask.                     \n   EVEX.128.66.0F.W0 6A /r                          Interleave high-order     \n   VPUNPCKHDQ xmm1                         AVX512VL doublewords from xmm2 and \n   {k1}{z}, xmm2,          D     V/V       AVX512F  xmm3/m128/m32bcst into    \n   xmm3/m128/m32bcst                                xmm1 register using k1    \n                                                    write mask.               \n   EVEX.128.66.0F.W1 6D /r                          Interleave high-order     \n   VPUNPCKHQDQ xmm1                        AVX512VL quadword from xmm2 and    \n   {k1}{z}, xmm2,          D     V/V       AVX512F  xmm3/m128/m64bcst into    \n   xmm3/m128/m64bcst                                xmm1 register using k1    \n                                                    write mask.               \n   EVEX.256.66.0F.WIG 68                            Interleave high-order     \n   /r VPUNPCKHBW ymm1                      AVX512VL bytes from ymm2 and       \n   {k1}{z}, ymm2,          C     V/V       AVX512BW ymm3/m256 into ymm1       \n   ymm3/m256                                        register using k1 write   \n                                                    mask.                     \n   EVEX.256.66.0F.WIG 69                            Interleave high-order     \n   /r VPUNPCKHWD ymm1                      AVX512VL words from ymm2 and       \n   {k1}{z}, ymm2,          C     V/V       AVX512BW ymm3/m256 into ymm1       \n   ymm3/m256                                        register using k1 write   \n                                                    mask.                     \n   EVEX.256.66.0F.W0 6A /r                          Interleave high-order     \n   VPUNPCKHDQ ymm1                         AVX512VL doublewords from ymm2 and \n   {k1}{z}, ymm2,          D     V/V       AVX512F  ymm3/m256/m32bcst into    \n   ymm3/m256/m32bcst                                ymm1 register using k1    \n                                                    write mask.               \n   EVEX.256.66.0F.W1 6D /r                          Interleave high-order     \n   VPUNPCKHQDQ ymm1                        AVX512VL quadword from ymm2 and    \n   {k1}{z}, ymm2,          D     V/V       AVX512F  ymm3/m256/m64bcst into    \n   ymm3/m256/m64bcst                                ymm1 register using k1    \n                                                    write mask.               \n   EVEX.512.66.0F.WIG 68/r                          Interleave high-order     \n   VPUNPCKHBW zmm1         C     V/V       AVX512BW bytes from zmm2 and       \n   {k1}{z}, zmm2,                                   zmm3/m512 into zmm1       \n   zmm3/m512                                        register.                 \n   EVEX.512.66.0F.WIG 69/r                          Interleave high-order     \n   VPUNPCKHWD zmm1         C     V/V       AVX512BW words from zmm2 and       \n   {k1}{z}, zmm2,                                   zmm3/m512 into zmm1       \n   zmm3/m512                                        register.                 \n   EVEX.512.66.0F.W0 6A /r                          Interleave high-order     \n   VPUNPCKHDQ zmm1                                  doublewords from zmm2 and \n   {k1}{z}, zmm2,          D     V/V       AVX512F  zmm3/m512/m32bcst into    \n   zmm3/m512/m32bcst                                zmm1 register using k1    \n                                                    write mask.               \n   EVEX.512.66.0F.W1 6D /r                          Interleave high-order     \n   VPUNPCKHQDQ zmm1                                 quadword from zmm2 and    \n   {k1}{z}, zmm2,          D     V/V       AVX512F  zmm3/m512/m64bcst into    \n   zmm3/m512/m64bcst                                zmm1 register using k1    \n                                                    write mask.               \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Unpacks and interleaves the high-order data elements (bytes, words,\n   doublewords, or quadwords) of the destination operand (first operand) and\n   source operand (second operand) into the destination operand. Figure 4-20\n   shows the unpack operation for bytes in 64-bit operands. The low-order\n   data elements are ignored.\n\n   SRC Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 X7 X6 X5 X4 X3 X2 X1 X0 DEST DEST Y7 X7 Y6 X6\n   Y5 X5 Y4 X4 Figure 4-20. PUNPCKHBW Instruction Operation Using 64-bit\n   Operands\n\n   255 ^31 0 255 31 0\n\n   SRC Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 X7 X6 X5 X4 X3 X2 X1 X0 255 0 DEST Y7 X7 Y6 X6\n   Y3 X3 Y2 X2 Figure 4-21. 256-bit VPUNPCKHDQ Instruction Operation\n\n   When the source data comes from a 64-bit memory operand, the full 64-bit\n   operand is accessed from memory, but the instruction uses only the\n   high-order 32 bits. When the source data comes from a 128-bit memory\n   operand, an implementation may fetch only the appropriate 64 bits;\n   however, alignment to a 16-byte boundary and normal segment checking will\n   still be enforced.\n\n   The (V)PUNPCKHBW instruction interleaves the high-order bytes of the\n   source and destination operands, the (V)PUNPCKHWD instruction interleaves\n   the high-order words of the source and destination operands, the\n   (V)PUNPCKHDQ instruction interleaves the high-order doubleword (or\n   doublewords) of the source and destination operands, and the (V)PUNPCKHQDQ\n   instruction interleaves the high-order quadwords of the source and\n   destination operands.\n\n   These instructions can be used to convert bytes to words, words to\n   doublewords, doublewords to quadwords, and quadwords to double quadwords,\n   respectively, by placing all 0s in the source operand. Here, if the source\n   operand contains all 0s, the result (stored in the destination operand)\n   contains zero extensions of the high-order data elements from the original\n   value in the destination operand. For example, with the (V)PUNPCKHBW\n   instruction the high-order bytes are zero extended (that is, unpacked into\n   unsigned word integers), and with the (V)PUNPCKHWD instruction, the\n   high-order words are zero extended (unpacked into unsigned doubleword\n   integers).\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE versions 64-bit operand: The source operand can be an MMX\n   technology register or a 64-bit memory location. The destination operand\n   is an MMX technology register.\n\n   128-bit Legacy SSE versions: The second source operand is an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged.\n\n   VEX.128 encoded versions: The second source operand is an XMM register or\n   a 128-bit memory location. The first source operand and destination\n   operands are XMM registers. Bits (MAXVL-1:128) of the destination YMM\n   register are zeroed.\n\n   VEX.256 encoded version: The second source operand is an YMM register or\n   an 256-bit memory location. The first source operand and destination\n   operands are YMM registers.\n\n   EVEX encoded VPUNPCKHDQ/QDQ: The second source operand is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32/64-bit memory location. The first source operand and\n   destination operands are ZMM/YMM/XMM registers. The destination is\n   conditionally updated with writemask k1.\n\n   EVEX encoded VPUNPCKHWD/BW: The second source operand is a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location. The first source operand and\n   destination operands are ZMM/YMM/XMM registers. The destination is\n   conditionally updated with writemask k1.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["blendvpd", "    BLENDVPD \u2014 Variable Blend Packed Double Precision Floating-Point Values\n\n                                 64/32-bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                           Flag    \n                                                   Select packed double       \n   66 0F 38 15 /r BLENDVPD                         precision floating-point   \n   xmm1, xmm2/m128 ,       RM0   V/V       SSE4_1  values from xmm1 and xmm2  \n   <XMM0>                                          from mask specified in     \n                                                   XMM0 and store the values  \n                                                   in xmm1.                   \n                                                   Conditionally copy double  \n   VEX.128.66.0F3A.W0 4B                           precision floating-point   \n   /r /is4 VBLENDVPD xmm1, RVMR  V/V       AVX     values from xmm2 or        \n   xmm2, xmm3/m128, xmm4                           xmm3/m128 to xmm1, based   \n                                                   on mask bits in the mask   \n                                                   operand, xmm4.             \n                                                   Conditionally copy double  \n   VEX.256.66.0F3A.W0 4B                           precision floating-point   \n   /r /is4 VBLENDVPD ymm1, RVMR  V/V       AVX     values from ymm2 or        \n   ymm2, ymm3/m256, ymm4                           ymm3/m256 to ymm1, based   \n                                                   on mask bits in the mask   \n                                                   operand, ymm4.             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM0   ModRM:reg (r, w) ModRM:r/m (r) implicit XMM0 N/A       \n   RVMR  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8[7:4] \n\nDescription \u00b6\n\n   Conditionally copy each quadword data element of double precision\n   floating-point value from the second source operand and the first source\n   operand depending on mask bits defined in the mask register operand. The\n   mask bits are the most significant bit in each quadword element of the\n   mask register.\n\n   Each quadword element of the destination operand is copied from:\n\n     * the corresponding quadword element in the second source operand, if a\n       mask bit is \u201c1\u201d; or\n     * the corresponding quadword element in the first source operand, if a\n       mask bit is \u201c0\u201d\n\n   The register assignment of the implicit mask operand for BLENDVPD is\n   defined to be the architectural register XMM0.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand is the same. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged. The mask register operand is\n   implicitly defined to be the architectural register XMM0. An attempt to\n   execute BLENDVPD with a VEX prefix will cause #UD.\n\n   VEX.128 encoded version: The first source operand and the destination\n   operand are XMM registers. The second source operand is an XMM register or\n   128-bit memory location. The mask operand is the third source register,\n   and encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of\n   imm8 are ignored. In 32-bit mode, imm8[7] is ignored. The upper bits\n   (MAXVL-1:128) of the corresponding YMM register (destination register) are\n   zeroed. VEX.W must be 0, otherwise, the instruction will #UD.\n\n   VEX.256 encoded version: The first source operand and destination operand\n   are YMM registers. The second source operand can be a YMM register or a\n   256-bit memory location. The mask operand is the third source register,\n   and encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of\n   imm8 are ignored. In 32-bit mode, imm8[7] is ignored. VEX.W must be 0,\n   otherwise, the instruction will #UD.\n\n   VBLENDVPD permits the mask to be any XMM or YMM register. In contrast,\n   BLENDVPD treats XMM0 implicitly as the mask and do not support\n   non-destructive destination operation.\n"],
	["vpmadd52luq", "VPMADD52LUQ \u2014 Packed Multiply of Unsigned 52-Bit Integers and Add the Low 52-Bit\n                         Productsto Qword Accumulators\n\n                                   64/32 Bit                                  \n   Opcode/Instruction        Op/En Mode      CPUID       Description\n                                   Support   \n                                                         Multiply unsigned    \n                                                         52-bit integers in   \n                                                         xmm2 and xmm3/m128   \n   EVEX.128.66.0F38.W1 B4 /r                 AVX512_IFMA and add the low 52   \n   VPMADD52LUQ xmm1 {k1}{z}, A     V/V       AVX512VL    bits of the 104-bit  \n   xmm2,xmm3/m128/m64bcst                                product to the qword \n                                                         unsigned integers in \n                                                         xmm1 using writemask \n                                                         k1.                  \n                                                         Multiply unsigned    \n                                                         52-bit integers in   \n                                                         ymm2 and ymm3/m256   \n   EVEX.256.66.0F38.W1 B4 /r                 AVX512_IFMA and add the low 52   \n   VPMADD52LUQ ymm1 {k1}{z}, A     V/V       AVX512VL    bits of the 104-bit  \n   ymm2, ymm3/m256/m64bcst                               product to the qword \n                                                         unsigned integers in \n                                                         ymm1 using writemask \n                                                         k1.                  \n                                                         Multiply unsigned    \n                                                         52-bit integers in   \n                                                         zmm2 and zmm3/m512   \n   EVEX.512.66.0F38.W1 B4 /r                             and add the low 52   \n   VPMADD52LUQ zmm1 {k1}{z}, A     V/V       AVX512_IFMA bits of the 104-bit  \n   zmm2,zmm3/m512/m64bcst                                product to the qword \n                                                         unsigned integers in \n                                                         zmm1 using writemask \n                                                         k1.                  \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3    Operand 4 \n   A     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m(r) N/A       \n\n  Description \u00b6\n\n   Multiplies packed unsigned 52-bit integers in each qword element of the\n   first source operand (the second operand) with the packed unsigned 52-bit\n   integers in the corresponding elements of the second source operand (the\n   third operand) to form packed 104-bit intermediate results. The low\n   52-bit, unsigned integer of each 104-bit product is added to the\n   corresponding qword unsigned integer of the destination operand (the first\n   operand) under the writemask k1.\n\n   The first source operand is a ZMM/YMM/XMM register. The second source\n   operand can be a ZMM/YMM/XMM register, a 512/256/128-bit memory location\n   or a 512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is a ZMM/YMM/XMM register conditionally updated with\n   writemask k1 at 64-bit granularity.\n\n  Flags Affected \u00b6\n\n   None.\n"],
	["vrsqrt14ss", "  VRSQRT14SS \u2014 Compute Approximate Reciprocal of Square Root of Scalar Float32\n                                     Value\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature Description\n                                 Support   Flag    \n                                                   Computes the approximate   \n                                                   reciprocal square root of  \n                                                   the scalar                 \n                                                   single-precision           \n   EVEX.LLIG.66.0F38.W0 4F                         floating-point value in    \n   /r VRSQRT14SS xmm1      A     V/V       AVX512F xmm3/m32 and stores the    \n   {k1}{z}, xmm2, xmm3/m32                         result in the low          \n                                                   doubleword element of xmm1 \n                                                   using writemask k1.        \n                                                   Bits[127:32] of xmm2 is    \n                                                   copied to xmm1[127:32].    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1     Operand 2    Operand 3     Operand 4 \n   A     Tuple1 Scalar ModRM:reg (w) VEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Computes of the approximate reciprocal of the square root of the scalar\n   single-precision floating-point value in the low doubleword element of the\n   source operand (the second operand) and stores the result in the low\n   doubleword element of the destination operand (the first operand)\n   according to the writemask. The maximum relative error for this\n   approximation is less than 2^-14. The source operand can be an XMM\n   register or a 32-bit memory location. The destination operand is an XMM\n   register.\n\n   Bits (127:32) of the XMM register destination are copied from\n   corresponding bits in the first source operand. Bits (MAXVL-1:128) of the\n   destination register are zeroed.\n\n   The VRSQRT14SS instruction is not affected by the rounding control bits in\n   the MXCSR register. When a source value is a 0.0, an \u221e with the sign of\n   the source value is returned. When the source operand is an \u221e, zero with\n   the sign of the source value is returned. A denormal source value is\n   treated as zero only if DAZ bit is set in MXCSR. Otherwise it is treated\n   correctly and performs the approximation with the specified masked\n   response. When a source value is a negative value (other than 0.0) a\n   floating-point indefinite is returned. When a source value is an SNaN or\n   QNaN, the SNaN is converted to a QNaN or the source QNaN is returned.\n\n   MXCSR exception flags are not affected by this instruction and\n   floating-point exceptions are not reported.\n\n  A numerically exact implementation of VRSQRT14xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["vreduceps", "     VREDUCEPS \u2014 Perform Reduction Transformation on Packed Float32 Values\n\n                                    64/32 bit CPUID                           \n   Opcode/Instruction         Op/En Mode      Feature  Description\n                                    Support   Flag     \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed                 \n                                                       single-precision       \n                                                       floating-point values  \n   EVEX.128.66.0F3A.W0 56 /r                  AVX512VL in xmm2/m128/m32bcst   \n   ib VREDUCEPS xmm1 {k1}{z}, A     V/V       AVX512DQ by subtracting a       \n   xmm2/m128/m32bcst, imm8                             number of fraction     \n                                                       bits specified by the  \n                                                       imm8 field. Stores the \n                                                       result in xmm1         \n                                                       register under         \n                                                       writemask k1.          \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed                 \n                                                       single-precision       \n                                                       floating-point values  \n   EVEX.256.66.0F3A.W0 56 /r                  AVX512VL in ymm2/m256/m32bcst   \n   ib VREDUCEPS ymm1 {k1}{z}, A     V/V       AVX512DQ by subtracting a       \n   ymm2/m256/m32bcst, imm8                             number of fraction     \n                                                       bits specified by the  \n                                                       imm8 field. Stores the \n                                                       result in ymm1         \n                                                       register under         \n                                                       writemask k1.          \n                                                       Perform reduction      \n                                                       transformation on      \n                                                       packed                 \n                                                       single-precision       \n   EVEX.512.66.0F3A.W0 56 /r                           floating-point values  \n   ib VREDUCEPS zmm1 {k1}{z},                          in zmm2/m512/m32bcst   \n   zmm2/m512/m32bcst{sae},    A     V/V       AVX512DQ by subtracting a       \n   imm8                                                number of fraction     \n                                                       bits specified by the  \n                                                       imm8 field. Stores the \n                                                       result in zmm1         \n                                                       register under         \n                                                       writemask k1.          \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\n  Description \u00b6\n\n   Perform reduction transformation of the packed binary encoded\n   single-precision floating-point values in the source operand (the second\n   operand) and store the reduced results in binary floating-point format to\n   the destination operand (the first operand) under the writemask k1.\n\n   The reduction transformation subtracts the integer part and the leading M\n   fractional bits from the binary floating-point source value, where M is a\n   unsigned integer specified by imm8[7:4], see Figure 5-28. Specifically,\n   the reduction transformation can be expressed as:\n\n   dest = src \u2013 (ROUND(2^M*src))*2^-M;\n\n   where \u201cRound()\u201d treats \u201csrc\u201d, \u201c2^M\u201d, and their product as binary\n   floating-point numbers with normalized significand and biased exponents.\n\n   The magnitude of the reduced result can be expressed by considering src=\n   2^p*man2,\n\n   where \u2018man2\u2019 is the normalized significand and \u2018p\u2019 is the unbiased\n   exponent\n\n   Then if RC = RNE: 0<=|Reduced Result|<=2^p-M-1\n\n   Then if RC =\u0338 RNE: 0<=|Reduced Result|<2^p-M\n\n   This instruction might end up with a precision exception set. However, in\n   case of SPE set (i.e., Suppress Precision Exception, which is imm8[3]=1),\n   no precision exception is reported.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   Handling of special case of input values are listed in Table 5-29.\n"],
	["vinserti128:vinserti32x4:vinserti64x2:vinserti32x8:vinserti64x4", "    VINSERTI128/VINSERTI32x4/VINSERTI64x2/VINSERTI32x8/VINSERTI64x4 \u2014 Insert\n                              PackedInteger Values\n\n                             Op / 64/32 Bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Insert 128 bits of       \n   VEX.256.66.0F3A.W0 38 /r                          integer data from        \n   ib VINSERTI128 ymm1,      A    V/V       AVX2     xmm3/m128 and the        \n   ymm2, xmm3/m128, imm8                             remaining values from    \n                                                     ymm2 into ymm1.          \n                                                     Insert 128 bits of       \n   EVEX.256.66.0F3A.W0 38 /r                         packed doubleword        \n   ib VINSERTI32X4 ymm1                     AVX512VL integer values from      \n   {k1}{z}, ymm2, xmm3/m128, C    V/V       AVX512F  xmm3/m128 and the        \n   imm8                                              remaining values from    \n                                                     ymm2 into ymm1 under     \n                                                     writemask k1.            \n                                                     Insert 128 bits of       \n   EVEX.512.66.0F3A.W0 38 /r                         packed doubleword        \n   ib VINSERTI32X4 zmm1                              integer values from      \n   {k1}{z}, zmm2, xmm3/m128, C    V/V       AVX512F  xmm3/m128 and the        \n   imm8                                              remaining values from    \n                                                     zmm2 into zmm1 under     \n                                                     writemask k1.            \n                                                     Insert 128 bits of       \n   EVEX.256.66.0F3A.W1 38 /r                         packed quadword integer  \n   ib VINSERTI64X2 ymm1      B    V/V       AVX512VL values from xmm3/m128    \n   {k1}{z}, ymm2, xmm3/m128,                AVX512DQ and the remaining values \n   imm8                                              from ymm2 into ymm1      \n                                                     under writemask k1.      \n                                                     Insert 128 bits of       \n   EVEX.512.66.0F3A.W1 38 /r                         packed quadword integer  \n   ib VINSERTI64X2 zmm1      B    V/V       AVX512DQ values from xmm3/m128    \n   {k1}{z}, zmm2, xmm3/m128,                         and the remaining values \n   imm8                                              from zmm2 into zmm1      \n                                                     under writemask k1.      \n                                                     Insert 256 bits of       \n   EVEX.512.66.0F3A.W0 3A /r                         packed doubleword        \n   ib VINSERTI32X8 zmm1                              integer values from      \n   {k1}{z}, zmm2, ymm3/m256, D    V/V       AVX512DQ ymm3/m256 and the        \n   imm8                                              remaining values from    \n                                                     zmm2 into zmm1 under     \n                                                     writemask k1.            \n                                                     Insert 256 bits of       \n   EVEX.512.66.0F3A.W1 3A /r                         packed quadword integer  \n   ib VINSERTI64X4 zmm1      C    V/V       AVX512F  values from ymm3/m256    \n   {k1}{z}, zmm2, ymm3/m256,                         and the remaining values \n   imm8                                              from zmm2 into zmm1      \n                                                     under writemask k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (w) VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   B     Tuple2     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n   C     Tuple4     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n   D     Tuple8     ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\n  Description \u00b6\n\n   VINSERTI32x4 and VINSERTI64x2 inserts 128-bits of packed integer values\n   from the second source operand (the third operand) into the destination\n   operand (the first operand) at an 128-bit granular offset multiplied by\n   imm8[0] (256-bit) or imm8[1:0]. The remaining portions of the destination\n   are copied from the corresponding fields of the first source operand (the\n   second operand). The second source operand can be either an XMM register\n   or a 128-bit memory location. The high 6/7bits of the immediate are\n   ignored. The destination operand is a ZMM/YMM register and updated at 32\n   and 64-bit granularity according to the writemask.\n\n   VINSERTI32x8 and VINSERTI64x4 inserts 256-bits of packed integer values\n   from the second source operand (the third operand) into the destination\n   operand (the first operand) at a 256-bit granular offset multiplied by\n   imm8[0]. The remaining portions of the destination are copied from the\n   corresponding fields of the first source operand (the second operand). The\n   second source operand can be either an YMM register or a 256-bit memory\n   location. The upper bits of the immediate are ignored. The destination\n   operand is a ZMM register and updated at 32 and 64-bit granularity\n   according to the writemask.\n\n   VINSERTI128 inserts 128-bits of packed integer data from the second source\n   operand (the third operand) into the destination operand (the first\n   operand) at a 128-bit granular offset multiplied by imm8[0]. The remaining\n   portions of the destination are copied from the corresponding fields of\n   the first source operand (the second operand). The\n\n   second source operand can be either an XMM register or a 128-bit memory\n   location. The high 7 bits of the immediate are ignored. VEX.L must be 1,\n   otherwise attempt to execute this instruction with VEX.L=0 will cause #UD.\n"],
	["vrsqrt28ps", "   VRSQRT28PS \u2014 Approximation to the Reciprocal Square Root of Packed Single\n       PrecisionFloating-Point Values With Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes approximations   \n                                                    to the Reciprocal square  \n   EVEX.512.66.0F38.W0 CC                           root (<2^-28 relative     \n   /r VRSQRT28PS zmm1                               error) of the packed      \n   {k1}{z},                A     V/V       AVX512ER single-precision          \n   zmm2/m512/m32bcst {sae}                          floating-point values     \n                                                    from zmm2/m512/m32bcst    \n                                                    and stores result in      \n                                                    zmm1with writemask k1.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2  \n   Operand 3 Operand 4                   \n   A                                     Full ModRM:reg (w) ModRM:r/m (r) \n                                         N/A N/A                          \n\n  Description \u00b6\n\n   Computes the reciprocal square root of the float32 values in the source\n   operand (the second operand) and store the results to the destination\n   operand (the first operand). The approximate reciprocal is evaluated with\n   less than 2^-28 of maximum relative error prior to final rounding. The\n   final results is rounded to < 2^-23 relative error before written to the\n   destination.\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. Negative (non-zero) source numbers, as well as -\u221e,\n   return the canonical NaN and set the Invalid Flag (#I).\n\n   A value of -0 must return -\u221e and set the DivByZero flags (#Z). Negative\n   numbers should return NaN and set the Invalid flag (#I). Note however that\n   the instruction flush input denormals to zero of the same sign, so\n   negative denormals return -\u221e and set the DivByZero flag.\n\n   The source operand is a ZMM register, a 512-bit memory location, or a\n   512-bit vector broadcasted from a 32-bit memory location. The destination\n   operand is a ZMM register, conditionally updated using writemask k1.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n  A numerically exact implementation of VRSQRT28xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
	["rdtscp", "               RDTSCP \u2014 Read Time-Stamp Counter and Processor ID\n\n   Opcode*  Instruction Op/En 64-Bit Compat/Leg Description                   \n                              Mode   Mode       \n                                                Read 64-bit time-stamp        \n   0F 01 F9 RDTSCP      ZO    Valid  Valid      counter and IA32_TSC_AUX      \n                                                value into EDX:EAX and ECX.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Reads the current value of the processor\u2019s time-stamp counter (a 64-bit\n   MSR) into the EDX:EAX registers and also reads the value of the\n   IA32_TSC_AUX MSR (address C0000103H) into the ECX register. The EDX\n   register is loaded with the high-order 32 bits of the IA32_TSC MSR; the\n   EAX register is loaded with the low-order 32 bits of the IA32_TSC MSR; and\n   the ECX register is loaded with the low-order 32-bits of IA32_TSC_AUX MSR.\n   On processors that support the Intel 64 architecture, the high-order 32\n   bits of each of RAX, RDX, and RCX are cleared.\n\n   The processor monotonically increments the time-stamp counter MSR every\n   clock cycle and resets it to 0 whenever the processor is reset. See \u201cTime\n   Stamp Counter\u201d in Chapter 18 of the Intel^\u00ae 64 and IA-32 Architectures\n   Software Developer\u2019s Manual, Volume 3B, for specific details of the time\n   stamp counter behavior.\n\n   The time stamp disable (TSD) flag in register CR4 restricts the use of the\n   RDTSCP instruction as follows. When the flag is clear, the RDTSCP\n   instruction can be executed at any privilege level; when the flag is set,\n   the instruction can only be executed at privilege level 0.\n\n   The RDTSCP instruction is not a serializing instruction, but it does wait\n   until all previous instructions have executed and all previous loads are\n   globally visible.^1 But it does not wait for previous stores to be\n   globally visible, and subsequent instructions may begin execution before\n   the read operation is performed. The following items may guide software\n   seeking to order executions of RDTSCP:\n\n     * If software requires RDTSCP to be executed only after all previous\n       stores are globally visible, it can execute MFENCE immediately before\n       RDTSCP.\n     * If software requires RDTSCP to be executed prior to execution of any\n       subsequent instruction (including any memory accesses), it can execute\n       LFENCE immediately after RDTSCP.\n\n   See \u201cChanges to Instruction Behavior in VMX Non-Root Operation\u201d in Chapter\n   26 of the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n   Volume 3C, for more information about the behavior of this instruction in\n   VMX non-root operation.\n\n     1. A load is considered to become globally visible when the value to be\n     loaded is determined.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pcmpgtb:pcmpgtw:pcmpgtd", "   PCMPGTB/PCMPGTW/PCMPGTD \u2014 Compare Packed Signed Integers for Greater Than\n\n                               64/32 bit CPUID                                \n   Opcode/Instruction    Op/En Mode      Feature  Description\n                               Support   Flag     \n   NP 0F 64 /r^1 PCMPGTB                          Compare packed signed byte  \n   mm, mm/m64            A     V/V       MMX      integers in mm and mm/m64   \n                                                  for greater than.           \n   66 0F 64 /r PCMPGTB                            Compare packed signed byte  \n   xmm1, xmm2/m128       A     V/V       SSE2     integers in xmm1 and        \n                                                  xmm2/m128 for greater than. \n   NP 0F 65 /r^1 PCMPGTW                          Compare packed signed word  \n   mm, mm/m64            A     V/V       MMX      integers in mm and mm/m64   \n                                                  for greater than.           \n   66 0F 65 /r PCMPGTW                            Compare packed signed word  \n   xmm1, xmm2/m128       A     V/V       SSE2     integers in xmm1 and        \n                                                  xmm2/m128 for greater than. \n                                                  Compare packed signed       \n   NP 0F 66 /r^1 PCMPGTD A     V/V       MMX      doubleword integers in mm   \n   mm, mm/m64                                     and mm/m64 for greater      \n                                                  than.                       \n                                                  Compare packed signed       \n   66 0F 66 /r PCMPGTD   A     V/V       SSE2     doubleword integers in xmm1 \n   xmm1, xmm2/m128                                and xmm2/m128 for greater   \n                                                  than.                       \n   VEX.128.66.0F.WIG 64                           Compare packed signed byte  \n   /r VPCMPGTB xmm1,     B     V/V       AVX      integers in xmm2 and        \n   xmm2, xmm3/m128                                xmm3/m128 for greater than. \n   VEX.128.66.0F.WIG 65                           Compare packed signed word  \n   /r VPCMPGTW xmm1,     B     V/V       AVX      integers in xmm2 and        \n   xmm2, xmm3/m128                                xmm3/m128 for greater than. \n   VEX.128.66.0F.WIG 66                           Compare packed signed       \n   /r VPCMPGTD xmm1,     B     V/V       AVX      doubleword integers in xmm2 \n   xmm2, xmm3/m128                                and xmm3/m128 for greater   \n                                                  than.                       \n   VEX.256.66.0F.WIG 64                           Compare packed signed byte  \n   /r VPCMPGTB ymm1,     B     V/V       AVX2     integers in ymm2 and        \n   ymm2, ymm3/m256                                ymm3/m256 for greater than. \n   VEX.256.66.0F.WIG 65                           Compare packed signed word  \n   /r VPCMPGTW ymm1,     B     V/V       AVX2     integers in ymm2 and        \n   ymm2, ymm3/m256                                ymm3/m256 for greater than. \n   VEX.256.66.0F.WIG 66                           Compare packed signed       \n   /r VPCMPGTD ymm1,     B     V/V       AVX2     doubleword integers in ymm2 \n   ymm2, ymm3/m256                                and ymm3/m256 for greater   \n                                                  than.                       \n                                                  Compare Greater between     \n                                                  int32 vector xmm2 and int32 \n   EVEX.128.66.0F.W0 66                           vector xmm3/m128/m32bcst,   \n   /r VPCMPGTD k1 {k2},  C     V/V       AVX512VL and set vector mask k1 to   \n   xmm2,                                 AVX512F  reflect the zero/nonzero    \n   xmm3/m128/m32bcst                              status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n                                                  Compare Greater between     \n                                                  int32 vector ymm2 and int32 \n   EVEX.256.66.0F.W0 66                           vector ymm3/m256/m32bcst,   \n   /r VPCMPGTD k1 {k2},  C     V/V       AVX512VL and set vector mask k1 to   \n   ymm2,                                 AVX512F  reflect the zero/nonzero    \n   ymm3/m256/m32bcst                              status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n                                                  Compare Greater between     \n   EVEX.512.66.0F.W0 66                           int32 elements in zmm2 and  \n   /r VPCMPGTD k1 {k2},  C     V/V       AVX512F  zmm3/m512/m32bcst, and set  \n   zmm2,                                          destination k1 according to \n   zmm3/m512/m32bcst                              the comparison results      \n                                                  under writemask. k2.        \n                                                  Compare packed signed byte  \n                                                  integers in xmm2 and        \n   EVEX.128.66.0F.WIG 64                          xmm3/m128 for greater than, \n   /r VPCMPGTB k1 {k2},  D     V/V       AVX512VL and set vector mask k1 to   \n   xmm2, xmm3/m128                       AVX512BW reflect the zero/nonzero    \n                                                  status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n                                                  Compare packed signed byte  \n                                                  integers in ymm2 and        \n   EVEX.256.66.0F.WIG 64                          ymm3/m256 for greater than, \n   /r VPCMPGTB k1 {k2},  D     V/V       AVX512VL and set vector mask k1 to   \n   ymm2, ymm3/m256                       AVX512BW reflect the zero/nonzero    \n                                                  status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n                                                  Compare packed signed byte  \n                                                  integers in zmm2 and        \n   EVEX.512.66.0F.WIG 64                          zmm3/m512 for greater than, \n   /r VPCMPGTB k1 {k2},  D     V/V       AVX512BW and set vector mask k1 to   \n   zmm2, zmm3/m512                                reflect the zero/nonzero    \n                                                  status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n                                                  Compare packed signed word  \n                                                  integers in xmm2 and        \n   EVEX.128.66.0F.WIG 65                          xmm3/m128 for greater than, \n   /r VPCMPGTW k1 {k2},  D     V/V       AVX512VL and set vector mask k1 to   \n   xmm2, xmm3/m128                       AVX512BW reflect the zero/nonzero    \n                                                  status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n                                                  Compare packed signed word  \n                                                  integers in ymm2 and        \n   EVEX.256.66.0F.WIG 65                          ymm3/m256 for greater than, \n   /r VPCMPGTW k1 {k2},  D     V/V       AVX512VL and set vector mask k1 to   \n   ymm2, ymm3/m256                       AVX512BW reflect the zero/nonzero    \n                                                  status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n                                                  Compare packed signed word  \n                                                  integers in zmm2 and        \n   EVEX.512.66.0F.WIG 65                          zmm3/m512 for greater than, \n   /r VPCMPGTW k1 {k2},  D     V/V       AVX512BW and set vector mask k1 to   \n   zmm2, zmm3/m512                                reflect the zero/nonzero    \n                                                  status of each element of   \n                                                  the result, under           \n                                                  writemask.                  \n\n     1. See note in Section 2.5, \u201cIntel\u00ae AVX and Intel\u00ae SSE Instruction\n     Exception Classification,\u201d in the Intel^\u00ae 64 and IA-32 Architectures\n     Software Developer\u2019s Manual, Volume 2A, and Section 23.25.3, \u201cException\n     Conditions of Legacy SIMD Instructions Operating on MMX Registers,\u201d in\n     the Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual,\n     Volume 3B.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n   D     Full Mem   ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs an SIMD signed compare for the greater value of the packed byte,\n   word, or doubleword integers in the destination operand (first operand)\n   and the source operand (second operand). If a data element in the\n   destination operand is greater than the corresponding date element in the\n   source operand, the corresponding data element in the destination operand\n   is set to all 1s; otherwise, it is set to all 0s.\n\n   The PCMPGTB instruction compares the corresponding signed byte integers in\n   the destination and source operands; the PCMPGTW instruction compares the\n   corresponding signed word integers in the destination and source operands;\n   and the PCMPGTD instruction compares the corresponding signed doubleword\n   integers in the destination and source operands.\n\n   In 64-bit mode and not encoded with VEX/EVEX, using a REX prefix in the\n   form of REX.R permits this instruction to access additional registers\n   (XMM8-XMM15).\n\n   Legacy SSE instructions: The source operand can be an MMX technology\n   register or a 64-bit memory location. The destination operand can be an\n   MMX technology register.\n\n   128-bit Legacy SSE version: The second source operand can be an XMM\n   register or a 128-bit memory location. The first source operand and\n   destination operand are XMM registers. Bits (MAXVL-1:128) of the\n   corresponding YMM destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand can be an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operand are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   register are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n\n   EVEX encoded VPCMPGTD: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. The destination operand (first\n   operand) is a mask register updated according to the writemask k2.\n\n   EVEX encoded VPCMPGTB/W: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location. The destination operand\n   (first operand) is a mask register updated according to the writemask k2.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["fbstp", "                       FBSTP \u2014 Store BCD Integer and Pop\n\n   Opcode  Mode Leg Mode Description                          \n   DF /6                 Store ST(0) in m80bcd and pop ST(0). \n\nDescription \u00b6\n\n   Converts the value in the ST(0) register to an 18-digit packed BCD\n   integer, stores the result in the destination operand, and pops the\n   register stack. If the source value is a non-integral value, it is rounded\n   to an integer value, according to rounding mode specified by the RC field\n   of the FPU control word. To pop the register stack, the processor marks\n   the ST(0) register as empty and increments the stack pointer (TOP) by 1.\n\n   The destination operand specifies the address where the first byte\n   destination value is to be stored. The BCD value (including its sign bit)\n   requires 10 bytes of space in memory.\n\n   The following table shows the results obtained when storing various\n   classes of numbers in packed BCD format.\n\n   ST(0)                                  DEST \n   \u2212 \u221e or Value Too Large for DEST Format *    \n   F\u2264\u22121                                   \u2212D   \n   \u22121 < F < -0                            **   \n   \u22120                                     \u22120   \n   +0                                     +0   \n   + 0 < F < +1                           **   \n   F \u2265 +1                                 +D   \n   + \u221e or Value Too Large for DEST Format *    \n   NaN                                    *    \n\n   Table 3-19. FBSTP Results\n\n     F Meansfinitefloating-pointvalue.\n\n     D Means packed-BCD number.\n\n     * Indicatesfloating-pointinvalid-operation(#IA)exception.\n\n     ** \u00b10 or \u00b11, depending on the rounding mode.\n\n   If the converted value is too large for the destination format, or if the\n   source operand is an \u221e, SNaN, QNAN, or is in an unsupported format, an\n   invalid-arithmetic-operand condition is signaled. If the invalid-operation\n   exception is not masked, an invalid-arithmetic-operand exception (#IA) is\n   generated and no value is stored in the destination operand. If the\n   invalid-operation exception is masked, the packed BCD indefinite value is\n   stored in memory.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 0 if stack underflow occurred.            \n              Set if result was rounded up; cleared otherwise. \n   C0, C2, C3 Undefined.                                       \n"],
	["cbw:cwde:cdqe", "    CBW/CWDE/CDQE \u2014 Convert Byte to Word/Convert Word to Doubleword/Convert\n                             Doubleword toQuadword\n\n   Opcode     Instruction Op/En 64-bit Mode Compat/Leg Description            \n                                            Mode       \n   98         CBW         ZO    Valid       Valid      AX := sign-extend of   \n                                                       AL.                    \n   98         CWDE        ZO    Valid       Valid      EAX := sign-extend of  \n                                                       AX.                    \n   REX.W + 98 CDQE        ZO    Valid       N.E.       RAX := sign-extend of  \n                                                       EAX.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Double the size of the source operand by means of sign extension. The CBW\n   (convert byte to word) instruction copies the sign (bit 7) in the source\n   operand into every bit in the AH register. The CWDE (convert word to\n   double-word) instruction copies the sign (bit 15) of the word in the AX\n   register into the high 16 bits of the EAX register.\n\n   CBW and CWDE reference the same opcode. The CBW instruction is intended\n   for use when the operand-size attribute is 16; CWDE is intended for use\n   when the operand-size attribute is 32. Some assemblers may force the\n   operand size. Others may treat these two mnemonics as synonyms (CBW/CWDE)\n   and use the setting of the operand-size attribute to determine the size of\n   values to be converted.\n\n   In 64-bit mode, the default operation size is the size of the destination\n   register. Use of the REX.W prefix promotes this instruction (CDQE when\n   promoted) to operate on 64-bit operands. In which case, CDQE copies the\n   sign (bit 31) of the doubleword in the EAX register into the high 32 bits\n   of RAX.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["vpgatherdq:vpgatherqq", "  VPGATHERDQ/VPGATHERQQ \u2014 Gather Packed Qword Values Using Signed Dword/Qword\n                                    Indices\n\n                                  64/32     CPUID                             \n   Opcode/Instruction       Op/En -bit Mode Feature Description\n                                            Flag    \n                                                    Using dword indices       \n                                                    specified in vm32x,       \n   VEX.128.66.0F38.W1 90 /r                         gather qword values from  \n   VPGATHERDQ xmm1, vm32x,  A     V/V       AVX2    memory conditioned on     \n   xmm2                                             mask specified by xmm2.   \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    xmm1.                     \n                                                    Using qword indices       \n                                                    specified in vm64x,       \n   VEX.128.66.0F38.W1 91 /r                         gather qword values from  \n   VPGATHERQQ xmm1, vm64x,  A     V/V       AVX2    memory conditioned on     \n   xmm2                                             mask specified by xmm2.   \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    xmm1.                     \n                                                    Using dword indices       \n                                                    specified in vm32x,       \n   VEX.256.66.0F38.W1 90 /r                         gather qword values from  \n   VPGATHERDQ ymm1, vm32x,  A     V/V       AVX2    memory conditioned on     \n   ymm2                                             mask specified by ymm2.   \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    ymm1.                     \n                                                    Using qword indices       \n                                                    specified in vm64y,       \n   VEX.256.66.0F38.W1 91 /r                         gather qword values from  \n   VPGATHERQQ ymm1, vm64y,  A     V/V       AVX2    memory conditioned on     \n   ymm2                                             mask specified by ymm2.   \n                                                    Conditionally gathered    \n                                                    elements are merged into  \n                                                    ymm1.                     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1       Operand 2                  Operand 3       Operand 4 \n   A     ModRM:reg (r,w) BaseReg (R): VSIB:base,    VEX.vvvv (r, w) N/A       \n                         VectorReg(R): VSIB:index   \n\nDescription \u00b6\n\n   The instruction conditionally loads up to 2 or 4 qword values from memory\n   addresses specified by the memory operand (the second operand) and using\n   qword indices. The memory operand uses the VSIB form of the SIB byte to\n   specify a general purpose register operand as the common base, a vector\n   register for an array of indices relative to the base and a constant scale\n   factor.\n\n   The mask operand (the third operand) specifies the conditional load\n   operation from each memory address and the corresponding update of each\n   data element of the destination operand (the first operand).\n   Conditionality is specified by the most significant bit of each data\n   element of the mask register. If an element\u2019s mask bit is not set, the\n   corresponding element of the destination register is left unchanged. The\n   width of data element in the destination register and mask register are\n   identical. The entire mask register will be set to zero by this\n   instruction unless the instruction causes an exception.\n\n   Using dword indices in the lower half of the mask register, the\n   instruction conditionally loads up to 2 or 4 qword values from the VSIB\n   addressing memory operand, and updates the destination register.\n\n   This instruction can be suspended by an exception if at least one element\n   is already gathered (i.e., if the exception is triggered by an element\n   other than the rightmost one with its mask bit set). When this happens,\n   the destination register and the mask operand are partially updated; those\n   elements that have been gathered are placed into the destination register\n   and have their mask bits set to zero. If any traps or interrupts are\n   pending from already gathered elements, they will be delivered in lieu of\n   the exception; in this case, EFLAG.RF is set to one so an instruction\n   breakpoint is not re-triggered when the instruction is continued.\n\n   If the data size and index size are different, part of the destination\n   register and part of the mask register do not correspond to any elements\n   being gathered. This instruction sets those parts to zero. It may do this\n   to one or both of those registers even if the instruction triggers an\n   exception, and even if the instruction triggers the exception before\n   gathering any elements.\n\n   VEX.128 version: The instruction will gather two qword values. For dword\n   indices, only the lower two indices in the vector index register are used.\n\n   VEX.256 version: The instruction will gather four qword values. For dword\n   indices, only the lower four indices in the vector index register are\n   used.\n\n   Note that:\n\n     * If any pair of the index, mask, or destination registers are the same,\n       this instruction results a UD fault.\n     * The values may be read from memory in any order. Memory ordering with\n       other instructions follows the Intel-64 memory-ordering model.\n     * Faults are delivered in a right-to-left manner. That is, if a fault is\n       triggered by an element and delivered, all elements closer to the LSB\n       of the destination will be completed (and non-faulting). Individual\n       elements closer to the MSB may or may not be completed. If a given\n       element triggers multiple faults, they are delivered in the\n       conventional order.\n     * Elements may be gathered in any order, but faults must be delivered in\n       a right-to-left order; thus, elements to the left of a faulting one\n       may be gathered before the fault is delivered. A given implementation\n       of this instruction is repeatable - given the same input values and\n       architectural state, the same set of elements to the left of the\n       faulting one will be gathered.\n     * This instruction does not perform AC checks, and so will never deliver\n       an AC fault.\n     * This instruction will cause a #UD if the address size attribute is\n       16-bit.\n     * This instruction will cause a #UD if the memory operand is encoded\n       without the SIB byte.\n     * This instruction should not be used to access memory mapped I/O as the\n       ordering of the individual loads it does is implementation specific,\n       and some implementations may use loads larger than the data element\n       size or load elements an indeterminate number of times.\n     * The scaled index may require more bits to represent than the address\n       bits used by the processor (e.g., in 32-bit mode, if the scale is\n       greater than one). In this case, the most significant bits beyond the\n       number of address bits are ignored.\n"],
	["pause", "                             PAUSE \u2014 Spin Loop Hint\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n                                                        Gives hint to         \n   F3 90  PAUSE       ZO    Valid       Valid           processor that        \n                                                        improves performance  \n                                                        of spin-wait loops.   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Improves the performance of spin-wait loops. When executing a \u201cspin-wait\n   loop,\u201d processors will suffer a severe performance penalty when exiting\n   the loop because it detects a possible memory order violation. The PAUSE\n   instruction provides a hint to the processor that the code sequence is a\n   spin-wait loop. The processor uses this hint to avoid the memory order\n   violation in most situations, which greatly improves processor\n   performance. For this reason, it is recommended that a PAUSE instruction\n   be placed in all spin-wait loops.\n\n   An additional function of the PAUSE instruction is to reduce the power\n   consumed by a processor while executing a spin loop. A processor can\n   execute a spin-wait loop extremely quickly, causing the processor to\n   consume a lot of power while it waits for the resource it is spinning on\n   to become available. Inserting a pause instruction in a spin-wait loop\n   greatly reduces the processor\u2019s power consumption.\n\n   This instruction was introduced in the Pentium 4 processors, but is\n   backward compatible with all IA-32 processors. In earlier IA-32\n   processors, the PAUSE instruction operates like a NOP instruction. The\n   Pentium 4 and Intel Xeon processors implement the PAUSE instruction as a\n   delay. The delay is finite and can be zero for some processors. This\n   instruction does not change the architectural state of the processor (that\n   is, it performs essentially a delaying no-op operation).\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n"],
	["movzx", "                         MOVZX \u2014 Move With Zero-Extend\n\n   Opcode     Instruction Op/En 64-Bit Compat/Leg Description                 \n                                Mode   Mode       \n   0F B6 /r   MOVZX r16,  RM    Valid  Valid      Move byte to word with      \n              r/m8                                zero-extension.             \n   0F B6 /r   MOVZX r32,  RM    Valid  Valid      Move byte to doubleword,    \n              r/m8                                zero-extension.             \n   REX.W + 0F MOVZX r64,  RM    Valid  N.E.       Move byte to quadword,      \n   B6 /r      r/m8^1                              zero-extension.             \n   0F B7 /r   MOVZX r32,  RM    Valid  Valid      Move word to doubleword,    \n              r/m16                               zero-extension.             \n   REX.W + 0F MOVZX r64,  RM    Valid  N.E.       Move word to quadword,      \n   B7 /r      r/m16                               zero-extension.             \n\n     1. In 64-bit mode, r/m8 can not be encoded to access the following byte\n     registers if the REX prefix is used: AH, BH, CH, DH.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Copies the contents of the source operand (register or memory location) to\n   the destination operand (register) and zero extends the value. The size of\n   the converted value depends on the operand-size attribute.\n\n   In 64-bit mode, the instruction\u2019s default operation size is 32 bits. Use\n   of the REX.R prefix permits access to additional registers (R8-R15). Use\n   of the REX.W prefix promotes operation to 64 bit operands. See the summary\n   chart at the beginning of this section for encoding data and limits.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["blsmsk", "                     BLSMSK \u2014 Get Mask Up to Lowest Set Bit\n\n                              64/32-bit CPUID                                 \n   Opcode/Instruction   Op/En Mode      Feature Description\n                                        Flag    \n   VEX.LZ.0F38.W0 F3 /2                         Set all lower bits in r32 to  \n   BLSMSK r32, r/m32    VM    V/V       BMI1    \u201c1\u201d starting from bit 0 to    \n                                                lowest set bit in r/m32.      \n   VEX.LZ.0F38.W1 F3 /2                         Set all lower bits in r64 to  \n   BLSMSK r64, r/m64    VM    V/N.E.    BMI1    \u201c1\u201d starting from bit 0 to    \n                                                lowest set bit in r/m64.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1    Operand 2     Operand 3 Operand 4 \n   VM    VEX.vvvv (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Sets all the lower bits of the destination operand to \u201c1\u201d up to and\n   including lowest set bit (=1) in the source operand. If source operand is\n   zero, BLSMSK sets all bits of the destination operand to 1 and also sets\n   CF to 1.\n\n   This instruction is not supported in real mode and virtual-8086 mode. The\n   operand size is always 32 bits if not in 64-bit mode. In 64-bit mode\n   operand size 64 requires VEX.W1. VEX.W1 is ignored in non-64-bit modes. An\n   attempt to execute this instruction with VEX.L not equal to 0 will cause\n   #UD.\n\nFlags Affected \u00b6\n\n   SF is updated based on the result. CF is set if the source if zero. ZF and\n   OF flags are cleared. AF and PF flag are undefined.\n"],
	["vcvtph2dq", "      VCVTPH2DQ \u2014 Convert Packed FP16 Values to Signed Doubleword Integers\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit     \n   Mode Flag Support 64/32 CPUID  \n   Feature Instruction En Bit     \n   Mode Flag CPUID Feature        \n   Instruction En Bit Mode Flag   \n   Op/ 64/32 CPUID Feature          Support             Description\n   Instruction En Bit Mode Flag   \n   64/32 CPUID Feature            \n   Instruction En Bit Mode Flag   \n   CPUID Feature Instruction En   \n   Bit Mode Flag Op/ 64/32 CPUID  \n   Feature                        \n                                                        Convert four packed   \n                                                        FP16 values in        \n   EVEX.128.66.MAP5.W0 5B /r                            xmm2/m64/m16bcst to   \n   VCVTPH2DQ xmm1{k1}{z},         A V/V     AVX512-FP16 four signed           \n   xmm2/m64/m16bcst                         AVX512VL    doubleword integers,  \n                                                        and store the result  \n                                                        in xmm1 subject to    \n                                                        writemask k1.         \n                                                        Convert eight packed  \n                                                        FP16 values in        \n   EVEX.256.66.MAP5.W0 5B /r                            xmm2/m128/m16bcst to  \n   VCVTPH2DQ ymm1{k1}{z},         A V/V     AVX512-FP16 eight signed          \n   xmm2/m128/m16bcst                        AVX512VL    doubleword integers,  \n                                                        and store the result  \n                                                        in ymm1 subject to    \n                                                        writemask k1.         \n                                                        Convert sixteen       \n                                                        packed FP16 values in \n   EVEX.512.66.MAP5.W0 5B /r                            ymm2/m256/m16bcst to  \n   VCVTPH2DQ zmm1{k1}{z},         A V/V     AVX512-FP16 sixteen signed        \n   ymm2/m256/m16bcst {er}                               doubleword integers,  \n                                                        and store the result  \n                                                        in zmm1 subject to    \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed FP16 values in the source operand to\n   signed doubleword integers in destination operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value is returned.\n\n   The destination elements are updated according to the writemask.\n"],
	["vcvttps2qq", "  VCVTTPS2QQ \u2014 Convert With Truncation Packed Single Precision Floating-Point\n                 Values toPacked Signed Quadword Integer Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert two packed       \n                                                     single precision         \n   EVEX.128.66.0F.W0 7A /r                           floating-point values    \n   VCVTTPS2QQ xmm1 {k1}{z}, A     V/V       AVX512VL from xmm2/m64/m32bcst to \n   xmm2/m64/m32bcst                         AVX512DQ two packed signed        \n                                                     quadword values in xmm1  \n                                                     using truncation subject \n                                                     to writemask k1.         \n                                                     Convert four packed      \n                                                     single precision         \n   EVEX.256.66.0F.W0 7A /r                           floating-point values    \n   VCVTTPS2QQ ymm1 {k1}{z}, A     V/V       AVX512VL from xmm2/m128/m32bcst   \n   xmm2/m128/m32bcst                        AVX512DQ to four packed signed    \n                                                     quadword values in ymm1  \n                                                     using truncation subject \n                                                     to writemask k1.         \n                                                     Convert eight packed     \n                                                     single precision         \n   EVEX.512.66.0F.W0 7A /r                           floating-point values    \n   VCVTTPS2QQ zmm1 {k1}{z}, A     V/V       AVX512DQ from ymm2/m256/m32bcst   \n   ymm2/m256/m32bcst{sae}                            to eight packed signed   \n                                                     quadword values in zmm1  \n                                                     using truncation subject \n                                                     to writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Half       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts with truncation packed single precision floating-point values in\n   the source operand to eight signed quadword integers in the destination\n   operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result cannot be represented in the destination\n   format, the floating-point invalid exception is raised, and if this\n   exception is masked, the indefinite integer value (2^w-1, where w\n   represents the number of bits in the destination format) is returned.\n\n   EVEX encoded versions: The source operand is a YMM/XMM/XMM (low 64 bits)\n   register or a 256/128/64-bit memory location. The destination operation is\n   a vector register conditionally updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n"],
	["vdpbf16ps", " VDPBF16PS \u2014 Dot Product of BF16 Pairs Accumulated Into Packed Single Precision\n\n                                64/32 Bit CPUID Feature                       \n   Opcode/Instruction     Op/En Mode      Flag          Description\n                                Support   \n                                                        Multiply BF16 pairs   \n                                                        from xmm2 and         \n   EVEX.128.F3.0F38.W0 52                               xmm3/m128, and        \n   /r VDPBF16PS           A     V/V       AVX512VL      accumulate the        \n   xmm1{k1}{z}, xmm2,                     AVX512_BF16   resulting packed      \n   xmm3/m128/m32bcst                                    single precision      \n                                                        results in xmm1 with  \n                                                        writemask k1.         \n                                                        Multiply BF16 pairs   \n                                                        from ymm2 and         \n   EVEX.256.F3.0F38.W0 52                               ymm3/m256, and        \n   /r VDPBF16PS           A     V/V       AVX512VL      accumulate the        \n   ymm1{k1}{z}, ymm2,                     AVX512_BF16   resulting packed      \n   ymm3/m256/m32bcst                                    single precision      \n                                                        results in ymm1 with  \n                                                        writemask k1.         \n                                                        Multiply BF16 pairs   \n                                                        from zmm2 and         \n   EVEX.512.F3.0F38.W0 52                               zmm3/m512, and        \n   /r VDPBF16PS           A     V/V       AVX512F       accumulate the        \n   zmm1{k1}{z}, zmm2,                     AVX512_BF16   resulting packed      \n   zmm3/m512/m32bcst                                    single precision      \n                                                        results in zmm1 with  \n                                                        writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction performs a SIMD dot-product of two BF16 pairs and\n   accumulates into a packed single precision register.\n\n   \u201cRound to nearest even\u201d rounding mode is used when doing each accumulation\n   of the FMA. Output denormals are always flushed to zero and input\n   denormals are always treated as zero. MXCSR is not consulted nor updated.\n\n   NaN propagation priorities are described in Table 5-1.\n\n   NaN Priority Description      Comments                                     \n   1            src1 low is NaN  Lower part has priority over upper part,     \n   2            src2 low is NaN  i.e., it overrides the upper part.           \n   3            src1 high is NaN Upper part may be overridden if lower has    \n   4            src2 high is NaN NaN.                                         \n   5            srcdest is NaN   Dest is propagated if no NaN is encountered  \n                                 by src2.                                     \n\n   Table 5-1. NaN Propagation Priorities\n"],
	["syscall", "                           SYSCALL \u2014 Fast System Call\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n                                                        Fast call to          \n   0F 05  SYSCALL     ZO    Valid       Invalid         privilege level 0     \n                                                        system procedures.    \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   SYSCALL invokes an OS system-call handler at privilege level 0. It does so\n   by loading RIP from the IA32_LSTAR MSR (after saving the address of the\n   instruction following SYSCALL into RCX). (The WRMSR instruction ensures\n   that the IA32_LSTAR MSR always contain a canonical address.)\n\n   SYSCALL also saves RFLAGS into R11 and then masks RFLAGS using the\n   IA32_FMASK MSR (MSR address C0000084H); specifically, the processor clears\n   in RFLAGS every bit corresponding to a bit that is set in the IA32_FMASK\n   MSR.\n\n   SYSCALL loads the CS and SS selectors with values derived from bits 47:32\n   of the IA32_STAR MSR. However, the CS and SS descriptor caches are not\n   loaded from the descriptors (in GDT or LDT) referenced by those selectors.\n   Instead, the descriptor caches are loaded with fixed values. See the\n   Operation section for details. It is the responsibility of OS software to\n   ensure that the descriptors (in GDT or LDT) referenced by those selector\n   values correspond to the fixed values loaded into the descriptor caches;\n   the SYSCALL instruction does not ensure this correspondence.\n\n   The SYSCALL instruction does not save the stack pointer (RSP). If the OS\n   system-call handler will change the stack pointer, it is the\n   responsibility of software to save the previous value of the stack\n   pointer. This might be done prior to executing SYSCALL, with software\n   restoring the stack pointer with the instruction following SYSCALL (which\n   will be executed after SYSRET). Alternatively, the OS system-call handler\n   may save the stack pointer and restore it before executing SYSRET.\n\n   When shadow stacks are enabled at a privilege level where the SYSCALL\n   instruction is invoked, the SSP is saved to the IA32_PL3_SSP MSR. If\n   shadow stacks are enabled at privilege level 0, the SSP is loaded with 0.\n   Refer to Chapter 6, \u201cProcedure Calls, Interrupts, and Exceptions\u201a\u201d and\n   Chapter 17, \u201cControl-flow Enforcement Technology (CET)\u201a\u201d in the Intel^\u00ae 64\n   and IA-32 Architectures Software Developer\u2019s Manual, Volume 1, for\n   additional CET details.\n\n   Instruction ordering. Instructions following a SYSCALL may be fetched from\n   memory before earlier instructions complete execution, but they will not\n   execute (even speculatively) until all instructions prior to the SYSCALL\n   have completed execution (the later instructions may execute before data\n   stored by the earlier instructions have become globally visible).\n\nFlags Affected \u00b6\n\n   All.\n"],
	["roundpd", "         ROUNDPD \u2014 Round Packed Double Precision Floating-Point Values\n\n                                  64/32 bit CPUID                             \n   Opcode*/Instruction      Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Round packed double       \n   66 0F 3A 09 /r ib                                precision floating-point  \n   ROUNDPD xmm1, xmm2/m128, RMI   V/V       SSE4_1  values in xmm2/m128 and   \n   imm8                                             place the result in xmm1. \n                                                    The rounding mode is      \n                                                    determined by imm8.       \n                                                    Round packed double       \n   VEX.128.66.0F3A.WIG 09                           precision floating-point  \n   /r ib VROUNDPD xmm1,     RMI   V/V       AVX     values in xmm2/m128 and   \n   xmm2/m128, imm8                                  place the result in xmm1. \n                                                    The rounding mode is      \n                                                    determined by imm8.       \n                                                    Round packed double       \n   VEX.256.66.0F3A.WIG 09                           precision floating-point  \n   /r ib VROUNDPD ymm1,     RMI   V/V       AVX     values in ymm2/m256 and   \n   ymm2/m256, imm8                                  place the result in ymm1. \n                                                    The rounding mode is      \n                                                    determined by imm8.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RMI   ModRM:reg (w) ModRM:r/m (r) imm8      N/A       \n\nDescription \u00b6\n\n   Round the 2 double precision floating-point values in the source operand\n   (second operand) using the rounding mode specified in the immediate\n   operand (third operand) and place the results in the destination operand\n   (first operand). The rounding process rounds each input floating-point\n   value to an integer value and returns the integer result as a double\n   precision floating-point value.\n\n   The immediate operand specifies control fields for the rounding operation,\n   three bit fields are defined and shown in Figure 4-24. Bit 3 of the\n   immediate byte controls processor behavior for a precision exception, bit\n   2 selects the source of rounding mode control. Bits 1:0 specify a\n   non-sticky rounding-mode value (Table 4-18 lists the encoded values for\n   rounding-mode field).\n\n   The Precision Floating-Point Exception is signaled according to the\n   immediate operand. If any source operand is an SNaN then it will be\n   converted to a QNaN. If DAZ is set to \u20181 then denormals will be converted\n   to zero before rounding.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   YMM register destination are unmodified.\n\n   VEX.128 encoded version: the source operand second source operand or a\n   128-bit memory location. The destination operand is an XMM register. The\n   upper bits (MAXVL-1:128) of the corresponding YMM register destination are\n   zeroed.\n\n   VEX.256 encoded version: The source operand is a YMM register or a 256-bit\n   memory location. The destination operand is a YMM register.\n\n   Note: In VEX-encoded versions, VEX.vvvv is reserved and must be 1111b,\n   otherwise instructions will #UD.\n\n    8                                             3210 \n    Reserved                                      \n    P \u2014 Precision Mask; 0: normal, 1: inexact     \n    RS \u2014 Rounding select; 1: MXCSR.RC, 0: Imm8.RC \n    RC \u2014 Rounding mode                            \n\n   Figure 4-24. Bit Control Fields of Immediate Byte for ROUNDxx Instruction\n   Table 4-18. Rounding Modes and Encoding of Rounding Control (RC) Field\n\n   Rounding RC Field Description Mode Setting\n\n   Round to 00B Rounded result is the closest to the infinitely precise\n   result. If two values are equally close, the result is nearest (even) the\n   even value (i.e., the integer value with the least-significant bit of\n   zero).\n\n   Round down 01B Rounded result is closest to but no greater than the\n   infinitely precise result. (toward \u2212\u221e)\n\n   Round up 10B Rounded result is closest to but no less than the infinitely\n   precise result. (toward +\u221e)\n\n   Round toward 11B Rounded result is closest to but no greater in absolute\n   value than the infinitely precise result. zero (Truncate)\n"],
	["vfmsub132ps:vfmsub213ps:vfmsub231ps", "    VFMSUB132PS/VFMSUB213PS/VFMSUB231PS \u2014 Fused Multiply-Subtract of Packed\n                     SinglePrecision Floating-Point Values\n\n                                   64/32 Bit CPUID                            \n   Opcode/Instruction        Op/En Mode      Feature  Description\n                                   Support   Flag     \n                                                      Multiply packed single  \n   VEX.128.66.0F38.W0 9A /r                           precision               \n   VFMSUB132PS xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm1 and xmm3/mem, \n                                                      subtract xmm2 and put   \n                                                      result in xmm1.         \n                                                      Multiply packed single  \n   VEX.128.66.0F38.W0 AA /r                           precision               \n   VFMSUB213PS xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm1 and xmm2,     \n                                                      subtract xmm3/mem and   \n                                                      put result in xmm1.     \n                                                      Multiply packed single  \n   VEX.128.66.0F38.W0 BA /r                           precision               \n   VFMSUB231PS xmm1, xmm2,   A     V/V       FMA      floating-point values   \n   xmm3/m128                                          from xmm2 and xmm3/mem, \n                                                      subtract xmm1 and put   \n                                                      result in xmm1.         \n                                                      Multiply packed single  \n   VEX.256.66.0F38.W0 9A /r                           precision               \n   VFMSUB132PS ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm1 and ymm3/mem, \n                                                      subtract ymm2 and put   \n                                                      result in ymm1.         \n                                                      Multiply packed single  \n   VEX.256.66.0F38.W0 AA /r                           precision               \n   VFMSUB213PS ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm1 and ymm2,     \n                                                      subtract ymm3/mem and   \n                                                      put result in ymm1.     \n                                                      Multiply packed single  \n   VEX.256.66.0F38.0 BA /r                            precision               \n   VFMSUB231PS ymm1, ymm2,   A     V/V       FMA      floating-point values   \n   ymm3/m256                                          from ymm2 and ymm3/mem, \n                                                      subtract ymm1 and put   \n                                                      result in ymm1.         \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.128.66.0F38.W0 9A /r                 AVX512VL floating-point values   \n   VFMSUB132PS xmm1 {k1}{z}, B     V/V       AVX512F  from xmm1 and           \n   xmm2, xmm3/m128/m32bcst                            xmm3/m128/m32bcst,      \n                                                      subtract xmm2 and put   \n                                                      result in xmm1.         \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.128.66.0F38.W0 AA /r                 AVX512VL floating-point values   \n   VFMSUB213PS xmm1 {k1}{z}, B     V/V       AVX512F  from xmm1 and xmm2,     \n   xmm2, xmm3/m128/m32bcst                            subtract                \n                                                      xmm3/m128/m32bcst and   \n                                                      put result in xmm1.     \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.128.66.0F38.W0 BA /r                 AVX512VL floating-point values   \n   VFMSUB231PS xmm1 {k1}{z}, B     V/V       AVX512F  from xmm2 and           \n   xmm2, xmm3/m128/m32bcst                            xmm3/m128/m32bcst,      \n                                                      subtract xmm1 and put   \n                                                      result in xmm1.         \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.256.66.0F38.W0 9A /r                 AVX512VL floating-point values   \n   VFMSUB132PS ymm1 {k1}{z}, B     V/V       AVX512F  from ymm1 and           \n   ymm2, ymm3/m256/m32bcst                            ymm3/m256/m32bcst,      \n                                                      subtract ymm2 and put   \n                                                      result in ymm1.         \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.256.66.0F38.W0 AA /r                 AVX512VL floating-point values   \n   VFMSUB213PS ymm1 {k1}{z}, B     V/V       AVX512F  from ymm1 and ymm2,     \n   ymm2, ymm3/m256/m32bcst                            subtract                \n                                                      ymm3/m256/m32bcst and   \n                                                      put result in ymm1.     \n                                                      Multiply packed single  \n                                                      precision               \n   EVEX.256.66.0F38.W0 BA /r                 AVX512VL floating-point values   \n   VFMSUB231PS ymm1 {k1}{z}, B     V/V       AVX512F  from ymm2 and           \n   ymm2, ymm3/m256/m32bcst                            ymm3/m256/m32bcst,      \n                                                      subtract ymm1 and put   \n                                                      result in ymm1.         \n                                                      Multiply packed single  \n   EVEX.512.66.0F38.W0 9A /r                          precision               \n   VFMSUB132PS zmm1 {k1}{z},                          floating-point values   \n   zmm2,                     B     V/V       AVX512F  from zmm1 and           \n   zmm3/m512/m32bcst{er}                              zmm3/m512/m32bcst,      \n                                                      subtract zmm2 and put   \n                                                      result in zmm1.         \n                                                      Multiply packed single  \n   EVEX.512.66.0F38.W0 AA /r                          precision               \n   VFMSUB213PS zmm1 {k1}{z},                          floating-point values   \n   zmm2,                     B     V/V       AVX512F  from zmm1 and zmm2,     \n   zmm3/m512/m32bcst{er}                              subtract                \n                                                      zmm3/m512/m32bcst and   \n                                                      put result in zmm1.     \n                                                      Multiply packed single  \n   EVEX.512.66.0F38.W0 BA /r                          precision               \n   VFMSUB231PS zmm1 {k1}{z},                          floating-point values   \n   zmm2,                     B     V/V       AVX512F  from zmm2 and           \n   zmm3/m512/m32bcst{er}                              zmm3/m512/m32bcst,      \n                                                      subtract zmm1 and put   \n                                                      result in zmm1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Performs a set of SIMD multiply-subtract computation on packed single\n   precision floating-point values using three source operands and writes the\n   multiply-subtract results in the destination operand. The destination\n   operand is also the first source operand. The second operand must be a\n   SIMD register. The third source operand can be a SIMD register or a memory\n   location.\n\n   VFMSUB132PS: Multiplies the four, eight or sixteen packed single precision\n   floating-point values from the first source operand to the four, eight or\n   sixteen packed single precision floating-point values in the third source\n   operand. From the infinite precision intermediate result, subtracts the\n   four, eight or sixteen packed single precision floating-point values in\n   the second source operand, performs rounding and stores the resulting\n   four, eight or sixteen packed single precision floating-point values to\n   the destination operand (first source operand).\n\n   VFMSUB213PS: Multiplies the four, eight or sixteen packed single precision\n   floating-point values from the second source operand to the four, eight or\n   sixteen packed single precision floating-point values in the first source\n   operand. From the infinite precision intermediate result, subtracts the\n   four, eight or sixteen packed single precision floating-point values in\n   the third source operand, performs rounding and stores the resulting four,\n   eight or sixteen packed single precision floating-point values to the\n   destination operand (first source operand).\n\n   VFMSUB231PS: Multiplies the four, eight or sixteen packed single precision\n   floating-point values from the second source to the four, eight or sixteen\n   packed single precision floating-point values in the third source operand.\n   From the infinite precision intermediate result, subtracts the four, eight\n   or sixteen packed single precision floating-point values in the first\n   source operand, performs rounding and stores the resulting four, eight or\n   sixteen packed single precision floating-point values to the destination\n   operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 32-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n"],
	["vfmaddsub132ps:vfmaddsub213ps:vfmaddsub231ps", "              VFMADDSUB132PS/VFMADDSUB213PS/VFMADDSUB231PS \u2014 Fused\n   Multiply-AlternatingAdd/Subtract of Packed Single Precision Floating-Point\n                                     Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed single   \n   VEX.128.66.0F38.W0 96 /r                          precision floating-point \n   VFMADDSUB132PS xmm1,     A     V/V       FMA      values from xmm1 and     \n   xmm2, xmm3/m128                                   xmm3/mem, add/subtract   \n                                                     elements in xmm2 and put \n                                                     result in xmm1.          \n                                                     Multiply packed single   \n   VEX.128.66.0F38.W0 A6 /r                          precision floating-point \n   VFMADDSUB213PS xmm1,     A     V/V       FMA      values from xmm1 and     \n   xmm2, xmm3/m128                                   xmm2, add/subtract       \n                                                     elements in xmm3/mem and \n                                                     put result in xmm1.      \n                                                     Multiply packed single   \n   VEX.128.66.0F38.W0 B6 /r                          precision floating-point \n   VFMADDSUB231PS xmm1,     A     V/V       FMA      values from xmm2 and     \n   xmm2, xmm3/m128                                   xmm3/mem, add/subtract   \n                                                     elements in xmm1 and put \n                                                     result in xmm1.          \n                                                     Multiply packed single   \n   VEX.256.66.0F38.W0 96 /r                          precision floating-point \n   VFMADDSUB132PS ymm1,     A     V/V       FMA      values from ymm1 and     \n   ymm2, ymm3/m256                                   ymm3/mem, add/subtract   \n                                                     elements in ymm2 and put \n                                                     result in ymm1.          \n                                                     Multiply packed single   \n   VEX.256.66.0F38.W0 A6 /r                          precision floating-point \n   VFMADDSUB213PS ymm1,     A     V/V       FMA      values from ymm1 and     \n   ymm2, ymm3/m256                                   ymm2, add/subtract       \n                                                     elements in ymm3/mem and \n                                                     put result in ymm1.      \n                                                     Multiply packed single   \n   VEX.256.66.0F38.W0 B6 /r                          precision floating-point \n   VFMADDSUB231PS ymm1,     A     V/V       FMA      values from ymm2 and     \n   ymm2, ymm3/m256                                   ymm3/mem, add/subtract   \n                                                     elements in ymm1 and put \n                                                     result in ymm1.          \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W0 A6                            values from xmm1 and     \n   /r VFMADDSUB213PS xmm1   B     V/V       AVX512VL xmm2, add/subtract       \n   {k1}{z}, xmm2,                           AVX512F  elements in              \n   xmm3/m128/m32bcst                                 xmm3/m128/m32bcst and    \n                                                     put result in xmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W0 B6                            values from xmm2 and     \n   /r VFMADDSUB231PS xmm1   B     V/V       AVX512VL xmm3/m128/m32bcst,       \n   {k1}{z}, xmm2,                           AVX512F  add/subtract elements in \n   xmm3/m128/m32bcst                                 xmm1 and put result in   \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W0 96                            values from xmm1 and     \n   /r VFMADDSUB132PS xmm1   B     V/V       AVX512VL xmm3/m128/m32bcst,       \n   {k1}{z}, xmm2,                           AVX512F  add/subtract elements in \n   xmm3/m128/m32bcst                                 zmm2 and put result in   \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W0 A6                            values from ymm1 and     \n   /r VFMADDSUB213PS ymm1   B     V/V       AVX512VL ymm2, add/subtract       \n   {k1}{z}, ymm2,                           AVX512F  elements in              \n   ymm3/m256/m32bcst                                 ymm3/m256/m32bcst and    \n                                                     put result in ymm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W0 B6                            values from ymm2 and     \n   /r VFMADDSUB231PS ymm1   B     V/V       AVX512VL ymm3/m256/m32bcst,       \n   {k1}{z}, ymm2,                           AVX512F  add/subtract elements in \n   ymm3/m256/m32bcst                                 ymm1 and put result in   \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W0 96                            values from ymm1 and     \n   /r VFMADDSUB132PS ymm1   B     V/V       AVX512VL ymm3/m256/m32bcst,       \n   {k1}{z}, ymm2,                           AVX512F  add/subtract elements in \n   ymm3/m256/m32bcst                                 ymm2 and put result in   \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W0 A6                            values from zmm1 and     \n   /r VFMADDSUB213PS zmm1   B     V/V       AVX512F  zmm2, add/subtract       \n   {k1}{z}, zmm2,                                    elements in              \n   zmm3/m512/m32bcst{er}                             zmm3/m512/m32bcst and    \n                                                     put result in zmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W0 B6                            values from zmm2 and     \n   /r VFMADDSUB231PS zmm1   B     V/V       AVX512F  zmm3/m512/m32bcst,       \n   {k1}{z}, zmm2,                                    add/subtract elements in \n   zmm3/m512/m32bcst{er}                             zmm1 and put result in   \n                                                     zmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed single   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W0 96                            values from zmm1 and     \n   /r VFMADDSUB132PS zmm1   B     V/V       AVX512F  zmm3/m512/m32bcst,       \n   {k1}{z}, zmm2,                                    add/subtract elements in \n   zmm3/m512/m32bcst{er}                             zmm2 and put result in   \n                                                     zmm1 subject to          \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFMADDSUB132PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the first source operand to the\n   corresponding packed single precision floating-point values in the third\n   source operand. From the infinite precision intermediate result, adds the\n   odd single precision floating-point elements and subtracts the even single\n   precision floating-point values in the second source operand, performs\n   rounding and stores the resulting packed single precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMADDSUB213PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the second source operand to the\n   corresponding packed single precision floating-point values in the first\n   source operand. From the infinite precision intermediate result, adds the\n   odd single precision floating-point elements and subtracts the even single\n   precision floating-point values in the third source operand, performs\n   rounding and stores the resulting packed single precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMADDSUB231PS: Multiplies the four, eight or sixteen packed single\n   precision floating-point values from the second source operand to the\n   corresponding packed single precision floating-point values in the third\n   source operand. From the infinite precision intermediate result, adds the\n   odd single precision floating-point elements and subtracts the even single\n   precision floating-point values in the first source operand, performs\n   rounding and stores the resulting packed single precision floating-point\n   values to the destination operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 32-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["cvttps2dq", "   CVTTPS2DQ \u2014 Convert With Truncation Packed Single Precision Floating-Point\n                Values to PackedSigned Doubleword Integer Values\n\n                         Op / 64/32 bit CPUID                                 \n   Opcode/Instruction    En   Mode      Feature  Description\n                              Support   Flag     \n                                                 Convert four packed single   \n                                                 precision floating-point     \n   F3 0F 5B /r CVTTPS2DQ A    V/V       SSE2     values from xmm2/mem to four \n   xmm1, xmm2/m128                               packed signed doubleword     \n                                                 values in xmm1 using         \n                                                 truncation.                  \n                                                 Convert four packed single   \n   VEX.128.F3.0F.WIG 5B                          precision floating-point     \n   /r VCVTTPS2DQ xmm1,   A    V/V       AVX      values from xmm2/mem to four \n   xmm2/m128                                     packed signed doubleword     \n                                                 values in xmm1 using         \n                                                 truncation.                  \n                                                 Convert eight packed single  \n   VEX.256.F3.0F.WIG 5B                          precision floating-point     \n   /r VCVTTPS2DQ ymm1,   A    V/V       AVX      values from ymm2/mem to      \n   ymm2/m256                                     eight packed signed          \n                                                 doubleword values in ymm1    \n                                                 using truncation.            \n                                                 Convert four packed single   \n                                                 precision floating-point     \n   EVEX.128.F3.0F.W0 5B                          values from                  \n   /r VCVTTPS2DQ xmm1    B    V/V       AVX512VL xmm2/m128/m32bcst to four    \n   {k1}{z},                             AVX512F  packed signed doubleword     \n   xmm2/m128/m32bcst                             values in xmm1 using         \n                                                 truncation subject to        \n                                                 writemask k1.                \n                                                 Convert eight packed single  \n                                                 precision floating-point     \n   EVEX.256.F3.0F.W0 5B                          values from                  \n   /r VCVTTPS2DQ ymm1    B    V/V       AVX512VL ymm2/m256/m32bcst to eight   \n   {k1}{z},                             AVX512F  packed signed doubleword     \n   ymm2/m256/m32bcst                             values in ymm1 using         \n                                                 truncation subject to        \n                                                 writemask k1.                \n                                                 Convert sixteen packed       \n   EVEX.512.F3.0F.W0 5B                          single precision             \n   /r VCVTTPS2DQ zmm1                            floating-point values from   \n   {k1}{z},              B    V/V       AVX512F  zmm2/m512/m32bcst to sixteen \n   zmm2/m512/m32bcst                             packed signed doubleword     \n   {sae}                                         values in zmm1 using         \n                                                 truncation subject to        \n                                                 writemask k1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Converts four, eight or sixteen packed single precision floating-point\n   values in the source operand to four, eight or sixteen signed doubleword\n   integers in the destination operand.\n\n   When a conversion is inexact, a truncated (round toward zero) value is\n   returned. If a converted result is larger than the maximum signed\n   doubleword integer, the floating-point invalid exception is raised, and if\n   this exception is masked, the indefinite integer value (80000000H) is\n   returned.\n\n   EVEX encoded versions: The source operand is a ZMM/YMM/XMM register, a\n   512/256/128-bit memory location or a 512/256/128-bit vector broadcasted\n   from a 32-bit memory location. The destination operand is a ZMM/YMM/XMM\n   register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The source operand is a YMM register or 256- bit\n   memory location. The destination operand is a YMM register. The upper bits\n   (MAXVL-1:256) of the corresponding ZMM register destination are zeroed.\n\n   VEX.128 encoded version: The source operand is an XMM register or 128- bit\n   memory location. The destination operand is a XMM register. The upper bits\n   (MAXVL-1:128) of the corresponding ZMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The source operand is an XMM register or 128-\n   bit memory location. The destination operand is an XMM register. The upper\n   bits (MAXVL-1:128) of the corresponding ZMM register destination are\n   unmodified.\n\n   Note: VEX.vvvv and EVEX.vvvv are reserved and must be 1111b otherwise\n   instructions will #UD.\n"],
	["cmpsd", "          CMPSD \u2014 Compare Scalar Double Precision Floating-Point Value\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature Description\n                                Support   Flag    \n                                                  Compare low double          \n   F2 0F C2 /r ib CMPSD                           precision floating-point    \n   xmm1, xmm2/m64, imm8    A    V/V       SSE2    value in xmm2/m64 and xmm1  \n                                                  using bits 2:0 of imm8 as   \n                                                  comparison predicate.       \n                                                  Compare low double          \n   VEX.LIG.F2.0F.WIG C2 /r                        precision floating-point    \n   ib VCMPSD xmm1, xmm2,   B    V/V       AVX     value in xmm3/m64 and xmm2  \n   xmm3/m64, imm8                                 using bits 4:0 of imm8 as   \n                                                  comparison predicate.       \n                                                  Compare low double          \n   EVEX.LLIG.F2.0F.W1 C2                          precision floating-point    \n   /r ib VCMPSD k1 {k2},                          value in xmm3/m64 and xmm2  \n   xmm2, xmm3/m64{sae},    C    V/V       AVX512F using bits 4:0 of imm8 as   \n   imm8                                           comparison predicate with   \n                                                  writemask k2 and leave the  \n                                                  result in mask register k1. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) ModRM:r/m (r) imm8          N/A       \n   B     N/A           ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8      \n   C     Tuple1 Scalar ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) imm8      \n\nDescription \u00b6\n\n   Compares the low double precision floating-point values in the second\n   source operand and the first source operand and returns the result of the\n   comparison to the destination operand. The comparison predicate operand\n   (immediate operand) specifies the type of comparison performed.\n\n   128-bit Legacy SSE version: The first source and destination operand\n   (first operand) is an XMM register. The second source operand (second\n   operand) can be an XMM register or 64-bit memory location. Bits\n   (MAXVL-1:64) of the corresponding YMM destination register remain\n   unchanged. The comparison result is a quadword mask of all 1s (comparison\n   true) or all 0s (comparison false).\n\n   VEX.128 encoded version: The first source operand (second operand) is an\n   XMM register. The second source operand (third operand) can be an XMM\n   register or a 64-bit memory location. The result is stored in the low\n   quadword of the destination operand; the high quadword is filled with the\n   contents of the high quadword of the first source operand. Bits\n   (MAXVL-1:128) of the destination ZMM register are zeroed. The comparison\n   result is a quadword mask of all 1s (comparison true) or all 0s\n   (comparison false).\n\n   EVEX encoded version: The first source operand (second operand) is an XMM\n   register. The second source operand can be a XMM register or a 64-bit\n   memory location. The destination operand (first operand) is an opmask\n   register. The comparison result is a single mask bit of 1 (comparison\n   true) or 0 (comparison false), written to the destination starting from\n   the LSB according to the writemask k2. Bits (MAX_KL-1:128) of the\n   destination register are cleared.\n\n   The comparison predicate operand is an 8-bit immediate:\n\n     * For instructions encoded using the VEX prefix, bits 4:0 define the\n       type of comparison to be performed (see Table 3-1). Bits 5 through 7\n       of the immediate are reserved.\n     * For instruction encodings that do not use VEX prefix, bits 2:0 define\n       the type of comparison to be made (see the first 8 rows of Table 3-1).\n       Bits 3 through 7 of the immediate are reserved.\n\n   The unordered relationship is true when at least one of the two source\n   operands being compared is a NaN; the ordered relationship is true when\n   neither source operand is a NaN.\n\n   A subsequent computational instruction that uses the mask result in the\n   destination operand as an input operand will not generate an exception,\n   because a mask of all 0s corresponds to a floating-point value of +0.0 and\n   a mask of all 1s corresponds to a QNaN.\n\n   Note that processors with \u201cCPUID.1H:ECX.AVX =0\u201d do not implement the\n   \u201cgreater-than\u201d, \u201cgreater-than-or-equal\u201d, \u201cnot-greater than\u201d, and\n   \u201cnot-greater-than-or-equal relations\u201d predicates. These comparisons can be\n   made either\n\n   by using the inverse relationship (that is, use the\n   \u201cnot-less-than-or-equal\u201d to make a \u201cgreater-than\u201d comparison) or by using\n   software emulation. When using software emulation, the program must swap\n   the operands (copying registers when necessary to protect the data that\n   will now be in the destination), and then perform the compare using a\n   different predicate. The predicate to be used for these emulations is\n   listed in the first 8 rows of Table 3-7 (Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 2A) under the heading\n   Emulation.\n\n   Compilers and assemblers may implement the following two-operand\n   pseudo-ops in addition to the three-operand CMPSD instruction, for\n   processors with \u201cCPUID.1H:ECX.AVX =0\u201d. See Table 3-6. The compiler should\n   treat reserved imm8 values as illegal syntax.\n\n   Pseudo-Op             CMPSD Implementation \n   CMPEQSD xmm1, xmm2    CMPSD xmm1, xmm2, 0  \n   CMPLTSD xmm1, xmm2    CMPSD xmm1, xmm2, 1  \n   CMPLESD xmm1, xmm2    CMPSD xmm1, xmm2, 2  \n   CMPUNORDSD xmm1, xmm2 CMPSD xmm1, xmm2, 3  \n   CMPNEQSD xmm1, xmm2   CMPSD xmm1, xmm2, 4  \n   CMPNLTSD xmm1, xmm2   CMPSD xmm1, xmm2, 5  \n   CMPNLESD xmm1, xmm2   CMPSD xmm1, xmm2, 6  \n   CMPORDSD xmm1, xmm2   CMPSD xmm1, xmm2, 7  \n\n   Table 3-6. Pseudo-Op and CMPSD Implementation\n\n   The greater-than relations that the processor does not implement require\n   more than one instruction to emulate in software and therefore should not\n   be implemented as pseudo-ops. (For these, the programmer should reverse\n   the operands of the corresponding less than relations and use move\n   instructions to ensure that the mask is moved to the correct destination\n   register and that the source operand is left intact.)\n\n   Processors with \u201cCPUID.1H:ECX.AVX =1\u201d implement the full complement of 32\n   predicates shown in Table 3-7, software emulation is no longer needed.\n   Compilers and assemblers may implement the following three-operand\n   pseudo-ops in addition to the four-operand VCMPSD instruction. See Table\n   3-7, where the notations of reg1 reg2, and reg3 represent either XMM\n   registers or YMM registers. The compiler should treat reserved imm8 values\n   as illegal syntax. Alternately, intrinsics can map the pseudo-ops to\n   pre-defined constants to support a simpler intrinsic interface. Compilers\n   and assemblers may implement three-operand pseudo-ops for EVEX encoded\n   VCMPSD instructions in a similar fashion by extending the syntax listed in\n   Table 3-7.\n\n   Pseudo-Op                     CMPSD Implementation         \n   VCMPEQSD reg1, reg2, reg3     VCMPSD reg1, reg2, reg3, 0   \n   VCMPLTSD reg1, reg2, reg3     VCMPSD reg1, reg2, reg3, 1   \n   VCMPLESD reg1, reg2, reg3     VCMPSD reg1, reg2, reg3, 2   \n   VCMPUNORDSD reg1, reg2, reg3  VCMPSD reg1, reg2, reg3, 3   \n   VCMPNEQSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 4   \n   VCMPNLTSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 5   \n   VCMPNLESD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 6   \n   VCMPORDSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 7   \n   VCMPEQ_UQSD reg1, reg2, reg3  VCMPSD reg1, reg2, reg3, 8   \n   VCMPNGESD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 9   \n   VCMPNGTSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 0AH \n   VCMPFALSESD reg1, reg2, reg3  VCMPSD reg1, reg2, reg3, 0BH \n   VCMPNEQ_OQSD reg1, reg2, reg3 VCMPSD reg1, reg2, reg3, 0CH \n   VCMPGESD reg1, reg2, reg3     VCMPSD reg1, reg2, reg3, 0DH \n\n   Table 3-7. Pseudo-Op and VCMPSD Implementation\n\n   Pseudo-Op                       CMPSD Implementation         \n   VCMPGTSD reg1, reg2, reg3       VCMPSD reg1, reg2, reg3, 0EH \n   VCMPTRUESD reg1, reg2, reg3     VCMPSD reg1, reg2, reg3, 0FH \n   VCMPEQ_OSSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 10H \n   VCMPLT_OQSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 11H \n   VCMPLE_OQSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 12H \n   VCMPUNORD_SSD reg1, reg2, reg3  VCMPSD reg1, reg2, reg3, 13H \n   VCMPNEQ_USSD reg1, reg2, reg3   VCMPSD reg1, reg2, reg3, 14H \n   VCMPNLT_UQSD reg1, reg2, reg3   VCMPSD reg1, reg2, reg3, 15H \n   VCMPNLE_UQSD reg1, reg2, reg3   VCMPSD reg1, reg2, reg3, 16H \n   VCMPORD_SSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 17H \n   VCMPEQ_USSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 18H \n   VCMPNGE_UQSD reg1, reg2, reg3   VCMPSD reg1, reg2, reg3, 19H \n   VCMPNGT_UQSD reg1, reg2, reg3   VCMPSD reg1, reg2, reg3, 1AH \n   VCMPFALSE_OSSD reg1, reg2, reg3 VCMPSD reg1, reg2, reg3, 1BH \n   VCMPNEQ_OSSD reg1, reg2, reg3   VCMPSD reg1, reg2, reg3, 1CH \n   VCMPGE_OQSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 1DH \n   VCMPGT_OQSD reg1, reg2, reg3    VCMPSD reg1, reg2, reg3, 1EH \n   VCMPTRUE_USSD reg1, reg2, reg3  VCMPSD reg1, reg2, reg3, 1FH \n\n   Table 3-7. Pseudo-Op and VCMPSD Implementation\n\n   Software should ensure VCMPSD is encoded with VEX.L=0. Encoding VCMPSD\n   with VEX.L=1 may encounter unpredictable behavior across different\n   processor generations.\n"],
	["vfnmadd132sd:vfnmadd213sd:vfnmadd231sd", "    VFNMADD132SD/VFNMADD213SD/VFNMADD231SD \u2014 Fused Negative Multiply-Add of\n                  ScalarDouble Precision Floating-Point Values\n\n                            Op / 64/32 Bit CPUID                              \n   Opcode/Instruction       En   Mode      Feature Description\n                                 Support   Flag    \n                                                   Multiply scalar double     \n                                                   precision floating-point   \n   VEX.LIG.66.0F38.W1 9D /r                        value from xmm1 and        \n   VFNMADD132SD xmm1, xmm2, A    V/V       FMA     xmm3/mem, negate the       \n   xmm3/m64                                        multiplication result and  \n                                                   add to xmm2 and put result \n                                                   in xmm1.                   \n                                                   Multiply scalar double     \n   VEX.LIG.66.0F38.W1 AD /r                        precision floating-point   \n   VFNMADD213SD xmm1, xmm2, A    V/V       FMA     value from xmm1 and xmm2,  \n   xmm3/m64                                        negate the multiplication  \n                                                   result and add to xmm3/mem \n                                                   and put result in xmm1.    \n                                                   Multiply scalar double     \n                                                   precision floating-point   \n   VEX.LIG.66.0F38.W1 BD /r                        value from xmm2 and        \n   VFNMADD231SD xmm1, xmm2, A    V/V       FMA     xmm3/mem, negate the       \n   xmm3/m64                                        multiplication result and  \n                                                   add to xmm1 and put result \n                                                   in xmm1.                   \n                                                   Multiply scalar double     \n   EVEX.LLIG.66.0F38.W1 9D                         precision floating-point   \n   /r VFNMADD132SD xmm1                            value from xmm1 and        \n   {k1}{z}, xmm2,           B    V/V       AVX512F xmm3/m64, negate the       \n   xmm3/m64{er}                                    multiplication result and  \n                                                   add to xmm2 and put result \n                                                   in xmm1.                   \n                                                   Multiply scalar double     \n   EVEX.LLIG.66.0F38.W1 AD                         precision floating-point   \n   /r VFNMADD213SD xmm1     B    V/V       AVX512F value from xmm1 and xmm2,  \n   {k1}{z}, xmm2,                                  negate the multiplication  \n   xmm3/m64{er}                                    result and add to xmm3/m64 \n                                                   and put result in xmm1.    \n                                                   Multiply scalar double     \n   EVEX.LLIG.66.0F38.W1 BD                         precision floating-point   \n   /r VFNMADD231SD xmm1                            value from xmm2 and        \n   {k1}{z}, xmm2,           B    V/V       AVX512F xmm3/m64, negate the       \n   xmm3/m64{er}                                    multiplication result and  \n                                                   add to xmm1 and put result \n                                                   in xmm1.                   \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type    Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A           ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Tuple1 Scalar ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFNMADD132SD: Multiplies the low packed double precision floating-point\n   value from the first source operand to the low packed double precision\n   floating-point value in the third source operand, adds the negated\n   infinite precision intermediate result to the low packed double precision\n   floating-point values in the second source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VFNMADD213SD: Multiplies the low packed double precision floating-point\n   value from the second source operand to the low packed double precision\n   floating-point value in the first source operand, adds the negated\n   infinite precision intermediate result to the low packed double precision\n   floating-point value in the third source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VFNMADD231SD: Multiplies the low packed double precision floating-point\n   value from the second source to the low packed double precision\n   floating-point value in the third source operand, adds the negated\n   infinite precision intermediate result to the low packed double precision\n   floating-point value in the first source operand, performs rounding and\n   stores the resulting packed double precision floating-point value to the\n   destination operand (first source operand).\n\n   VEX.128 and EVEX encoded version: The destination operand (also first\n   source operand) is encoded in reg_field. The second source operand is\n   encoded in VEX.vvvv/EVEX.vvvv. The third source operand is encoded in\n   rm_field. Bits 127:64 of the destination are unchanged. Bits MAXVL-1:128\n   of the destination register are zeroed.\n\n   EVEX encoded version: The low quadword element of the destination is\n   updated according to the writemask.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["vcvtps2udq", "  VCVTPS2UDQ \u2014 Convert Packed Single Precision Floating-Point Values to Packed\n                       UnsignedDoubleword Integer Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Convert four packed      \n                                                     single precision         \n   EVEX.128.0F.W0 79 /r                              floating-point values    \n   VCVTPS2UDQ xmm1 {k1}{z}, A     V/V       AVX512VL from xmm2/m128/m32bcst   \n   xmm2/m128/m32bcst                        AVX512F  to four packed unsigned  \n                                                     doubleword values in     \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Convert eight packed     \n                                                     single precision         \n   EVEX.256.0F.W0 79 /r                              floating-point values    \n   VCVTPS2UDQ ymm1 {k1}{z}, A     V/V       AVX512VL from ymm2/m256/m32bcst   \n   ymm2/m256/m32bcst                        AVX512F  to eight packed unsigned \n                                                     doubleword values in     \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Convert sixteen packed   \n                                                     single precision         \n   EVEX.512.0F.W0 79 /r                              floating-point values    \n   VCVTPS2UDQ zmm1 {k1}{z}, A     V/V       AVX512F  from zmm2/m512/m32bcst   \n   zmm2/m512/m32bcst{er}                             to sixteen packed        \n                                                     unsigned doubleword      \n                                                     values in zmm1 subject   \n                                                     to writemask k1.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full       ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   Converts sixteen packed single precision floating-point values in the\n   source operand to sixteen unsigned double-word integers in the destination\n   operand.\n\n   When a conversion is inexact, the value returned is rounded according to\n   the rounding control bits in the MXCSR register or the embedded rounding\n   control bits. If a converted result cannot be represented in the\n   destination format, the floating-point invalid exception is raised, and if\n   this exception is masked, the integer value 2^w \u2013 1 is returned, where w\n   represents the number of bits in the destination format.\n\n   The source operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory\n   location, or a 512/256/128-bit vector broadcasted from a 32-bit memory\n   location. The destination operand is a ZMM/YMM/XMM register conditionally\n   updated with writemask k1.\n\n   Note: EVEX.vvvv is reserved and must be 1111b otherwise instructions will\n   #UD.\n"],
	["fld", "                        FLD \u2014 Load Floating-Point Value\n\n   Opcode  Instruction 64-Bit Mode Compat/Leg Mode Description                \n   D9 /0   FLD m32fp   Valid       Valid           Push m32fp onto the FPU    \n                                                   register stack.            \n   DD /0   FLD m64fp   Valid       Valid           Push m64fp onto the FPU    \n                                                   register stack.            \n   DB /5   FLD m80fp   Valid       Valid           Push m80fp onto the FPU    \n                                                   register stack.            \n   D9 C0+i FLD ST(i)   Valid       Valid           Push ST(i) onto the FPU    \n                                                   register stack.            \n\nDescription \u00b6\n\n   Pushes the source operand onto the FPU register stack. The source operand\n   can be in single precision, double precision, or double extended-precision\n   floating-point format. If the source operand is in single precision or\n   double precision floating-point format, it is automatically converted to\n   the double extended-precision floating-point format before being pushed on\n   the stack.\n\n   The FLD instruction can also push the value in a selected FPU register\n   [ST(i)] onto the stack. Here, pushing register ST(0) duplicates the stack\n   top.\n\n     When the FLD instruction loads a denormal value and the DM bit in the CW\n     is not masked, an exception is flagged but the value is still pushed\n     onto the x87 stack.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFPU Flags Affected \u00b6\n\n   C1         Set to 1 if stack overflow occurred; otherwise, set to 0. \n   C0, C2, C3 Undefined.                                                \n"],
	["vp2intersectd:vp2intersectq", " VP2INTERSECTD/VP2INTERSECTQ \u2014 Compute Intersection Between DWORDS/QUADWORDS to\n                            aPair of Mask Registers\n\n                                 64/32                                         \n   Opcode/Instruction      Op/En bit     CPUID Feature Flag  Description\n                                 Mode    \n                                 Support \n                                                             Store, in an      \n                                                             even/odd pair of  \n   EVEX.NDS.128.F2.0F38.W0                                   mask registers,   \n   68 /r VP2INTERSECTD                   AVX512VL            the indicators of \n   k1+1, xmm2,             A     V/V     AVX512_VP2INTERSECT the locations of  \n   xmm3/m128/m32bcst                                         value matches     \n                                                             between dwords in \n                                                             xmm3/m128/m32bcst \n                                                             and xmm2.         \n                                                             Store, in an      \n                                                             even/odd pair of  \n   EVEX.NDS.256.F2.0F38.W0                                   mask registers,   \n   68 /r VP2INTERSECTD                   AVX512VL            the indicators of \n   k1+1, ymm2,             A     V/V     AVX512_VP2INTERSECT the locations of  \n   ymm3/m256/m32bcst                                         value matches     \n                                                             between dwords in \n                                                             ymm3/m256/m32bcst \n                                                             and ymm2.         \n                                                             Store, in an      \n                                                             even/odd pair of  \n   EVEX.NDS.512.F2.0F38.W0                                   mask registers,   \n   68 /r VP2INTERSECTD                   AVX512F             the indicators of \n   k1+1, zmm2,             A     V/V     AVX512_VP2INTERSECT the locations of  \n   zmm3/m512/m32bcst                                         value matches     \n                                                             between dwords in \n                                                             zmm3/m512/m32bcst \n                                                             and zmm2.         \n                                                             Store, in an      \n                                                             even/odd pair of  \n                                                             mask registers,   \n   EVEX.NDS.128.F2.0F38.W1                                   the indicators of \n   68 /r VP2INTERSECTQ     A     V/V     AVX512VL            the locations of  \n   k1+1, xmm2,                           AVX512_VP2INTERSECT value matches     \n   xmm3/m128/m64bcst                                         between quadwords \n                                                             in                \n                                                             xmm3/m128/m64bcst \n                                                             and xmm2.         \n                                                             Store, in an      \n                                                             even/odd pair of  \n                                                             mask registers,   \n   EVEX.NDS.256.F2.0F38.W1                                   the indicators of \n   68 /r VP2INTERSECTQ     A     V/V     AVX512VL            the locations of  \n   k1+1, ymm2,                           AVX512_VP2INTERSECT value matches     \n   ymm3/m256/m64bcst                                         between quadwords \n                                                             in                \n                                                             ymm3/m256/m64bcst \n                                                             and ymm2.         \n                                                             Store, in an      \n                                                             even/odd pair of  \n                                                             mask registers,   \n   EVEX.NDS.512.F2.0F38.W1                                   the indicators of \n   68 /r VP2INTERSECTQ     A     V/V     AVX512F             the locations of  \n   k1+1, zmm2,                           AVX512_VP2INTERSECT value matches     \n   zmm3/m512/m64bcst                                         between quadwords \n                                                             in                \n                                                             zmm3/m512/m64bcst \n                                                             and zmm2.         \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3     Operand 4 \n   A     Full  ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   This instruction writes an even/odd pair of mask registers. The mask\n   register destination indicated in the MODRM.REG field is used to form the\n   basis of the register pair. The low bit of that field is masked off (set\n   to zero) to create the first register of the pair.\n\n   EVEX.aaa and EVEX.z must be zero.\n"],
	["mulps", "         MULPS \u2014 Multiply Packed Single Precision Floating-Point Values\n\n                           Op / 64/32 bit CPUID                               \n   Opcode/Instruction      En   Mode      Feature  Description\n                                Support   Flag     \n                                                   Multiply packed single     \n   NP 0F 59 /r MULPS xmm1,                         precision floating-point   \n   xmm2/m128               A    V/V       SSE      values in xmm2/m128 with   \n                                                   xmm1 and store result in   \n                                                   xmm1.                      \n                                                   Multiply packed single     \n   VEX.128.0F.WIG 59 /r                            precision floating-point   \n   VMULPS xmm1,xmm2,       B    V/V       AVX      values in xmm3/m128 with   \n   xmm3/m128                                       xmm2 and store result in   \n                                                   xmm1.                      \n                                                   Multiply packed single     \n   VEX.256.0F.WIG 59 /r                            precision floating-point   \n   VMULPS ymm1, ymm2,      B    V/V       AVX      values in ymm3/m256 with   \n   ymm3/m256                                       ymm2 and store result in   \n                                                   ymm1.                      \n                                                   Multiply packed single     \n   EVEX.128.0F.W0 59 /r                   AVX512VL precision floating-point   \n   VMULPS xmm1 {k1}{z},    C    V/V       AVX512F  values from                \n   xmm2, xmm3/m128/m32bcst                         xmm3/m128/m32bcst to xmm2  \n                                                   and store result in xmm1.  \n                                                   Multiply packed single     \n   EVEX.256.0F.W0 59 /r                   AVX512VL precision floating-point   \n   VMULPS ymm1 {k1}{z},    C    V/V       AVX512F  values from                \n   ymm2, ymm3/m256/m32bcst                         ymm3/m256/m32bcst to ymm2  \n                                                   and store result in ymm1.  \n                                                   Multiply packed single     \n   EVEX.512.0F.W0 59 /r                            precision floating-point   \n   VMULPS zmm1 {k1}{z},    C    V/V       AVX512F  values in                  \n   zmm2, zmm3/m512/m32bcst                         zmm3/m512/m32bcst with     \n   {er}                                            zmm2 and store result in   \n                                                   zmm1.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Multiply the packed single precision floating-point values from the first\n   source operand with the corresponding values in the second source operand,\n   and stores the packed double precision floating-point results in the\n   destination operand.\n\n   EVEX encoded versions: The first source operand (the second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 32-bit memory location. The destination operand is a\n   ZMM/YMM/XMM register conditionally updated with writemask k1.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand can be a YMM register or a 256-bit memory location.\n   The destination operand is a YMM register. Bits (MAXVL-1:256) of the\n   corresponding destination ZMM register are zeroed.\n\n   VEX.128 encoded version: The first source operand is a XMM register. The\n   second source operand can be a XMM register or a 128-bit memory location.\n   The destination operand is a XMM register. The upper bits (MAXVL-1:128) of\n   the destination YMM register destination are zeroed.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper bits (MAXVL-1:128) of the corresponding\n   ZMM register destination are unmodified.\n"],
	["pblendvb", "                     PBLENDVB \u2014 Variable Blend Packed Bytes\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature Description\n                                  Support   Flag    \n                                                    Select byte values from   \n                                                    xmm1 and xmm2/m128 from   \n   66 0F 38 10 /r PBLENDVB  RM    V/V       SSE4_1  mask specified in the     \n   xmm1, xmm2/m128, <XMM0>                          high bit of each byte in  \n                                                    XMM0 and store the values \n                                                    into xmm1.                \n                                                    Select byte values from   \n   VEX.128.66.0F3A.W0 4C /r                         xmm2 and xmm3/m128 using  \n   /is4 VPBLENDVB xmm1,     RVMR  V/V       AVX     mask bits in the          \n   xmm2, xmm3/m128, xmm4                            specified mask register,  \n                                                    xmm4, and store the       \n                                                    values into xmm1.         \n                                                    Select byte values from   \n   VEX.256.66.0F3A.W0 4C /r                         ymm2 and ymm3/m256 from   \n   /is4 VPBLENDVB ymm1,     RVMR  V/V       AVX2    mask specified in the     \n   ymm2, ymm3/m256, ymm4                            high bit of each byte in  \n                                                    ymm4 and store the values \n                                                    into ymm1.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1        Operand 2     Operand 3     Operand 4 \n   RM    ModRM:reg (r, w) ModRM:r/m (r) <XMM0>        N/A       \n   RVMR  ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) imm8[7:4] \n\nDescription \u00b6\n\n   Conditionally copies byte elements from the source operand (second\n   operand) to the destination operand (first operand) depending on mask bits\n   defined in the implicit third register argument, XMM0. The mask bits are\n   the most significant bit in each byte element of the XMM0 register.\n\n   If a mask bit is \u201c1\", then the corresponding byte element in the source\n   operand is copied to the destination, else the byte element in the\n   destination operand is left unchanged.\n\n   The register assignment of the implicit third operand is defined to be the\n   architectural register XMM0.\n\n   128-bit Legacy SSE version: The first source operand and the destination\n   operand is the same. Bits (MAXVL-1:128) of the corresponding YMM\n   destination register remain unchanged. The mask register operand is\n   implicitly defined to be the architectural register XMM0. An attempt to\n   execute PBLENDVB with a VEX prefix will cause #UD.\n\n   VEX.128 encoded version: The first source operand and the destination\n   operand are XMM registers. The second source operand is an XMM register or\n   128-bit memory location. The mask operand is the third source register,\n   and encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of\n   imm8 are ignored. In 32-bit mode, imm8[7] is ignored. The upper bits\n   (MAXVL-1:128) of the corresponding YMM register (destination register) are\n   zeroed. VEX.L must be 0, otherwise the instruction will #UD. VEX.W must be\n   0, otherwise, the instruction will #UD.\n\n   VEX.256 encoded version: The first source operand and the destination\n   operand are YMM registers. The second source operand is an YMM register or\n   256-bit memory location. The third source register is an YMM register and\n   encoded in bits[7:4] of the immediate byte(imm8). The bits[3:0] of imm8\n   are ignored. In 32-bit mode, imm8[7] is ignored.\n\n   VPBLENDVB permits the mask to be any XMM or YMM register. In contrast,\n   PBLENDVB treats XMM0 implicitly as the mask and do not support\n   non-destructive destination operation. An attempt to execute PBLENDVB\n   encoded with a VEX prefix will cause a #UD exception.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["pcmpgtq", "                 PCMPGTQ \u2014 Compare Packed Data for Greater Than\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n   66 0F 38 37 /r PCMPGTQ                           Compare packed signed     \n   xmm1,xmm2/m128          A     V/V       SSE4_2   qwords in xmm2/m128 and   \n                                                    xmm1 for greater than.    \n   VEX.128.66.0F38.WIG 37                           Compare packed signed     \n   /r VPCMPGTQ xmm1, xmm2, B     V/V       AVX      qwords in xmm2 and        \n   xmm3/m128                                        xmm3/m128 for greater     \n                                                    than.                     \n   VEX.256.66.0F38.WIG 37                           Compare packed signed     \n   /r VPCMPGTQ ymm1, ymm2, B     V/V       AVX2     qwords in ymm2 and        \n   ymm3/m256                                        ymm3/m256 for greater     \n                                                    than.                     \n                                                    Compare Greater between   \n                                                    int64 vector xmm2 and     \n                                                    int64 vector              \n   EVEX.128.66.0F38.W1 37                  AVX512VL xmm3/m128/m64bcst, and    \n   /r VPCMPGTQ k1 {k2},    C     V/V       AVX512F  set vector mask k1 to     \n   xmm2, xmm3/m128/m64bcst                          reflect the zero/nonzero  \n                                                    status of each element of \n                                                    the result, under         \n                                                    writemask.                \n                                                    Compare Greater between   \n                                                    int64 vector ymm2 and     \n                                                    int64 vector              \n   EVEX.256.66.0F38.W1 37                  AVX512VL ymm3/m256/m64bcst, and    \n   /r VPCMPGTQ k1 {k2},    C     V/V       AVX512F  set vector mask k1 to     \n   ymm2, ymm3/m256/m64bcst                          reflect the zero/nonzero  \n                                                    status of each element of \n                                                    the result, under         \n                                                    writemask.                \n                                                    Compare Greater between   \n                                                    int64 vector zmm2 and     \n                                                    int64 vector              \n   EVEX.512.66.0F38.W1 37                           zmm3/m512/m64bcst, and    \n   /r VPCMPGTQ k1 {k2},    C     V/V       AVX512F  set vector mask k1 to     \n   zmm2, zmm3/m512/m64bcst                          reflect the zero/nonzero  \n                                                    status of each element of \n                                                    the result, under         \n                                                    writemask.                \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs an SIMD signed compare for the packed quadwords in the\n   destination operand (first operand) and the source operand (second\n   operand). If the data element in the first (destination) operand is\n   greater than the corresponding element in the second (source) operand, the\n   corresponding data element in the destination is set to all 1s; otherwise,\n   it is set to 0s.\n\n   128-bit Legacy SSE version: The second source operand can be an XMM\n   register or a 128-bit memory location. The first source operand and\n   destination operand are XMM registers. Bits (MAXVL-1:128) of the\n   corresponding YMM destination register remain unchanged.\n\n   VEX.128 encoded version: The second source operand can be an XMM register\n   or a 128-bit memory location. The first source operand and destination\n   operand are XMM registers. Bits (MAXVL-1:128) of the corresponding YMM\n   register are zeroed.\n\n   VEX.256 encoded version: The first source operand is a YMM register. The\n   second source operand is a YMM register or a 256-bit memory location. The\n   destination operand is a YMM register.\n\n   EVEX encoded VPCMPGTD/Q: The first source operand (second operand) is a\n   ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM\n   register, a 512/256/128-bit memory location or a 512/256/128-bit vector\n   broadcasted from a 64-bit memory location. The destination operand (first\n   operand) is a mask register updated according to the writemask k2.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["ud", "                           UD \u2014 Undefined Instruction\n\n   Opcode   Instruction      Op/En 64-Bit Compat/Leg Description              \n                                   Mode   Mode       \n   0F FF /r UD0^1 r32, r/m32 RM    Valid  Valid      Raise invalid opcode     \n                                                     exception.               \n   0F B9 /r UD1 r32, r/m32   RM    Valid  Valid      Raise invalid opcode     \n                                                     exception.               \n   0F 0B    UD2              ZO    Valid  Valid      Raise invalid opcode     \n                                                     exception.               \n\n     1. Some processors decode the UD0 instruction without a ModR/M byte. As\n     a result, those processors would deliver an invalid-opcode exception\n     instead of a fault on instruction fetch when the instruction with a\n     ModR/M byte (and any implied bytes) would cross a page or segment\n     boundary.\n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   ZO    N/A           N/A           N/A       N/A       \n   RM    ModRM:reg (r) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Generates an invalid opcode exception. This instruction is provided for\n   software testing to explicitly generate an invalid opcode exception. The\n   opcodes for this instruction are reserved for this purpose.\n\n   Other than raising the invalid opcode exception, this instruction has no\n   effect on processor state or memory.\n\n   Even though it is the execution of the UD instruction that causes the\n   invalid opcode exception, the instruction pointer saved by delivery of the\n   exception references the UD instruction (and not the following\n   instruction).\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["lgdt:lidt", "          LGDT/LIDT \u2014 Load Global/Interrupt Descriptor Table Register\n\n   Opcode   Instruction Op/En 64-Bit Mode Compat/Leg Mode Description       \n   0F 01 /2 LGDT m16&32 M     N.E.        Valid           Load m into GDTR. \n   0F 01 /3 LIDT m16&32 M     N.E.        Valid           Load m into IDTR. \n   0F 01 /2 LGDT m16&64 M     Valid       N.E.            Load m into GDTR. \n   0F 01 /3 LIDT m16&64 M     Valid       N.E.            Load m into IDTR. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2 Operand 3 Operand 4 \n   M     ModRM:r/m (r) N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Loads the values in the source operand into the global descriptor table\n   register (GDTR) or the interrupt descriptor table register (IDTR). The\n   source operand specifies a 6-byte memory location that contains the base\n   address (a linear address) and the limit (size of table in bytes) of the\n   global descriptor table (GDT) or the interrupt descriptor table (IDT). If\n   operand-size attribute is 32 bits, a 16-bit limit (lower 2 bytes of the\n   6-byte data operand) and a 32-bit base address (upper 4 bytes of the data\n   operand) are loaded into the register. If the operand-size attribute is 16\n   bits, a 16-bit limit (lower 2 bytes) and a 24-bit base address (third,\n   fourth, and fifth byte) are loaded. Here, the high-order byte of the\n   operand is not used and the high-order byte of the base address in the\n   GDTR or IDTR is filled with zeros.\n\n   The LGDT and LIDT instructions are used only in operating-system software;\n   they are not used in application programs. They are the only instructions\n   that directly load a linear address (that is, not a segment-relative\n   address) and a limit in protected mode. They are commonly executed in\n   real-address mode to allow processor initialization prior to switching to\n   protected mode.\n\n   In 64-bit mode, the instruction\u2019s operand size is fixed at 8+2 bytes (an\n   8-byte base and a 2-byte limit). See the summary chart at the beginning of\n   this section for encoding data and limits.\n\n   See \u201cSGDT\u2014Store Global Descriptor Table Register\u201d in Chapter 4, of the\n   Intel^\u00ae 64 and IA-32 Architectures Software Developer\u2019s Manual, Volume 2B,\n   for information on storing the contents of the GDTR and IDTR.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["sfence", "                              SFENCE \u2014 Store Fence\n\n   Opcode*     Instruction Op/En 64-Bit Compat/Leg Mode Description           \n                                 Mode   \n   NP 0F AE F8 SFENCE      ZO    Valid  Valid           Serializes store      \n                                                        operations.           \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Orders processor execution relative to all memory stores prior to the\n   SFENCE instruction. The processor ensures that every store prior to SFENCE\n   is globally visible before any store after SFENCE becomes globally\n   visible. The SFENCE instruction is ordered with respect to memory stores,\n   other SFENCE instructions, MFENCE instructions, and any serializing\n   instructions (such as the CPUID instruction). It is not ordered with\n   respect to memory loads or the LFENCE instruction.\n\n   Weakly ordered memory types can be used to achieve higher processor\n   performance through such techniques as out-of-order issue,\n   write-combining, and write-collapsing. The degree to which a consumer of\n   data recognizes or knows that the data is weakly ordered varies among\n   applications and may be unknown to the producer of this data. The SFENCE\n   instruction provides a performance-efficient way of ensuring store\n   ordering between routines that produce weakly-ordered results and routines\n   that consume this data.\n\n   This instruction\u2019s operation is the same in non-64-bit modes and 64-bit\n   mode.\n\n   Specification of the instruction's opcode above indicates a ModR/M byte of\n   F8. For this instruction, the processor ignores the r/m field of the\n   ModR/M byte. Thus, SFENCE is encoded by any opcode of the form 0F AE Fx,\n   where x is in the range 8-F.\n"],
	["vpermt2b", "      VPERMT2B \u2014 Full Permute of Bytes From Two Tables Overwriting a Table\n\n                                   64/32 bit CPUID Feature                    \n   Opcode/Instruction       Op /En Mode      Flag          Description\n                                   Support   \n                                                           Permute bytes in   \n                                                           xmm3/m128 and xmm1 \n   EVEX.128.66.0F38.W0 7D                    AVX512VL      using byte indexes \n   /r VPERMT2B xmm1         A      V/V       AVX512_VBMI   in xmm2 and store  \n   {k1}{z}, xmm2, xmm3/m128                                the byte results   \n                                                           in xmm1 using      \n                                                           writemask k1.      \n                                                           Permute bytes in   \n                                                           ymm3/m256 and ymm1 \n   EVEX.256.66.0F38.W0 7D                    AVX512VL      using byte indexes \n   /r VPERMT2B ymm1         A      V/V       AVX512_VBMI   in ymm2 and store  \n   {k1}{z}, ymm2, ymm3/m256                                the byte results   \n                                                           in ymm1 using      \n                                                           writemask k1.      \n                                                           Permute bytes in   \n                                                           zmm3/m512 and zmm1 \n   EVEX.512.66.0F38.W0 7D                                  using byte indexes \n   /r VPERMT2B zmm1         A      V/V       AVX512_VBMI   in zmm2 and store  \n   {k1}{z}, zmm2, zmm3/m512                                the byte results   \n                                                           in zmm1 using      \n                                                           writemask k1.      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     Full Mem   ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   Permutes byte values from two tables, comprising of the first operand\n   (also the destination operand) and the third operand (the second source\n   operand). The second operand (the first source operand) provides byte\n   indices to select byte results from the two tables. The selected byte\n   elements are written to the destination at byte granularity under the\n   writemask k1.\n\n   The first and second operands are ZMM/YMM/XMM registers. The second\n   operand contains input indices to select elements from the two input\n   tables in the 1st and 3rd operands. The first operand is also the\n   destination of the result. The second source operand can be a ZMM/YMM/XMM\n   register, or a 512/256/128-bit memory location. In each index byte, the id\n   bit for table selection is bit 6/5/4, and bits [5:0]/[4:0]/[3:0] selects\n   element within each input table.\n\n   Note that these instructions permit a byte value in the source operands to\n   be copied to more than one location in the destination operand. Also, the\n   second table and the indices can be reused in subsequent iterations, but\n   the first table is overwritten.\n\n   Bits (MAX_VL-1:256/128) of the destination are zeroed for VL=256,128.\n"],
	["vfmaddrnd231pd", " VFMADDRND231PD \u2014 Fused Multiply-Add of Packed Double-Precision Floating-Point\n                          Valueswith rounding control\n\n   Opcode/ Mode CPUID Description Instruction Support Feature Flag            \n   VEX.DDS.128.66.0F3A.W1 B8 /r /ib V/V FMA Multiply packed double-precision  \n   floating-point values from xmm1 VFMADDRND231PD xmm0, and xmm2/mem, add to  \n   xmm0 and xmm1, xmm2/m128, imm8 put result in xmm0. VEX.DDS.256.66.0F3A.W1  \n   B8 /r /ib V/V FMA Multiply packed double-precision floating-point values   \n   from ymm1 VFMADDRND231PD ymm0, and ymm2/mem, add to ymm0 and ymm1,         \n   ymm2/m256, imm8 put result in ymm0.                                        \n\nDescription \u00b6\n\n   Multiplies the two or four packed double-precision floating-point values\n   from the second source operand to the two or four packed double-precision\n   floating-point values in the third source operand, adds the infinite\n   precision intermediate result to the two or four packed double-precision\n   floating-point values in the first source operand, performs rounding and\n   stores the resulting two or four packed double-precision floating-point\n   values to the destination operand (first source operand).\n\n   The immediate byte defines several bit fields that control rounding, DAZ,\n   FTZ, and exception suppression (SeeTable 5-3).The rounding mode specified\n   in MXCSR.RC may be bypassed if the immediate bit called MS1 (MXCSR.RC\n   Override) is set. Likewise, the MXCSR.FTZ and MXCSR.DAZ may also be\n   bypassed if the immediate bit called MS2 (MXCSR.FTZ/DAZ Override) is set.\n   In case SAE (Suppress All Exceptions) bit is set (i.e. imm8[3] = 1), the\n   status flags in MXCSR are not updated and no SIMD floating-point\n   exceptions are raised. When SAE bit is not set (i.e. imm8[3] = 0) then\n   SIMD floating-point exceptions are signaled according to the MXCSR. If any\n   result operand is an SNaN then it will be converted to a QNaN.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n\n   Bits       Field Name/value Description            Comment                 \n              RC=0             Round to nearest even                          \n   Imm8[1:0 ] RC=1             Round down             If Imm8[2] = 1\n              RC=2             Round up               \n              RC=3             Truncate               \n              MS1=0            Use MXCSR.RC for       \n   Imm8[2]                     rounding               \n              MS1=1            Use Imm8[1:0] for      Ignore MXCSR.RC         \n                               rounding               \n              SAE=0            Use MXCSR Exception    \n                               Mask settings          \n   Imm8[3]                     Suppress all Exception Numerical result is     \n              SAE=1            signaling              computed as if FP       \n                                                      exceptions are masked.  \n              MS2=0            Use MXCSR.DAZ and      \n                               MXCSR.FTZ              \n   Imm8[4]                     Use Imm8[6:5] to       Ignore MXCSR.DAZ and    \n              MS2=1            control DAZ/FTZ        MXCSR.FTZ               \n                               operation              \n   Imm8[5]    DAZ              Control DAZ            IF MS2 = 1              \n   Imm8[6]    FTZ              Control FTZ            IF MS2 = 1              \n   Imm8[7]    MBZ              Must be zero           \n\n   Table 5-3. Immediate Byte Encoding\n\n   Compiler tools may optionally support the complementary mnemonic\n   VMADDRND321PD. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column. See also Section 2.3.1, \u201cFMA\n   Instruction Operand Order and Arithmetic Behavior\u201d\n"],
	["vcvtqq2ph", "   VCVTQQ2PH \u2014 Convert Packed Signed Quadword Integers to Packed FP16 Values\n\n   Instruction En Bit Mode Flag                                               \n   Support Instruction En Bit Mode \n   Flag Support 64/32 CPUID        \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32        Support             Description\n   CPUID Feature Instruction En    \n   Bit Mode Flag 64/32 CPUID       \n   Feature Instruction En Bit Mode \n   Flag CPUID Feature Instruction  \n   En Bit Mode Flag Op/ 64/32      \n   CPUID Feature                   \n                                                         Convert two packed   \n                                                         signed quadword      \n   EVEX.128.NP.MAP5.W1 5B /r                             integers in          \n   VCVTQQ2PH xmm1{k1}{z},          A V/V     AVX512-FP16 xmm2/m128/m64bcst to \n   xmm2/m128/m64bcst                         AVX512VL    packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n                                                         Convert four packed  \n                                                         signed quadword      \n   EVEX.256.NP.MAP5.W1 5B /r                             integers in          \n   VCVTQQ2PH xmm1{k1}{z},          A V/V     AVX512-FP16 ymm2/m256/m64bcst to \n   ymm2/m256/m64bcst                         AVX512VL    packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n                                                         Convert eight packed \n                                                         signed quadword      \n   EVEX.512.NP.MAP5.W1 5B /r                             integers in          \n   VCVTQQ2PH xmm1{k1}{z},          A V/V     AVX512-FP16 zmm2/m512/m64bcst to \n   zmm2/m512/m64bcst {er}                                packed FP16 values,  \n                                                         and store the result \n                                                         in xmm1 subject to   \n                                                         writemask k1.        \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Operand 1     Operand 2     Operand 3 Operand 4 \n   A     Full  ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\n  Description \u00b6\n\n   This instruction converts packed signed quadword integers in the source\n   operand to packed FP16 values in the destination operand. The destination\n   elements are updated according to the writemask.\n\n   EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.\n\n   If the result of the convert operation is overflow and MXCSR.OM=0 then a\n   SIMD exception will be raised with OE=1, PE=1.\n"],
	["phminposuw", "                  PHMINPOSUW \u2014 Packed Horizontal Word Minimum\n\n                                64/32 bit CPUID                               \n   Opcode/Instruction     Op/En Mode      Feature Description\n                                Support   Flag    \n                                                  Find the minimum unsigned   \n   66 0F 38 41 /r                                 word in xmm2/m128 and place \n   PHMINPOSUW xmm1,       RM    V/V       SSE4_1  its value in the low word   \n   xmm2/m128                                      of xmm1 and its index in    \n                                                  the second-lowest word of   \n                                                  xmm1.                       \n                                                  Find the minimum unsigned   \n   VEX.128.66.0F38.WIG 41                         word in xmm2/m128 and place \n   /r VPHMINPOSUW xmm1,   RM    V/V       AVX     its value in the low word   \n   xmm2/m128                                      of xmm1 and its index in    \n                                                  the second-lowest word of   \n                                                  xmm1.                       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1     Operand 2     Operand 3 Operand 4 \n   RM    ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   Determine the minimum unsigned word value in the source operand (second\n   operand) and place the unsigned word in the low word (bits 0-15) of the\n   destination operand (first operand). The word index of the minimum value\n   is stored in bits 16-18 of the destination operand. The remaining upper\n   bits of the destination are set to zero.\n\n   128-bit Legacy SSE version: Bits (MAXVL-1:128) of the corresponding XMM\n   destination register remain unchanged.\n\n   VEX.128 encoded version: Bits (MAXVL-1:128) of the destination XMM\n   register are zeroed. VEX.vvvv is reserved and must be 1111b, VEX.L must be\n   0, otherwise the instruction will #UD.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["endbr32", "    ENDBR32 \u2014 Terminate an Indirect Branch in 32-bit and Compatibility Mode\n\n   Opcode/Instruction  Op / 64/32 bit    CPUID        Description             \n                       En   Mode Support Feature Flag \n                                                      Terminate indirect      \n   F3 0F 1E FB ENDBR32 ZO   V/V          CET_IBT      branch in 32-bit and    \n                                                      compatibility mode.     \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A        N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Terminate an indirect branch in 32 bit and compatibility mode.\n\nFlags Affected \u00b6\n\n   None.\n"],
	["movntdqa", "           MOVNTDQA \u2014 Load Double Quadword Non-Temporal Aligned Hint\n\n                             Op / 64/32 bit CPUID                             \n   Opcode/Instruction        En   Mode      Feature  Description\n                                  Support   Flag     \n                                                     Move double quadword     \n   66 0F 38 2A /r MOVNTDQA   A    V/V       SSE4_1   from m128 to xmm1 using  \n   xmm1, m128                                        non-temporal hint if WC  \n                                                     memory type.             \n                                                     Move double quadword     \n   VEX.128.66.0F38.WIG 2A /r A    V/V       AVX      from m128 to xmm using   \n   VMOVNTDQA xmm1, m128                              non-temporal hint if WC  \n                                                     memory type.             \n                                                     Move 256-bit data from   \n   VEX.256.66.0F38.WIG 2A /r A    V/V       AVX2     m256 to ymm using        \n   VMOVNTDQA ymm1, m256                              non-temporal hint if WC  \n                                                     memory type.             \n                                                     Move 128-bit data from   \n   EVEX.128.66.0F38.W0 2A /r B    V/V       AVX512VL m128 to xmm using        \n   VMOVNTDQA xmm1, m128                     AVX512F  non-temporal hint if WC  \n                                                     memory type.             \n                                                     Move 256-bit data from   \n   EVEX.256.66.0F38.W0 2A /r B    V/V       AVX512VL m256 to ymm using        \n   VMOVNTDQA ymm1, m256                     AVX512F  non-temporal hint if WC  \n                                                     memory type.             \n                                                     Move 512-bit data from   \n   EVEX.512.66.0F38.W0 2A /r B    V/V       AVX512F  m512 to zmm using        \n   VMOVNTDQA zmm1, m512                              non-temporal hint if WC  \n                                                     memory type.             \n\nInstruction Operand Encoding^1 \u00b6\n\n     1. ModRM.MOD != 011B\n\n   Op/En Tuple Type Operand 1     Operand 2     Operand 3 Operand 4 \n   A     N/A        ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n   B     Full Mem   ModRM:reg (w) ModRM:r/m (r) N/A       N/A       \n\nDescription \u00b6\n\n   MOVNTDQA loads a double quadword from the source operand (second operand)\n   to the destination operand (first operand) using a non-temporal hint if\n   the memory source is WC (write combining) memory type. For WC memory type,\n   the nontemporal hint may be implemented by loading a temporary internal\n   buffer with the equivalent of an aligned cache line without filling this\n   data to the cache. Any memory-type aliased lines in the cache will be\n   snooped and flushed. Subsequent MOVNTDQA reads to unread portions of the\n   WC cache line will receive data from the temporary internal buffer if data\n   is available. The temporary internal buffer may be flushed by the\n   processor at any time for any reason, for example:\n\n     * A load operation other than a MOVNTDQA which references memory already\n       resident in a temporary internal buffer.\n     * A non-WC reference to memory already resident in a temporary internal\n       buffer.\n     * Interleaving of reads and writes to a single temporary internal\n       buffer.\n     * Repeated (V)MOVNTDQA loads of a particular 16-byte item in a streaming\n       line.\n     * Certain micro-architectural conditions including resource shortages,\n       detection of\n\n   a mis-speculation condition, and various fault conditions\n\n   The non-temporal hint is implemented by using a write combining (WC)\n   memory type protocol when reading the data from memory. Using this\n   protocol, the processor does not read the data into the cache hierarchy,\n   nor does it fetch the corresponding cache line from memory into the cache\n   hierarchy. The memory type of the region being read can override the\n   non-temporal hint, if the memory address specified for the non-temporal\n   read is not a WC memory region. Information on non-temporal reads and\n   writes can be found in \u201cCaching of Temporal vs. NonTemporal Data\u201d in\n   Chapter 10 in the Intel\u00ae 64 and IA-32 Architecture Software Developer\u2019s\n   Manual, Volume 3A.\n\n   Because the WC protocol uses a weakly-ordered memory consistency model, a\n   fencing operation implemented with a MFENCE instruction should be used in\n   conjunction with MOVNTDQA instructions if multiple processors might use\n   different memory types for the referenced memory locations or to\n   synchronize reads of a processor with writes by other agents in the\n   system. A processor\u2019s implementation of the streaming load hint does not\n   override the effective memory type, but the implementation of the hint is\n   processor dependent. For example, a processor implementa-\n\n   tion may choose to ignore the hint and process the instruction as a normal\n   MOVDQA for any memory type. Alternatively, another implementation may\n   optimize cache reads generated by MOVNTDQA on WB memory type to reduce\n   cache evictions.\n\n   The 128-bit (V)MOVNTDQA addresses must be 16-byte aligned or the\n   instruction will cause a #GP.\n\n   The 256-bit VMOVNTDQA addresses must be 32-byte aligned or the instruction\n   will cause a #GP.\n\n   The 512-bit VMOVNTDQA addresses must be 64-byte aligned or the instruction\n   will cause a #GP.\n"],
	["vfmsubadd132pd:vfmsubadd213pd:vfmsubadd231pd", "              VFMSUBADD132PD/VFMSUBADD213PD/VFMSUBADD231PD \u2014 Fused\n   Multiply-AlternatingSubtract/Add of Packed Double Precision Floating-Point\n                                     Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 97 /r                          precision floating-point \n   VFMSUBADD132PD xmm1,     A     V/V       FMA      values from xmm1 and     \n   xmm2, xmm3/m128                                   xmm3/mem, subtract/add   \n                                                     elements in xmm2 and put \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 A7 /r                          precision floating-point \n   VFMSUBADD213PD xmm1,     A     V/V       FMA      values from xmm1 and     \n   xmm2, xmm3/m128                                   xmm2, subtract/add       \n                                                     elements in xmm3/mem and \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 B7 /r                          precision floating-point \n   VFMSUBADD231PD xmm1,     A     V/V       FMA      values from xmm2 and     \n   xmm2, xmm3/m128                                   xmm3/mem, subtract/add   \n                                                     elements in xmm1 and put \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 97 /r                          precision floating-point \n   VFMSUBADD132PD ymm1,     A     V/V       FMA      values from ymm1 and     \n   ymm2, ymm3/m256                                   ymm3/mem, subtract/add   \n                                                     elements in ymm2 and put \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 A7 /r                          precision floating-point \n   VFMSUBADD213PD ymm1,     A     V/V       FMA      values from ymm1 and     \n   ymm2, ymm3/m256                                   ymm2, subtract/add       \n                                                     elements in ymm3/mem and \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 B7 /r                          precision floating-point \n   VFMSUBADD231PD ymm1,     A     V/V       FMA      values from ymm2 and     \n   ymm2, ymm3/m256                                   ymm3/mem, subtract/add   \n                                                     elements in ymm1 and put \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 97                            values from xmm1 and     \n   /r VFMSUBADD132PD xmm1   B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm2,                           AVX512F  subtract/add elements in \n   xmm3/m128/m64bcst                                 xmm2 and put result in   \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 A7                            values from xmm1 and     \n   /r VFMSUBADD213PD xmm1   B     V/V       AVX512VL xmm2, subtract/add       \n   {k1}{z}, xmm2,                           AVX512F  elements in              \n   xmm3/m128/m64bcst                                 xmm3/m128/m64bcst and    \n                                                     put result in xmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 B7                            values from xmm2 and     \n   /r VFMSUBADD231PD xmm1   B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm2,                           AVX512F  subtract/add elements in \n   xmm3/m128/m64bcst                                 xmm1 and put result in   \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 97                            values from ymm1 and     \n   /r VFMSUBADD132PD ymm1   B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  subtract/add elements in \n   ymm3/m256/m64bcst                                 ymm2 and put result in   \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 A7                            values from ymm1 and     \n   /r VFMSUBADD213PD ymm1   B     V/V       AVX512VL ymm2, subtract/add       \n   {k1}{z}, ymm2,                           AVX512F  elements in              \n   ymm3/m256/m64bcst                                 ymm3/m256/m64bcst and    \n                                                     put result in ymm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 B7                            values from ymm2 and     \n   /r VFMSUBADD231PD ymm1   B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  subtract/add elements in \n   ymm3/m256/m64bcst                                 ymm1 and put result in   \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 97                            values from zmm1 and     \n   /r VFMSUBADD132PD zmm1   B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    subtract/add elements in \n   zmm3/m512/m64bcst{er}                             zmm2 and put result in   \n                                                     zmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 A7                            values from zmm1 and     \n   /r VFMSUBADD213PD zmm1   B     V/V       AVX512F  zmm2, subtract/add       \n   {k1}{z}, zmm2,                                    elements in              \n   zmm3/m512/m64bcst{er}                             zmm3/m512/m64bcst and    \n                                                     put result in zmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 B7                            values from zmm2 and     \n   /r VFMSUBADD231PD zmm1   B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    subtract/add elements in \n   zmm3/m512/m64bcst{er}                             zmm1 and put result in   \n                                                     zmm1 subject to          \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFMSUBADD132PD: Multiplies the two, four, or eight packed double precision\n   floating-point values from the first source operand to the two or four\n   packed double precision floating-point values in the third source operand.\n   From the infinite precision intermediate result, subtracts the odd double\n   precision floating-point elements and adds the even double precision\n   floating-point values in the second source operand, performs rounding and\n   stores the resulting two or four packed double precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMSUBADD213PD: Multiplies the two, four, or eight packed double precision\n   floating-point values from the second source operand to the two or four\n   packed double precision floating-point values in the first source operand.\n   From the infinite precision intermediate result, subtracts the odd double\n   precision floating-point elements and adds the even double precision\n   floating-point values in the third source operand, performs rounding and\n   stores the resulting two or four packed double precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMSUBADD231PD: Multiplies the two, four, or eight packed double precision\n   floating-point values from the second source operand to the two or four\n   packed double precision floating-point values in the third source operand.\n   From the infinite precision intermediate result, subtracts the odd double\n   precision floating-point elements and adds the even double precision\n   floating-point values in the first source operand, performs rounding and\n   stores the resulting two or four packed double precision floating-point\n   values to the destination operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["eaug", "                  EAUG \u2014 Add a Page to an Initialized Enclave\n\n   Opcode/Instruction    Op/En 64/32 bit    CPUID        Description          \n                               Mode Support Feature Flag \n                                                         This leaf function   \n   EAX = 0DH ENCLS[EAUG] IR    V/V          SGX2         adds a page to an    \n                                                         initialized enclave. \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX       RBX                   RCX                                  \n   IR    EAUG (In) Address of a PAGEINFO Address of the destination EPC page  \n                   (In)                  (In)                                 \n\n  Description \u00b6\n\n   This leaf function zeroes a page of EPC memory, associates the EPC page\n   with an SECS page residing in the EPC, and stores the linear address and\n   security attributes in the EPCM. As part of the association, the security\n   attributes are configured to prevent access to the EPC page until a\n   corresponding invocation of the EACCEPT leaf or EACCEPTCOPY leaf confirms\n   the addition of the new page into the enclave. This instruction can only\n   be executed when current privilege level is 0.\n\n   RBX contains the effective address of a PAGEINFO structure while RCX\n   contains the effective address of an EPC page. The table below provides\n   additional information on the memory parameter of the EAUG leaf function.\n\nEAUG Memory Parameter Semantics \u00b6\n\n   PAGEINFO     PAGEINFO.SECS     PAGEINFO.SRCPGE PAGEINFO.SECINFO EPCPAGE    \n   Read access  Read/Write access                 Read access      Write      \n   permitted by permitted by      Must be zero    permitted by Non access     \n   Non Enclave  Enclave                           Enclave          permitted  \n                                                                   by Enclave \n\n   The instruction faults if any of the following:\n\nEAUG Faulting Conditions \u00b6\n\n   The operands are not properly  Unsupported security attributes are set.    \n   aligned.                       \n   Refers to an invalid SECS.     Reference is made to an SECS that is locked \n                                  by another thread.                          \n   The EPC page is locked by      RCX does not contain an effective address   \n   another thread.                of an EPC page.                             \n   The EPC page is already valid. The specified enclave offset is outside of  \n                                  the enclave address space.                  \n   The SECS has been initialized. \n\n  Concurrency Restrictions \u00b6\n\n                              Base Concurrency Restrictions\n   Leaf Parameter             Access    On       SGX_CONFLICT VM Exit         \n                                        Conflict Qualification                \n        Target [DS:RCX]       Exclusive #GP      EPC_PAGE_CONFLICT_EXCEPTION  \n   EAUG SECS                  Shared    #GP      \n        [DS:RBX]PAGEINFO.SECS \n\n   Table 38-10. Base Concurrency Restrictions of EAUG\n\n                           Additional Concurrency Restrictions\n                           vs. EACCEPT,                                       \n                           EACCEPTCOPY,        vs. EADD, EEXTEND,  vs. ETRACK, ETRACKC\nLeaf Parameter             EMODPE, EMODPR,     EINIT\n                           EMODT      \n                           Access     On       Access     On       Access     On       \n                                      Conflict            Conflict            Conflict \n     Target [DS:RCX]       Concurrent          Concurrent          Concurrent \nEAUG SECS                  Concurrent          Concurrent          Concurrent \n     [DS:RBX]PAGEINFO.SECS \n\n   Table 38-11. Additional Concurrency Restrictions of EAUG\n\n  Flags Affected \u00b6\n\n   None\n"],
	["edeccssa", "                         EDECCSSA \u2014 Decrements TCS.CSSA\n\n                            64/32 bit CPUID                                   \n   Opcode/Instruction Op/En Mode      Feature Flag Description\n                            Support   \n   EAX = 09H          IR    V/V       EDECCSSA     This leaf function         \n   ENCLU[EDECCSSA]                                 decrements TCS.CSSA.       \n\nInstruction Operand Encoding \u00b6\n\n   Op/En EAX           \n   IR    EDECCSSA (In) \n\n  Description \u00b6\n\n   This leaf function changes the current SSA frame by decrementing TCS.CSSA\n   for the current enclave thread. If the enclave has enabled CET shadow\n   stacks or indirect branch tracking, then EDECCSSA also changes the current\n   CET state save frame. This instruction leaf can only be executed inside an\n   enclave.\n\nEDECCSSA Memory Parameter Semantics \u00b6\n\n   TCS                          \n   Read/Write access by Enclave \n\n   The instruction faults if any of the following:\n\nEDECCSSA Faulting Conditions \u00b6\n\n   TCS.CSSA is 0.                       TCS is not valid or available or      \n                                        locked.                               \n   The SSA frame is not valid or in     \n   use.                                 \n\n  Concurrency Restrictions \u00b6\n\n   Leaf                         Parameter       Base Concurrency Restrictions\n                                                       On Conflict      \n   EDECCSSA EDECCSSA TCS                        \n   [CR_TCS_PA] Shared EDECCSSA  TCS [CR_TCS_PA]\n   TCS [CR_TCS_PA]              \n\n   Table 38-60. Base Concurrency Restrictions of EDECCSSA\n\n                        Additional Concurrency Restrictions\n                        vs. EACCEPT, EACCEPTCOPY,                            \n                        vs. EADD, EEXTEND, EINIT   vs. EADD,                 \n                        vs. ETRACK, ETRACKC Access EEXTEND, EINIT\n                        vs. ETRACK, ETRACKC Access vs. EADD,      vs. ETRACK,\n                        On Conflict Access vs.     EEXTEND, EINIT ETRACKC\n   Leaf     Parameter   ETRACK, ETRACKC Access On  vs. ETRACK,  \n                        Conflict EMODPE, EMODPR,   ETRACKC\n                        EMODT                    \n                        Access On Conflict       \n                        Access On Conflict       \n                        Access Access On         \n                        Conflict Access On       \n                        Conflict                 \n   EDECCSSA TCS         Concurrent                 Concurrent     Concurrent \n            [CR_TCS_PA] \n\n   Table 38-61. Additional Concurrency Restrictions of EDECCSSA\n\n  Flags Affected \u00b6\n\n   None\n"],
	["senter", "                 GETSEC[SENTER] \u2014 Enter a Measured Environment\n\n   Opcode           Instruction    Description                                \n                                   Launch a measured environment. EBX holds   \n                                   the SINIT authenticated code module        \n                                   physical base address. ECX holds the SINIT \n   NP 0F 37 (EAX=4) GETSEC[SENTER] authenticated code module size (bytes).    \n                                   EDX controls the level of functionality    \n                                   supported by the measured environment      \n                                   launch.                                    \n\nDescription \u00b6\n\n   The GETSEC[SENTER] instruction initiates the launch of a measured\n   environment and places the initiating logical processor (ILP) into the\n   authenticated code execution mode. The SENTER leaf of GETSEC is selected\n   with EAX set to 4 at execution. The physical base address of the AC module\n   to be loaded and authenticated is specified in EBX. The size of the module\n   in bytes is specified in ECX. EDX controls the level of functionality\n   supported by the measured environment launch. To enable the full\n   functionality of the protected environment launch, EDX must be initialized\n   to zero.\n\n   The authenticated code base address and size parameters (in bytes) are\n   passed to the GETSEC[SENTER] instruction using EBX and ECX respectively.\n   The ILP evaluates the contents of these registers according to the rules\n   for the AC module address in GETSEC[ENTERACCS]. AC module execution\n   follows the same rules, as set by GETSEC[ENTERACCS].\n\n   The launching software must ensure that the TPM.ACCESS_0.activeLocality\n   bit is clear before executing the GETSEC[SENTER] instruction.\n\n   There are restrictions enforced by the processor for execution of the\n   GETSEC[SENTER] instruction:\n\n     * Execution is not allowed unless the processor is in protected mode or\n       IA-32e mode with CPL = 0 and EFLAGS.VM = 0.\n     * Processor cache must be available and not disabled using the CR0.CD\n       and NW bits.\n     * For enforcing consistency of operation with numeric exception\n       reporting using Interrupt 16, CR0.NE must be set.\n     * An Intel TXT-capable chipset must be present as communicated to the\n       processor by sampling of the power-on configuration capability field\n       after reset.\n     * The processor can not be in authenticated code execution mode or\n       already in a measured environment (as launched by a previous\n       GETSEC[ENTERACCS] or GETSEC[SENTER] instruction).\n     * To avoid potential operability conflicts between modes, the processor\n       is not allowed to execute this instruction if it currently is in SMM\n       or VMX operation.\n     * To ensure consistent handling of SIPI messages, the processor\n       executing the GETSEC[SENTER] instruction must also be designated the\n       BSP (boot-strap processor) as defined by IA32_APIC_BASE.BSP (Bit 8).\n     * EDX must be initialized to a setting supportable by the processor.\n       Unless enumeration by the GETSEC[PARAMETERS] leaf reports otherwise,\n       only a value of zero is supported.\n\n   Failure to abide by the above conditions results in the processor\n   signaling a general protection violation.\n\n   This instruction leaf starts the launch of a measured environment by\n   initiating a rendezvous sequence for all logical processors in the\n   platform. The rendezvous sequence involves the initiating logical\n   processor sending a message (by executing GETSEC[SENTER]) and other\n   responding logical processors (RLPs) acknowledging the message, thus\n   synchronizing the RLP(s) with the ILP.\n\n   In response to a message signaling the completion of rendezvous, RLPs\n   clear the bootstrap processor indicator flag (IA32_APIC_BASE.BSP) and\n   enter an SENTER sleep state. In this sleep state, RLPs enter an idle\n   processor condition while waiting to be activated after a measured\n   environment has been established by the system executive. RLPs in the\n   SENTER sleep state can only be activated by the GETSEC leaf function\n   WAKEUP in a measured environment.\n\n   A successful launch of the measured environment results in the initiating\n   logical processor entering the authenticated code execution mode. Prior to\n   reaching this point, the ILP performs the following steps internally:\n\n     * Inhibit processor response to the external events: INIT, A20M, NMI,\n       and SMI.\n     * Establish and check the location and size of the authenticated code\n       module to be executed by the ILP.\n     * Check for the existence of an Intel^\u00ae TXT-capable chipset.\n     * Verify the current power management configuration is acceptable.\n     * Broadcast a message to enable protection of memory and I/O from\n       activities from other processor agents.\n     * Load the designated AC module into authenticated code execution area.\n     * Isolate the content of authenticated code execution area from further\n       state modification by external agents.\n     * Authenticate the AC module.\n     * Updated the Trusted Platform Module (TPM) with the authenticated code\n       module's hash.\n     * Initialize processor state based on the authenticated code module\n       header information.\n     * Unlock the Intel^\u00ae TXT-capable chipset private configuration register\n       space and TPM locality 3 space.\n     * Begin execution in the authenticated code module at the defined entry\n       point.\n\n   As an integrity check for proper processor hardware operation, execution\n   of GETSEC[SENTER] will also check the contents of all the machine check\n   status registers (as reported by the MSRs IA32_MCi_STATUS) for any valid\n   uncorrectable error condition. In addition, the global machine check\n   status register IA32_MCG_STATUS MCIP bit must be cleared and the IERR\n   processor package pin (or its equivalent) must be not asserted, indicating\n   that no machine check exception processing is currently in-progress. These\n   checks are performed twice: once by the ILP prior to the broadcast of the\n   rendezvous message to RLPs, and later in response to RLPs acknowledging\n   the rendezvous message. Any outstanding valid uncorrectable machine check\n   error condition present in the machine check status registers at the first\n   check point will result in the ILP signaling a general protection\n   violation. If an outstanding valid uncorrectable machine check error\n   condition is present at the second check point, then this will result in\n   the corresponding logical processor signaling the more severe TXT-shutdown\n   condition with an error code of 12.\n\n   Before loading and authentication of the target code module is performed,\n   the processor also checks that the current voltage and bus ratio encodings\n   correspond to known good values supportable by the processor. The MSR\n   IA32_PERF_STATUS values are compared against either the processor\n   supported maximum operating target setting, system reset setting, or the\n   thermal monitor operating target. If the current settings do not meet any\n   of these criteria then the SENTER function will attempt to change the\n   voltage and bus ratio select controls in a processor-specific manner. This\n   adjustment may be to the thermal monitor, minimum (if different), or\n   maximum operating target depending on the processor.\n\n   This implies that some thermal operating target parameters configured by\n   BIOS may be overridden by SENTER. The measured environment software may\n   need to take responsibility for restoring such settings that are deemed to\n   be safe, but not necessarily recognized by SENTER. If an adjustment is not\n   possible when an out of range setting is discovered, then the processor\n   will abort the measured launch. This may be the case for chipset\n   controlled settings of these values or if the controllability is not\n   enabled on the processor. In this case it is the responsibility of the\n   external software to program the chipset voltage ID and/or bus ratio\n   select settings to known good values recognized by the processor, prior to\n   executing SENTER.\n\n     For a mobile processor, an adjustment can be made according to the\n     thermal monitor operating target. For a quad-core processor the SENTER\n     adjustment mechanism may result in a more conservative but non-uniform\n     voltage setting, depending on the pre-SENTER settings per core.\n\n   The ILP and RLPs mask the response to the assertion of the external\n   signals INIT#, A20M, NMI#, and SMI#. The purpose of this masking control\n   is to prevent exposure to existing external event handlers until a\n   protected handler has been put in place to directly handle these events.\n   Masked external pin events may be unmasked conditionally or\n   unconditionally via the GETSEC[EXITAC], GETSEC[SEXIT], GETSEC[SMCTRL] or\n   for specific VMX related operations such as a VM entry or the VMXOFF\n   instruction (see respective GETSEC leaves and Intel^\u00ae 64 and IA-32\n   Architectures Software Developer\u2019s Manual, Volume 3C, for more details).\n   The state of the A20M pin is masked and forced internally to a de-asserted\n   state so that external assertion is not recognized. A20M masking as set by\n\n   GETSEC[SENTER] is undone only after taking down the measured environment\n   with the GETSEC[SEXIT] instruction or processor reset. INTR is masked by\n   simply clearing the EFLAGS.IF bit. It is the responsibility of system\n   software to control the processor response to INTR through appropriate\n   management of EFLAGS.\n\n   To prevent other (logical) processors from interfering with the ILP\n   operating in authenticated code execution mode, memory (excluding implicit\n   write-back transactions) and I/O activities originating from other\n   processor agents are blocked. This protection starts when the ILP enters\n   into authenticated code execution mode. Only memory and I/O transactions\n   initiated from the ILP are allowed to proceed. Exiting authenticated code\n   execution mode is done by executing GETSEC[EXITAC]. The protection of\n   memory and I/O activities remains in effect until the ILP executes\n   GETSEC[EXITAC].\n\n   Once the authenticated code module has been loaded into the authenticated\n   code execution area, it is protected against further modification from\n   external bus snoops. There is also a requirement that the memory type for\n   the authenticated code module address range be WB (via initialization of\n   the MTRRs prior to execution of this instruction). If this condition is\n   not satisfied, it is a violation of security and the processor will force\n   a TXT system reset (after writing an error code to the chipset\n   LT.ERRORCODE register). This action is referred to as a Intel\u00ae TXT reset\n   condition. It is performed when it is considered unreliable to signal an\n   error through the conventional exception reporting mechanism.\n\n   To conform to the minimum granularity of MTRR MSRs for specifying the\n   memory type, authenticated code RAM (ACRAM) is allocated to the processor\n   in 4096 byte granular blocks. If an AC module size as specified in ECX is\n   not a multiple of 4096 then the processor will allocate up to the next\n   4096 byte boundary for mapping as ACRAM with indeterminate data. This pad\n   area will not be visible to the authenticated code module as external\n   memory nor can it depend on the value of the data used to fill the pad\n   area.\n\n   Once successful authentication has been completed by the ILP, the computed\n   hash is stored in a trusted storage facility in the platform. The\n   following trusted storage facility are supported:\n\n     * If the platform register FTM_INTERFACE_ID.[bits 3:0] = 0, the computed\n       hash is stored to the platform\u2019s TPM at PCR17 after this register is\n       implicitly reset. PCR17 is a dedicated register for holding the\n       computed hash of the authenticated code module loaded and subsequently\n       executed by the GETSEC[SENTER]. As part of this process, the dynamic\n       PCRs 18-22 are reset so they can be utilized by subsequently software\n       for registration of code and data modules.\n     * If the platform register FTM_INTERFACE_ID.[bits 3:0] = 1, the computed\n       hash is stored in a firmware trusted module (FTM) using a modified\n       protocol similar to the protocol used to write to TPM\u2019s PCR17.\n\n   After successful execution of SENTER, either PCR17 (if FTM is not enabled)\n   or the FTM (if enabled) contains the measurement of AC code and the SENTER\n   launching parameters.\n\n   After authentication is completed successfully, the private configuration\n   space of the Intel^\u00ae TXT-capable chipset is unlocked so that the\n   authenticated code module and measured environment software can gain\n   access to this normally restricted chipset state. The Intel\u00ae TXT-capable\n   chipset private configuration space can be locked later by software\n   writing to the chipset LT.CMD.CLOSE-PRIVATE register or unconditionally\n   using the GETSEC[SEXIT] instruction.\n\n   The SENTER leaf function also initializes some processor architecture\n   state for the ILP from contents held in the header of the authenticated\n   code module. Since the authenticated code module is relocatable, all\n   address references are relative to the base address passed in via EBX. The\n   ILP GDTR base value is initialized to EBX + [GDTBasePtr] and GDTR limit\n   set to [GDTLimit]. The CS selector is initialized to the value held in the\n   AC module header field SegSel, while the DS, SS, and ES selectors are\n   initialized to CS+8. The segment descriptor fields are initialized\n   implicitly with BASE=0, LIMIT=FFFFFh, G=1, D=1, P=1, S=1,\n   read/write/accessed for DS, SS, and ES, while execute/read/accessed for\n   CS. Execution in the authenticated code module for the ILP begins with the\n   EIP set to EBX + [EntryPoint]. AC module defined fields used for\n   initializing processor state are consistency checked with a failure\n   resulting in an TXT-shutdown condition.\n\n   Table 7-6 provides a summary of processor state initialization for the ILP\n   and RLP(s) after successful completion of GETSEC[SENTER]. For both ILP and\n   RLP(s), paging is disabled upon entry to the measured environment. It is\n   up to the ILP to establish a trusted paging environment, with appropriate\n   mappings, to meet protection requirements established during the launch of\n   the measured environment. RLP state initialization is not completed until\n   a subsequent wake-up has been signaled by execution of the GETSEC[WAKEUP]\n   function by the ILP.\n\n   Register State        ILP after GETSEC[SENTER]    RLP after GETSEC[WAKEUP] \n   CR0                   PG\u21900, AM\u21900, WP\u21900; Others    PG\u21900, CD\u21900, NW\u21900, AM\u21900,  \n                         unchanged                   WP\u21900; PE\u21901, NE\u21901         \n   CR4                   00004000H                   00004000H                \n   EFLAGS                00000002H                   00000002H                \n   IA32_EFER             0H                          0                        \n   EIP                   [EntryPoint from MLE        [LT.MLE.JOIN + 12]       \n                         header^1]                   \n   EBX                   Unchanged [SINIT.BASE]      Unchanged                \n   EDX                   SENTER control flags        Unchanged                \n   EBP                   SINIT.BASE                  Unchanged                \n                         Sel=[SINIT SegSel], base=0, Sel = [LT.MLE.JOIN + 8], \n   CS                    limit=FFFFFh, G=1, D=1,     base = 0, limit =        \n                         AR=9BH                      FFFFFH, G = 1, D = 1, AR \n                                                     = 9BH                    \n                         Sel=[SINIT SegSel] +8,      Sel = [LT.MLE.JOIN + 8]  \n   DS, ES, SS            base=0, limit=FFFFFh, G=1,  +8, base = 0, limit =    \n                         D=1, AR=93H                 FFFFFH, G = 1, D = 1, AR \n                                                     = 93H                    \n                         Base= SINIT.base (EBX) +    Base = [LT.MLE.JOIN +    \n   GDTR                  [SINIT.GDTBasePtr],         4], Limit =              \n                         Limit=[SINIT.GDTLimit]      [LT.MLE.JOIN]            \n   DR7                   00000400H                   00000400H                \n   IA32_DEBUGCTL         0H                          0H                       \n   Performance counters                                                       \n   and counter control   0H                          0H\n   registers             \n   IA32_MISC_ENABLE      See Table 7-5               See Table 7-5            \n   IA32_SMM_MONITOR _CTL Bit 2\u21900                     Bit 2\u21900                  \n\n   Table 7-6. Register State Initialization After GETSEC[SENTER] and\n   GETSEC[WAKEUP]\n\n     1. See the Intel\u00ae Trusted Execution Technology Measured Launched\n     Environment Programming Guide for MLE header format.\n\n     Segmentation related processor state that has not been initialized by\n     GETSEC[SENTER] requires appropriate initialization before use. Since a\n     new GDT context has been established, the previous state of the segment\n     selector values held in FS, GS, TR, and LDTR may no longer be valid. The\n     IDTR will also require reloading with a new IDT context after launching\n     the measured environment before exceptions or the external interrupts\n     INTR and NMI can be handled. In the meantime, the programmer must take\n     care in not executing an INT n instruction or any other condition that\n     would result in an exception or trap signaling.\n\n     Debug exception and trap related signaling is also disabled as part of\n     execution of GETSEC[SENTER]. This is achieved by clearing DR7, TF in\n     EFLAGs, and the MSR IA32_DEBUGCTL as defined in Table 7-6. These can be\n     reenabled once supporting exception handler(s), descriptor tables, and\n     debug registers have been properly re-initialized following SENTER.\n     Also, any pending single-step trap condition will be cleared at the\n     completion of SENTER for both the ILP and RLP(s).\n\n     Performance related counters and counter control registers are cleared\n     as part of execution of SENTER on both the ILP and RLP. This implies any\n     active performance counters at the time of SENTER execution will be\n     disabled. To reactive the processor performance counters, this state\n     must be re-initialized and re-enabled.\n\n     Since MCE along with all other state bits (with the exception of SMXE)\n     are cleared in CR4 upon execution of SENTER processing, any enabled\n     machine check error condition that occurs will result in the processor\n     performing the TXT-shutdown action. This also applies to an RLP while in\n     the SENTER sleep state. For each logical processor CR4.MCE\n\n   must be reestablished with a valid machine check exception handler to\n   otherwise avoid an TXT-shutdown under such conditions.\n\n   The MSR IA32_EFER is also unconditionally cleared as part of the processor\n   state initialized by SENTER for both the ILP and RLP. Since paging is\n   disabled upon entering authenticated code execution mode, a new paging\n   environment will have to be re-established if it is desired to enable\n   IA-32e mode while operating in authenticated code execution mode.\n\n   The miscellaneous feature control MSR, IA32_MISC_ENABLE, is initialized as\n   part of the measured environment launch. Certain bits of this MSR are\n   preserved because preserving these bits may be important to maintain\n   previously established platform settings. See the footnote for Table 7-5\n   The remaining bits are cleared for the purpose of establishing a more\n   consistent environment for the execution of authenticated code modules.\n   Among the impact of initializing this MSR, any previous condition\n   established by the MONITOR instruction will be cleared.\n\n   Effect of MSR IA32_FEATURE_CONTROL MSR\n\n   Bits 15:8 of the IA32_FEATURE_CONTROL MSR affect the execution of\n   GETSEC[SENTER]. These bits consist of two fields:\n\n     * Bit 15: a global enable control for execution of SENTER.\n     * Bits 14:8: a parameter control field providing the ability to qualify\n       SENTER execution based on the level of functionality specified with\n       corresponding EDX parameter bits 6:0.\n\n   The layout of these fields in the IA32_FEATURE_CONTROL MSR is shown in\n   Table 7-1.\n\n   Prior to the execution of GETSEC[SENTER], the lock bit of\n   IA32_FEATURE_CONTROL MSR must be bit set to affirm the settings to be\n   used. Once the lock bit is set, only a power-up reset condition will clear\n   this MSR. The IA32_FEA-TURE_CONTROL MSR must be configured in accordance\n   to the intended usage at platform initialization. Note that this MSR is\n   only available on SMX or VMX enabled processors. Otherwise,\n   IA32_FEATURE_CONTROL is treated as reserved.\n\n   The Intel\u00ae Trusted Execution Technology Measured Launched Environment\n   Programming Guide provides additional details and requirements for\n   programming measured environment software to launch in an Intel TXT\n   platform.\n\nOperation in a Uni-Processor Platform \u00b6\n\n   (* The state of the internal flag ACMODEFLAG and SENTERFLAG persist across\n   instruction boundary *)\n\n   GETSEC[SENTER] (ILP Only):\n\n   IF (CR4.SMXE=0)\n\n   THEN #UD;\n\n   ELSE IF (in VMX non-root operation)\n\n   THEN VM Exit (reason=\u201dGETSEC instruction\u201d);\n\n   ELSE IF (GETSEC leaf unsupported)\n\n   THEN #UD;\n\n   ELSE IF ((in VMX root operation) or\n\n   (CR0.PE=0) or (CR0.CD=1) or (CR0.NW=1) or (CR0.NE=0) or\n\n   (CPL>0) or (EFLAGS.VM=1) or\n\n   (IA32_APIC_BASE.BSP=0) or (TXT chipset not present) or\n\n   (SENTERFLAG=1) or (ACMODEFLAG=1) or (IN_SMM=1) or\n\n   (TPM interface is not present) or\n\n   (EDX =\u0338 (SENTER_EDX_support_mask & EDX)) or\n\n   (IA32_FEATURE_CONTROL[0]=0) or (IA32_FEATURE_CONTROL[15]=0) or\n\n   ((IA32_FEATURE_CONTROL[14:8] & EDX[6:0]) =\u0338 EDX[6:0]))\n\n   THEN #GP(0);\n\n   IF (GETSEC[PARAMETERS].Parameter_Type = 5, MCA_Handling (bit 6) = 0)\n\n   FOR I = 0 to IA32_MCG_CAP.COUNT-1 DO\n\n   IF IA32_MC[I]_STATUS = uncorrectable error\n\n   THEN #GP(0);\n\n   FI;\n\n   OD;\n\n   FI;\n\n   IF (IA32_MCG_STATUS.MCIP=1) or (IERR pin is asserted)\n\n   THEN #GP(0);\n\n   ACBASE := EBX;\n\n   ACSIZE := ECX;\n\n   IF (((ACBASE MOD 4096) =\u0338 0) or ((ACSIZE MOD 64) =\u0338 0 ) or (ACSIZE <\n   minimum\n\n   module size) or (ACSIZE > AC RAM capacity) or ((ACBASE+ACSIZE) > (2^32\n   -1)))\n\n   THEN #GP(0);\n\n   Mask SMI, INIT, A20M, and NMI external pin events;\n\n   SignalTXTMsg(SENTER);\n\n   DO\n\n   WHILE (no SignalSENTER message);\n\n   TXT_SENTER__MSG_EVENT (ILP & RLP):\n\n   Mask and clear SignalSENTER event;\n\n   Unmask SignalSEXIT event;\n\n   IF (in VMX operation)\n\n   THEN TXT-SHUTDOWN(#IllegalEvent);\n\n   FOR I = 0 to IA32_MCG_CAP.COUNT-1 DO\n\n   IF IA32_MC[I]_STATUS = uncorrectable error\n\n   THEN TXT-SHUTDOWN(#UnrecovMCError);\n\n   FI;\n\n   OD;\n\n   IF (IA32_MCG_STATUS.MCIP=1) or (IERR pin is asserted)\n\n   THEN TXT-SHUTDOWN(#UnrecovMCError);\n\n   IF (Voltage or bus ratio status are NOT at a known good state)\n\n   THEN IF (Voltage select and bus ratio are internally adjustable)\n\n   THEN\n\n   Make product-specific adjustment on operating parameters;\n\n   ELSE\n\n   TXT-SHUTDOWN(#IIlegalVIDBRatio);\n\n   FI;\n\n   IA32_MISC_ENABLE := (IA32_MISC_ENABLE & MASK_CONST*)\n\n   (* The hexadecimal value of MASK_CONST may vary due to processor\n   implementations *)\n\n   A20M := 0;\n\n   IA32_DEBUGCTL := 0;\n\n   Invalidate processor TLB(s);\n\n   Drain outgoing transactions;\n\n   Clear performance monitor counters and control;\n\n   SENTERFLAG := 1;\n\n   SignalTXTMsg(SENTERAck);\n\n   IF (logical processor is not ILP)\n\n   THEN GOTO RLP_SENTER_ROUTINE;\n\n   (* ILP waits for all logical processors to ACK *)\n\n   DO\n\n   DONE := TXT.READ(LT.STS);\n\n   WHILE (not DONE);\n\n   SignalTXTMsg(SENTERContinue);\n\n   SignalTXTMsg(ProcessorHold);\n\n   FOR I=ACBASE to ACBASE+ACSIZE-1 DO\n\n   ACRAM[I-ACBASE].ADDR := I;\n\n   ACRAM[I-ACBASE].DATA := LOAD(I);\n\n   OD;\n\n   IF (ACRAM memory type =\u0338 WB)\n\n   THEN TXT-SHUTDOWN(#BadACMMType);\n\n   IF (AC module header version is not supported) OR (ACRAM[ModuleType] =\u0338 2)\n\n   THEN TXT-SHUTDOWN(#UnsupportedACM);\n\n   KEY := GETKEY(ACRAM, ACBASE);\n\n   KEYHASH := HASH(KEY);\n\n   CSKEYHASH := LT.READ(LT.PUBLIC.KEY);\n\n   IF (KEYHASH =\u0338 CSKEYHASH)\n\n   THEN TXT-SHUTDOWN(#AuthenticateFail);\n\n   SIGNATURE := DECRYPT(ACRAM, ACBASE, KEY);\n\n   (* The value of SIGNATURE_LEN_CONST is implementation-specific*)\n\n   FOR I=0 to SIGNATURE_LEN_CONST - 1 DO\n\n   ACRAM[SCRATCH.I] := SIGNATURE[I];\n\n   COMPUTEDSIGNATURE := HASH(ACRAM, ACBASE, ACSIZE);\n\n   FOR I=0 to SIGNATURE_LEN_CONST - 1 DO\n\n   ACRAM[SCRATCH.SIGNATURE_LEN_CONST+I] := COMPUTEDSIGNATURE[I];\n\n   IF (SIGNATURE =\u0338 COMPUTEDSIGNATURE)\n\n   THEN TXT-SHUTDOWN(#AuthenticateFail);\n\n   ACMCONTROL := ACRAM[CodeControl];\n\n   IF ((ACMCONTROL.0 = 0) and (ACMCONTROL.1 = 1) and (snoop hit to modified\n   line detected on ACRAM load))\n\n   THEN TXT-SHUTDOWN(#UnexpectedHITM);\n\n   IF (ACMCONTROL reserved bits are set)\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACRAM[GDTBasePtr] < (ACRAM[HeaderLen] * 4 + Scratch_size)) OR\n\n   ((ACRAM[GDTBasePtr] + ACRAM[GDTLimit]) >= ACSIZE))\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACMCONTROL.0 = 1) and (ACMCONTROL.1 = 1) and (snoop hit to modified\n\n   line detected on ACRAM load))\n\n   THEN ACEntryPoint := ACBASE+ACRAM[ErrorEntryPoint];\n\n   ELSE\n\n   ACEntryPoint := ACBASE+ACRAM[EntryPoint];\n\n   IF ((ACEntryPoint >= ACSIZE) or (ACEntryPoint < (ACRAM[HeaderLen] * 4 +\n   Scratch_size)))\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACRAM[SegSel] > (ACRAM[GDTLimit] - 15)) or (ACRAM[SegSel] < 8))\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF ((ACRAM[SegSel].TI=1) or (ACRAM[SegSel].RPL=\u03380))\n\n   THEN TXT-SHUTDOWN(#BadACMFormat);\n\n   IF (FTM_INTERFACE_ID.[3:0] = 1 ) (* Alternate FTM Interface has been\n   enabled *)\n\n   THEN (* TPM_LOC_CTRL_4 is located at 0FED44008H, TMP_DATA_BUFFER_4 is\n   located at 0FED44080H *)\n\n   WRITE(TPM_LOC_CTRL_4) := 01H; (* Modified HASH.START protocol *)\n\n   (* Write to firmware storage *)\n\n   WRITE(TPM_DATA_BUFFER_4) := SIGNATURE_LEN_CONST + 4;\n\n   FOR I=0 to SIGNATURE_LEN_CONST - 1 DO\n\n   WRITE(TPM_DATA_BUFFER_4 + 2 + I ) := ACRAM[SCRATCH.I];\n\n   WRITE(TPM_DATA_BUFFER_4 + 2 + SIGNATURE_LEN_CONST) := EDX;\n\n   WRITE(FTM.LOC_CTRL) := 06H; (* Modified protocol combining HASH.DATA and\n   HASH.END *)\n\n   ELSE IF (FTM_INTERFACE_ID.[3:0] = 0 ) (* Use standard TPM Interface *)\n\n   ACRAM[SCRATCH.SIGNATURE_LEN_CONST] := EDX;\n\n   WRITE(TPM.HASH.START) := 0;\n\n   FOR I=0 to SIGNATURE_LEN_CONST + 3 DO\n\n   WRITE(TPM.HASH.DATA) := ACRAM[SCRATCH.I];\n\n   WRITE(TPM.HASH.END) := 0;\n\n   ACMODEFLAG := 1;\n\n   CR0.[PG.AM.WP] := 0;\n\n   CR4 := 00004000h;\n\n   EFLAGS := 00000002h;\n\n   IA32_EFER := 0;\n\n   EBP := ACBASE;\n\n   GDTR.BASE := ACBASE+ACRAM[GDTBasePtr];\n\n   GDTR.LIMIT := ACRAM[GDTLimit];\n\n   CS.SEL := ACRAM[SegSel];\n\n   CS.BASE := 0;\n\n   CS.LIMIT := FFFFFh;\n\n   CS.G := 1;\n\n   CS.D := 1;\n\n   CS.AR := 9Bh;\n\n   DS.SEL := ACRAM[SegSel]+8;\n\n   DS.BASE := 0;\n\n   DS.LIMIT := FFFFFh;\n\n   DS.G := 1;\n\n   DS.D := 1;\n\n   DS.AR := 93h;\n\n   SS := DS;\n\n   ES := DS;\n\n   DR7 := 00000400h;\n\n   IA32_DEBUGCTL := 0;\n\n   SignalTXTMsg(UnlockSMRAM);\n\n   SignalTXTMsg(OpenPrivate);\n\n   SignalTXTMsg(OpenLocality3);\n\n   EIP := ACEntryPoint;\n\n   END;\n\n   RLP_SENTER_ROUTINE: (RLP Only)\n\n   Mask SMI, INIT, A20M, and NMI external pin events\n\n   Unmask SignalWAKEUP event;\n\n   Wait for SignalSENTERContinue message;\n\n   IA32_APIC_BASE.BSP := 0;\n\n   GOTO SENTER sleep state;\n\n   END;\n\nFlags Affected \u00b6\n\n   All flags are cleared.\n\nUse of Prefixes \u00b6\n\n   LOCK Causes #UD.\n\n   REP* Cause #UD (includes REPNE/REPNZ and REP/REPE/REPZ).\n\n   Operand size Causes #UD.\n\n   NP 66/F2/F3 prefixes are not allowed.\n\n   Segmentoverrides Ignored.\n\n   Address size Ignored.\n\n   REX Ignored.\n\nVM-Exit Condition \u00b6\n\n   Reason (GETSEC) If in VMX non-root operation.\n"],
	["popf:popfd:popfq", "               POPF/POPFD/POPFQ \u2014 Pop Stack Into EFLAGS Register\n\n   Opcode Instruction Op/En 64-Bit Mode Compat/Leg Mode Description           \n                                                        Pop top of stack into \n   9D     POPF        ZO    Valid       Valid           lower 16 bits of      \n                                                        EFLAGS.               \n   9D     POPFD       ZO    N.E.        Valid           Pop top of stack into \n                                                        EFLAGS.               \n                                                        Pop top of stack and  \n   9D     POPFQ       ZO    Valid       N.E.            zero-extend into      \n                                                        RFLAGS.               \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Operand 1 Operand 2 Operand 3 Operand 4 \n   ZO    N/A       N/A       N/A       N/A       \n\nDescription \u00b6\n\n   Pops a doubleword (POPFD) from the top of the stack (if the current\n   operand-size attribute is 32) and stores the value in the EFLAGS register,\n   or pops a word from the top of the stack (if the operand-size attribute is\n   16) and stores it in the lower 16 bits of the EFLAGS register (that is,\n   the FLAGS register). These instructions reverse the operation of the\n   PUSHF/PUSHFD/PUSHFQ instructions.\n\n   The POPF (pop flags) and POPFD (pop flags double) mnemonics reference the\n   same opcode. The POPF instruction is intended for use when the\n   operand-size attribute is 16; the POPFD instruction is intended for use\n   when the operand-size attribute is 32. Some assemblers may force the\n   operand size to 16 for POPF and to 32 for POPFD. Others may treat the\n   mnemonics as synonyms (POPF/POPFD) and use the setting of the operand-size\n   attribute to determine the size of values to pop from the stack.\n\n   The effect of POPF/POPFD on the EFLAGS register changes, depending on the\n   mode of operation. See Table 4-16 and the key below for details.\n\n   When operating in protected, compatibility, or 64-bit mode at privilege\n   level 0 (or in real-address mode, the equivalent to privilege level 0),\n   all non-reserved flags in the EFLAGS register except RF^1, VIP, VIF, and\n   VM may be modified. VIP, VIF, and VM remain unaffected.\n\n   When operating in protected, compatibility, or 64-bit mode with a\n   privilege level greater than 0, but less than or equal to IOPL, all flags\n   can be modified except the IOPL field and RF, IF, VIP, VIF, and VM; these\n   remain unaffected. The AC and ID flags can only be modified if the\n   operand-size attribute is 32. The interrupt flag (IF) is altered only when\n   executing at a level at least as privileged as the IOPL. If a POPF/POPFD\n   instruction is executed with insufficient privilege, an exception does not\n   occur but privileged bits do not change.\n\n   When operating in virtual-8086 mode (EFLAGS.VM = 1) without the\n   virtual-8086 mode extensions (CR4.VME = 0), the POPF/POPFD instructions\n   can be used only if IOPL = 3; otherwise, a general-protection exception\n   (#GP) occurs. If the virtual-8086 mode extensions are enabled (CR4.VME =\n   1), POPF (but not POPFD) can be executed in virtual-8086 mode with IOPL <\n   3.\n\n   (The protected-mode virtual-interrupt feature \u2014 enabled by setting CR4.PVI\n   \u2014 affects the CLI and STI instructions in the same manner as the\n   virtual-8086 mode extensions. POPF, however, is not affected by CR4.PVI.)\n\n   In 64-bit mode, the mnemonic assigned is POPFQ (note that the 32-bit\n   operand is not encodable). POPFQ pops 64 bits from the stack. Reserved\n   bits of RFLAGS (including the upper 32 bits of RFLAGS) are not affected.\n\n   See Chapter 3 of the Intel^\u00ae 64 and IA-32 Architectures Software\n   Developer\u2019s Manual, Volume 1, for more information about the EFLAGS\n   registers.\n\n     1. RF is always zero after the execution of POPF. This is because POPF,\n     like all instructions, clears RF as it begins to execute.\n\n               Operand          Flags                                                                        \nMode           Size    CPL IOPL 21  20  19   18  17  16  14  13:12 11  10  9   8   7   6   4   2   0   Notes\n                                ID  VIP VIF  AC  VM  RF  NT  IOPL  OF  DF  IF  TF  SF  ZF  AF  PF  CF  \nReal-Address   16      0   0-3  N   N   N    N   N   0   S   S     S   S   S   S   S   S   S   S   S   \nMode (CR0.PE = \n0)             32      0   0-3  S   N   N    S   N   0   S   S     S   S   S   S   S   S   S   S   S   \nProtected,     16      0   0-3  N   N   N    N   N   0   S   S     S   S   S   S   S   S   S   S   S   \nCompatibility, 16      1-3 <CPL N   N   N    N   N   0   S   N     S   S   N   S   S   S   S   S   S   \nand 64-Bit     16      1-3 \u2265CPL N   N   N    N   N   0   S   N     S   S   S   S   S   S   S   S   S   \nModes (CR0.PE  32, 64  0   0-3  S   N   N    S   N   0   S   S     S   S   S   S   S   S   S   S   S   \n= 1 EFLAGS.VM  32, 64  1-3 <CPL S   N   N    S   N   0   S   N     S   S   N   S   S   S   S   S   S   \n= 0)           32, 64  1-3 \u2265CPL S   N   N    S   N   0   S   N     S   S   S   S   S   S   S   S   S   \nVirtual-8086   16      3   0-2  X   X   X    X   X   X   X   X     X   X   X   X   X   X   X   X   X   1     \n(CR0.PE = 1    16      3   3    N   N   N    N   N   0   S   N     S   S   S   S   S   S   S   S   S   \nEFLAGS.VM = 1  32      3   0-2  X   X   X    X   X   X   X   X     X   X   X   X   X   X   X   X   X   1     \nCR4.VME = 0)   32      3   3    S   N   N    S   N   0   S   N     S   S   S   S   S   S   S   S   S   \nVME (CR0.PE =  16      3   0-2  N/X N/X SV/X N/X N/X 0/X S/X N/X   S/X S/X N/X S/X S/X S/X S/X S/X S/X 2,3   \n1 EFLAGS.VM =  16      3   3    N   N   N    N   N   0   S   N     S   S   S   S   S   S   S   S   S   \n1 CR4.VME = 1) 32      3   0-2  X   X   X    X   X   X   X   X     X   X   X   X   X   X   X   X   X   1     \n               32      3   3    S   N   N    S   N   0   S   N     S   S   S   S   S   S   S   S   S   \n\n   Table 4-16. Effect of POPF/POPFD on the EFLAGS Register\n\n     1. #GP fault - no flag update\n\n     2. #GP fault with no flag update if VIP=1 in EFLAGS register and IF=1 in\n     FLAGS value on stack\n\n     3. #GP fault with no flag update if TF=1 in FLAGS value on stack\n\n   Key\n   S  Updated from stack                              \n   SV Updated from IF (bit 9) in FLAGS value on stack \n   N  No change in value                              \n   X  No EFLAGS update                                \n   0  Value is cleared                                \n\nFlags Affected \u00b6\n\n   All flags may be affected; see the Operation section for details.\n"],
	["vfmaddsub132pd:vfmaddsub213pd:vfmaddsub231pd", "              VFMADDSUB132PD/VFMADDSUB213PD/VFMADDSUB231PD \u2014 Fused\n   Multiply-AlternatingAdd/Subtract of Packed Double Precision Floating-Point\n                                     Values\n\n                                  64/32 Bit CPUID                             \n   Opcode/Instruction       Op/En Mode      Feature  Description\n                                  Support   Flag     \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 96 /r                          precision floating-point \n   VFMADDSUB132PD xmm1,     A     V/V       FMA      values from xmm1 and     \n   xmm2, xmm3/m128                                   xmm3/mem, add/subtract   \n                                                     elements in xmm2 and put \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 A6 /r                          precision floating-point \n   VFMADDSUB213PD xmm1,     A     V/V       FMA      values from xmm1 and     \n   xmm2, xmm3/m128                                   xmm2, add/subtract       \n                                                     elements in xmm3/mem and \n                                                     put result in xmm1.      \n                                                     Multiply packed double   \n   VEX.128.66.0F38.W1 B6 /r                          precision floating-point \n   VFMADDSUB231PD xmm1,     A     V/V       FMA      values from xmm2 and     \n   xmm2, xmm3/m128                                   xmm3/mem, add/subtract   \n                                                     elements in xmm1 and put \n                                                     result in xmm1.          \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 96 /r                          precision floating-point \n   VFMADDSUB132PD ymm1,     A     V/V       FMA      values from ymm1 and     \n   ymm2, ymm3/m256                                   ymm3/mem, add/subtract   \n                                                     elements in ymm2 and put \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 A6 /r                          precision floating-point \n   VFMADDSUB213PD ymm1,     A     V/V       FMA      values from ymm1 and     \n   ymm2, ymm3/m256                                   ymm2, add/subtract       \n                                                     elements in ymm3/mem and \n                                                     put result in ymm1.      \n                                                     Multiply packed double   \n   VEX.256.66.0F38.W1 B6 /r                          precision floating-point \n   VFMADDSUB231PD ymm1,     A     V/V       FMA      values from ymm2 and     \n   ymm2, ymm3/m256                                   ymm3/mem, add/subtract   \n                                                     elements in ymm1 and put \n                                                     result in ymm1.          \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 A6                            values from xmm1 and     \n   /r VFMADDSUB213PD xmm1   B     V/V       AVX512VL xmm2, add/subtract       \n   {k1}{z}, xmm2,                           AVX512F  elements in              \n   xmm3/m128/m64bcst                                 xmm3/m128/m64bcst and    \n                                                     put result in xmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 B6                            values from xmm2 and     \n   /r VFMADDSUB231PD xmm1   B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm2,                           AVX512F  add/subtract elements in \n   xmm3/m128/m64bcst                                 xmm1 and put result in   \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.128.66.0F38.W1 96                            values from xmm1 and     \n   /r VFMADDSUB132PD xmm1   B     V/V       AVX512VL xmm3/m128/m64bcst,       \n   {k1}{z}, xmm2,                           AVX512F  add/subtract elements in \n   xmm3/m128/m64bcst                                 xmm2 and put result in   \n                                                     xmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 A6                            values from ymm1 and     \n   /r VFMADDSUB213PD ymm1   B     V/V       AVX512VL ymm2, add/subtract       \n   {k1}{z}, ymm2,                           AVX512F  elements in              \n   ymm3/m256/m64bcst                                 ymm3/m256/m64bcst and    \n                                                     put result in ymm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 B6                            values from ymm2 and     \n   /r VFMADDSUB231PD ymm1   B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  add/subtract elements in \n   ymm3/m256/m64bcst                                 ymm1 and put result in   \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.256.66.0F38.W1 96                            values from ymm1 and     \n   /r VFMADDSUB132PD ymm1   B     V/V       AVX512VL ymm3/m256/m64bcst,       \n   {k1}{z}, ymm2,                           AVX512F  add/subtract elements in \n   ymm3/m256/m64bcst                                 ymm2 and put result in   \n                                                     ymm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 A6                            values from zmm1and      \n   /r VFMADDSUB213PD zmm1   B     V/V       AVX512F  zmm2, add/subtract       \n   {k1}{z}, zmm2,                                    elements in              \n   zmm3/m512/m64bcst{er}                             zmm3/m512/m64bcst and    \n                                                     put result in zmm1       \n                                                     subject to writemask k1. \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 B6                            values from zmm2 and     \n   /r VFMADDSUB231PD zmm1   B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    add/subtract elements in \n   zmm3/m512/m64bcst{er}                             zmm1 and put result in   \n                                                     zmm1 subject to          \n                                                     writemask k1.            \n                                                     Multiply packed double   \n                                                     precision floating-point \n   EVEX.512.66.0F38.W1 96                            values from zmm1 and     \n   /r VFMADDSUB132PD zmm1   B     V/V       AVX512F  zmm3/m512/m64bcst,       \n   {k1}{z}, zmm2,                                    add/subtract elements in \n   zmm3/m512/m64bcst{er}                             zmm2 and put result in   \n                                                     zmm1 subject to          \n                                                     writemask k1.            \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   B     Full       ModRM:reg (r, w) EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\n  Description \u00b6\n\n   VFMADDSUB132PD: Multiplies the two, four, or eight packed double precision\n   floating-point values from the first source operand to the two or four\n   packed double precision floating-point values in the third source operand.\n   From the infinite precision intermediate result, adds the odd double\n   precision floating-point elements and subtracts the even double precision\n   floating-point values in the second source operand, performs rounding and\n   stores the resulting two or four packed double precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMADDSUB213PD: Multiplies the two, four, or eight packed double precision\n   floating-point values from the second source operand to the two or four\n   packed double precision floating-point values in the first source operand.\n   From the infinite precision intermediate result, adds the odd double\n   precision floating-point elements and subtracts the even double precision\n   floating-point values in the third source operand, performs rounding and\n   stores the resulting two or four packed double precision floating-point\n   values to the destination operand (first source operand).\n\n   VFMADDSUB231PD: Multiplies the two, four, or eight packed double precision\n   floating-point values from the second source operand to the two or four\n   packed double precision floating-point values in the third source operand.\n   From the infinite precision intermediate result, adds the odd double\n   precision floating-point elements and subtracts the even double precision\n   floating-point values in the first source operand, performs rounding and\n   stores the resulting two or four packed double precision floating-point\n   values to the destination operand (first source operand).\n\n   EVEX encoded versions: The destination operand (also first source operand)\n   and the second source operand are ZMM/YMM/XMM register. The third source\n   operand is a ZMM/YMM/XMM register, a 512/256/128-bit memory location or a\n   512/256/128-bit vector broadcasted from a 64-bit memory location. The\n   destination operand is conditionally updated with write mask k1.\n\n   VEX.256 encoded version: The destination operand (also first source\n   operand) is a YMM register and encoded in reg_field. The second source\n   operand is a YMM register and encoded in VEX.vvvv. The third source\n   operand is a YMM register or a 256-bit memory location and encoded in\n   rm_field.\n\n   VEX.128 encoded version: The destination operand (also first source\n   operand) is a XMM register and encoded in reg_field. The second source\n   operand is a XMM register and encoded in VEX.vvvv. The third source\n   operand is a XMM register or a 128-bit memory location and encoded in\n   rm_field. The upper 128 bits of the YMM destination register are zeroed.\n\n   Compiler tools may optionally support a complementary mnemonic for each\n   instruction mnemonic listed in the opcode/instruction column of the\n   summary table. The behavior of the complementary mnemonic in situations\n   involving NANs are governed by the definition of the instruction mnemonic\n   defined in the opcode/instruction column.\n"],
	["subps", "         SUBPS \u2014 Subtract Packed Single Precision Floating-Point Values\n\n                                  64/32 bit CPUID                             \n   Opcode/Instruction      Op/E n Mode      Feature  Description\n                                  Support   Flag     \n                                                     Subtract packed single   \n   NP 0F 5C /r SUBPS xmm1,                           precision floating-point \n   xmm2/m128               A      V/V       SSE      values in xmm2/mem from  \n                                                     xmm1 and store result in \n                                                     xmm1.                    \n                                                     Subtract packed single   \n   VEX.128.0F.WIG 5C /r                              precision floating-point \n   VSUBPS xmm1,xmm2,       B      V/V       AVX      values in xmm3/mem from  \n   xmm3/m128                                         xmm2 and stores result   \n                                                     in xmm1.                 \n                                                     Subtract packed single   \n   VEX.256.0F.WIG 5C /r                              precision floating-point \n   VSUBPS ymm1, ymm2,      B      V/V       AVX      values in ymm3/mem from  \n   ymm3/m256                                         ymm2 and stores result   \n                                                     in ymm1.                 \n                                                     Subtract packed single   \n                                                     precision floating-point \n   EVEX.128.0F.W0 5C /r                     AVX512VL values from              \n   VSUBPS xmm1 {k1}{z},    C      V/V       AVX512F  xmm3/m128/m32bcst to     \n   xmm2, xmm3/m128/m32bcst                           xmm2 and stores result   \n                                                     in xmm1 with writemask   \n                                                     k1.                      \n                                                     Subtract packed single   \n                                                     precision floating-point \n   EVEX.256.0F.W0 5C /r                     AVX512VL values from              \n   VSUBPS ymm1 {k1}{z},    C      V/V       AVX512F  ymm3/m256/m32bcst to     \n   ymm2, ymm3/m256/m32bcst                           ymm2 and stores result   \n                                                     in ymm1 with writemask   \n                                                     k1.                      \n                                                     Subtract packed single   \n   EVEX.512.0F.W0 5C /r                              precision floating-point \n   VSUBPS zmm1 {k1}{z},                              values in                \n   zmm2,                   C      V/V       AVX512F  zmm3/m512/m32bcst from   \n   zmm3/m512/m32bcst{er}                             zmm2 and stores result   \n                                                     in zmm1 with writemask   \n                                                     k1.                      \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1        Operand 2     Operand 3     Operand 4 \n   A     N/A        ModRM:reg (r, w) ModRM:r/m (r) N/A           N/A       \n   B     N/A        ModRM:reg (w)    VEX.vvvv (r)  ModRM:r/m (r) N/A       \n   C     Full       ModRM:reg (w)    EVEX.vvvv (r) ModRM:r/m (r) N/A       \n\nDescription \u00b6\n\n   Performs a SIMD subtract of the packed single precision floating-point\n   values in the second Source operand from the First Source operand, and\n   stores the packed single precision floating-point results in the\n   destination operand.\n\n   VEX.128 and EVEX.128 encoded versions: The second source operand is an XMM\n   register or an 128-bit memory location. The first source operand and\n   destination operands are XMM registers. Bits (MAXVL-1:128) of the\n   corresponding destination register are zeroed.\n\n   VEX.256 and EVEX.256 encoded versions: The second source operand is an YMM\n   register or an 256-bit memory location. The first source operand and\n   destination operands are YMM registers. Bits (MAXVL-1:256) of the\n   corresponding destination register are zeroed.\n\n   EVEX.512 encoded version: The second source operand is a ZMM register, a\n   512-bit memory location or a 512-bit vector broadcasted from a 32-bit\n   memory location. The first source operand and destination operands are ZMM\n   registers. The destination operand is conditionally updated according to\n   the writemask.\n\n   128-bit Legacy SSE version: The second source can be an XMM register or an\n   128-bit memory location. The destination is not distinct from the first\n   source XMM register and the upper Bits (MAXVL-1:128) of the corresponding\n   register destination are unmodified.\n"],
	["vrsqrt28sd", "   VRSQRT28SD \u2014 Approximation to the Reciprocal Square Root of Scalar Double\n       PrecisionFloating-Point Value With Less Than 2^-28 Relative Error\n\n                                 64/32 bit CPUID                              \n   Opcode/Instruction      Op/En Mode      Feature  Description\n                                 Support   Flag     \n                                                    Computes approximate      \n                                                    reciprocal square root    \n                                                    (<2^-28 relative error)   \n                                                    of the scalar double      \n   EVEX.LLIG.66.0F38.W1 CD                          precision floating-point  \n   /r VRSQRT28SD xmm1                               value from xmm3/m64 and   \n   {k1}{z}, xmm2, xmm3/m64 A     V/V       AVX512ER stores result in xmm1with \n   {sae}                                            writemask k1. Also, upper \n                                                    double precision          \n                                                    floating-point value      \n                                                    (bits[127:64]) from xmm2  \n                                                    is copied to              \n                                                    xmm1[127:64].             \n\nInstruction Operand Encoding \u00b6\n\n   Op/En Tuple Type Operand 1 Operand 2 Operand 3 Operand 4      \n   A Tuple1 Scalar ModRM:reg (w) EVEX.vvvv (r) ModRM:r/m (r) N/A \n\n  Description \u00b6\n\n   Computes the reciprocal square root of the low float64 value in the second\n   source operand (the third operand) and store the result to the destination\n   operand (the first operand). The approximate reciprocal square root is\n   evaluated with less than 2^-28 of maximum relative error. The result is\n   written into the low float64 element of xmm1 according to the writemask\n   k1. Bits 127:64 of the destination is copied from the corresponding bits\n   of the first source operand (the second operand).\n\n   If any source element is NaN, the quietized NaN source value is returned\n   for that element. Negative (non-zero) source numbers, as well as -\u221e,\n   return the canonical NaN and set the Invalid Flag (#I).\n\n   A value of -0 must return -\u221e and set the DivByZero flags (#Z). Negative\n   numbers should return NaN and set the Invalid flag (#I). Note however that\n   the instruction flush input denormals to zero of the same sign, so\n   negative denormals return -\u221e and set the DivByZero flag.\n\n   The first source operand is an XMM register. The second source operand is\n   an XMM register or a 64-bit memory location. The destination operand is a\n   XMM register.\n\n  A numerically exact implementation of VRSQRT28xx can be found at\n  https://software.intel.com/en-us/arti- \u00b6\n\n  cles/reference-implementations-for-IA-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.\n  \u00b6\n"],
]

def lookup_sdm_entry(name):
	for entry in sdm:
		if name in entry[0].lower().split(":"):
			return entry[1]
	return None

async def sdm_command(interaction: discord.Interaction, instruction: str):
	try:
		description = lookup_sdm_entry(instruction.lower())
		if description == None:
			await interaction.response.send_message("No sdm entry found.", ephemeral=True)
			return
		file = helpers.text_to_file(description, filename="sdm-entry.txt")
		await interaction.response.send_message(file=file, ephemeral=True)
	except:
		await interaction.response.send_message("An unknown error occured.", ephemeral=True)

module = {
	"type": "command",
	"name": "sdm",
	"description": "Nab an entry from the Intel Software Developer's Manual",
	"callback": sdm_command
}
